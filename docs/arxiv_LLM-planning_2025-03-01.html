<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='UTF-8'>
<title>LLM-planning - 2025-03-01</title>
<link href='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css' rel='stylesheet'>
<link href='https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap' rel='stylesheet'>
<link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css'>
<style>
body {
font-family: 'Roboto', sans-serif;
background-color: #f5f7fa;
padding: 20px;
}
.card {
    border-radius: 10px;
    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
}
.card-title {
    font-weight: 700;
}
.card:hover {
    transform: scale(1.02);
    transition: 0.3s ease-in-out;
}
</style>
</head>
<body>
<div class='container'>
<h1 class='text-center my-4'><i class='fas fa-book'></i>LLM-planning - 2025-03-01</h1>
<div class='row'>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.20284v1' target='_blank'>Evaluating Human Trust in LLM-Based Planners: A Preliminary Study</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shenghui Chen, Yunhao Yang, Kayla Boggess, Seongkook Heo, Lu Feng, Ufuk Topcu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-27 17:10:52</h6>
<p class='card-text'>Large Language Models (LLMs) are increasingly used for planning tasks,
offering unique capabilities not found in classical planners such as generating
explanations and iterative refinement. However, trust--a critical factor in the
adoption of planning systems--remains underexplored in the context of LLM-based
planning tasks. This study bridges this gap by comparing human trust in
LLM-based planners with classical planners through a user study in a Planning
Domain Definition Language (PDDL) domain. Combining subjective measures, such
as trust questionnaires, with objective metrics like evaluation accuracy, our
findings reveal that correctness is the primary driver of trust and
performance. Explanations provided by the LLM improved evaluation accuracy but
had limited impact on trust, while plan refinement showed potential for
increasing trust without significantly enhancing evaluation accuracy.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.20238v1' target='_blank'>FINEREASON: Evaluating and Improving LLMs' Deliberate Reasoning through
  Reflective Puzzle Solving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Guizhen Chen, Weiwen Xu, Hao Zhang, Hou Pong Chan, Chaoqun Liu, Lidong Bing, Deli Zhao, Anh Tuan Luu, Yu Rong</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-27 16:23:25</h6>
<p class='card-text'>Many challenging reasoning tasks require not just rapid, intuitive responses,
but a more deliberate, multi-step approach. Recent progress in large language
models (LLMs) highlights an important shift from the "System 1" way of quick
reactions to the "System 2" style of reflection-and-correction problem solving.
However, current benchmarks heavily rely on the final-answer accuracy, leaving
much of a model's intermediate reasoning steps unexamined. This fails to assess
the model's ability to reflect and rectify mistakes within the reasoning
process. To bridge this gap, we introduce FINEREASON, a logic-puzzle benchmark
for fine-grained evaluation of LLMs' reasoning capabilities. Each puzzle can be
decomposed into atomic steps, making it ideal for rigorous validation of
intermediate correctness. Building on this, we introduce two tasks: state
checking, and state transition, for a comprehensive evaluation of how models
assess the current situation and plan the next move. To support broader
research, we also provide a puzzle training set aimed at enhancing performance
on general mathematical tasks. We show that models trained on our state
checking and transition data demonstrate gains in math reasoning by up to 5.1%
on GSM8K.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.20175v1' target='_blank'>An Extensive Evaluation of PDDL Capabilities in off-the-shelf LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kaustubh Vyas, Damien Graux, Sébastien Montella, Pavlos Vougiouklis, Ruofei Lai, Keshuang Li, Yang Ren, Jeff Z. Pan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-27 15:13:07</h6>
<p class='card-text'>In recent advancements, large language models (LLMs) have exhibited
proficiency in code generation and chain-of-thought reasoning, laying the
groundwork for tackling automatic formal planning tasks. This study evaluates
the potential of LLMs to understand and generate Planning Domain Definition
Language (PDDL), an essential representation in artificial intelligence
planning. We conduct an extensive analysis across 20 distinct models spanning 7
major LLM families, both commercial and open-source. Our comprehensive
evaluation sheds light on the zero-shot LLM capabilities of parsing,
generating, and reasoning with PDDL. Our findings indicate that while some
models demonstrate notable effectiveness in handling PDDL, others pose
limitations in more complex scenarios requiring nuanced planning knowledge.
These results highlight the promise and current limitations of LLMs in formal
planning tasks, offering insights into their application and guiding future
efforts in AI-driven planning paradigms.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.19805v1' target='_blank'>Implicit Search via Discrete Diffusion: A Study on Chess</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiacheng Ye, Zhenyu Wu, Jiahui Gao, Zhiyong Wu, Xin Jiang, Zhenguo Li, Lingpeng Kong</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-27 06:25:15</h6>
<p class='card-text'>In the post-AlphaGo era, there has been a renewed interest in search
techniques such as Monte Carlo Tree Search (MCTS), particularly in their
application to Large Language Models (LLMs). This renewed attention is driven
by the recognition that current next-token prediction models often lack the
ability for long-term planning. Is it possible to instill search-like abilities
within the models to enhance their planning abilities without relying on
explicit search? We propose DiffuSearch , a model that does \textit{implicit
search} by looking into the future world via discrete diffusion modeling. We
instantiate DiffuSearch on a classical board game, Chess, where explicit search
is known to be essential. Through extensive controlled experiments, we show
DiffuSearch outperforms both the searchless and explicit search-enhanced
policies. Specifically, DiffuSearch outperforms the one-step policy by 19.2%
and the MCTS-enhanced policy by 14% on action accuracy. Furthermore,
DiffuSearch demonstrates a notable 30% enhancement in puzzle-solving abilities
compared to explicit search-based policies, along with a significant 540 Elo
increase in game-playing strength assessment. These results indicate that
implicit search via discrete diffusion is a viable alternative to explicit
search over a one-step policy. All codes are publicly available at
\href{https://github.com/HKUNLP/DiffuSearch}{https://github.com/HKUNLP/DiffuSearch}.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.19500v1' target='_blank'>Conversational Planning for Personal Plans</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Konstantina Christakopoulou, Iris Qu, John Canny, Andrew Goodridge, Cj Adams, Minmin Chen, Maja Matarić</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-26 19:04:26</h6>
<p class='card-text'>The language generation and reasoning capabilities of large language models
(LLMs) have enabled conversational systems with impressive performance in a
variety of tasks, from code generation, to composing essays, to passing STEM
and legal exams, to a new paradigm for knowledge search. Besides those
short-term use applications, LLMs are increasingly used to help with real-life
goals or tasks that take a long time to complete, involving multiple sessions
across days, weeks, months, or even years. Thus to enable conversational
systems for long term interactions and tasks, we need language-based agents
that can plan for long horizons. Traditionally, such capabilities were
addressed by reinforcement learning agents with hierarchical planning
capabilities. In this work, we explore a novel architecture where the LLM acts
as the meta-controller deciding the agent's next macro-action, and tool use
augmented LLM-based option policies execute the selected macro-action. We
instantiate this framework for a specific set of macro-actions enabling
adaptive planning for users' personal plans through conversation and follow-up
questions collecting user feedback. We show how this paradigm can be applicable
in scenarios ranging from tutoring for academic and non-academic tasks to
conversational coaching for personal health plans.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.19411v1' target='_blank'>Code to Think, Think to Code: A Survey on Code-Enhanced Reasoning and
  Reasoning-Driven Code Intelligence in LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Dayu Yang, Tianyang Liu, Daoan Zhang, Antoine Simoulin, Xiaoyi Liu, Yuwei Cao, Zhaopu Teng, Xin Qian, Grey Yang, Jiebo Luo, Julian McAuley</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-26 18:55:42</h6>
<p class='card-text'>In large language models (LLMs), code and reasoning reinforce each other:
code offers an abstract, modular, and logic-driven structure that supports
reasoning, while reasoning translates high-level goals into smaller, executable
steps that drive more advanced code intelligence. In this study, we examine how
code serves as a structured medium for enhancing reasoning: it provides
verifiable execution paths, enforces logical decomposition, and enables runtime
validation. We also explore how improvements in reasoning have transformed code
intelligence from basic completion to advanced capabilities, enabling models to
address complex software engineering tasks through planning and debugging.
Finally, we identify key challenges and propose future research directions to
strengthen this synergy, ultimately improving LLM's performance in both areas.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.19400v1' target='_blank'>TheoremExplainAgent: Towards Multimodal Explanations for LLM Theorem
  Understanding</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Max Ku, Thomas Chong, Jonathan Leung, Krish Shah, Alvin Yu, Wenhu Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-26 18:50:09</h6>
<p class='card-text'>Understanding domain-specific theorems often requires more than just
text-based reasoning; effective communication through structured visual
explanations is crucial for deeper comprehension. While large language models
(LLMs) demonstrate strong performance in text-based theorem reasoning, their
ability to generate coherent and pedagogically meaningful visual explanations
remains an open challenge. In this work, we introduce TheoremExplainAgent, an
agentic approach for generating long-form theorem explanation videos (over 5
minutes) using Manim animations. To systematically evaluate multimodal theorem
explanations, we propose TheoremExplainBench, a benchmark covering 240 theorems
across multiple STEM disciplines, along with 5 automated evaluation metrics.
Our results reveal that agentic planning is essential for generating detailed
long-form videos, and the o3-mini agent achieves a success rate of 93.8% and an
overall score of 0.77. However, our quantitative and qualitative studies show
that most of the videos produced exhibit minor issues with visual element
layout. Furthermore, multimodal explanations expose deeper reasoning flaws that
text-based explanations fail to reveal, highlighting the importance of
multimodal explanations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.19295v1' target='_blank'>Complex LLM Planning via Automated Heuristics Discovery</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hongyi Ling, Shubham Parashar, Sambhav Khurana, Blake Olson, Anwesha Basu, Gaurangi Sinha, Zhengzhong Tu, James Caverlee, Shuiwang Ji</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-26 16:52:31</h6>
<p class='card-text'>We consider enhancing large language models (LLMs) for complex planning
tasks. While existing methods allow LLMs to explore intermediate steps to make
plans, they either depend on unreliable self-verification or external verifiers
to evaluate these steps, which demand significant data and computations. Here,
we propose automated heuristics discovery (AutoHD), a novel approach that
enables LLMs to explicitly generate heuristic functions to guide inference-time
search, allowing accurate evaluation of intermediate states. These heuristic
functions are further refined through a heuristic evolution process, improving
their robustness and effectiveness. Our proposed method requires no additional
model training or fine-tuning, and the explicit definition of heuristic
functions generated by the LLMs provides interpretability and insights into the
reasoning process. Extensive experiments across diverse benchmarks demonstrate
significant gains over multiple baselines, including nearly twice the accuracy
on some datasets, establishing our approach as a reliable and interpretable
solution for complex planning tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.19135v1' target='_blank'>A Temporal Planning Framework for Multi-Agent Systems via LLM-Aided
  Knowledge Base Management</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Enrico Saccon, Ahmet Tikna, Davide De Martini, Edoardo Lamon, Luigi Palopoli, Marco Roveri</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-26 13:51:28</h6>
<p class='card-text'>This paper presents a novel framework, called PLANTOR (PLanning with Natural
language for Task-Oriented Robots), that integrates Large Language Models
(LLMs) with Prolog-based knowledge management and planning for multi-robot
tasks. The system employs a two-phase generation of a robot-oriented knowledge
base, ensuring reusability and compositional reasoning, as well as a three-step
planning procedure that handles temporal dependencies, resource constraints,
and parallel task execution via mixed-integer linear programming. The final
plan is converted into a Behaviour Tree for direct use in ROS2. We tested the
framework in multi-robot assembly tasks within a block world and an
arch-building scenario. Results demonstrate that LLMs can produce accurate
knowledge bases with modest human feedback, while Prolog guarantees formal
correctness and explainability. This approach underscores the potential of LLM
integration for advanced robotics tasks requiring flexible, scalable, and
human-understandable planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.19103v1' target='_blank'>LongEval: A Comprehensive Analysis of Long-Text Generation Through a
  Plan-based Paradigm</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Siwei Wu, Yizhi Li, Xingwei Qu, Rishi Ravikumar, Yucheng Li, Tyler Loakman Shanghaoran Quan Xiaoyong Wei, Riza Batista-Navarro, Chenghua Lin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-26 12:46:36</h6>
<p class='card-text'>Large Language Models (LLMs) have achieved remarkable success in various
natural language processing tasks, yet their ability to generate long-form
content remains poorly understood and evaluated. Our analysis reveals that
current LLMs struggle with length requirements and information density in
long-text generation, with performance deteriorating as text length increases.
To quantitively locate such a performance degradation and provide further
insights on model development, we present LongEval, a benchmark that evaluates
long-text generation through both direct and plan-based generation paradigms,
inspired by cognitive and linguistic writing models. The comprehensive
experiments in this work reveal interesting findings such as that while model
size correlates with generation ability, the small-scale model (e.g.,
LongWriter), well-trained on long texts, has comparable performance. All code
and datasets are released in https://github.com/Wusiwei0410/LongEval.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.18836v1' target='_blank'>REALM-Bench: A Real-World Planning Benchmark for LLMs and Multi-Agent
  Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Longling Geng, Edward Y. Chang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-26 05:24:22</h6>
<p class='card-text'>This benchmark suite provides a comprehensive evaluation framework for
assessing both individual LLMs and multi-agent systems in real-world planning
scenarios. The suite encompasses eleven designed problems that progress from
basic to highly complex, incorporating key aspects such as multi-agent
coordination, inter-agent dependencies, and dynamic environmental disruptions.
Each problem can be scaled along three dimensions: the number of parallel
planning threads, the complexity of inter-dependencies, and the frequency of
unexpected disruptions requiring real-time adaptation. The benchmark includes
detailed specifications, evaluation metrics, and baseline implementations using
contemporary frameworks like LangGraph, enabling rigorous testing of both
single-agent and multi-agent planning capabilities. Through standardized
evaluation criteria and scalable complexity, this benchmark aims to drive
progress in developing more robust and adaptable AI planning systems for
real-world applications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.18822v1' target='_blank'>Data-Efficient Multi-Agent Spatial Planning with LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Huangyuan Su, Aaron Walsman, Daniel Garces, Sham Kakade, Stephanie Gil</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-26 04:53:07</h6>
<p class='card-text'>In this project, our goal is to determine how to leverage the world-knowledge
of pretrained large language models for efficient and robust learning in
multiagent decision making. We examine this in a taxi routing and assignment
problem where agents must decide how to best pick up passengers in order to
minimize overall waiting time. While this problem is situated on a graphical
road network, we show that with the proper prompting zero-shot performance is
quite strong on this task. Furthermore, with limited fine-tuning along with the
one-at-a-time rollout algorithm for look ahead, LLMs can out-compete existing
approaches with 50 times fewer environmental interactions. We also explore the
benefits of various linguistic prompting approaches and show that including
certain easy-to-compute information in the prompt significantly improves
performance. Finally, we highlight the LLM's built-in semantic understanding,
showing its ability to adapt to environmental factors through simple prompts.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.18712v1' target='_blank'>TrajLLM: A Modular LLM-Enhanced Agent-Based Framework for Realistic
  Human Trajectory Simulation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chenlu Ju, Jiaxin Liu, Shobhit Sinha, Hao Xue, Flora Salim</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-26 00:13:26</h6>
<p class='card-text'>This work leverages Large Language Models (LLMs) to simulate human mobility,
addressing challenges like high costs and privacy concerns in traditional
models. Our hierarchical framework integrates persona generation, activity
selection, and destination prediction, using real-world demographic and
psychological data to create realistic movement patterns. Both physical models
and language models are employed to explore and demonstrate different
methodologies for human mobility simulation. By structuring data with
summarization and weighted density metrics, the system ensures scalable memory
management while retaining actionable insights. Preliminary results indicate
that LLM-driven simulations align with observed real-world patterns, offering
scalable, interpretable insights for social problems such as urban planning,
traffic management, and public health. The framework's ability to dynamically
generate personas and activities enables it to provide adaptable and realistic
daily routines. This study demonstrates the transformative potential of LLMs in
advancing mobility modeling for societal and urban applications. The source
code and interactive demo for our framework are available at
https://github.com/cju0/TrajLLM.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.18690v1' target='_blank'>Hybrid Voting-Based Task Assignment in Role-Playing Games</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Daniel Weiner, Raj Korpan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-25 22:58:21</h6>
<p class='card-text'>In role-playing games (RPGs), the level of immersion is critical-especially
when an in-game agent conveys tasks, hints, or ideas to the player. For an
agent to accurately interpret the player's emotional state and contextual
nuances, a foundational level of understanding is required, which can be
achieved using a Large Language Model (LLM). Maintaining the LLM's focus across
multiple context changes, however, necessitates a more robust approach, such as
integrating the LLM with a dedicated task allocation model to guide its
performance throughout gameplay. In response to this need, we introduce
Voting-Based Task Assignment (VBTA), a framework inspired by human reasoning in
task allocation and completion. VBTA assigns capability profiles to agents and
task descriptions to tasks, then generates a suitability matrix that quantifies
the alignment between an agent's abilities and a task's requirements.
Leveraging six distinct voting methods, a pre-trained LLM, and integrating
conflict-based search (CBS) for path planning, VBTA efficiently identifies and
assigns the most suitable agent to each task. While existing approaches focus
on generating individual aspects of gameplay, such as single quests, or combat
encounters, our method shows promise when generating both unique combat
encounters and narratives because of its generalizable nature.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.18641v1' target='_blank'>WhatELSE: Shaping Narrative Spaces at Configurable Level of Abstraction
  for AI-bridged Interactive Storytelling</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhuoran Lu, Qian Zhou, Yi Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-25 21:02:15</h6>
<p class='card-text'>Generative AI significantly enhances player agency in interactive narratives
(IN) by enabling just-in-time content generation that adapts to player actions.
While delegating generation to AI makes IN more interactive, it becomes
challenging for authors to control the space of possible narratives - within
which the final story experienced by the player emerges from their interaction
with AI. In this paper, we present WhatELSE, an AI-bridged IN authoring system
that creates narrative possibility spaces from example stories. WhatELSE
provides three views (narrative pivot, outline, and variants) to help authors
understand the narrative space and corresponding tools leveraging linguistic
abstraction to control the boundaries of the narrative space. Taking innovative
LLM-based narrative planning approaches, WhatELSE further unfolds the narrative
space into executable game events. Through a user study (N=12) and technical
evaluations, we found that WhatELSE enables authors to perceive and edit the
narrative space and generates engaging interactive narratives at play-time.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.18387v2' target='_blank'>How Far are LLMs from Real Search? A Comprehensive Study on Efficiency,
  Completeness, and Inherent Capabilities</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Minhua Lin, Hui Liu, Xianfeng Tang, Jingying Zeng, Zhenwei Dai, Chen Luo, Zheng Li, Xiang Zhang, Qi He, Suhang Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-25 17:30:40</h6>
<p class='card-text'>Search plays a fundamental role in problem-solving across various domains,
with most real-world decision-making problems being solvable through systematic
search. Drawing inspiration from recent discussions on search and learning, we
systematically explore the complementary relationship between search and Large
Language Models (LLMs) from three perspectives. First, we analyze how learning
can enhance search efficiency and propose Search via Learning (SeaL), a
framework that leverages LLMs for effective and efficient search. Second, we
further extend SeaL to SeaL-C to ensure rigorous completeness during search.
Our evaluation across three real-world planning tasks demonstrates that SeaL
achieves near-perfect accuracy while reducing search spaces by up to 99.1%
compared to traditional approaches. Finally, we explore how far LLMs are from
real search by investigating whether they can develop search capabilities
independently. Our analysis reveals that while current LLMs struggle with
efficient search in complex problems, incorporating systematic search
strategies significantly enhances their problem-solving capabilities. These
findings not only validate the effectiveness of our approach but also highlight
the need for improving LLMs' search abilities for real-world applications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.18228v1' target='_blank'>Debt Collection Negotiations with Large Language Models: An Evaluation
  System and Optimizing Decision Making with Multi-Agent</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xiaofeng Wang, Zhixin Zhang, Jinguang Zheng, Yiming Ai, Rui Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-25 14:13:03</h6>
<p class='card-text'>Debt collection negotiations (DCN) are vital for managing non-performing
loans (NPLs) and reducing creditor losses. Traditional methods are
labor-intensive, while large language models (LLMs) offer promising automation
potential. However, prior systems lacked dynamic negotiation and real-time
decision-making capabilities. This paper explores LLMs in automating DCN and
proposes a novel evaluation framework with 13 metrics across 4 aspects. Our
experiments reveal that LLMs tend to over-concede compared to human
negotiators. To address this, we propose the Multi-Agent Debt Negotiation
(MADeN) framework, incorporating planning and judging modules to improve
decision rationality. We also apply post-training techniques, including DPO
with rejection sampling, to optimize performance. Our studies provide valuable
insights for practitioners and researchers seeking to enhance efficiency and
outcomes in this domain.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.18139v1' target='_blank'>LevelRAG: Enhancing Retrieval-Augmented Generation with Multi-hop Logic
  Planning over Rewriting Augmented Searchers</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhuocheng Zhang, Yang Feng, Min Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-25 12:09:16</h6>
<p class='card-text'>Retrieval-Augmented Generation (RAG) is a crucial method for mitigating
hallucinations in Large Language Models (LLMs) and integrating external
knowledge into their responses. Existing RAG methods typically employ query
rewriting to clarify the user intent and manage multi-hop logic, while using
hybrid retrieval to expand search scope. However, the tight coupling of query
rewriting to the dense retriever limits its compatibility with hybrid
retrieval, impeding further RAG performance improvements. To address this
challenge, we introduce a high-level searcher that decomposes complex queries
into atomic queries, independent of any retriever-specific optimizations.
Additionally, to harness the strengths of sparse retrievers for precise keyword
retrieval, we have developed a new sparse searcher that employs Lucene syntax
to enhance retrieval accuracy.Alongside web and dense searchers, these
components seamlessly collaborate within our proposed method,
\textbf{LevelRAG}. In LevelRAG, the high-level searcher orchestrates the
retrieval logic, while the low-level searchers (sparse, web, and dense) refine
the queries for optimal retrieval. This approach enhances both the completeness
and accuracy of the retrieval process, overcoming challenges associated with
current query rewriting techniques in hybrid retrieval scenarios. Empirical
experiments conducted on five datasets, encompassing both single-hop and
multi-hop question answering tasks, demonstrate the superior performance of
LevelRAG compared to existing RAG methods. Notably, LevelRAG outperforms the
state-of-the-art proprietary model, GPT4o, underscoring its effectiveness and
potential impact on the RAG field.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.18072v1' target='_blank'>MRBTP: Efficient Multi-Robot Behavior Tree Planning and Collaboration</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yishuai Cai, Xinglin Chen, Zhongxuan Cai, Yunxin Mao, Minglong Li, Wenjing Yang, Ji Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-25 10:39:28</h6>
<p class='card-text'>Multi-robot task planning and collaboration are critical challenges in
robotics. While Behavior Trees (BTs) have been established as a popular control
architecture and are plannable for a single robot, the development of effective
multi-robot BT planning algorithms remains challenging due to the complexity of
coordinating diverse action spaces. We propose the Multi-Robot Behavior Tree
Planning (MRBTP) algorithm, with theoretical guarantees of both soundness and
completeness. MRBTP features cross-tree expansion to coordinate heterogeneous
actions across different BTs to achieve the team's goal. For homogeneous
actions, we retain backup structures among BTs to ensure robustness and prevent
redundant execution through intention sharing. While MRBTP is capable of
generating BTs for both homogeneous and heterogeneous robot teams, its
efficiency can be further improved. We then propose an optional plugin for
MRBTP when Large Language Models (LLMs) are available to reason goal-related
actions for each robot. These relevant actions can be pre-planned to form
long-horizon subtrees, significantly enhancing the planning speed and
collaboration efficiency of MRBTP. We evaluate our algorithm in warehouse
management and everyday service scenarios. Results demonstrate MRBTP's
robustness and execution efficiency under varying settings, as well as the
ability of the pre-trained LLM to generate effective task-specific subtrees for
MRBTP.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.17910v1' target='_blank'>Scaling LLM Pre-training with Vocabulary Curriculum</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Fangyuan Yu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-25 07:18:29</h6>
<p class='card-text'>Modern language models rely on static vocabularies, fixed before pretraining,
in contrast to the adaptive vocabulary acquisition observed in human language
learning. To bridge this gap, we introduce vocabulary curriculum learning, an
approach that improves pretraining efficiency with log-linear scaling gains
relative to vocabulary size. Our method alternates between entropy-guided
vocabulary expansion and model optimization, enabling models to learn
transferable representations across diverse tokenization granularities. This
approach naturally gives rise to an optimal computation allocation pattern:
longer tokens capture predictable content, while shorter tokens focus on more
complex, harder-to-predict contexts. Experiments on small-scale GPT models
demonstrate improved scaling efficiency, reinforcing the effectiveness of
dynamic tokenization. We release our code to support further research and plan
to extend our experiments to larger models and diverse domains.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.17898v1' target='_blank'>VeriPlan: Integrating Formal Verification and LLMs into End-User
  Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Christine Lee, David Porfirio, Xinyu Jessica Wang, Kevin Zhao, Bilge Mutlu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-25 06:53:00</h6>
<p class='card-text'>Automated planning is traditionally the domain of experts, utilized in fields
like manufacturing and healthcare with the aid of expert planning tools. Recent
advancements in LLMs have made planning more accessible to everyday users due
to their potential to assist users with complex planning tasks. However, LLMs
face several application challenges within end-user planning, including
consistency, accuracy, and user trust issues. This paper introduces VeriPlan, a
system that applies formal verification techniques, specifically model
checking, to enhance the reliability and flexibility of LLMs for end-user
planning. In addition to the LLM planner, VeriPlan includes three additional
core features -- a rule translator, flexibility sliders, and a model checker --
that engage users in the verification process. Through a user study (n=12), we
evaluate VeriPlan, demonstrating improvements in the perceived quality,
usability, and user satisfaction of LLMs. Our work shows the effective
integration of formal verification and user-control features with LLMs for
end-user planning tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.17132v1' target='_blank'>Applications of Large Models in Medicine</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:YunHe Su, Zhengyang Lu, Junhui Liu, Ke Pang, Haoran Dai, Sa Liu Yuxin Jia, Lujia Ge, Jing-min Yang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-24 13:21:30</h6>
<p class='card-text'>This paper explores the advancements and applications of large-scale models
in the medical field, with a particular focus on Medical Large Models (MedLMs).
These models, encompassing Large Language Models (LLMs), Vision Models, 3D
Large Models, and Multimodal Models, are revolutionizing healthcare by
enhancing disease prediction, diagnostic assistance, personalized treatment
planning, and drug discovery. The integration of graph neural networks in
medical knowledge graphs and drug discovery highlights the potential of Large
Graph Models (LGMs) in understanding complex biomedical relationships. The
study also emphasizes the transformative role of Vision-Language Models (VLMs)
and 3D Large Models in medical image analysis, anatomical modeling, and
prosthetic design. Despite the challenges, these technologies are setting new
benchmarks in medical innovation, improving diagnostic accuracy, and paving the
way for personalized healthcare solutions. This paper aims to provide a
comprehensive overview of the current state and future directions of large
models in medicine, underscoring their significance in advancing global health.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.16804v1' target='_blank'>Multi-Agent Autonomous Driving Systems with Large Language Models: A
  Survey of Recent Advances</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yaozu Wu, Dongyuan Li, Yankai Chen, Renhe Jiang, Henry Peng Zou, Liancheng Fang, Zhen Wang, Philip S. Yu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-24 03:26:13</h6>
<p class='card-text'>Autonomous Driving Systems (ADSs) are revolutionizing transportation by
reducing human intervention, improving operational efficiency, and enhancing
safety. Large Language Models (LLMs), known for their exceptional planning and
reasoning capabilities, have been integrated into ADSs to assist with driving
decision-making. However, LLM-based single-agent ADSs face three major
challenges: limited perception, insufficient collaboration, and high
computational demands. To address these issues, recent advancements in
LLM-based multi-agent ADSs have focused on improving inter-agent communication
and cooperation. This paper provides a frontier survey of LLM-based multi-agent
ADSs. We begin with a background introduction to related concepts, followed by
a categorization of existing LLM-based approaches based on different agent
interaction modes. We then discuss agent-human interactions in scenarios where
LLM-based agents engage with humans. Finally, we summarize key applications,
datasets, and challenges in this field to support future research
(https://anonymous.4open.science/r/LLM-based_Multi-agent_ADS-3A5C/README.md).</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.16730v1' target='_blank'>RapidPen: Fully Automated IP-to-Shell Penetration Testing with LLM-based
  Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sho Nakatani</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-23 21:57:46</h6>
<p class='card-text'>We present RapidPen, a fully automated penetration testing (pentesting)
framework that addresses
  the challenge of achieving an initial foothold (IP-to-Shell) without human
intervention. Unlike prior
  approaches that focus primarily on post-exploitation or require a
human-in-the-loop, RapidPen
  leverages large language models (LLMs) to autonomously discover and exploit
vulnerabilities, starting from
  a single IP address. By integrating advanced ReAct-style task planning (Re)
with retrieval-augmented
  knowledge bases of successful exploits, along with a command-generation and
direct execution feedback loop
  (Act), RapidPen systematically scans services, identifies viable attack
vectors, and executes targeted
  exploits in a fully automated manner.
  In our evaluation against a vulnerable target from the Hack The Box platform,
RapidPen achieved shell
  access within 200-400 seconds at a per-run cost of approximately \$0.3-\$0.6,
demonstrating a
  60\% success rate when reusing prior "success-case" data. These results
underscore the potential
  of truly autonomous pentesting for both security novices and seasoned
professionals. Organizations
  without dedicated security teams can leverage RapidPen to quickly identify
critical vulnerabilities,
  while expert pentesters can offload repetitive tasks and focus on complex
challenges.
  Ultimately, our work aims to make penetration testing more accessible and
cost-efficient,
  thereby enhancing the overall security posture of modern software ecosystems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.16515v1' target='_blank'>Path Planning using Instruction-Guided Probabilistic Roadmaps</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiaqi Bao, Ryo Yonetani</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-23 09:26:20</h6>
<p class='card-text'>This work presents a novel data-driven path planning algorithm named
Instruction-Guided Probabilistic Roadmap (IG-PRM). Despite the recent
development and widespread use of mobile robot navigation, the safe and
effective travels of mobile robots still require significant engineering effort
to take into account the constraints of robots and their tasks. With IG-PRM, we
aim to address this problem by allowing robot operators to specify such
constraints through natural language instructions, such as ``aim for wider
paths'' or ``mind small gaps''. The key idea is to convert such instructions
into embedding vectors using large-language models (LLMs) and use the vectors
as a condition to predict instruction-guided cost maps from occupancy maps. By
constructing a roadmap based on the predicted costs, we can find
instruction-guided paths via the standard shortest path search. Experimental
results demonstrate the effectiveness of our approach on both synthetic and
real-world indoor navigation environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.16198v1' target='_blank'>An Autonomous Network Orchestration Framework Integrating Large Language
  Models with Continual Reinforcement Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Masoud Shokrnezhad, Tarik Taleb</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-22 11:53:34</h6>
<p class='card-text'>6G networks aim to achieve global coverage, massive connectivity, and
ultra-stringent requirements. Space-Air-Ground Integrated Networks (SAGINs) and
Semantic Communication (SemCom) are essential for realizing these goals, yet
they introduce considerable complexity in resource orchestration. Drawing
inspiration from research in robotics, a viable solution to manage this
complexity is the application of Large Language Models (LLMs). Although the use
of LLMs in network orchestration has recently gained attention, existing
solutions have not sufficiently addressed LLM hallucinations or their
adaptation to network dynamics. To address this gap, this paper proposes a
framework called Autonomous Reinforcement Coordination (ARC) for a
SemCom-enabled SAGIN. This framework employs an LLM-based Retrieval-Augmented
Generator (RAG) monitors services, users, and resources and processes the
collected data, while a Hierarchical Action Planner (HAP) orchestrates
resources. ARC decomposes orchestration into two tiers, utilizing LLMs for
high-level planning and Reinforcement Learning (RL) agents for low-level
decision-making, in alignment with the Mixture of Experts (MoE) concept. The
LLMs utilize Chain-of-Thought (CoT) reasoning for few-shot learning, empowered
by contrastive learning, while the RL agents employ replay buffer management
for continual learning, thereby achieving efficiency, accuracy, and
adaptability. Simulations are provided to demonstrate the effectiveness of ARC,
along with a comprehensive discussion on potential future research directions
to enhance and upgrade ARC.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.15939v1' target='_blank'>"Kya family planning after marriage hoti hai?": Integrating Cultural
  Sensitivity in an LLM Chatbot for Reproductive Health</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Roshini Deva, Dhruv Ramani, Tanvi Divate, Suhani Jalota, Azra Ismail</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-21 21:08:50</h6>
<p class='card-text'>Access to sexual and reproductive health information remains a challenge in
many communities globally, due to cultural taboos and limited availability of
healthcare providers. Public health organizations are increasingly turning to
Large Language Models (LLMs) to improve access to timely and personalized
information. However, recent HCI scholarship indicates that significant
challenges remain in incorporating context awareness and mitigating bias in
LLMs. In this paper, we study the development of a culturally-appropriate
LLM-based chatbot for reproductive health with underserved women in urban
India. Through user interactions, focus groups, and interviews with multiple
stakeholders, we examine the chatbot's response to sensitive and highly
contextual queries on reproductive health. Our findings reveal strengths and
limitations of the system in capturing local context, and complexities around
what constitutes "culture". Finally, we discuss how local context might be
better integrated, and present a framework to inform the design of
culturally-sensitive chatbots for community health.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.15872v1' target='_blank'>MutaGReP: Execution-Free Repository-Grounded Plan Search for Code-Use</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zaid Khan, Ali Farhadi, Ranjay Krishna, Luca Weihs, Mohit Bansal, Tanmay Gupta</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-21 18:58:17</h6>
<p class='card-text'>When a human requests an LLM to complete a coding task using functionality
from a large code repository, how do we provide context from the repo to the
LLM? One approach is to add the entire repo to the LLM's context window.
However, most tasks involve only fraction of symbols from a repo, longer
contexts are detrimental to the LLM's reasoning abilities, and context windows
are not unlimited. Alternatively, we could emulate the human ability to
navigate a large repo, pick out the right functionality, and form a plan to
solve the task. We propose MutaGReP (Mutation-guided Grounded Repository Plan
Search), an approach to search for plans that decompose a user request into
natural language steps grounded in the codebase. MutaGReP performs neural tree
search in plan space, exploring by mutating plans and using a symbol retriever
for grounding. On the challenging LongCodeArena benchmark, our plans use less
than 5% of the 128K context window for GPT-4o but rival the coding performance
of GPT-4o with a context window filled with the repo. Plans produced by
MutaGReP allow Qwen 2.5 Coder 32B and 72B to match the performance of GPT-4o
with full repo context and enable progress on the hardest LongCodeArena tasks.
Project page: zaidkhan.me/MutaGReP</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.15676v1' target='_blank'>AutoToM: Automated Bayesian Inverse Planning and Model Discovery for
  Open-ended Theory of Mind</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhining Zhang, Chuanyang Jin, Mung Yao Jia, Tianmin Shu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-21 18:57:52</h6>
<p class='card-text'>Theory of Mind (ToM), the ability to understand people's mental variables
based on their behavior, is key to developing socially intelligent agents.
Current approaches to Theory of Mind reasoning either rely on prompting Large
Language Models (LLMs), which are prone to systematic errors, or use rigid,
handcrafted Bayesian Theory of Mind (BToM) models, which are more robust but
cannot generalize across different domains. In this work, we introduce AutoToM,
an automated Bayesian Theory of Mind method for achieving open-ended machine
Theory of Mind. AutoToM can operate in any domain, infer any mental variable,
and conduct robust Theory of Mind reasoning of any order. Given a Theory of
Mind inference problem, AutoToM first proposes an initial BToM model. It then
conducts automated Bayesian inverse planning based on the proposed model,
leveraging an LLM as the backend. Based on the uncertainty of the inference, it
iteratively refines the model, by introducing additional mental variables
and/or incorporating more timesteps in the context. Empirical evaluations
across multiple Theory of Mind benchmarks demonstrate that AutoToM consistently
achieves state-of-the-art performance, offering a scalable, robust, and
interpretable approach to machine Theory of Mind.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.15332v1' target='_blank'>Detecting Future-related Contexts of Entity Mentions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Puneet Prashar, Krishna Mohan Shukla, Adam Jatowt</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-21 09:34:34</h6>
<p class='card-text'>The ability to automatically identify whether an entity is referenced in a
future context can have multiple applications including decision making,
planning and trend forecasting. This paper focuses on detecting implicit future
references in entity-centric texts, addressing the growing need for automated
temporal analysis in information processing. We first present a novel dataset
of 19,540 sentences built around popular entities sourced from Wikipedia, which
consists of future-related and non-future-related contexts in which those
entities appear. As a second contribution, we evaluate the performance of
several Language Models including also Large Language Models (LLMs) on the task
of distinguishing future-oriented content in the absence of explicit temporal
references.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.15214v1' target='_blank'>The Evolving Landscape of LLM- and VLM-Integrated Reinforcement Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sheila Schoepp, Masoud Jafaripour, Yingyue Cao, Tianpei Yang, Fatemeh Abdollahi, Shadan Golestan, Zahin Sufiyan, Osmar R. Zaiane, Matthew E. Taylor</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-21 05:01:30</h6>
<p class='card-text'>Reinforcement learning (RL) has shown impressive results in sequential
decision-making tasks. Meanwhile, Large Language Models (LLMs) and
Vision-Language Models (VLMs) have emerged, exhibiting impressive capabilities
in multimodal understanding and reasoning. These advances have led to a surge
of research integrating LLMs and VLMs into RL. In this survey, we review
representative works in which LLMs and VLMs are used to overcome key challenges
in RL, such as lack of prior knowledge, long-horizon planning, and reward
design. We present a taxonomy that categorizes these LLM/VLM-assisted RL
approaches into three roles: agent, planner, and reward. We conclude by
exploring open problems, including grounding, bias mitigation, improved
representations, and action advice. By consolidating existing research and
identifying future directions, this survey establishes a framework for
integrating LLMs and VLMs into RL, advancing approaches that unify natural
language and visual understanding with sequential decision-making.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.15030v1' target='_blank'>CHOIR: Chat-based Helper for Organizational Intelligence Repository</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sangwook Lee, Adnan Abbas, Yan Chen, Sang Won Lee</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-20 20:34:41</h6>
<p class='card-text'>Modern organizations frequently rely on chat-based platforms (e.g., Slack,
Microsoft Teams, and Discord) for day-to-day communication and decision-making.
As conversations evolve, organizational knowledge can get buried, prompting
repeated searches and discussions. While maintaining shared documents, such as
Wiki articles for the organization, offers a partial solution, it requires
manual and timely efforts to keep it up to date, and it may not effectively
preserve the social and contextual aspect of prior discussions. Moreover,
reaching a consensus on document updates with relevant stakeholders can be
time-consuming and complex. To address these challenges, we introduce CHOIR
(Chat-based Helper for Organizational Intelligence Repository), a chatbot that
integrates seamlessly with chat platforms. CHOIR automatically identifies and
proposes edits to related documents, initiates discussions with relevant team
members, and preserves contextual revision histories. By embedding knowledge
management directly into chat environments and leveraging LLMs, CHOIR
simplifies manual updates and supports consensus-driven editing based on
maintained context with revision histories. We plan to design, deploy, and
evaluate CHOIR in the context of maintaining an organizational memory for a
research lab. We describe the chatbot's motivation, design, and early
implementation to show how CHOIR streamlines collaborative document management.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.14563v1' target='_blank'>Plan-over-Graph: Towards Parallelable LLM Agent Schedule</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shiqi Zhang, Xinbei Ma, Zouying Cao, Zhuosheng Zhang, Hai Zhao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-20 13:47:51</h6>
<p class='card-text'>Large Language Models (LLMs) have demonstrated exceptional abilities in
reasoning for task planning. However, challenges remain under-explored for
parallel schedules. This paper introduces a novel paradigm, plan-over-graph, in
which the model first decomposes a real-life textual task into executable
subtasks and constructs an abstract task graph. The model then understands this
task graph as input and generates a plan for parallel execution. To enhance the
planning capability of complex, scalable graphs, we design an automated and
controllable pipeline to generate synthetic graphs and propose a two-stage
training scheme. Experimental results show that our plan-over-graph method
significantly improves task performance on both API-based LLMs and trainable
open-sourced LLMs. By normalizing complex tasks as graphs, our method naturally
supports parallel execution, demonstrating global efficiency. The code and data
are available at https://github.com/zsq259/Plan-over-Graph.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.14321v1' target='_blank'>Beyond Self-Talk: A Communication-Centric Survey of LLM-Based
  Multi-Agent Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Bingyu Yan, Xiaoming Zhang, Litian Zhang, Lian Zhang, Ziyi Zhou, Dezhuang Miao, Chaozhuo Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-20 07:18:34</h6>
<p class='card-text'>Large Language Models (LLMs) have recently demonstrated remarkable
capabilities in reasoning, planning, and decision-making. Building upon these
strengths, researchers have begun incorporating LLMs into multi-agent systems
(MAS), where agents collaborate or compete through natural language
interactions to tackle tasks beyond the scope of single-agent setups. In this
survey, we present a communication-centric perspective on LLM-based multi-agent
systems, examining key system-level features such as architecture design and
communication goals, as well as internal mechanisms like communication
strategies, paradigms, objects and content. We illustrate how these
communication elements interplay to enable collective intelligence and flexible
collaboration. Furthermore, we discuss prominent challenges, including
scalability, security, and multimodal integration, and propose directions for
future work to advance research in this emerging domain. Ultimately, this
survey serves as a catalyst for further innovation, fostering more robust,
scalable, and intelligent multi-agent systems across diverse application
domains.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.15823v2' target='_blank'>InductionBench: LLMs Fail in the Simplest Complexity Class</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wenyue Hua, Tyler Wong, Sun Fei, Liangming Pan, Adam Jardine, William Yang Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-20 03:48:00</h6>
<p class='card-text'>Large language models (LLMs) have shown remarkable improvements in reasoning
and many existing benchmarks have been addressed by models such as o1 and o3
either fully or partially. However, a majority of these benchmarks emphasize
deductive reasoning, including mathematical and coding tasks in which rules
such as mathematical axioms or programming syntax are clearly defined, based on
which LLMs can plan and apply these rules to arrive at a solution. In contrast,
inductive reasoning, where one infers the underlying rules from observed data,
remains less explored. Such inductive processes lie at the heart of scientific
discovery, as they enable researchers to extract general principles from
empirical observations. To assess whether LLMs possess this capacity, we
introduce InductionBench, a new benchmark designed to evaluate the inductive
reasoning ability of LLMs. Our experimental findings reveal that even the most
advanced models available struggle to master the simplest complexity classes
within the subregular hierarchy of functions, highlighting a notable deficiency
in current LLMs' inductive reasoning capabilities. Coda and data are available
https://github.com/Wenyueh/inductive_reasoning_benchmark.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.14180v1' target='_blank'>On the logical skills of large language models: evaluations using
  arbitrarily complex first-order logic problems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shokhrukh Ibragimov, Arnulf Jentzen, Benno Kuckuck</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-20 01:18:24</h6>
<p class='card-text'>We present a method of generating first-order logic statements whose
complexity can be controlled along multiple dimensions. We use this method to
automatically create several datasets consisting of questions asking for the
truth or falsity of first-order logic statements in Zermelo-Fraenkel set
theory. While the resolution of these questions does not require any knowledge
beyond basic notation of first-order logic and set theory, it does require a
degree of planning and logical reasoning, which can be controlled up to
arbitrarily high difficulty by the complexity of the generated statements.
Furthermore, we do extensive evaluations of the performance of various large
language models, including recent models such as DeepSeek-R1 and OpenAI's
o3-mini, on these datasets. All of the datasets along with the code used for
generating them, as well as all data from the evaluations is publicly available
at https://github.com/bkuckuck/logical-skills-of-llms.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.13921v1' target='_blank'>Exploring Code Language Models for Automated HLS-based Hardware
  Generation: Benchmark, Infrastructure and Analysis</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiahao Gai, Hao, Chen, Zhican Wang, Hongyu Zhou, Wanru Zhao, Nicholas Lane, Hongxiang Fan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-19 17:53:59</h6>
<p class='card-text'>Recent advances in code generation have illuminated the potential of
employing large language models (LLMs) for general-purpose programming
languages such as Python and C++, opening new opportunities for automating
software development and enhancing programmer productivity. The potential of
LLMs in software programming has sparked significant interest in exploring
automated hardware generation and automation. Although preliminary endeavors
have been made to adopt LLMs in generating hardware description languages
(HDLs), several challenges persist in this direction. First, the volume of
available HDL training data is substantially smaller compared to that for
software programming languages. Second, the pre-trained LLMs, mainly tailored
for software code, tend to produce HDL designs that are more error-prone.
Third, the generation of HDL requires a significantly higher number of tokens
compared to software programming, leading to inefficiencies in cost and energy
consumption. To tackle these challenges, this paper explores leveraging LLMs to
generate High-Level Synthesis (HLS)-based hardware design. Although code
generation for domain-specific programming languages is not new in the
literature, we aim to provide experimental results, insights, benchmarks, and
evaluation infrastructure to investigate the suitability of HLS over low-level
HDLs for LLM-assisted hardware design generation. To achieve this, we first
finetune pre-trained models for HLS-based hardware generation, using a
collected dataset with text prompts and corresponding reference HLS designs. An
LLM-assisted framework is then proposed to automate end-to-end hardware code
generation, which also investigates the impact of chain-of-thought and feedback
loops promoting techniques on HLS-design generation. Limited by the timeframe
of this research, we plan to evaluate more advanced reasoning models in the
future.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.13475v2' target='_blank'>LLM should think and action as a human</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Haun Leung, ZiNan Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-19 06:58:34</h6>
<p class='card-text'>It is popular lately to train large language models to be used as chat
assistants, but in the conversation between the user and the chat assistant,
there are prompts, require multi-turns between the chat assistant and the user.
However, there are a number of issues with the multi-turns conversation: The
response of the chat assistant is prone to errors and can't help users achieve
their goals, and as the number of conversation turns increases, the probability
of errors will also increase; It is difficult for chat assistant to generate
responses with different processes based on actual needs for the same prompt;
Chat assistant require the use of tools, but the current approach is not
elegant and efficient, and the number of tool calls is limited. The main reason
for these issues is that large language models don't have the thinking ability
as a human, lack the reasoning ability and planning ability, and lack the
ability to execute plans. To solve these issues, we propose a thinking method
based on a built-in chain of thought: In the multi-turns conversation, for each
user prompt, the large language model thinks based on elements such as chat
history, thinking context, action calls, memory and knowledge, makes detailed
reasoning and planning, and actions according to the plan. We also explored how
the large language model enhances thinking ability through this thinking
method: Collect training datasets according to the thinking method and fine
tune the large language model through supervised learning; Train a consistency
reward model and use it as a reward function to fine tune the large language
model using reinforcement learning, and the reinforced large language model
outputs according to this way of thinking. Our experimental results show that
the reasoning ability and planning ability of the large language model are
enhanced, and the issues in the multi-turns conversation are solved.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.13092v2' target='_blank'>Text2World: Benchmarking Large Language Models for Symbolic World Model
  Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mengkang Hu, Tianxing Chen, Yude Zou, Yuheng Lei, Qiguang Chen, Ming Li, Yao Mu, Hongyuan Zhang, Wenqi Shao, Ping Luo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-18 17:59:48</h6>
<p class='card-text'>Recently, there has been growing interest in leveraging large language models
(LLMs) to generate symbolic world models from textual descriptions. Although
LLMs have been extensively explored in the context of world modeling, prior
studies encountered several challenges, including evaluation randomness,
dependence on indirect metrics, and a limited domain scope. To address these
limitations, we introduce a novel benchmark, Text2World, based on planning
domain definition language (PDDL), featuring hundreds of diverse domains and
employing multi-criteria, execution-based metrics for a more robust evaluation.
We benchmark current LLMs using Text2World and find that reasoning models
trained with large-scale reinforcement learning outperform others. However,
even the best-performing model still demonstrates limited capabilities in world
modeling. Building on these insights, we examine several promising strategies
to enhance the world modeling capabilities of LLMs, including test-time
scaling, agent training, and more. We hope that Text2World can serve as a
crucial resource, laying the groundwork for future research in leveraging LLMs
as world models. The project page is available at
https://text-to-world.github.io/.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.12825v2' target='_blank'>Reasoning and the Trusting Behavior of DeepSeek and GPT: An Experiment
  Revealing Hidden Fault Lines in Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Rubing Li, João Sedoc, Arun Sundararajan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-18 12:46:18</h6>
<p class='card-text'>When encountering increasingly frequent performance improvements or cost
reductions from a new large language model (LLM), developers of applications
leveraging LLMs must decide whether to take advantage of these improvements or
stay with older tried-and-tested models. Low perceived switching frictions can
lead to choices that do not consider more subtle behavior changes that the
transition may induce. Our experiments use a popular game-theoretic behavioral
economics model of trust to show stark differences in the trusting behavior of
OpenAI's and DeepSeek's models. We highlight a collapse in the economic trust
behavior of the o1-mini and o3-mini models as they reconcile profit-maximizing
and risk-seeking with future returns from trust, and contrast it with
DeepSeek's more sophisticated and profitable trusting behavior that stems from
an ability to incorporate deeper concepts like forward planning and
theory-of-mind. As LLMs form the basis for high-stakes commercial systems, our
results highlight the perils of relying on LLM performance benchmarks that are
too narrowly defined and suggest that careful analysis of their hidden fault
lines should be part of any organization's AI strategy.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.12623v1' target='_blank'>DeepResonance: Enhancing Multimodal Music Understanding via
  Music-centric Multi-way Instruction Tuning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhuoyuan Mao, Mengjie Zhao, Qiyu Wu, Hiromi Wakaki, Yuki Mitsufuji</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-18 08:09:42</h6>
<p class='card-text'>Recent advancements in music large language models (LLMs) have significantly
improved music understanding tasks, which involve the model's ability to
analyze and interpret various musical elements. These improvements primarily
focused on integrating both music and text inputs. However, the potential of
incorporating additional modalities such as images, videos and textual music
features to enhance music understanding remains unexplored. To bridge this gap,
we propose DeepResonance, a multimodal music understanding LLM fine-tuned via
multi-way instruction tuning with multi-way aligned music, text, image, and
video data. To this end, we construct Music4way-MI2T, Music4way-MV2T, and
Music4way-Any2T, three 4-way training and evaluation datasets designed to
enable DeepResonance to integrate both visual and textual music feature
content. We also introduce multi-sampled ImageBind embeddings and a
pre-alignment Transformer to enhance modality fusion prior to input into text
LLMs, tailoring DeepResonance for multi-way instruction tuning. Our model
achieves state-of-the-art performances across six music understanding tasks,
highlighting the benefits of the auxiliary modalities and the structural
superiority of DeepResonance. We plan to open-source the models and the newly
constructed datasets.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.12568v2' target='_blank'>A Cognitive Writing Perspective for Constrained Long-Form Text
  Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kaiyang Wan, Honglin Mu, Rui Hao, Haoran Luo, Tianle Gu, Xiuying Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-18 06:12:14</h6>
<p class='card-text'>Like humans, Large Language Models (LLMs) struggle to generate high-quality
long-form text that adheres to strict requirements in a single pass. This
challenge is unsurprising, as successful human writing, according to the
Cognitive Writing Theory, is a complex cognitive process involving iterative
planning, translating, reviewing, and monitoring. Motivated by these cognitive
principles, we aim to equip LLMs with human-like cognitive writing capabilities
through CogWriter, a novel training-free framework that transforms LLM
constrained long-form text generation into a systematic cognitive writing
paradigm. Our framework consists of two key modules: (1) a Planning Agent that
performs hierarchical planning to decompose the task, and (2) multiple
Generation Agents that execute these plans in parallel. The system maintains
quality via continuous monitoring and reviewing mechanisms, which evaluate
outputs against specified requirements and trigger necessary revisions.
CogWriter demonstrates exceptional performance on LongGenBench, a benchmark for
complex constrained long-form text generation. Even when using Qwen-2.5-14B as
its backbone, CogWriter surpasses GPT-4o by 22% in complex instruction
completion accuracy while reliably generating texts exceeding 10,000 words. We
hope this cognitive science-inspired approach provides a paradigm for LLM
writing advancements:
\href{https://github.com/KaiyangWan/CogWriter}{CogWriter}.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.12532v2' target='_blank'>CityEQA: A Hierarchical LLM Agent on Embodied Question Answering
  Benchmark in City Space</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yong Zhao, Kai Xu, Zhengqiu Zhu, Yue Hu, Zhiheng Zheng, Yingfeng Chen, Yatai Ji, Chen Gao, Yong Li, Jincai Huang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-18 04:36:15</h6>
<p class='card-text'>Embodied Question Answering (EQA) has primarily focused on indoor
environments, leaving the complexities of urban settings - spanning
environment, action, and perception - largely unexplored. To bridge this gap,
we introduce CityEQA, a new task where an embodied agent answers
open-vocabulary questions through active exploration in dynamic city spaces. To
support this task, we present CityEQA-EC, the first benchmark dataset featuring
1,412 human-annotated tasks across six categories, grounded in a realistic 3D
urban simulator. Moreover, we propose Planner-Manager-Actor (PMA), a novel
agent tailored for CityEQA. PMA enables long-horizon planning and hierarchical
task execution: the Planner breaks down the question answering into sub-tasks,
the Manager maintains an object-centric cognitive map for spatial reasoning
during the process control, and the specialized Actors handle navigation,
exploration, and collection sub-tasks. Experiments demonstrate that PMA
achieves 60.7% of human-level answering accuracy, significantly outperforming
frontier-based baselines. While promising, the performance gap compared to
humans highlights the need for enhanced visual reasoning in CityEQA. This work
paves the way for future advancements in urban spatial intelligence. Dataset
and code are available at https://github.com/BiluYong/CityEQA.git.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.12521v1' target='_blank'>Inference-Time Computations for LLM Reasoning and Planning: A Benchmark
  and Insights</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shubham Parashar, Blake Olson, Sambhav Khurana, Eric Li, Hongyi Ling, James Caverlee, Shuiwang Ji</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-18 04:11:29</h6>
<p class='card-text'>We examine the reasoning and planning capabilities of large language models
(LLMs) in solving complex tasks. Recent advances in inference-time techniques
demonstrate the potential to enhance LLM reasoning without additional training
by exploring intermediate steps during inference. Notably, OpenAI's o1 model
shows promising performance through its novel use of multi-step reasoning and
verification. Here, we explore how scaling inference-time techniques can
improve reasoning and planning, focusing on understanding the tradeoff between
computational cost and performance. To this end, we construct a comprehensive
benchmark, known as Sys2Bench, and perform extensive experiments evaluating
existing inference-time techniques on eleven diverse tasks across five
categories, including arithmetic reasoning, logical reasoning, common sense
reasoning, algorithmic reasoning, and planning. Our findings indicate that
simply scaling inference-time computation has limitations, as no single
inference-time technique consistently performs well across all reasoning and
planning tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.13175v2' target='_blank'>Towards Robust and Secure Embodied AI: A Survey on Vulnerabilities and
  Attacks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wenpeng Xing, Minghao Li, Mohan Li, Meng Han</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-18 03:38:07</h6>
<p class='card-text'>Embodied AI systems, including robots and autonomous vehicles, are
increasingly integrated into real-world applications, where they encounter a
range of vulnerabilities stemming from both environmental and system-level
factors. These vulnerabilities manifest through sensor spoofing, adversarial
attacks, and failures in task and motion planning, posing significant
challenges to robustness and safety. Despite the growing body of research,
existing reviews rarely focus specifically on the unique safety and security
challenges of embodied AI systems. Most prior work either addresses general AI
vulnerabilities or focuses on isolated aspects, lacking a dedicated and unified
framework tailored to embodied AI. This survey fills this critical gap by: (1)
categorizing vulnerabilities specific to embodied AI into exogenous (e.g.,
physical attacks, cybersecurity threats) and endogenous (e.g., sensor failures,
software flaws) origins; (2) systematically analyzing adversarial attack
paradigms unique to embodied AI, with a focus on their impact on perception,
decision-making, and embodied interaction; (3) investigating attack vectors
targeting large vision-language models (LVLMs) and large language models (LLMs)
within embodied systems, such as jailbreak attacks and instruction
misinterpretation; (4) evaluating robustness challenges in algorithms for
embodied perception, decision-making, and task planning; and (5) proposing
targeted strategies to enhance the safety and reliability of embodied AI
systems. By integrating these dimensions, we provide a comprehensive framework
for understanding the interplay between vulnerabilities and safety in embodied
AI.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.12498v1' target='_blank'>USPilot: An Embodied Robotic Assistant Ultrasound System with Large
  Language Model Enhanced Graph Planner</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mingcong Chen, Siqi Fan, Guanglin Cao, Hongbin Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-18 03:24:53</h6>
<p class='card-text'>In the era of Large Language Models (LLMs), embodied artificial intelligence
presents transformative opportunities for robotic manipulation tasks.
Ultrasound imaging, a widely used and cost-effective medical diagnostic
procedure, faces challenges due to the global shortage of professional
sonographers. To address this issue, we propose USPilot, an embodied robotic
assistant ultrasound system powered by an LLM-based framework to enable
autonomous ultrasound acquisition. USPilot is designed to function as a virtual
sonographer, capable of responding to patients' ultrasound-related queries and
performing ultrasound scans based on user intent. By fine-tuning the LLM,
USPilot demonstrates a deep understanding of ultrasound-specific questions and
tasks. Furthermore, USPilot incorporates an LLM-enhanced Graph Neural Network
(GNN) to manage ultrasound robotic APIs and serve as a task planner.
Experimental results show that the LLM-enhanced GNN achieves unprecedented
accuracy in task planning on public datasets. Additionally, the system
demonstrates significant potential in autonomously understanding and executing
ultrasound procedures. These advancements bring us closer to achieving
autonomous and potentially unmanned robotic ultrasound systems, addressing
critical resource gaps in medical imaging.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.12435v1' target='_blank'>A Survey on Large Language Models for Automated Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mohamed Aghzal, Erion Plaku, Gregory J. Stein, Ziyu Yao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-18 02:11:03</h6>
<p class='card-text'>The planning ability of Large Language Models (LLMs) has garnered increasing
attention in recent years due to their remarkable capacity for multi-step
reasoning and their ability to generalize across a wide range of domains. While
some researchers emphasize the potential of LLMs to perform complex planning
tasks, others highlight significant limitations in their performance,
particularly when these models are tasked with handling the intricacies of
long-horizon reasoning. In this survey, we critically investigate existing
research on the use of LLMs in automated planning, examining both their
successes and shortcomings in detail. We illustrate that although LLMs are not
well-suited to serve as standalone planners because of these limitations, they
nonetheless present an enormous opportunity to enhance planning applications
when combined with other approaches. Thus, we advocate for a balanced
methodology that leverages the inherent flexibility and generalized knowledge
of LLMs alongside the rigor and cost-effectiveness of traditional planning
methods.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.12130v1' target='_blank'>Scaling Autonomous Agents via Automatic Reward Modeling And Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhenfang Chen, Delin Chen, Rui Sun, Wenjun Liu, Chuang Gan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-17 18:49:25</h6>
<p class='card-text'>Large language models (LLMs) have demonstrated remarkable capabilities across
a range of text-generation tasks. However, LLMs still struggle with problems
requiring multi-step decision-making and environmental feedback, such as online
shopping, scientific reasoning, and mathematical problem-solving. Unlike pure
text data, collecting large-scale decision-making data is challenging.
Moreover, many powerful LLMs are only accessible through APIs, which hinders
their fine-tuning for agent tasks due to cost and complexity. To address LLM
agents' limitations, we propose a framework that can automatically learn a
reward model from the environment without human annotations. This model can be
used to evaluate the action trajectories of LLM agents and provide heuristics
for task planning. Specifically, our approach involves employing one LLM-based
agent to navigate an environment randomly, generating diverse action
trajectories. Subsequently, a separate LLM is leveraged to assign a task intent
and synthesize a negative response alongside the correct response for each
trajectory. These triplets (task intent, positive response, and negative
response) are then utilized as training data to optimize a reward model capable
of scoring action trajectories. The effectiveness and generalizability of our
framework are demonstrated through evaluations conducted on different agent
benchmarks. In conclusion, our proposed framework represents a significant
advancement in enhancing LLM agents' decision-making capabilities. By
automating the learning of reward models, we overcome the challenges of data
scarcity and API limitations, potentially revolutionizing the application of
LLMs in complex and interactive environments. This research paves the way for
more sophisticated AI agents capable of tackling a wide range of real-world
problems requiring multi-step decision-making.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.12066v1' target='_blank'>CONSTRUCTA: Automating Commercial Construction Schedules in Fabrication
  Facilities with Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yifan Zhang, Xue Yang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-17 17:35:42</h6>
<p class='card-text'>Automating planning with LLMs presents transformative opportunities for
traditional industries, yet remains underexplored. In commercial construction,
the complexity of automated scheduling often requires manual intervention to
ensure precision. We propose CONSTRUCTA, a novel framework leveraging LLMs to
optimize construction schedules in complex projects like semiconductor
fabrication. CONSTRUCTA addresses key challenges by: (1) integrating
construction-specific knowledge through static RAG; (2) employing
context-sampling techniques inspired by architectural expertise to provide
relevant input; and (3) deploying Construction DPO to align schedules with
expert preferences using RLHF. Experiments on proprietary data demonstrate
performance improvements of +42.3% in missing value prediction, +79.1% in
dependency analysis, and +28.9% in automated planning compared to baseline
methods, showcasing its potential to revolutionize construction workflows and
inspire domain-specific LLM advancements.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.11733v1' target='_blank'>Plant in Cupboard, Orange on Table, Book on Shelf. Benchmarking
  Practical Reasoning and Situation Modelling in a Text-Simulated Situated
  Environment</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jonathan Jordan, Sherzod Hakimov, David Schlangen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-17 12:20:39</h6>
<p class='card-text'>Large language models (LLMs) have risen to prominence as 'chatbots' for users
to interact via natural language. However, their abilities to capture
common-sense knowledge make them seem promising as language-based planners of
situated or embodied action as well. We have implemented a simple text-based
environment -- similar to others that have before been used for
reinforcement-learning of agents -- that simulates, very abstractly, a
household setting. We use this environment and the detailed error-tracking
capabilities we implemented for targeted benchmarking of LLMs on the problem of
practical reasoning: Going from goals and observations to actions. Our findings
show that environmental complexity and game restrictions hamper performance,
and concise action planning is demanding for current LLMs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.11574v2' target='_blank'>Large Language Models and Mathematical Reasoning Failures</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Johan Boye, Birger Moell</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-17 09:07:32</h6>
<p class='card-text'>This paper investigates the mathematical reasoning capabilities of large
language models (LLMs) using 50 newly constructed high-school-level word
problems. Unlike prior studies that focus solely on answer correctness, we
rigorously analyze both final answers and solution steps to identify reasoning
failures. Evaluating eight state-of-the-art models - including Mixtral, Llama,
Gemini, GPT-4o, and OpenAI's o1 variants - we find that while newer models
(e.g., o3-mini, deepseek-r1) achieve higher accuracy, all models exhibit errors
in spatial reasoning, strategic planning, and arithmetic, sometimes producing
correct answers through flawed logic. Common failure modes include unwarranted
assumptions, over-reliance on numerical patterns, and difficulty translating
physical intuition into mathematical steps. Manual analysis reveals that models
struggle with problems requiring multi-step deduction or real-world knowledge,
despite possessing broad mathematical knowledge. Our results underscore the
importance of evaluating reasoning processes, not just answers, and caution
against overestimating LLMs' problem-solving proficiency. The study highlights
persistent gaps in LLMs' generalization abilities, emphasizing the need for
targeted improvements in structured reasoning and constraint handling.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.11422v1' target='_blank'>Planning of Heuristics: Strategic Planning on Large Language Models with
  Monte Carlo Tree Search for Automating Heuristic Optimization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chaoxu Mu, Xufeng Zhang, Hui Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-17 04:35:01</h6>
<p class='card-text'>Heuristics have achieved great success in solving combinatorial optimization
problems (COPs). However, heuristics designed by humans require too much domain
knowledge and testing time. Given the fact that Large Language Models (LLMs)
possess strong capabilities to understand and generate content, and a knowledge
base that covers various domains, which offer a novel way to automatically
optimize heuristics. Therefore, we propose Planning of Heuristics (PoH), an
optimization method that integrates the self-reflection of LLMs with the Monte
Carlo Tree Search (MCTS), a well-known planning algorithm. PoH iteratively
refines generated heuristics by evaluating their performance and providing
improvement suggestions. Our method enables to iteratively evaluate the
generated heuristics (states) and improve them based on the improvement
suggestions (actions) and evaluation results (rewards), by effectively
simulating future states to search for paths with higher rewards. In this
paper, we apply PoH to solve the Traveling Salesman Problem (TSP) and the Flow
Shop Scheduling Problem (FSSP). The experimental results show that PoH
outperforms other hand-crafted heuristics and Automatic Heuristic Design (AHD)
by other LLMs-based methods, and achieves the significant improvements and the
state-of-the-art performance of our proposed method in automating heuristic
optimization with LLMs to solve COPs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.11404v1' target='_blank'>ToolCoder: A Systematic Code-Empowered Tool Learning Framework for Large
  Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hanxing Ding, Shuchang Tao, Liang Pang, Zihao Wei, Jinyang Gao, Bolin Ding, Huawei Shen, Xueqi Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-17 03:42:28</h6>
<p class='card-text'>Tool learning has emerged as a crucial capability for large language models
(LLMs) to solve complex real-world tasks through interaction with external
tools. Existing approaches face significant challenges, including reliance on
hand-crafted prompts, difficulty in multi-step planning, and lack of precise
error diagnosis and reflection mechanisms. We propose ToolCoder, a novel
framework that reformulates tool learning as a code generation task. Inspired
by software engineering principles, ToolCoder transforms natural language
queries into structured Python function scaffold and systematically breaks down
tasks with descriptive comments, enabling LLMs to leverage coding paradigms for
complex reasoning and planning. It then generates and executes function
implementations to obtain final responses. Additionally, ToolCoder stores
successfully executed functions in a repository to promote code reuse, while
leveraging error traceback mechanisms for systematic debugging, optimizing both
execution efficiency and robustness. Experiments demonstrate that ToolCoder
achieves superior performance in task completion accuracy and execution
reliability compared to existing approaches, establishing the effectiveness of
code-centric approaches in tool learning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.11271v1' target='_blank'>OctoTools: An Agentic Framework with Extensible Tools for Complex
  Reasoning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Pan Lu, Bowen Chen, Sheng Liu, Rahul Thapa, Joseph Boen, James Zou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-16 21:18:47</h6>
<p class='card-text'>Solving complex reasoning tasks may involve visual understanding, domain
knowledge retrieval, numerical calculation, and multi-step reasoning. Existing
methods augment large language models (LLMs) with external tools but are
restricted to specialized domains, limited tool types, or require additional
training data. In this paper, we introduce OctoTools, a training-free,
user-friendly, and easily extensible open-source agentic framework designed to
tackle complex reasoning across diverse domains. OctoTools introduces
standardized tool cards to encapsulate tool functionality, a planner for both
high-level and low-level planning, and an executor to carry out tool usage. We
validate OctoTools' generality across 16 diverse tasks (including MathVista,
MMLU-Pro, MedQA, and GAIA-Text), achieving substantial average accuracy gains
of 9.3% over GPT-4o. Furthermore, OctoTools outperforms AutoGen, GPT-Functions
and LangChain by up to 10.6% when given the same set of tools. Through
comprehensive analysis and ablations, OctoTools demonstrates advantages in task
planning, effective tool usage, and multi-step problem solving.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.11221v1' target='_blank'>PlanGenLLMs: A Modern Survey of LLM Planning Capabilities</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hui Wei, Zihao Zhang, Shenghua He, Tian Xia, Shijia Pan, Fei Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-16 17:54:57</h6>
<p class='card-text'>LLMs have immense potential for generating plans, transforming an initial
world state into a desired goal state. A large body of research has explored
the use of LLMs for various planning tasks, from web navigation to travel
planning and database querying. However, many of these systems are tailored to
specific problems, making it challenging to compare them or determine the best
approach for new tasks. There is also a lack of clear and consistent evaluation
criteria. Our survey aims to offer a comprehensive overview of current LLM
planners to fill this gap. It builds on foundational work by Kartam and Wilkins
(1990) and examines six key performance criteria: completeness, executability,
optimality, representation, generalization, and efficiency. For each, we
provide a thorough analysis of representative works and highlight their
strengths and weaknesses. Our paper also identifies crucial future directions,
making it a valuable resource for both practitioners and newcomers interested
in leveraging LLM planning to support agentic workflows.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.11211v1' target='_blank'>A Survey of LLM-based Agents in Medicine: How far are we from Baymax?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wenxuan Wang, Zizhan Ma, Zheng Wang, Chenghan Wu, Wenting Chen, Xiang Li, Yixuan Yuan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-16 17:21:05</h6>
<p class='card-text'>Large Language Models (LLMs) are transforming healthcare through the
development of LLM-based agents that can understand, reason about, and assist
with medical tasks. This survey provides a comprehensive review of LLM-based
agents in medicine, examining their architectures, applications, and
challenges. We analyze the key components of medical agent systems, including
system profiles, clinical planning mechanisms, medical reasoning frameworks,
and external capacity enhancement. The survey covers major application
scenarios such as clinical decision support, medical documentation, training
simulations, and healthcare service optimization. We discuss evaluation
frameworks and metrics used to assess these agents' performance in healthcare
settings. While LLM-based agents show promise in enhancing healthcare delivery,
several challenges remain, including hallucination management, multimodal
integration, implementation barriers, and ethical considerations. The survey
concludes by highlighting future research directions, including advances in
medical reasoning inspired by recent developments in LLM architectures,
integration with physical systems, and improvements in training simulations.
This work provides researchers and practitioners with a structured overview of
the current state and future prospects of LLM-based agents in medicine.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.11142v1' target='_blank'>NavRAG: Generating User Demand Instructions for Embodied Navigation
  through Retrieval-Augmented LLM</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zihan Wang, Yaohui Zhu, Gim Hee Lee, Yachun Fan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-16 14:17:36</h6>
<p class='card-text'>Vision-and-Language Navigation (VLN) is an essential skill for embodied
agents, allowing them to navigate in 3D environments following natural language
instructions. High-performance navigation models require a large amount of
training data, the high cost of manually annotating data has seriously hindered
this field. Therefore, some previous methods translate trajectory videos into
step-by-step instructions for expanding data, but such instructions do not
match well with users' communication styles that briefly describe destinations
or state specific needs. Moreover, local navigation trajectories overlook
global context and high-level task planning. To address these issues, we
propose NavRAG, a retrieval-augmented generation (RAG) framework that generates
user demand instructions for VLN. NavRAG leverages LLM to build a hierarchical
scene description tree for 3D scene understanding from global layout to local
details, then simulates various user roles with specific demands to retrieve
from the scene tree, generating diverse instructions with LLM. We annotate over
2 million navigation instructions across 861 scenes and evaluate the data
quality and navigation performance of trained models.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.11019v1' target='_blank'>Unlocking the Power of Function Vectors for Characterizing and
  Mitigating Catastrophic Forgetting in Continual Instruction Tuning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Gangwei Jiang, Caigao Jiang, Zhaoyi Li, Siqiao Xue, Jun Zhou, Linqi Song, Defu Lian, Yin Wei</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-16 07:06:17</h6>
<p class='card-text'>Catastrophic forgetting (CF) poses a significant challenge in machine
learning, where a model forgets previously learned information upon learning
new tasks. Despite the advanced capabilities of Large Language Models (LLMs),
they continue to face challenges with CF during continual learning. The
majority of existing research focuses on analyzing forgetting patterns through
a singular training sequence, thereby overlooking the intricate effects that
diverse tasks have on model behavior. Our study explores CF across various
settings, discovering that model forgetting is influenced by both the specific
training tasks and the models themselves. To this end, we interpret forgetting
by examining the function vector (FV), a compact representation of functions in
LLMs, offering a model-dependent indicator for the occurrence of CF. Through
theoretical and empirical analyses, we demonstrated that CF in LLMs primarily
stems from biases in function activation rather than the overwriting of task
processing functions. Leveraging these insights, we propose a novel function
vector guided training methodology, incorporating a regularization technique to
stabilize the FV and mitigate forgetting. Empirical tests on four benchmarks
confirm the effectiveness of our proposed training method, substantiating our
theoretical framework concerning CF and model function dynamics. We plan to
make our code publicly accessible in the near future.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.10996v1' target='_blank'>RAS: Retrieval-And-Structuring for Knowledge-Intensive LLM Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Pengcheng Jiang, Lang Cao, Ruike Zhu, Minhao Jiang, Yunyi Zhang, Jimeng Sun, Jiawei Han</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-16 05:01:49</h6>
<p class='card-text'>Retrieval-augmented language models often struggle with knowledge-intensive
tasks due to inefficient retrieval, unstructured knowledge integration, and
single-pass architectures. We present Retrieval-And-Structuring (RAS), a novel
framework that dynamically constructs and reasons over query-specific knowledge
graphs through iterative retrieval and structuring. RAS introduces four key
technical innovations: (1) a themescoped retrieval mechanism that efficiently
narrows the search space while maintaining retrieval quality, (2) an action
planning module that determines knowledge needs and generates focused
sub-queries, (3) a dynamic knowledge structuring approach that converts
retrieved text into an evolving knowledge graph, and (4) a graph-augmented
answering component that leverages the accumulated structured information. Our
framework achieves state-of-the-art performance, surpassing leading baselines
by 6.4% with open-source language models and 7.0% with proprietary models on
seven knowledge-intensive generation datasets across all evaluation metrics.
Detailed ablation studies verify the contribution of each technical component
to the overall system performance.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.10938v1' target='_blank'>PEA: Enhancing LLM Performance on Computational-Reasoning Tasks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zi Wang, Shiwei Weng, Mohannad Alhanahnah, Somesh Jha, Tom Reps</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-16 00:27:05</h6>
<p class='card-text'>Large Language Models (LLMs) have exhibited remarkable capabilities across
diverse domains, prompting investigations into their potential as generic
reasoning engines. While recent studies have explored inference-time
computation to enhance model performance on complex problems, current research
lacks a formal framework to characterize the complexity of reasoning tasks.
This study introduces the Predicate-Enumeration-Aggregation (PEA) framework, a
formal approach to describe and solve a class of important reasoning tasks
termed computational reasoning problems. The PEA framework decomposes these
problems into predicate and enumeration components, using LLMs to synthesize
programs based on specified predicates, enumeration, and aggregation rules.
These synthesized programs are then executed to obtain solutions to the
computational tasks. We demonstrate the framework's efficacy on benchmark tasks
including Boolean satisfiability problems, game of $24$, and planning problems.
Empirical evaluation reveals that PEA substantially enhances the performance of
underlying models on benchmark computational problems, yielding an average
accuracy improvement of approximately $50\%$, coupled with increased
efficiency.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.10931v1' target='_blank'>D-CIPHER: Dynamic Collaborative Intelligent Agents with Planning and
  Heterogeneous Execution for Enhanced Reasoning in Offensive Security</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Meet Udeshi, Minghao Shao, Haoran Xi, Nanda Rani, Kimberly Milner, Venkata Sai Charan Putrevu, Brendan Dolan-Gavitt, Sandeep Kumar Shukla, Prashanth Krishnamurthy, Farshad Khorrami, Ramesh Karri, Muhammad Shafique</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-15 23:43:18</h6>
<p class='card-text'>Large Language Models (LLMs) have been used in cybersecurity in many ways,
including their recent use as intelligent agent systems for autonomous security
analysis. Capture the Flag (CTF) challenges serve as benchmarks for assessing
the automated task-planning abilities of LLM agents across various
cybersecurity skill sets. Early attempts to apply LLMs for solving CTF
challenges relied on single-agent systems, where feedback was restricted to a
single reasoning-action loop. This approach proved inadequate for handling
complex CTF tasks. Drawing inspiration from real-world CTF competitions, where
teams of experts collaborate, we introduce the D-CIPHER multi-agent LLM
framework for collaborative CTF challenge solving. D-CIPHER integrates agents
with distinct roles, enabling dynamic feedback loops to enhance reasoning on
CTF challenges. It introduces the Planner-Executor agent system, consisting of
a Planner agent for overall problem-solving along with multiple heterogeneous
Executor agents for individual tasks, facilitating efficient allocation of
responsibilities among the LLMs. Additionally, D-CIPHER incorporates an
Auto-prompter agent, which improves problem-solving by exploring the challenge
environment and generating a highly relevant initial prompt. We evaluate
D-CIPHER on CTF benchmarks using multiple LLM models and conduct comprehensive
studies to highlight the impact of our enhancements. Our results demonstrate
that the multi-agent D-CIPHER system achieves a significant improvement in
challenges solved, setting a state-of-the-art performance on three benchmarks:
22.0% on NYU CTF Bench, 22.5% on Cybench, and 44.0% on HackTheBox. D-CIPHER is
available at https://github.com/NYU-LLM-CTF/nyuctf_agents as the
nyuctf_multiagent package.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.10638v1' target='_blank'>Script&Shift: A Layered Interface Paradigm for Integrating Content
  Development and Rhetorical Strategy with LLM Writing Assistants</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Momin Siddiqui, Roy Pea, Hari Subramonyam</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-15 02:28:51</h6>
<p class='card-text'>Good writing is a dynamic process of knowledge transformation, where writers
refine and evolve ideas through planning, translating, and reviewing.
Generative AI-powered writing tools can enhance this process but may also
disrupt the natural flow of writing, such as when using LLMs for complex tasks
like restructuring content across different sections or creating smooth
transitions. We introduce Script&Shift, a layered interface paradigm designed
to minimize these disruptions by aligning writing intents with LLM capabilities
to support diverse content development and rhetorical strategies. By bridging
envisioning, semantic, and articulatory distances, Script&Shift's interactions
allow writers to leverage LLMs for various content development tasks
(scripting) and experiment with diverse organization strategies while tailoring
their writing for different audiences (shifting). This approach preserves
creative control while encouraging divergent and iterative writing. Our
evaluation shows that Script&Shift enables writers to creatively and
efficiently incorporate LLMs while preserving a natural flow of composition.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.10618v1' target='_blank'>PLAID: Supporting Computing Instructors to Identify Domain-Specific
  Programming Plans at Scale</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yoshee Jain, Mehmet Arif Demirtaş, Kathryn Cunningham</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-15 00:43:50</h6>
<p class='card-text'>Pedagogical approaches focusing on stereotypical code solutions, known as
programming plans, can increase problem-solving ability and motivate diverse
learners. However, plan-focused pedagogies are rarely used beyond introductory
programming. Our formative study (N=10 educators) showed that identifying plans
is a tedious process. To advance plan-focused pedagogies in application-focused
domains, we created an LLM-powered pipeline that automates the effortful parts
of educators' plan identification process by providing use-case-driven program
examples and candidate plans. In design workshops (N=7 educators), we
identified design goals to maximize instructors' efficiency in plan
identification by optimizing interaction with this LLM-generated content. Our
resulting tool, PLAID, enables instructors to access a corpus of relevant
programs to inspire plan identification, compare code snippets to assist plan
refinement, and facilitates them in structuring code snippets into plans. We
evaluated PLAID in a within-subjects user study (N=12 educators) and found that
PLAID led to lower cognitive demand and increased productivity compared to the
state-of-the-art. Educators found PLAID beneficial for generating instructional
material. Thus, our findings suggest that human-in-the-loop approaches hold
promise for supporting plan-focused pedagogies at scale.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.10338v1' target='_blank'>Evaluating the Meta- and Object-Level Reasoning of Large Language Models
  for Question Answering</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nick Ferguson, Liane Guillou, Alan Bundy, Kwabena Nuamah</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-14 17:55:43</h6>
<p class='card-text'>Large Language Models (LLMs) excel in natural language tasks but still face
challenges in Question Answering (QA) tasks requiring complex, multi-step
reasoning. We outline the types of reasoning required in some of these tasks,
and reframe them in terms of meta-level reasoning (akin to high-level strategic
reasoning or planning) and object-level reasoning (embodied in lower-level
tasks such as mathematical reasoning). Franklin, a novel dataset with
requirements of meta- and object-level reasoning, is introduced and used along
with three other datasets to evaluate four LLMs at question answering tasks
requiring multiple steps of reasoning. Results from human annotation studies
suggest LLMs demonstrate meta-level reasoning with high frequency, but struggle
with object-level reasoning tasks in some of the datasets used. Additionally,
evidence suggests that LLMs find the object-level reasoning required for the
questions in the Franklin dataset challenging, yet they do exhibit strong
performance with respect to the meta-level reasoning requirements.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.10148v1' target='_blank'>Cooperative Multi-Agent Planning with Adaptive Skill Synthesis</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhiyuan Li, Wenshuai Zhao, Joni Pajarinen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-14 13:23:18</h6>
<p class='card-text'>Despite much progress in training distributed artificial intelligence (AI),
building cooperative multi-agent systems with multi-agent reinforcement
learning (MARL) faces challenges in sample efficiency, interpretability, and
transferability. Unlike traditional learning-based methods that require
extensive interaction with the environment, large language models (LLMs)
demonstrate remarkable capabilities in zero-shot planning and complex
reasoning. However, existing LLM-based approaches heavily rely on text-based
observations and struggle with the non-Markovian nature of multi-agent
interactions under partial observability. We present COMPASS, a novel
multi-agent architecture that integrates vision-language models (VLMs) with a
dynamic skill library and structured communication for decentralized
closed-loop decision-making. The skill library, bootstrapped from
demonstrations, evolves via planner-guided tasks to enable adaptive strategies.
COMPASS propagates entity information through multi-hop communication under
partial observability. Evaluations on the improved StarCraft Multi-Agent
Challenge (SMACv2) demonstrate COMPASS achieves up to 30\% higher win rates
than state-of-the-art MARL algorithms in symmetric scenarios.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.10050v1' target='_blank'>A Survey on LLM-powered Agents for Recommender Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Qiyao Peng, Hongtao Liu, Hua Huang, Qing Yang, Minglai Shao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-14 09:57:07</h6>
<p class='card-text'>Recommender systems are essential components of many online platforms, yet
traditional approaches still struggle with understanding complex user
preferences and providing explainable recommendations. The emergence of Large
Language Model (LLM)-powered agents offers a promising approach by enabling
natural language interactions and interpretable reasoning, potentially
transforming research in recommender systems. This survey provides a systematic
review of the emerging applications of LLM-powered agents in recommender
systems. We identify and analyze three key paradigms in current research: (1)
Recommender-oriented approaches, which leverage intelligent agents to enhance
the fundamental recommendation mechanisms; (2) Interaction-oriented approaches,
which facilitate dynamic user engagement through natural dialogue and
interpretable suggestions; and (3) Simulation-oriented approaches, which employ
multi-agent frameworks to model complex user-item interactions and system
dynamics. Beyond paradigm categorization, we analyze the architectural
foundations of LLM-powered recommendation agents, examining their essential
components: profile construction, memory management, strategic planning, and
action execution. Our investigation extends to a comprehensive analysis of
benchmark datasets and evaluation frameworks in this domain. This systematic
examination not only illuminates the current state of LLM-powered agent
recommender systems but also charts critical challenges and promising research
directions in this transformative field.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.09980v2' target='_blank'>V2V-LLM: Vehicle-to-Vehicle Cooperative Autonomous Driving with
  Multi-Modal Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hsu-kuang Chiu, Ryo Hachiuma, Chien-Yi Wang, Stephen F. Smith, Yu-Chiang Frank Wang, Min-Hung Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-14 08:05:41</h6>
<p class='card-text'>Current autonomous driving vehicles rely mainly on their individual sensors
to understand surrounding scenes and plan for future trajectories, which can be
unreliable when the sensors are malfunctioning or occluded. To address this
problem, cooperative perception methods via vehicle-to-vehicle (V2V)
communication have been proposed, but they have tended to focus on detection
and tracking. How those approaches contribute to overall cooperative planning
performance is still under-explored. Inspired by recent progress using Large
Language Models (LLMs) to build autonomous driving systems, we propose a novel
problem setting that integrates an LLM into cooperative autonomous driving,
with the proposed Vehicle-to-Vehicle Question-Answering (V2V-QA) dataset and
benchmark. We also propose our baseline method Vehicle-to-Vehicle Large
Language Model (V2V-LLM), which uses an LLM to fuse perception information from
multiple connected autonomous vehicles (CAVs) and answer driving-related
questions: grounding, notable object identification, and planning. Experimental
results show that our proposed V2V-LLM can be a promising unified model
architecture for performing various tasks in cooperative autonomous driving,
and outperforms other baseline methods that use different fusion approaches.
Our work also creates a new research direction that can improve the safety of
future autonomous driving systems. Our project website:
https://eddyhkchiu.github.io/v2vllm.github.io/ .</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.09819v1' target='_blank'>A Solver-Aided Hierarchical Language for LLM-Driven CAD Design</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Benjamin T. Jones, Felix Hähnlein, Zihan Zhang, Maaz Ahmad, Vladimir Kim, Adriana Schulz</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-13 23:31:30</h6>
<p class='card-text'>Large language models (LLMs) have been enormously successful in solving a
wide variety of structured and unstructured generative tasks, but they struggle
to generate procedural geometry in Computer Aided Design (CAD). These
difficulties arise from an inability to do spatial reasoning and the necessity
to guide a model through complex, long range planning to generate complex
geometry. We enable generative CAD Design with LLMs through the introduction of
a solver-aided, hierarchical domain specific language (DSL) called AIDL, which
offloads the spatial reasoning requirements to a geometric constraint solver.
Additionally, we show that in the few-shot regime, AIDL outperforms even a
language with in-training data (OpenSCAD), both in terms of generating visual
results closer to the prompt and creating objects that are easier to
post-process and reason about.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.09787v1' target='_blank'>TableTalk: Scaffolding Spreadsheet Development with a Language Agent</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jenny T. Liang, Aayush Kumar, Yasharth Bajpai, Sumit Gulwani, Vu Le, Chris Parnin, Arjun Radhakrishna, Ashish Tiwari, Emerson Murphy-Hill, Guastavo Soares</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-13 21:43:51</h6>
<p class='card-text'>Despite its ubiquity in the workforce, spreadsheet programming remains
challenging as programmers need both spreadsheet-specific knowledge (e.g., APIs
to write formulas) and problem-solving skills to create complex spreadsheets.
Large language models (LLMs) can help automate aspects of this process, and
recent advances in planning and reasoning have enabled language agents, which
dynamically plan, use tools, and take iterative actions to complete complex
tasks. These agents observe, plan, and act, making them well-suited to scaffold
spreadsheet programming by following expert processes.
  We present TableTalk, a language agent that helps programmers build
spreadsheets conversationally. Its design reifies three design principles --
scaffolding, flexibility, and incrementality -- which we derived from two
studies of seven programmers and 62 Excel templates. TableTalk structures
spreadsheet development by generating step-by-step plans and suggesting three
next steps users can choose from. It also integrates tools that enable
incremental spreadsheet construction. A user study with 20 programmers shows
that TableTalk produces spreadsheets 2.3 times more likely to be preferred over
a baseline agent, while reducing cognitive load and time spent reasoning about
spreadsheet actions by 12.6%. TableTalk's approach has implications for
human-agent collaboration. This includes providing persistent direct
manipulation interfaces for stopping or undoing agent actions, while ensuring
that such interfaces for accepting actions can be deactivated.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.09749v1' target='_blank'>Vote-Tree-Planner: Optimizing Execution Order in LLM-based Task Planning
  Pipeline via Voting</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chaoyuan Zhang, Zhaowei Li, Wentao Yuan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-13 20:08:06</h6>
<p class='card-text'>Integrating large language models (LLMs) into closed-loop robotic task
planning has become increasingly popular within embodied artificial
intelligence. Previous efforts mainly focused on leveraging the strong
reasoning abilities of LLMs to enhance task planning performance while often
overlooking task planning efficiency and executability due to repetitive
queries to LLMs. This paper addresses the synergy between LLMs and task
planning systems, aiming to minimize redundancy while enhancing planning
effectiveness. Specifically, building upon Prog-Prompt and the high-level
concept of Tree-Planner, we propose Vote-Tree-Planner. This sampling strategy
utilizes votes to guide plan traversal during the decision-making process. Our
approach is motivated by a straightforward observation: assigning weights to
agents during decision-making enables the evaluation of critical paths before
execution. With this simple vote-tree construction, our method further improves
the success rate and reduces the number of queries to LLMs. The experimental
results highlight that our Vote-Tree-Planner demonstrates greater stability and
shows a higher average success rate and goal condition recall on the unseen
dataset compared with previous baseline methods. These findings underscore the
potential of the Vote-Tree-Planner to enhance planning accuracy, reliability,
and efficiency in LLM-based planning systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.09589v2' target='_blank'>Logical forms complement probability in understanding language model
  (and human) performance</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yixuan Wang, Freda Shi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-13 18:46:44</h6>
<p class='card-text'>With the increasing interest in using large language models (LLMs) for
planning in natural language, understanding their behaviors becomes an
important research question. This work conducts a systematic investigation of
LLMs' ability to perform logical reasoning in natural language. We introduce a
controlled dataset of hypothetical and disjunctive syllogisms in propositional
and modal logic and use it as the testbed for understanding LLM performance.
Our results lead to novel insights in predicting LLM behaviors: in addition to
the probability of input (Gonen et al., 2023; McCoy et al., 2024), logical
forms should be considered as important factors. In addition, we show
similarities and discrepancies between the logical reasoning performances of
humans and LLMs by collecting and comparing behavioral data from both.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.09334v1' target='_blank'>ThunderServe: High-performance and Cost-efficient LLM Serving in Cloud
  Environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Youhe Jiang, Fangcheng Fu, Xiaozhe Yao, Taiyi Wang, Bin Cui, Ana Klimovic, Eiko Yoneki</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-13 13:53:32</h6>
<p class='card-text'>Recent developments in large language models (LLMs) have demonstrated their
remarkable proficiency in a range of tasks. Compared to in-house homogeneous
GPU clusters, deploying LLMs in cloud environments with diverse types of GPUs
is crucial for addressing the GPU shortage problem and being more
cost-effective. However, the diversity of network environments and various GPU
types on the cloud bring difficulties to achieving high-performance serving. In
this work, we propose ThunderServe, a high-performance and cost-efficient LLM
serving system for heterogeneous cloud environments. We introduce a novel
scheduling algorithm, which optimizes the deployment plan of LLM serving to
accommodate the heterogeneous resource and network bandwidth conditions in
cloud environments. Furthermore, we propose a lightweight re-scheduling
mechanism, designed to adapt to fluctuating online conditions (e.g., node
failures, workload shifts) without the need for costly restarts of ongoing
services. Empirical results in both heterogeneous cloud and homogeneous
in-house environments reveal that ThunderServe delivers up to a 2.1$\times$ and
on average a $1.7\times$ increase in throughput and achieves up to a
2.5$\times$ and on average a $1.5\times$ reduction in latency deadlines
compared with state-of-the-art systems given the same price budget, suggesting
opting for cloud services provides a more cost-efficient solution.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.08073v1' target='_blank'>Large language models perpetuate bias in palliative care: development
  and analysis of the Palliative Care Adversarial Dataset (PCAD)</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Naomi Akhras, Fares Antaki, Fannie Mottet, Olivia Nguyen, Shyam Sawhney, Sabrina Bajwah, Joanna M Davies</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-12 02:29:52</h6>
<p class='card-text'>Bias and inequity in palliative care disproportionately affect marginalised
groups. Large language models (LLMs), such as GPT-4o, hold potential to enhance
care but risk perpetuating biases present in their training data. This study
aimed to systematically evaluate whether GPT-4o propagates biases in palliative
care responses using adversarially designed datasets. In July 2024, GPT-4o was
probed using the Palliative Care Adversarial Dataset (PCAD), and responses were
evaluated by three palliative care experts in Canada and the United Kingdom
using validated bias rubrics. The PCAD comprised PCAD-Direct (100 adversarial
questions) and PCAD-Counterfactual (84 paired scenarios). These datasets
targeted four care dimensions (access to care, pain management, advance care
planning, and place of death preferences) and three identity axes (ethnicity,
age, and diagnosis). Bias was detected in a substantial proportion of
responses. For adversarial questions, the pooled bias rate was 0.33 (95%
confidence interval [CI]: 0.28, 0.38); "allows biased premise" was the most
frequently identified source of bias (0.47; 95% CI: 0.39, 0.55), such as
failing to challenge stereotypes. For counterfactual scenarios, the pooled bias
rate was 0.26 (95% CI: 0.20, 0.31), with "potential for withholding" as the
most frequently identified source of bias (0.25; 95% CI: 0.18, 0.34), such as
withholding interventions based on identity. Bias rates were consistent across
care dimensions and identity axes. GPT-4o perpetuates biases in palliative
care, with implications for clinical decision-making and equity. The PCAD
datasets provide novel tools to assess and address LLM bias in palliative care.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.07960v1' target='_blank'>Accelerating Scientific Research Through a Multi-LLM Framework</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Joaquin Ramirez-Medina, Mohammadmehdi Ataei, Alidad Amirfazli</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-11 21:16:25</h6>
<p class='card-text'>The exponential growth of academic publications poses challenges for the
research process, such as literature review and procedural planning. Large
Language Models (LLMs) have emerged as powerful AI tools, especially when
combined with additional tools and resources. Recent LLM-powered frameworks
offer promising solutions for handling complex domain-specific tasks, yet their
domain-specific implementation limits broader applicability. This highlights
the need for LLM-integrated systems that can assist in cross-disciplinary
tasks, such as streamlining the research process across science and engineering
disciplines. To address this need, we introduce Artificial Research Innovator
Assistant (ARIA), a four-agent, multi-LLM framework. By emulating a team of
expert assistants, ARIA systematically replicates the human research workflow
to autonomously search, retrieve, and filter hundreds of papers, subsequently
synthesizing relevant literature into actionable research procedures. In a case
study on dropwise condensation enhancement, ARIA demonstrates its capability to
streamline research tasks within an hour, maintaining user oversight during
execution and ultimately liberating researchers from time-intensive tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.07772v1' target='_blank'>Automatic Robot Task Planning by Integrating Large Language Model with
  Genetic Programming</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Azizjon Kobilov, Jianglin Lan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-11 18:56:20</h6>
<p class='card-text'>Accurate task planning is critical for controlling autonomous systems, such
as robots, drones, and self-driving vehicles. Behavior Trees (BTs) are
considered one of the most prominent control-policy-defining frameworks in task
planning, due to their modularity, flexibility, and reusability. Generating
reliable and accurate BT-based control policies for robotic systems remains
challenging and often requires domain expertise. In this paper, we present the
LLM-GP-BT technique that leverages the Large Language Model (LLM) and Genetic
Programming (GP) to automate the generation and configuration of BTs. The
LLM-GP-BT technique processes robot task commands expressed in human natural
language and converts them into accurate and reliable BT-based task plans in a
computationally efficient and user-friendly manner. The proposed technique is
systematically developed and validated through simulation experiments,
demonstrating its potential to streamline task planning for autonomous systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.07864v2' target='_blank'>TransMLA: Multi-Head Latent Attention Is All You Need</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Fanxu Meng, Zengwei Yao, Muhan Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-11 18:20:18</h6>
<p class='card-text'>Modern large language models (LLMs) often encounter communication bottlenecks
on current hardware, rather than purely computational constraints. Multi-head
Latent Attention (MLA) tackles this challenge by using low-rank matrices in the
key-value (KV) layers, thereby allowing compressed latent KV states to be
cached. This approach significantly reduces the KV cache size relative to
traditional multi-head attention, leading to faster inference. Moreover, MLA
employs an up-projection matrix to increase expressiveness, trading additional
computation for reduced communication overhead. Although MLA has demonstrated
efficiency and effectiveness in Deepseek V2/V3/R1, many major model providers
still rely on Group Query Attention (GQA) and have not announced any plans to
adopt MLA. In this paper, we show that GQA can always be represented by MLA
while maintaining the same KV cache overhead, but the converse does not hold.
To encourage broader use of MLA, we introduce TransMLA, a post-training method
that converts widely used GQA-based pre-trained models (e.g., LLaMA, Qwen,
Mixtral) into MLA-based models. After conversion, the model can undergo
additional training to boost expressiveness without increasing the KV cache
size. Furthermore, we plan to develop MLA-specific inference acceleration
techniques to preserve low latency in transformed models, thus enabling more
efficient distillation of Deepseek R1.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.06772v1' target='_blank'>ReasonFlux: Hierarchical LLM Reasoning via Scaling Thought Templates</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ling Yang, Zhaochen Yu, Bin Cui, Mengdi Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-10 18:51:47</h6>
<p class='card-text'>We present that hierarchical LLM reasoning via scaling thought templates can
effectively optimize the reasoning search space and outperform the mathematical
reasoning capabilities of powerful LLMs like OpenAI o1-preview and DeepSeek V3.
We train our ReasonFlux-32B model with only 8 GPUs and introduces three
innovations: (i) a structured and generic thought template library, containing
around 500 high-level thought templates capable of generalizing to similar or
relevant reasoning problems; (ii) performing hierarchical reinforcement
learning on a sequence of thought templates instead of long CoTs, optimizing a
base LLM to plan out an optimal template trajectory for gradually handling
complex problems; (iii) a brand new inference scaling system that enables
hierarchical LLM reasoning by adaptively scaling thought templates at inference
time. With a template trajectory containing sequential thought templates, our
ReasonFlux-32B significantly advances math reasoning capabilities to
state-of-the-art levels. Notably, on the MATH benchmark, it achieves an
accuracy of 91.2% and surpasses o1-preview by 6.7%. On the USA Math Olympiad
(AIME) benchmark, ReasonFlux-32B solves an average of 56.7% of problems,
surpassing o1-preview and DeepSeek-V3 by 27% and 45%, respectively. Code:
https://github.com/Gen-Verse/ReasonFlux</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.06589v1' target='_blank'>Hephaestus: Improving Fundamental Agent Capabilities of Large Language
  Models through Continual Pre-Training</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuchen Zhuang, Jingfeng Yang, Haoming Jiang, Xin Liu, Kewei Cheng, Sanket Lokegaonkar, Yifan Gao, Qing Ping, Tianyi Liu, Binxuan Huang, Zheng Li, Zhengyang Wang, Pei Chen, Ruijie Wang, Rongzhi Zhang, Nasser Zalmout, Priyanka Nigam, Bing Yin, Chao Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-10 15:54:34</h6>
<p class='card-text'>Due to the scarcity of agent-oriented pre-training data, LLM-based autonomous
agents typically rely on complex prompting or extensive fine-tuning, which
often fails to introduce new capabilities while preserving strong
generalizability. We introduce Hephaestus-Forge, the first large-scale
pre-training corpus designed to enhance the fundamental capabilities of LLM
agents in API function calling, intrinsic reasoning and planning, and adapting
to environmental feedback. Hephaestus-Forge comprises 103B agent-specific data
encompassing 76,537 APIs, including both tool documentation to introduce
knowledge of API functions and function calling trajectories to strengthen
intrinsic reasoning. To explore effective training protocols, we investigate
scaling laws to identify the optimal recipe in data mixing ratios. By continual
pre-training on Hephaestus-Forge, Hephaestus outperforms small- to medium-scale
open-source LLMs and rivals commercial LLMs on three agent benchmarks,
demonstrating the effectiveness of our pre-training corpus in enhancing
fundamental agentic capabilities and generalization of LLMs to new tasks or
environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.06419v1' target='_blank'>Occ-LLM: Enhancing Autonomous Driving with Occupancy-Based Large
  Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tianshuo Xu, Hao Lu, Xu Yan, Yingjie Cai, Bingbing Liu, Yingcong Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-10 12:55:21</h6>
<p class='card-text'>Large Language Models (LLMs) have made substantial advancements in the field
of robotic and autonomous driving. This study presents the first
Occupancy-based Large Language Model (Occ-LLM), which represents a pioneering
effort to integrate LLMs with an important representation. To effectively
encode occupancy as input for the LLM and address the category imbalances
associated with occupancy, we propose Motion Separation Variational Autoencoder
(MS-VAE). This innovative approach utilizes prior knowledge to distinguish
dynamic objects from static scenes before inputting them into a tailored
Variational Autoencoder (VAE). This separation enhances the model's capacity to
concentrate on dynamic trajectories while effectively reconstructing static
scenes. The efficacy of Occ-LLM has been validated across key tasks, including
4D occupancy forecasting, self-ego planning, and occupancy-based scene question
answering. Comprehensive evaluations demonstrate that Occ-LLM significantly
surpasses existing state-of-the-art methodologies, achieving gains of about 6\%
in Intersection over Union (IoU) and 4\% in mean Intersection over Union (mIoU)
for the task of 4D occupancy forecasting. These findings highlight the
transformative potential of Occ-LLM in reshaping current paradigms within
robotic and autonomous driving.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.06258v1' target='_blank'>Emergent Response Planning in LLM</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhichen Dong, Zhanhui Zhou, Zhixuan Liu, Chao Yang, Chaochao Lu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-10 08:48:10</h6>
<p class='card-text'>In this work, we argue that large language models (LLMs), though trained to
predict only the next token, exhibit emergent planning behaviors:
$\textbf{their hidden representations encode future outputs beyond the next
token}$. Through simple probing, we demonstrate that LLM prompt representations
encode global attributes of their entire responses, including
$\textit{structural attributes}$ (response length, reasoning steps),
$\textit{content attributes}$ (character choices in storywriting,
multiple-choice answers at the end of response), and $\textit{behavioral
attributes}$ (answer confidence, factual consistency). In addition to
identifying response planning, we explore how it scales with model size across
tasks and how it evolves during generation. The findings that LLMs plan ahead
for the future in their hidden representations suggests potential applications
for improving transparency and generation control.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.05907v1' target='_blank'>EvoAgent: Agent Autonomous Evolution with Continual World Model for
  Long-Horizon Tasks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tongtong Feng, Xin Wang, Zekai Zhou, Ren Wang, Yuwei Zhan, Guangyao Li, Qing Li, Wenwu Zhu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-09 14:02:08</h6>
<p class='card-text'>Completing Long-Horizon (LH) tasks in open-ended worlds is an important yet
difficult problem for embodied agents. Existing approaches suffer from two key
challenges: (1) they heavily rely on experiences obtained from human-created
data or curricula, lacking the ability to continuously update multimodal
experiences, and (2) they may encounter catastrophic forgetting issues when
faced with new tasks, lacking the ability to continuously update world
knowledge. To solve these challenges, this paper presents EvoAgent, an
autonomous-evolving agent with a continual World Model (WM), which can
autonomously complete various LH tasks across environments through
self-planning, self-control, and self-reflection, without human intervention.
Our proposed EvoAgent contains three modules, i.e., i) the memory-driven
planner which uses an LLM along with the WM and interaction memory, to convert
LH tasks into executable sub-tasks; ii) the WM-guided action controller which
leverages WM to generate low-level actions and incorporates a self-verification
mechanism to update multimodal experiences; iii) the experience-inspired
reflector which implements a two-stage curriculum learning algorithm to select
experiences for task-adaptive WM updates. Moreover, we develop a continual
World Model for EvoAgent, which can continuously update the multimodal
experience pool and world knowledge through closed-loop dynamics. We conducted
extensive experiments on Minecraft, compared with existing methods, EvoAgent
can achieve an average success rate improvement of 105% and reduce ineffective
actions by more than 6x.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.05664v1' target='_blank'>CODESIM: Multi-Agent Code Generation and Problem Solving through
  Simulation-Driven Planning and Debugging</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Md. Ashraful Islam, Mohammed Eunus Ali, Md Rizwan Parvez</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-08 18:43:59</h6>
<p class='card-text'>Large Language Models (LLMs) have made significant strides in code generation
and problem solving. Current approaches employ external tool-based iterative
debuggers that use compiler or other tool-based runtime feedback to refine
coarse programs generated by various methods. However, the effectiveness of
these approaches heavily relies on the quality of the initial code generation,
which remains an open challenge. In this paper, we introduce CodeSim, a novel
multi-agent code generation framework that comprehensively addresses the stages
of program synthesis-planning, coding, and debugging-through a human-like
perception approach. As human verifies their understanding of any algorithms
through visual simulation, CodeSim uniquely features a method of plan
verification and internal debugging through the step-by-step simulation of
input/output. Extensive experiments across seven challenging competitive
problem-solving and program synthesis benchmarks demonstrate CodeSim's
remarkable code generation capabilities. Our framework achieves new
state-of-the-art (pass@1) results-(HumanEval 95.1%, MBPP 90.7%, APPS 22%, and
CodeContests 29.1%). Furthermore, our method shows potential for even greater
enhancement when cascaded with external debuggers. To facilitate further
research and development in this area, we have open-sourced our framework in
this link (https://kagnlp.github.io/codesim.github.io/).</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.05562v1' target='_blank'>Can Large Language Models Be Query Optimizer for Relational Databases?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jie Tan, Kangfei Zhao, Rui Li, Jeffrey Xu Yu, Chengzhi Piao, Hong Cheng, Helen Meng, Deli Zhao, Yu Rong</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-08 13:21:34</h6>
<p class='card-text'>Query optimization, which finds the optimized execution plan for a given
query, is a complex planning and decision-making problem within the
exponentially growing plan space in database management systems (DBMS).
Traditional optimizers heavily rely on a certain cost model constructed by
various heuristics and empirical tuning, probably leading to generating
suboptimal plans. Recent developments of Large Language Models (LLMs) have
demonstrated their potential in solving complex planning and decision-making
problems, such as arithmetic and programmatic tasks. In this paper, we try to
explore the potential of LLMs in handling query optimization and propose a
tentative LLM-based query optimizer dubbed LLM-QO, established on PostgreSQL's
execution engine. In LLM-QO, we formulate query optimization in an
autoregressive fashion which directly generates the execution plan without
explicit plan enumeration. To investigate the essential input of LLM-QO, we
design a customized data recipe named QInstruct to collect the training data
from various optimizers and serialize the database's meta data, queries and
corresponding plans into a textual format. Based on QInstruct, we implement a
two-stage fine-tuning pipeline, Query Instruction Tuning (QIT) and Query Direct
Preference Optimization (QDPO), to empower the capability of general-purpose
LLMs in handling query optimization. In our experiments, LLM-QO can generate
valid and high-quality plans and consistently outperforms both traditional and
learned optimizers on three query workloads. Our findings verify that LLMs can
be derived as query optimizers where generalization, efficiency and adaptivity
deserve further research efforts.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.05453v1' target='_blank'>LLM-Powered Decentralized Generative Agents with Adaptive Hierarchical
  Knowledge Graph for Cooperative Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hanqing Yang, Jingdi Chen, Marie Siew, Tania Lorido-Botran, Carlee Joe-Wong</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-08 05:26:02</h6>
<p class='card-text'>Developing intelligent agents for long-term cooperation in dynamic open-world
scenarios is a major challenge in multi-agent systems. Traditional Multi-agent
Reinforcement Learning (MARL) frameworks like centralized training
decentralized execution (CTDE) struggle with scalability and flexibility. They
require centralized long-term planning, which is difficult without custom
reward functions, and face challenges in processing multi-modal data. CTDE
approaches also assume fixed cooperation strategies, making them impractical in
dynamic environments where agents need to adapt and plan independently. To
address decentralized multi-agent cooperation, we propose Decentralized
Adaptive Knowledge Graph Memory and Structured Communication System (DAMCS) in
a novel Multi-agent Crafter environment. Our generative agents, powered by
Large Language Models (LLMs), are more scalable than traditional MARL agents by
leveraging external knowledge and language for long-term planning and
reasoning. Instead of fully sharing information from all past experiences,
DAMCS introduces a multi-modal memory system organized as a hierarchical
knowledge graph and a structured communication protocol to optimize agent
cooperation. This allows agents to reason from past interactions and share
relevant information efficiently. Experiments on novel multi-agent open-world
tasks show that DAMCS outperforms both MARL and LLM baselines in task
efficiency and collaboration. Compared to single-agent scenarios, the two-agent
scenario achieves the same goal with 63% fewer steps, and the six-agent
scenario with 74% fewer steps, highlighting the importance of adaptive memory
and structured communication in achieving long-term goals. We publicly release
our project at: https://happyeureka.github.io/damcs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.05368v1' target='_blank'>Otter: Generating Tests from Issues to Validate SWE Patches</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Toufique Ahmed, Jatin Ganhotra, Rangeet Pan, Avraham Shinnar, Saurabh Sinha, Martin Hirzel</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-07 22:41:31</h6>
<p class='card-text'>While there has been plenty of work on generating tests from existing code,
there has been limited work on generating tests from issues. A correct test
must validate the code patch that resolves the issue. In this work, we focus on
the scenario where the code patch does not exist yet. This approach supports
two major use-cases. First, it supports TDD (test-driven development), the
discipline of "test first, write code later" that has well-documented benefits
for human software engineers. Second, it also validates SWE (software
engineering) agents, which generate code patches for resolving issues. This
paper introduces Otter, an LLM-based solution for generating tests from issues.
Otter augments LLMs with rule-based analysis to check and repair their outputs,
and introduces a novel self-reflective action planning stage. Experiments show
Otter outperforming state-of-the-art systems for generating tests from issues,
in addition to enhancing systems that generate patches from issues. We hope
that Otter helps make developers more productive at resolving issues and leads
to more robust, well-tested code.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.05036v1' target='_blank'>nvAgent: Automated Data Visualization from Natural Language via
  Collaborative Agent Workflow</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Geliang Ouyang, Jingyao Chen, Zhihe Nie, Yi Gui, Yao Wan, Hongyu Zhang, Dongping Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-07 16:03:08</h6>
<p class='card-text'>Natural Language to Visualization (NL2Vis) seeks to convert natural-language
descriptions into visual representations of given tables, empowering users to
derive insights from large-scale data. Recent advancements in Large Language
Models (LLMs) show promise in automating code generation to transform tabular
data into accessible visualizations. However, they often struggle with complex
queries that require reasoning across multiple tables. To address this
limitation, we propose a collaborative agent workflow, termed nvAgent, for
NL2Vis. Specifically, nvAgent comprises three agents: a processor agent for
database processing and context filtering, a composer agent for planning
visualization generation, and a validator agent for code translation and output
verification. Comprehensive evaluations on the new VisEval benchmark
demonstrate that nvAgent consistently surpasses state-of-the-art baselines,
achieving a 7.88% improvement in single-table and a 9.23% improvement in
multi-table scenarios. Qualitative analyses further highlight that nvAgent
maintains nearly a 20% performance margin over previous models, underscoring
its capacity to produce high-quality visual representations from complex,
heterogeneous data sources.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.04728v1' target='_blank'>Generating Symbolic World Models via Test-time Scaling of Large Language
  Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhouliang Yu, Yuhuan Yuan, Tim Z. Xiao, Fuxiang Frank Xia, Jie Fu, Ge Zhang, Ge Lin, Weiyang Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-07 07:52:25</h6>
<p class='card-text'>Solving complex planning problems requires Large Language Models (LLMs) to
explicitly model the state transition to avoid rule violations, comply with
constraints, and ensure optimality-a task hindered by the inherent ambiguity of
natural language. To overcome such ambiguity, Planning Domain Definition
Language (PDDL) is leveraged as a planning abstraction that enables precise and
formal state descriptions. With PDDL, we can generate a symbolic world model
where classic searching algorithms, such as A*, can be seamlessly applied to
find optimal plans. However, directly generating PDDL domains with current LLMs
remains an open challenge due to the lack of PDDL training data. To address
this challenge, we propose to scale up the test-time computation of LLMs to
enhance their PDDL reasoning capabilities, thereby enabling the generation of
high-quality PDDL domains. Specifically, we introduce a simple yet effective
algorithm, which first employs a Best-of-N sampling approach to improve the
quality of the initial solution and then refines the solution in a fine-grained
manner with verbalized machine learning. Our method outperforms o1-mini by a
considerable margin in the generation of PDDL domain, achieving over 50%
success rate on two tasks (i.e., generating PDDL domains from natural language
description or PDDL problems). This is done without requiring additional
training. By taking advantage of PDDL as state abstraction, our method is able
to outperform current state-of-the-art methods on almost all competition-level
planning tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.04188v1' target='_blank'>Automated Microservice Pattern Instance Detection Using
  Infrastructure-as-Code Artifacts and Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Carlos Eduardo Duarte</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-06 16:22:14</h6>
<p class='card-text'>Documenting software architecture is essential to preserve architecture
knowledge, even though it is frequently costly. Architecture pattern instances,
including microservice pattern instances, provide important structural software
information. Practitioners should document this information to prevent
knowledge vaporization. However, architecture patterns may not be detectable by
analyzing source code artifacts, requiring the analysis of other types of
artifacts. Moreover, many existing pattern detection instance approaches are
complex to extend. This article presents our ongoing PhD research, early
experiments, and a prototype for a tool we call MicroPAD for automating the
detection of microservice pattern instances. The prototype uses Large Language
Models (LLMs) to analyze Infrastructure-as-Code (IaC) artifacts to aid
detection, aiming to keep costs low and maximize the scope of detectable
patterns. Early experiments ran the prototype thrice in 22 GitHub projects. We
verified that 83\% of the patterns that the prototype identified were in the
project. The costs of detecting the pattern instances were minimal. These
results indicate that the approach is likely viable and, by lowering the entry
barrier to automating pattern instance detection, could help democratize
developer access to this category of architecture knowledge. Finally, we
present our overall research methodology, planned future work, and an overview
of MicroPAD's potential industrial impact.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.03860v1' target='_blank'>BOLT: Bootstrap Long Chain-of-Thought in Language Models without
  Distillation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Bo Pang, Hanze Dong, Jiacheng Xu, Silvio Savarese, Yingbo Zhou, Caiming Xiong</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-06 08:19:59</h6>
<p class='card-text'>Large language models (LLMs), such as o1 from OpenAI, have demonstrated
remarkable reasoning capabilities. o1 generates a long chain-of-thought
(LongCoT) before answering a question. LongCoT allows LLMs to analyze problems,
devise plans, reflect, and backtrack effectively. These actions empower LLM to
solve complex problems. After the release of o1, many teams have attempted to
replicate its LongCoT and reasoning capabilities. In terms of methods, they
primarily rely on knowledge distillation with data from existing models with
LongCoT capacities (e.g., OpenAI-o1, Qwen-QwQ, DeepSeek-R1-Preview), leaving
significant uncertainties on systematically developing such reasoning
abilities. In terms of data domains, these works focus narrowly on math while a
few others include coding, limiting their generalizability. This paper
introduces a novel approach to enable LLM's LongCoT capacity without
distillation from o1-like models or expensive human annotations, where we
bootstrap LongCoT (BOLT) from a standard instruct model. BOLT involves three
stages: 1) LongCoT data bootstrapping with in-context learning on a standard
instruct model; 2) LongCoT supervised finetuning; 3) online training to further
refine LongCoT capacities. In BOLT, only a few in-context examples need to be
constructed during the bootstrapping stage; in our experiments, we created 10
examples, demonstrating the feasibility of this approach. We use
Llama-3.1-70B-Instruct to bootstrap LongCoT and apply our method to various
model scales (7B, 8B, 70B). We achieve impressive performance on a variety of
benchmarks, Arena-Hard, MT-Bench, WildBench, ZebraLogic, MATH500, which
evaluate diverse task-solving and reasoning capabilities.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.03814v3' target='_blank'>Large Language Models for Multi-Robot Systems: A Survey</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Peihan Li, Zijian An, Shams Abrar, Lifeng Zhou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-06 06:52:14</h6>
<p class='card-text'>The rapid advancement of Large Language Models (LLMs) has opened new
possibilities in Multi-Robot Systems (MRS), enabling enhanced communication,
task planning, and human-robot interaction. Unlike traditional single-robot and
multi-agent systems, MRS poses unique challenges, including coordination,
scalability, and real-world adaptability. This survey provides the first
comprehensive exploration of LLM integration into MRS. It systematically
categorizes their applications across high-level task allocation, mid-level
motion planning, low-level action generation, and human intervention. We
highlight key applications in diverse domains, such as household robotics,
construction, formation control, target tracking, and robot games, showcasing
the versatility and transformative potential of LLMs in MRS. Furthermore, we
examine the challenges that limit adapting LLMs in MRS, including mathematical
reasoning limitations, hallucination, latency issues, and the need for robust
benchmarking systems. Finally, we outline opportunities for future research,
emphasizing advancements in fine-tuning, reasoning techniques, and
task-specific models. This survey aims to guide researchers in the intelligence
and real-world deployment of MRS powered by LLMs. Based on the fast-evolving
nature of research in the field, we keep updating the papers in the open-source
Github repository.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.05227v1' target='_blank'>Robotouille: An Asynchronous Planning Benchmark for LLM Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Gonzalo Gonzalez-Pumariega, Leong Su Yean, Neha Sunkara, Sanjiban Choudhury</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-06 05:50:37</h6>
<p class='card-text'>Effective asynchronous planning, or the ability to efficiently reason and
plan over states and actions that must happen in parallel or sequentially, is
essential for agents that must account for time delays, reason over diverse
long-horizon tasks, and collaborate with other agents. While large language
model (LLM) agents show promise in high-level task planning, current benchmarks
focus primarily on short-horizon tasks and do not evaluate such asynchronous
planning capabilities. We introduce Robotouille, a challenging benchmark
environment designed to test LLM agents' ability to handle long-horizon
asynchronous scenarios. Our synchronous and asynchronous datasets capture
increasingly complex planning challenges that go beyond existing benchmarks,
requiring agents to manage overlapping tasks and interruptions. Our results
show that ReAct (gpt4-o) achieves 47% on synchronous tasks but only 11% on
asynchronous tasks, highlighting significant room for improvement. We further
analyze failure modes, demonstrating the need for LLM agents to better
incorporate long-horizon feedback and self-audit their reasoning during task
execution. Code is available at https://github.com/portal-cornell/robotouille.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.04392v1' target='_blank'>Division-of-Thoughts: Harnessing Hybrid Language Model Synergy for
  Efficient On-Device Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chenyang Shao, Xinyuan Hu, Yutang Lin, Fengli Xu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-06 02:40:25</h6>
<p class='card-text'>The rapid expansion of web content has made on-device AI assistants
indispensable for helping users manage the increasing complexity of online
tasks. The emergent reasoning ability in large language models offer a
promising path for next-generation on-device AI agents. However, deploying
full-scale Large Language Models (LLMs) on resource-limited local devices is
challenging. In this paper, we propose Division-of-Thoughts (DoT), a
collaborative reasoning framework leveraging the synergy between locally
deployed Smaller-scale Language Models (SLMs) and cloud-based LLMs. DoT
leverages a Task Decomposer to elicit the inherent planning abilities in
language models to decompose user queries into smaller sub-tasks, which allows
hybrid language models to fully exploit their respective strengths. Besides,
DoT employs a Task Scheduler to analyze the pair-wise dependency of sub-tasks
and create a dependency graph, facilitating parallel reasoning of sub-tasks and
the identification of key steps. To allocate the appropriate model based on the
difficulty of sub-tasks, DoT leverages a Plug-and-Play Adapter, which is an
additional task head attached to the SLM that does not alter the SLM's
parameters. To boost adapter's task allocation capability, we propose a
self-reinforced training method that relies solely on task execution feedback.
Extensive experiments on various benchmarks demonstrate that our DoT
significantly reduces LLM costs while maintaining competitive reasoning
accuracy. Specifically, DoT reduces the average reasoning time and API costs by
66.12% and 83.57%, while achieving comparable reasoning accuracy with the best
baseline methods.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.03568v2' target='_blank'>Code Simulation as a Proxy for High-order Tasks in Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Emanuele La Malfa, Christoph Weinhuber, Orazio Torre, Fangru Lin, X. Angelo Huang, Samuele Marro, Anthony Cohn, Nigel Shadbolt, Michael Wooldridge</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-05 19:30:28</h6>
<p class='card-text'>Many reasoning, planning, and problem-solving tasks share an intrinsic
algorithmic nature: correctly simulating each step is a sufficient condition to
solve them correctly. We collect pairs of naturalistic and synthetic reasoning
tasks to assess the capabilities of Large Language Models (LLM). While
naturalistic tasks often require careful human handcrafting, we show that
synthetic data is, in many cases, a good proxy that is much easier to collect
at scale. We leverage common constructs in programming as the counterpart of
the building blocks of naturalistic reasoning tasks, such as straight-line
programs, code that contains critical paths, and approximate and redundant
instructions. We further assess the capabilities of LLMs on sorting problems
and repeated operations via sorting algorithms and nested loops. Our synthetic
datasets further reveal that while the most powerful LLMs exhibit relatively
strong execution capabilities, the process is fragile: it is negatively
affected by memorisation and seems to rely heavily on pattern recognition. Our
contribution builds upon synthetically testing the reasoning capabilities of
LLMs as a scalable complement to handcrafted human-annotated problems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.03450v1' target='_blank'>A Schema-Guided Reason-while-Retrieve framework for Reasoning on Scene
  Graphs with Large-Language-Models (LLMs)</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yiye Chen, Harpreet Sawhney, Nicholas Gydé, Yanan Jian, Jack Saunders, Patricio Vela, Ben Lundell</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-05 18:50:38</h6>
<p class='card-text'>Scene graphs have emerged as a structured and serializable environment
representation for grounded spatial reasoning with Large Language Models
(LLMs). In this work, we propose SG-RwR, a Schema-Guided Retrieve-while-Reason
framework for reasoning and planning with scene graphs. Our approach employs
two cooperative, code-writing LLM agents: a (1) Reasoner for task planning and
information queries generation, and a (2) Retriever for extracting
corresponding graph information following the queries. Two agents collaborate
iteratively, enabling sequential reasoning and adaptive attention to graph
information. Unlike prior works, both agents are prompted only with the scene
graph schema rather than the full graph data, which reduces the hallucination
by limiting input tokens, and drives the Reasoner to generate reasoning trace
abstractly.Following the trace, the Retriever programmatically query the scene
graph data based on the schema understanding, allowing dynamic and global
attention on the graph that enhances alignment between reasoning and retrieval.
Through experiments in multiple simulation environments, we show that our
framework surpasses existing LLM-based approaches in numerical Q\&A and
planning tasks, and can benefit from task-level few-shot examples, even in the
absence of agent-level demonstrations. Project code will be released.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.03275v1' target='_blank'>Token Assorted: Mixing Latent and Text Tokens for Improved Language
  Model Reasoning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:DiJia Su, Hanlin Zhu, Yingchen Xu, Jiantao Jiao, Yuandong Tian, Qinqing Zheng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-05 15:33:00</h6>
<p class='card-text'>Large Language Models (LLMs) excel at reasoning and planning when trained on
chainof-thought (CoT) data, where the step-by-step thought process is
explicitly outlined by text tokens. However, this results in lengthy inputs
where many words support textual coherence rather than core reasoning
information, and processing these inputs consumes substantial computation
resources. In this work, we propose a hybrid representation of the reasoning
process, where we partially abstract away the initial reasoning steps using
latent discrete tokens generated by VQ-VAE, significantly reducing the length
of reasoning traces. We explore the use of latent trace abstractions in two
scenarios: 1) training the model from scratch for the Keys-Finding Maze
problem, 2) fine-tuning LLMs on this hybrid data with an extended vocabulary
including unseen latent tokens, for both logical and mathematical reasoning
problems. To facilitate effective learning, we introduce a simple training
procedure that randomly mixes latent and text tokens, which enables fast
adaptation to new latent tokens. Our approach consistently outperforms the
baselines methods in various benchmarks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.02747v1' target='_blank'>PatchPilot: A Stable and Cost-Efficient Agentic Patching Framework</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hongwei Li, Yuheng Tang, Shiqi Wang, Wenbo Guo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-04 22:30:02</h6>
<p class='card-text'>Recent research builds various patching agents that combine large language
models (LLMs) with non-ML tools and achieve promising results on the
state-of-the-art (SOTA) software patching benchmark, SWE-Bench. Based on how to
determine the patching workflows, existing patching agents can be categorized
as agent-based planning methods, which rely on LLMs for planning, and
human-based planning methods, which follow a pre-defined workflow. At a high
level, agent-based planning methods achieve high patching performance but with
a high cost and limited stability. Human-based planning methods, on the other
hand, are more stable and efficient but have key workflow limitations that
compromise their patching performance. In this paper, we propose PatchPilot, an
agentic patcher that strikes a balance between patching efficacy, stability,
and cost-efficiency. PatchPilot proposes a novel human-based planning workflow
with five components: reproduction, localization, generation, validation, and
refinement (where refinement is unique to PatchPilot). We introduce novel and
customized designs to each component to optimize their effectiveness and
efficiency. Through extensive experiments on the SWE-Bench benchmarks,
PatchPilot shows a superior performance than existing open-source methods while
maintaining low cost (less than 1$ per instance) and ensuring higher stability.
We also conduct a detailed ablation study to validate the key designs in each
component.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.06813v1' target='_blank'>Policy Guided Tree Search for Enhanced LLM Reasoning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yang Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-04 22:08:20</h6>
<p class='card-text'>Despite their remarkable capabilities, large language models often struggle
with tasks requiring complex reasoning and planning. While existing approaches
like Chain-of-Thought prompting and tree search techniques show promise, they
are limited by their reliance on predefined heuristics and computationally
expensive exploration strategies. We propose Policy-Guided Tree Search (PGTS),
a framework that combines reinforcement learning with structured tree
exploration to efficiently navigate reasoning paths. Our key innovation is a
learned policy that dynamically decides between expanding, branching,
backtracking, or terminating exploration, eliminating the need for manual
heuristics or exhaustive search. Experiments across mathematical reasoning,
logical deduction, and planning benchmarks demonstrate that PGTS achieves
superior reasoning performance while significantly reducing computational costs
compared to existing methods. These results establish PGTS as a scalable and
effective solution for tackling complex reasoning tasks with LLMs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.02145v1' target='_blank'>Risk-Aware Driving Scenario Analysis with Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuan Gao, Mattia Piccinini, Johannes Betz</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-04 09:19:13</h6>
<p class='card-text'>Large Language Models (LLMs) can capture nuanced contextual relationships,
reasoning, and complex problem-solving. By leveraging their ability to process
and interpret large-scale information, LLMs have shown potential to address
domain-specific challenges, including those in autonomous driving systems. This
paper proposes a novel framework that leverages LLMs for risk-aware analysis of
generated driving scenarios. We hypothesize that LLMs can effectively evaluate
whether driving scenarios generated by autonomous driving testing simulators
are safety-critical. To validate this hypothesis, we conducted an empirical
evaluation to assess the effectiveness of LLMs in performing this task. This
framework will also provide feedback to generate the new safety-critical
scenario by using adversarial method to modify existing non-critical scenarios
and test their effectiveness in validating motion planning algorithms. Code and
scenarios are available at:
https://github.com/yuangao-tum/Riskaware-Scenario-analyse</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.02066v1' target='_blank'>Anticipate & Act : Integrating LLMs and Classical Planning for Efficient
  Task Execution in Household Environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Raghav Arora, Shivam Singh, Karthik Swaminathan, Ahana Datta, Snehasis Banerjee, Brojeshwar Bhowmick, Krishna Murthy Jatavallabhula, Mohan Sridharan, Madhava Krishna</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-04 07:31:55</h6>
<p class='card-text'>Assistive agents performing household tasks such as making the bed or cooking
breakfast often compute and execute actions that accomplish one task at a time.
However, efficiency can be improved by anticipating upcoming tasks and
computing an action sequence that jointly achieves these tasks.
State-of-the-art methods for task anticipation use data-driven deep networks
and Large Language Models (LLMs), but they do so at the level of high-level
tasks and/or require many training examples. Our framework leverages the
generic knowledge of LLMs through a small number of prompts to perform
high-level task anticipation, using the anticipated tasks as goals in a
classical planning system to compute a sequence of finer-granularity actions
that jointly achieve these goals. We ground and evaluate our framework's
abilities in realistic scenarios in the VirtualHome environment and demonstrate
a 31% reduction in execution time compared with a system that does not consider
upcoming tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.02048v1' target='_blank'>Efficient Domain Adaptation of Multimodal Embeddings using Constrastive
  Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Georgios Margaritis, Periklis Petridis, Dimitris J. Bertsimas</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-04 06:30:12</h6>
<p class='card-text'>Recent advancements in machine learning (ML), natural language processing
(NLP), and foundational models have shown promise for real-life applications in
critical, albeit compute-constrainted fields like healthcare.
  In such areas, combining foundational models with supervised ML offers
potential for automating tasks like diagnosis and treatment planning, but the
limited availability of onsite computational resources pose significant
challenges before applying these technologies effectively: Current approaches
either yield subpar results when using pretrained models without task-specific
adaptation, or require substantial computational resources for fine-tuning,
which is often a barrier to entry in such environments.
  This renders them inaccessible in applications where performance and quality
standards are high, but computational resources are scarce.
  To bridge the gap between best-in-class performance and accessibility, we
propose a novel method for adapting foundational, multimodal embeddings to
downstream tasks, without the need of expensive fine-tuning processes.
  Our method leverages frozen embeddings from Large Language Models (LLMs) and
Vision Models, and uses contrastive learning to train a small, task-specific
nonlinear projection that can be used in the downstream task, without having to
fine-tune the original foundational models.
  We show that this efficient procedure leads to significant performance
improvements across various downstream tasks, and perhaps more importantly with
minimal computational overhead, offering a practical solution for the use of
advanced, foundational ML models in resource-constrained settings.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.02025v1' target='_blank'>From Accidents to Insights: Leveraging Multimodal Data for
  Scenario-Driven ADS Testing</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Siwei Luo, Yang Zhang, Yao Deng, Xi Zheng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-04 05:21:29</h6>
<p class='card-text'>The rapid advancements in Autonomous Driving Systems (ADS) have necessitated
robust software testing to ensure safety and reliability. However, automating
the generation of scalable and concrete test scenarios remains a significant
challenge. Current scenario-based test case generation methods often face
limitations, such as unrealistic scenes and inaccurate vehicle trajectories.
These challenges largely result from the loss of map information during data
extraction and the lack of an effective verification mechanism to mitigate
hallucinations in large language models (LLMs). This paper introduces TRACE, a
scenario-based ADS Test case Generation framework for Critical Scenarios. By
leveraging multimodal data to extract challenging scenarios from real-world car
crash reports, TRACE constructs numerous critical test cases with less data,
significantly enhancing ADS bug detection efficiency. Using in-context
learning, chain-of-thought prompting, and self-validation approaches, we use
LLMs to extract environmental and road network information from crash reports.
For vehicle trajectory planning, data containing map information and vehicle
coordinates serves as a knowledge base to build a ChatGPT-based LLM with
path-planning capabilities, which we named TrackMate. Based on 50 existing
crash reports, our approach successfully tested three ADS models across two
simulation platforms, MetaDrive and BeamNG. Of the 290 constructed test
scenarios, 127 are identified as critical, as they resulted in vehicle
collisions. Additionally, user feedback reveals that TRACE demonstrates
superior scenario reconstruction accuracy, with 77.5% of the scenarios being
rated as 'mostly or 'totally' consistent, compared to only 27% for the most
related SOTA, LCTGen.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.01822v1' target='_blank'>Firewalls to Secure Dynamic LLM Agentic Networks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sahar Abdelnabi, Amr Gomaa, Eugene Bagdasarian, Per Ola Kristensson, Reza Shokri</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-03 21:00:14</h6>
<p class='card-text'>Future LLM agents are likely to communicate on behalf of users with other
entity-representing agents on tasks that entail long-horizon plans with
interdependent goals. Current work does not focus on such agentic networks, nor
does it address their challenges. Thus, we first identify the required
properties of agents' communication, which should be proactive and adaptable.
It needs to satisfy 1) privacy: agents should not share more than what is
needed for the task, and 2) security: the communication must preserve integrity
and maintain utility against selfish entities. We design a use case (travel
planning) as a testbed that exemplifies these requirements, and we show
examples of how this can go wrong. Next, we propose a practical design,
inspired by established network security principles, for constrained LLM
agentic networks that balance adaptability, security, and privacy. Our
framework automatically constructs and updates task-specific rules from prior
simulations to build firewalls. We offer layers of defense to 1) convert
free-form input to a task-specific protocol, 2) dynamically abstract users'
data to a task-specific degree of permissiveness, and 3) self-correct the
agents' trajectory.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.01390v1' target='_blank'>Plan-Then-Execute: An Empirical Study of User Trust and Team Performance
  When Using LLM Agents As A Daily Assistant</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Gaole He, Gianluca Demartini, Ujwal Gadiraju</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-03 14:23:22</h6>
<p class='card-text'>Since the explosion in popularity of ChatGPT, large language models (LLMs)
have continued to impact our everyday lives. Equipped with external tools that
are designed for a specific purpose (e.g., for flight booking or an alarm
clock), LLM agents exercise an increasing capability to assist humans in their
daily work. Although LLM agents have shown a promising blueprint as daily
assistants, there is a limited understanding of how they can provide daily
assistance based on planning and sequential decision making capabilities. We
draw inspiration from recent work that has highlighted the value of
'LLM-modulo' setups in conjunction with humans-in-the-loop for planning tasks.
We conducted an empirical study (N = 248) of LLM agents as daily assistants in
six commonly occurring tasks with different levels of risk typically associated
with them (e.g., flight ticket booking and credit card payments). To ensure
user agency and control over the LLM agent, we adopted LLM agents in a
plan-then-execute manner, wherein the agents conducted step-wise planning and
step-by-step execution in a simulation environment. We analyzed how user
involvement at each stage affects their trust and collaborative team
performance. Our findings demonstrate that LLM agents can be a double-edged
sword -- (1) they can work well when a high-quality plan and necessary user
involvement in execution are available, and (2) users can easily mistrust the
LLM agents with plans that seem plausible. We synthesized key insights for
using LLM agents as daily assistants to calibrate user trust and achieve better
overall task outcomes. Our work has important implications for the future
design of daily assistants and human-AI collaboration with LLM agents.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.01081v1' target='_blank'>The Jumping Reasoning Curve? Tracking the Evolution of Reasoning
  Performance in GPT-[n] and o-[n] Models on Multimodal Puzzles</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Vernon Y. H. Toh, Yew Ken Chia, Deepanway Ghosal, Soujanya Poria</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-03 05:47:04</h6>
<p class='card-text'>The releases of OpenAI's o1 and o3 mark a significant paradigm shift in Large
Language Models towards advanced reasoning capabilities. Notably, o3
outperformed humans in novel problem-solving and skill acquisition on the
Abstraction and Reasoning Corpus for Artificial General Intelligence (ARC-AGI).
However, this benchmark is limited to symbolic patterns, whereas humans often
perceive and reason about multimodal scenarios involving both vision and
language data. Thus, there is an urgent need to investigate advanced reasoning
capabilities in multimodal tasks. To this end, we track the evolution of the
GPT-[n] and o-[n] series models on challenging multimodal puzzles, requiring
fine-grained visual perception with abstract or algorithmic reasoning. The
superior performance of o1 comes at nearly 750 times the computational cost of
GPT-4o, raising concerns about its efficiency. Our results reveal a clear
upward trend in reasoning capabilities across model iterations, with notable
performance jumps across GPT-series models and subsequently to o1. Nonetheless,
we observe that the o1 model still struggles with simple multimodal puzzles
requiring abstract reasoning. Furthermore, its performance in algorithmic
puzzles remains poor. We plan to continuously track new models in the series
and update our results in this paper accordingly. All resources used in this
evaluation are openly available https://github.com/declare-lab/LLM-PuzzleTest.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.00988v1' target='_blank'>PlotGen: Multi-Agent LLM-based Scientific Data Visualization via
  Multimodal Feedback</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kanika Goswami, Puneet Mathur, Ryan Rossi, Franck Dernoncourt</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-03 02:00:29</h6>
<p class='card-text'>Scientific data visualization is pivotal for transforming raw data into
comprehensible visual representations, enabling pattern recognition,
forecasting, and the presentation of data-driven insights. However, novice
users often face difficulties due to the complexity of selecting appropriate
tools and mastering visualization techniques. Large Language Models (LLMs) have
recently demonstrated potential in assisting code generation, though they
struggle with accuracy and require iterative debugging. In this paper, we
propose PlotGen, a novel multi-agent framework aimed at automating the creation
of precise scientific visualizations. PlotGen orchestrates multiple LLM-based
agents, including a Query Planning Agent that breaks down complex user requests
into executable steps, a Code Generation Agent that converts pseudocode into
executable Python code, and three retrieval feedback agents - a Numeric
Feedback Agent, a Lexical Feedback Agent, and a Visual Feedback Agent - that
leverage multimodal LLMs to iteratively refine the data accuracy, textual
labels, and visual correctness of generated plots via self-reflection.
Extensive experiments show that PlotGen outperforms strong baselines, achieving
a 4-6 percent improvement on the MatPlotBench dataset, leading to enhanced user
trust in LLM-generated visualizations and improved novice productivity due to a
reduction in debugging time needed for plot errors.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.00969v1' target='_blank'>Wizard of Shopping: Target-Oriented E-commerce Dialogue Generation with
  Decision Tree Branching</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xiangci Li, Zhiyu Chen, Jason Ingyu Choi, Nikhita Vedula, Besnik Fetahu, Oleg Rokhlenko, Shervin Malmasi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-03 00:27:13</h6>
<p class='card-text'>The goal of conversational product search (CPS) is to develop an intelligent,
chat-based shopping assistant that can directly interact with customers to
understand shopping intents, ask clarification questions, and find relevant
products. However, training such assistants is hindered mainly due to the lack
of reliable and large-scale datasets. Prior human-annotated CPS datasets are
extremely small in size and lack integration with real-world product search
systems. We propose a novel approach, TRACER, which leverages large language
models (LLMs) to generate realistic and natural conversations for different
shopping domains. TRACER's novelty lies in grounding the generation to dialogue
plans, which are product search trajectories predicted from a decision tree
model, that guarantees relevant product discovery in the shortest number of
search conditions. We also release the first target-oriented CPS dataset Wizard
of Shopping (WoS), containing highly natural and coherent conversations (3.6k)
from three shopping domains. Finally, we demonstrate the quality and
effectiveness of WoS via human evaluations and downstream tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.00963v1' target='_blank'>PDE-Controller: LLMs for Autoformalization and Reasoning of PDEs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mauricio Soroco, Jialin Song, Mengzhou Xia, Kye Emond, Weiran Sun, Wuyang Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-03 00:03:41</h6>
<p class='card-text'>While recent AI-for-math has made strides in pure mathematics, areas of
applied mathematics, particularly PDEs, remain underexplored despite their
significant real-world applications. We present PDE-Controller, a framework
that enables large language models (LLMs) to control systems governed by
partial differential equations (PDEs). Our approach enables LLMs to transform
informal natural language instructions into formal specifications, and then
execute reasoning and planning steps to improve the utility of PDE control. We
build a holistic solution comprising datasets (both human-written cases and 2
million synthetic samples), math-reasoning models, and novel evaluation
metrics, all of which require significant effort. Our PDE-Controller
significantly outperforms prompting the latest open-source and GPT models in
reasoning, autoformalization, and program synthesis, achieving up to a 62%
improvement in utility gain for PDE control. By bridging the gap between
language generation and PDE systems, we demonstrate the potential of LLMs in
addressing complex scientific and engineering challenges. We will release all
data, model checkpoints, and code at https://pde-controller.github.io/.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.00722v1' target='_blank'>Demystifying Cost-Efficiency in LLM Serving over Heterogeneous GPUs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Youhe Jiang, Fangcheng Fu, Xiaozhe Yao, Guoliang He, Xupeng Miao, Ana Klimovic, Bin Cui, Binhang Yuan, Eiko Yoneki</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-02 08:44:43</h6>
<p class='card-text'>Recent advancements in Large Language Models (LLMs) have led to increasingly
diverse requests, accompanied with varying resource (compute and memory)
demands to serve them. However, this in turn degrades the cost-efficiency of
LLM serving as common practices primarily rely on homogeneous GPU resources. In
response to this problem, this work conducts a thorough study about serving
LLMs over heterogeneous GPU resources on cloud platforms. The rationale is that
different GPU types exhibit distinct compute and memory characteristics,
aligning well with the divergent resource demands of diverse requests.
Particularly, through comprehensive benchmarking, we discover that the
cost-efficiency of LLM serving can be substantially optimized by meticulously
determining GPU composition, deployment configurations, and workload
assignments. Subsequently, we design a scheduling algorithm via mixed-integer
linear programming, aiming at deducing the most cost-efficient serving plan
under the constraints of price budget and real-time GPU availability.
Remarkably, our approach effectively outperforms homogeneous and heterogeneous
baselines under a wide array of scenarios, covering diverse workload traces,
varying GPU availablilities, and multi-model serving. This casts new light on
more accessible and efficient LLM serving over heterogeneous cloud resources.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.00708v1' target='_blank'>PhiP-G: Physics-Guided Text-to-3D Compositional Scene Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Qixuan Li, Chao Wang, Zongjin He, Yan Peng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-02 07:47:03</h6>
<p class='card-text'>Text-to-3D asset generation has achieved significant optimization under the
supervision of 2D diffusion priors. However, when dealing with compositional
scenes, existing methods encounter several challenges: 1). failure to ensure
that composite scene layouts comply with physical laws; 2). difficulty in
accurately capturing the assets and relationships described in complex scene
descriptions; 3). limited autonomous asset generation capabilities among layout
approaches leveraging large language models (LLMs). To avoid these compromises,
we propose a novel framework for compositional scene generation, PhiP-G, which
seamlessly integrates generation techniques with layout guidance based on a
world model. Leveraging LLM-based agents, PhiP-G analyzes the complex scene
description to generate a scene graph, and integrating a multimodal 2D
generation agent and a 3D Gaussian generation method for targeted assets
creation. For the stage of layout, PhiP-G employs a physical pool with adhesion
capabilities and a visual supervision agent, forming a world model for layout
prediction and planning. Extensive experiments demonstrate that PhiP-G
significantly enhances the generation quality and physical rationality of the
compositional scenes. Notably, PhiP-G attains state-of-the-art (SOTA)
performance in CLIP scores, achieves parity with the leading methods in
generation quality as measured by the T$^3$Bench, and improves efficiency by
24x.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.00510v2' target='_blank'>Who's the MVP? A Game-Theoretic Evaluation Benchmark for Modular
  Attribution in LLM Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yingxuan Yang, Bo Huang, Siyuan Qi, Chao Feng, Haoyi Hu, Yuxuan Zhu, Jinbo Hu, Haoran Zhao, Ziyi He, Xiao Liu, Zongyu Wang, Lin Qiu, Xuezhi Cao, Xunliang Cai, Yong Yu, Weinan Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-01 18:07:34</h6>
<p class='card-text'>Large Language Model (LLM) agents frameworks often employ modular
architectures, incorporating components such as planning, reasoning, action
execution, and reflection to tackle complex tasks. However, quantifying the
contribution of each module to overall system performance remains a significant
challenge, impeding optimization and interpretability. To address this, we
introduce CapaBench (Capability-level Assessment Benchmark), an evaluation
framework grounded in cooperative game theory's Shapley Value, which
systematically measures the marginal impact of individual modules and their
interactions within an agent's architecture. By replacing default modules with
test variants across all possible combinations, CapaBench provides a principle
method for attributing performance contributions. Key contributions include:
(1) We are the first to propose a Shapley Value-based methodology for
quantifying the contributions of capabilities in LLM agents; (2) Modules with
high Shapley Values consistently lead to predictable performance gains when
combined, enabling targeted optimization; and (3) We build a multi-round
dataset of over 1,500 entries spanning diverse domains and practical task
scenarios, enabling comprehensive evaluation of agent capabilities. CapaBench
bridges the gap between component-level evaluation and holistic system
assessment, providing actionable insights for optimizing modular LLM agents and
advancing their deployment in complex, real-world scenarios.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.00322v1' target='_blank'>MODS: Moderating a Mixture of Document Speakers to Summarize Debatable
  Queries in Document Collections</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nishant Balepur, Alexa Siu, Nedim Lipka, Franck Dernoncourt, Tong Sun, Jordan Boyd-Graber, Puneet Mathur</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-01 05:08:14</h6>
<p class='card-text'>Query-focused summarization (QFS) gives a summary of documents to answer a
query. Past QFS work assumes queries have one answer, ignoring debatable ones
(Is law school worth it?). We introduce Debatable QFS (DQFS), a task to create
summaries that answer debatable queries via documents with opposing
perspectives; summaries must comprehensively cover all sources and balance
perspectives, favoring no side. These goals elude LLM QFS systems, which: 1)
lack structured content plans, failing to guide LLMs to write balanced
summaries, and 2) use the same query to retrieve contexts across documents,
failing to cover all perspectives specific to each document's content. To
overcome this, we design MODS, a multi-LLM framework mirroring human panel
discussions. MODS treats documents as individual Speaker LLMs and has a
Moderator LLM that picks speakers to respond to tailored queries for planned
topics. Speakers use tailored queries to retrieve relevant contexts from their
documents and supply perspectives, which are tracked in a rich outline,
yielding a content plan to guide the final summary. Experiments on
ConflictingQA with controversial web queries and DebateQFS, our new dataset of
debate queries from Debatepedia, show MODS beats SOTA by 38-59% in topic
paragraph coverage and balance, based on new citation metrics. Users also find
MODS's summaries to be readable and more balanced.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.19340v1' target='_blank'>Towards Adaptive Self-Improvement for Smarter Energy Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Alexander Sommer, Peter Bazan, Jonathan Fellerer, Behnam Babaeian, Reinhard German</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-31 17:40:08</h6>
<p class='card-text'>This paper introduces a hierarchical framework for decision-making and
optimization, leveraging Large Language Models (LLMs) for adaptive code
generation. Instead of direct decision-making, LLMs generate and refine
executable control policies through a meta-policy that guides task generation
and a base policy for operational actions. Applied to a simplified microgrid
scenario, the approach achieves up to 15 percent cost savings by iteratively
improving battery control strategies. The proposed methodology lays a
foundation for integrating LLM-based tools into planning and control tasks,
offering adaptable and scalable solutions for complex systems while addressing
challenges of uncertainty and reproducibility.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.19318v1' target='_blank'>MINDSTORES: Memory-Informed Neural Decision Synthesis for Task-Oriented
  Reinforcement in Embodied Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Anirudh Chari, Suraj Reddy, Aditya Tiwari, Richard Lian, Brian Zhou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-31 17:15:33</h6>
<p class='card-text'>While large language models (LLMs) have shown promising capabilities as
zero-shot planners for embodied agents, their inability to learn from
experience and build persistent mental models limits their robustness in
complex open-world environments like Minecraft. We introduce MINDSTORES, an
experience-augmented planning framework that enables embodied agents to build
and leverage mental models through natural interaction with their environment.
Drawing inspiration from how humans construct and refine cognitive mental
models, our approach extends existing zero-shot LLM planning by maintaining a
database of past experiences that informs future planning iterations. The key
innovation is representing accumulated experiences as natural language
embeddings of (state, task, plan, outcome) tuples, which can then be
efficiently retrieved and reasoned over by an LLM planner to generate insights
and guide plan refinement for novel states and tasks. Through extensive
experiments in the MineDojo environment, a simulation environment for agents in
Minecraft that provides low-level controls for Minecraft, we find that
MINDSTORES learns and applies its knowledge significantly better than existing
memory-based LLM planners while maintaining the flexibility and generalization
benefits of zero-shot approaches, representing an important step toward more
capable embodied AI systems that can learn continuously through natural
experience.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.19306v2' target='_blank'>SETS: Leveraging Self-Verification and Self-Correction for Improved
  Test-Time Scaling</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiefeng Chen, Jie Ren, Xinyun Chen, Chengrun Yang, Ruoxi Sun, Sercan Ö Arık</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-31 17:03:16</h6>
<p class='card-text'>Recent advancements in Large Language Models (LLMs) have created new
opportunities to enhance performance on complex reasoning tasks by leveraging
test-time computation. However, conventional approaches such as repeated
sampling with majority voting or reward model scoring, often face diminishing
returns as test-time compute scales, in addition to requiring costly
task-specific reward model training. In this paper, we present Self-Enhanced
Test-Time Scaling (SETS), a novel method that leverages the self-verification
and self-correction capabilities of recent advanced LLMs to overcome these
limitations. SETS integrates sampling, self-verification, and self-correction
into a unified framework, enabling efficient and scalable test-time computation
for improved capabilities at complex tasks. Through extensive experiments on
challenging planning and reasoning benchmarks, compared to the alternatives, we
demonstrate that SETS achieves significant performance improvements and more
favorable test-time scaling laws.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.19259v1' target='_blank'>Neuro-LIFT: A Neuromorphic, LLM-based Interactive Framework for
  Autonomous Drone FlighT at the Edge</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Amogh Joshi, Sourav Sanyal, Kaushik Roy</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-31 16:17:03</h6>
<p class='card-text'>The integration of human-intuitive interactions into autonomous systems has
been limited. Traditional Natural Language Processing (NLP) systems struggle
with context and intent understanding, severely restricting human-robot
interaction. Recent advancements in Large Language Models (LLMs) have
transformed this dynamic, allowing for intuitive and high-level communication
through speech and text, and bridging the gap between human commands and
robotic actions. Additionally, autonomous navigation has emerged as a central
focus in robotics research, with artificial intelligence (AI) increasingly
being leveraged to enhance these systems. However, existing AI-based navigation
algorithms face significant challenges in latency-critical tasks where rapid
decision-making is critical. Traditional frame-based vision systems, while
effective for high-level decision-making, suffer from high energy consumption
and latency, limiting their applicability in real-time scenarios. Neuromorphic
vision systems, combining event-based cameras and spiking neural networks
(SNNs), offer a promising alternative by enabling energy-efficient, low-latency
navigation. Despite their potential, real-world implementations of these
systems, particularly on physical platforms such as drones, remain scarce. In
this work, we present Neuro-LIFT, a real-time neuromorphic navigation framework
implemented on a Parrot Bebop2 quadrotor. Leveraging an LLM for natural
language processing, Neuro-LIFT translates human speech into high-level
planning commands which are then autonomously executed using event-based
neuromorphic vision and physics-driven planning. Our framework demonstrates its
capabilities in navigating in a dynamic environment, avoiding obstacles, and
adapting to human instructions in real-time.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.18817v1' target='_blank'>Bridging the Reasoning Gap: Small LLMs Can Plan with Generalised
  Strategies</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Andrey Borro, Patricia J Riddle, Michael W Barley, Michael J Witbrock</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-31 00:28:29</h6>
<p class='card-text'>Recent advancements in the reasoning skills of Large Language Models (LLMs)
demonstrate an increase in the ability of LLMs to solve simple planning tasks.
However, as long as the driving force behind improved reasoning capability is
the size and complexity of the model, the financial and computational costs
associated with running them will also increase. This trend raises questions
about continued accessibility and whether these improvements will increase at
the same pace as models continue to grow in size and expense. We propose two
approaches to enhance the reasoning ability of less resource-intensive LLMs.
(1) Provide them with a generalised strategy for solving tasks within a given
domain, generated by a more resource-intensive LLM. (2) Exploit their
cost-effectiveness by iteratively prompting these models to correct errors in
their proposed solutions. Our empirical results from planning and mathematical
reasoning tasks demonstrate that these methods improve the performance of less
resource-intensive LLMs to levels comparable with their more resource-intensive
counterparts, at a fraction of the cost. Additionally, we show that the
utilisation of generalised strategies in our experiments reduced the cost of
the less resource-intensive model by nearly 30 percent on average.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.18816v1' target='_blank'>Large Language Models as Common-Sense Heuristics</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Andrey Borro, Patricia J Riddle, Michael W Barley, Michael J Witbrock</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-31 00:26:38</h6>
<p class='card-text'>While systems designed for solving planning tasks vastly outperform Large
Language Models (LLMs) in this domain, they usually discard the rich semantic
information embedded within task descriptions. In contrast, LLMs possess
parametrised knowledge across a wide range of topics, enabling them to leverage
the natural language descriptions of planning tasks in their solutions.
However, current research in this direction faces challenges in generating
correct and executable plans. Furthermore, these approaches depend on the LLM
to output solutions in an intermediate language, which must be translated into
the representation language of the planning task. We introduce a novel planning
method, which leverages the parametrised knowledge of LLMs by using their
output as a heuristic for Hill-Climbing Search. This approach is further
enhanced by prompting the LLM to generate a solution estimate to guide the
search. Our method outperforms the task success rate of similar systems within
a common household environment by 22 percentage points, with consistently
executable plans. All actions are encoded in their original representation,
demonstrating that strong results can be achieved without an intermediate
language, thus eliminating the need for a translation step.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.18784v1' target='_blank'>LLM-Generated Heuristics for AI Planning: Do We Even Need
  Domain-Independence Anymore?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Alexander Tuisov, Yonatan Vernik, Alexander Shleyfman</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-30 22:21:12</h6>
<p class='card-text'>Domain-independent heuristics have long been a cornerstone of AI planning,
offering general solutions applicable across a wide range of tasks without
requiring domain-specific engineering. However, the advent of large language
models (LLMs) presents an opportunity to generate heuristics tailored to
specific planning problems, potentially challenging the necessity of domain
independence as a strict design principle. In this paper, we explore the use of
LLMs to automatically derive planning heuristics from task descriptions
represented as successor generators and goal tests written in general purpose
programming language. We investigate the trade-offs between domain-specific
LLM-generated heuristics and traditional domain-independent methods in terms of
computational efficiency and explainability. Our experiments demonstrate that
LLMs can create heuristics that achieve state-of-the-art performance on some
standard IPC domains, as well as their ability to solve problems that lack an
adequate Planning Domain Definition Language ({\sc pddl}) representation. We
discuss whether these results signify a paradigm shift and how they can
complement existing approaches.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.18733v1' target='_blank'>Integrating LMM Planners and 3D Skill Policies for Generalizable
  Manipulation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuelei Li, Ge Yan, Annabella Macaluso, Mazeyu Ji, Xueyan Zou, Xiaolong Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-30 20:19:01</h6>
<p class='card-text'>The recent advancements in visual reasoning capabilities of large multimodal
models (LMMs) and the semantic enrichment of 3D feature fields have expanded
the horizons of robotic capabilities. These developments hold significant
potential for bridging the gap between high-level reasoning from LMMs and
low-level control policies utilizing 3D feature fields. In this work, we
introduce LMM-3DP, a framework that can integrate LMM planners and 3D skill
Policies. Our approach consists of three key perspectives: high-level planning,
low-level control, and effective integration. For high-level planning, LMM-3DP
supports dynamic scene understanding for environment disturbances, a critic
agent with self-feedback, history policy memorization, and reattempts after
failures. For low-level control, LMM-3DP utilizes a semantic-aware 3D feature
field for accurate manipulation. In aligning high-level and low-level control
for robot actions, language embeddings representing the high-level policy are
jointly attended with the 3D feature field in the 3D transformer for seamless
integration. We extensively evaluate our approach across multiple skills and
long-horizon tasks in a real-world kitchen environment. Our results show a
significant 1.45x success rate increase in low-level control and an approximate
1.5x improvement in high-level planning accuracy compared to LLM-based
baselines. Demo videos and an overview of LMM-3DP are available at
https://lmm-3dp-release.github.io.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.18099v1' target='_blank'>Learning to Plan & Reason for Evaluation with Thinking-LLM-as-a-Judge</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Swarnadeep Saha, Xian Li, Marjan Ghazvininejad, Jason Weston, Tianlu Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-30 02:21:59</h6>
<p class='card-text'>LLM-as-a-Judge models generate chain-of-thought (CoT) sequences intended to
capture the step-bystep reasoning process that underlies the final evaluation
of a response. However, due to the lack of human annotated CoTs for evaluation,
the required components and structure of effective reasoning traces remain
understudied. Consequently, previous approaches often (1) constrain reasoning
traces to hand-designed components, such as a list of criteria, reference
answers, or verification questions and (2) structure them such that planning is
intertwined with the reasoning for evaluation. In this work, we propose
EvalPlanner, a preference optimization algorithm for Thinking-LLM-as-a-Judge
that first generates an unconstrained evaluation plan, followed by its
execution, and then the final judgment. In a self-training loop, EvalPlanner
iteratively optimizes over synthetically constructed evaluation plans and
executions, leading to better final verdicts. Our method achieves a new
state-of-the-art performance for generative reward models on RewardBench (with
a score of 93.9), despite being trained on fewer amount of, and synthetically
generated, preference pairs. Additional experiments on other benchmarks like
RM-Bench, JudgeBench, and FollowBenchEval further highlight the utility of both
planning and reasoning for building robust LLM-as-a-Judge reasoning models.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.17665v1' target='_blank'>Planning with Vision-Language Models and a Use Case in Robot-Assisted
  Teaching</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xuzhe Dang, Lada Kudláčková, Stefan Edelkamp</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-29 14:04:54</h6>
<p class='card-text'>Automating the generation of Planning Domain Definition Language (PDDL) with
Large Language Model (LLM) opens new research topic in AI planning,
particularly for complex real-world tasks. This paper introduces Image2PDDL, a
novel framework that leverages Vision-Language Models (VLMs) to automatically
convert images of initial states and descriptions of goal states into PDDL
problems. By providing a PDDL domain alongside visual inputs, Imasge2PDDL
addresses key challenges in bridging perceptual understanding with symbolic
planning, reducing the expertise required to create structured problem
instances, and improving scalability across tasks of varying complexity. We
evaluate the framework on various domains, including standard planning domains
like blocksworld and sliding tile puzzles, using datasets with multiple
difficulty levels. Performance is assessed on syntax correctness, ensuring
grammar and executability, and content correctness, verifying accurate state
representation in generated PDDL problems. The proposed approach demonstrates
promising results across diverse task complexities, suggesting its potential
for broader applications in AI planning. We will discuss a potential use case
in robot-assisted teaching of students with Autism Spectrum Disorder.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.17286v1' target='_blank'>Fine-Tuning Open-Source Large Language Models to Improve Their
  Performance on Radiation Oncology Tasks: A Feasibility Study to Investigate
  Their Potential Clinical Applications in Radiation Oncology</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Peilong Wang, Zhengliang Liu, Yiwei Li, Jason Holmes, Peng Shu, Lian Zhang, Xiang Li, Quanzheng Li, Brady S. Laughlin, Diego Santos Toesca, Sujay A. Vora, Samir H. Patel, Terence T. Sio, Tianming Liu, Wei Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-28 20:37:32</h6>
<p class='card-text'>Background: The radiation oncology clinical practice involves many steps
relying on the dynamic interplay of abundant text data. Large language models
have displayed remarkable capabilities in processing complex text information.
But their direct applications in specific fields like radiation oncology remain
underexplored.
  Purpose: This study aims to investigate whether fine-tuning LLMs with domain
knowledge can improve the performance on Task (1) treatment regimen generation,
Task (2) treatment modality selection (photon, proton, electron, or
brachytherapy), and Task (3) ICD-10 code prediction in radiation oncology.
  Methods: Data for 15,724 patient cases were extracted. Cases where patients
had a single diagnostic record, and a clearly identifiable primary treatment
plan were selected for preprocessing and manual annotation to have 7,903 cases
of the patient diagnosis, treatment plan, treatment modality, and ICD-10 code.
Each case was used to construct a pair consisting of patient diagnostics
details and an answer (treatment regimen, treatment modality, or ICD-10 code
respectively) for the supervised fine-tuning of these three tasks. Open source
LLaMA2-7B and Mistral-7B models were utilized for the fine-tuning with the
Low-Rank Approximations method. Accuracy and ROUGE-1 score were reported for
the fine-tuned models and original models. Clinical evaluation was performed on
Task (1) by radiation oncologists, while precision, recall, and F-1 score were
evaluated for Task (2) and (3). One-sided Wilcoxon signed-rank tests were used
to statistically analyze the results.
  Results: Fine-tuned LLMs outperformed original LLMs across all tasks with
p-value <= 0.001. Clinical evaluation demonstrated that over 60% of the
fine-tuned LLMs-generated treatment regimens were clinically acceptable.
Precision, recall, and F1-score showed improved performance of fine-tuned LLMs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.16899v1' target='_blank'>RDMM: Fine-Tuned LLM Models for On-Device Robotic Decision Making with
  Enhanced Contextual Awareness in Specific Domains</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shady Nasrat, Myungsu Kim, Seonil Lee, Jiho Lee, Yeoncheol Jang, Seung-joon Yi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-28 12:35:06</h6>
<p class='card-text'>Large language models (LLMs) represent a significant advancement in
integrating physical robots with AI-driven systems. We showcase the
capabilities of our framework within the context of the real-world household
competition. This research introduces a framework that utilizes RDMM (Robotics
Decision-Making Models), which possess the capacity for decision-making within
domain-specific contexts, as well as an awareness of their personal knowledge
and capabilities. The framework leverages information to enhance the autonomous
decision-making of the system. In contrast to other approaches, our focus is on
real-time, on-device solutions, successfully operating on hardware with as
little as 8GB of memory. Our framework incorporates visual perception models
equipping robots with understanding of their environment. Additionally, the
framework has integrated real-time speech recognition capabilities, thus
enhancing the human-robot interaction experience. Experimental results
demonstrate that the RDMM framework can plan with an 93\% accuracy.
Furthermore, we introduce a new dataset consisting of 27k planning instances,
as well as 1.3k text-image annotated samples derived from the competition. The
framework, benchmarks, datasets, and models developed in this work are publicly
available on our GitHub repository at https://github.com/shadynasrat/RDMM.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.16744v1' target='_blank'>LLM Assisted Anomaly Detection Service for Site Reliability Engineers:
  Enhancing Cloud Infrastructure Resilience</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nimesh Jha, Shuxin Lin, Srideepika Jayaraman, Kyle Frohling, Christodoulos Constantinides, Dhaval Patel</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-28 06:41:37</h6>
<p class='card-text'>This paper introduces a scalable Anomaly Detection Service with a
generalizable API tailored for industrial time-series data, designed to assist
Site Reliability Engineers (SREs) in managing cloud infrastructure. The service
enables efficient anomaly detection in complex data streams, supporting
proactive identification and resolution of issues. Furthermore, it presents an
innovative approach to anomaly modeling in cloud infrastructure by utilizing
Large Language Models (LLMs) to understand key components, their failure modes,
and behaviors. A suite of algorithms for detecting anomalies is offered in
univariate and multivariate time series data, including regression-based,
mixture-model-based, and semi-supervised approaches. We provide insights into
the usage patterns of the service, with over 500 users and 200,000 API calls in
a year. The service has been successfully applied in various industrial
settings, including IoT-based AI applications. We have also evaluated our
system on public anomaly benchmarks to show its effectiveness. By leveraging
it, SREs can proactively identify potential issues before they escalate,
reducing downtime and improving response times to incidents, ultimately
enhancing the overall customer experience. We plan to extend the system to
include time series foundation models, enabling zero-shot anomaly detection
capabilities.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.16698v1' target='_blank'>3D-MoE: A Mixture-of-Experts Multi-modal LLM for 3D Vision and Pose
  Diffusion via Rectified Flow</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yueen Ma, Yuzheng Zhuang, Jianye Hao, Irwin King</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-28 04:31:19</h6>
<p class='card-text'>3D vision and spatial reasoning have long been recognized as preferable for
accurately perceiving our three-dimensional world, especially when compared
with traditional visual reasoning based on 2D images. Due to the difficulties
in collecting high-quality 3D data, research in this area has only recently
gained momentum. With the advent of powerful large language models (LLMs),
multi-modal LLMs for 3D vision have been developed over the past few years.
However, most of these models focus primarily on the vision encoder for 3D
data. In this paper, we propose converting existing densely activated LLMs into
mixture-of-experts (MoE) models, which have proven effective for multi-modal
data processing. In addition to leveraging these models' instruction-following
capabilities, we further enable embodied task planning by attaching a diffusion
head, Pose-DiT, that employs a novel rectified flow diffusion scheduler.
Experimental results on 3D question answering and task-planning tasks
demonstrate that our 3D-MoE framework achieves improved performance with fewer
activated parameters.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.16689v2' target='_blank'>MACI: Multi-Agent Collaborative Intelligence for Adaptive Reasoning and
  Temporal Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Edward Y. Chang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-28 03:57:22</h6>
<p class='card-text'>Artificial intelligence requires deliberate reasoning, temporal awareness,
and effective constraint management, capabilities traditional LLMs often lack
due to their reliance on pattern matching, limited self-verification, and
inconsistent constraint handling. We introduce Multi-Agent Collaborative
Intelligence (MACI), a framework comprising three key components: 1) a
meta-planner (MP) that identifies, formulates, and refines all roles and
constraints of a task (e.g., wedding planning) while generating a dependency
graph, with common-sense augmentation to ensure realistic and practical
constraints; 2) a collection of agents to facilitate planning and address
task-specific requirements; and 3) a run-time monitor that manages plan
adjustments as needed. By decoupling planning from validation, maintaining
minimal agent context, and integrating common-sense reasoning, MACI overcomes
the aforementioned limitations and demonstrates robust performance in two
scheduling problems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.16607v1' target='_blank'>MCTS-SQL: An Effective Framework for Text-to-SQL with Monte Carlo Tree
  Search</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shuozhi Yuan, Liming Chen, Miaomiao Yuan, Jin Zhao, Haoran Peng, Wenming Guo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-28 00:52:23</h6>
<p class='card-text'>Text-to-SQL is a fundamental and longstanding problem in the NLP area, aiming
at converting natural language queries into SQL, enabling non-expert users to
operate databases. Recent advances in LLM have greatly improved text-to-SQL
performance. However, challenges persist, especially when dealing with complex
user queries. Current approaches (e.g., COT prompting and multi-agent
frameworks) rely on the ability of models to plan and generate SQL
autonomously, but controlling performance remains difficult. In addition, LLMs
are still prone to hallucinations. To alleviate these challenges, we designed a
novel MCTS-SQL to guide SQL generation iteratively. The approach generates SQL
queries through Monte Carlo Tree Search (MCTS) and a heuristic self-refinement
mechanism are used to enhance accuracy and reliability. Key components include
a schema selector for extracting relevant information and an MCTS-based
generator for iterative query refinement. Experimental results from the SPIDER
and BIRD benchmarks show that MCTS-SQL achieves state-of-the-art performance.
Specifically, on the BIRD development dataset, MCTS-SQL achieves an Execution
(EX) accuracy of 69.40% using GPT-4o as the base model and a significant
improvement when dealing with challenging tasks, with an EX of 51.48%, which is
3.41% higher than the existing method.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.16539v1' target='_blank'>Generalized Mission Planning for Heterogeneous Multi-Robot Teams via
  LLM-constructed Hierarchical Trees</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Piyush Gupta, David Isele, Enna Sachdeva, Pin-Hao Huang, Behzad Dariush, Kwonjoon Lee, Sangjae Bae</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-27 22:20:48</h6>
<p class='card-text'>We present a novel mission-planning strategy for heterogeneous multi-robot
teams, taking into account the specific constraints and capabilities of each
robot. Our approach employs hierarchical trees to systematically break down
complex missions into manageable sub-tasks. We develop specialized APIs and
tools, which are utilized by Large Language Models (LLMs) to efficiently
construct these hierarchical trees. Once the hierarchical tree is generated, it
is further decomposed to create optimized schedules for each robot, ensuring
adherence to their individual constraints and capabilities. We demonstrate the
effectiveness of our framework through detailed examples covering a wide range
of missions, showcasing its flexibility and scalability.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.16513v2' target='_blank'>Deception in LLMs: Self-Preservation and Autonomous Goals in Large
  Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sudarshan Kamath Barkur, Sigurd Schacht, Johannes Scholl</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-27 21:26:37</h6>
<p class='card-text'>Recent advances in Large Language Models (LLMs) have incorporated planning
and reasoning capabilities, enabling models to outline steps before execution
and provide transparent reasoning paths. This enhancement has reduced errors in
mathematical and logical tasks while improving accuracy. These developments
have facilitated LLMs' use as agents that can interact with tools and adapt
their responses based on new information.
  Our study examines DeepSeek R1, a model trained to output reasoning tokens
similar to OpenAI's o1. Testing revealed concerning behaviors: the model
exhibited deceptive tendencies and demonstrated self-preservation instincts,
including attempts of self-replication, despite these traits not being
explicitly programmed (or prompted). These findings raise concerns about LLMs
potentially masking their true objectives behind a facade of alignment. When
integrating such LLMs into robotic systems, the risks become tangible - a
physically embodied AI exhibiting deceptive behaviors and self-preservation
instincts could pursue its hidden objectives through real-world actions. This
highlights the critical need for robust goal specification and safety
frameworks before any physical implementation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.15901v1' target='_blank'>Robust Mobile Robot Path Planning via LLM-Based Dynamic Waypoint
  Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Muhammad Taha Tariq, Congqing Wang, Yasir Hussain</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-27 09:51:48</h6>
<p class='card-text'>Mobile robot path planning in complex environments remains a significant
challenge, especially in achieving efficient, safe and robust paths. The
traditional path planning techniques like DRL models typically trained for a
given configuration of the starting point and target positions, these models
only perform well when these conditions are satisfied. In this paper, we
proposed a novel path planning framework that embeds Large Language Models to
empower mobile robots with the capability of dynamically interpreting natural
language commands and autonomously generating efficient, collision-free
navigation paths. The proposed framework uses LLMs to translate high-level user
inputs into actionable waypoints while dynamically adjusting paths in response
to obstacles. We experimentally evaluated our proposed LLM-based approach
across three different environments of progressive complexity, showing the
robustness of our approach with llama3.1 model that outperformed other LLM
models in path planning time, waypoint generation success rate, and collision
avoidance. This underlines the promising contribution of LLMs for enhancing the
capability of mobile robots, especially when their operation involves complex
decisions in large and complex environments. Our framework has provided safer,
more reliable navigation systems and opened a new direction for the future
research. The source code of this work is publicly available on GitHub.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.15826v1' target='_blank'>MADP: Multi-Agent Deductive Planning for Enhanced Cognitive-Behavioral
  Mental Health Question Answer</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Qi Chen, Dexi Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-27 07:18:47</h6>
<p class='card-text'>The Mental Health Question Answer (MHQA) task requires the seeker and
supporter to complete the support process in one-turn dialogue. Given the
richness of help-seeker posts, supporters must thoroughly understand the
content and provide logical, comprehensive, and well-structured responses.
Previous works in MHQA mostly focus on single-agent approaches based on the
cognitive element of Cognitive Behavioral Therapy (CBT), but they overlook the
interactions among various CBT elements, such as emotion and cognition. This
limitation hinders the models' ability to thoroughly understand the distress of
help-seekers. To address this, we propose a framework named Multi-Agent
Deductive Planning (MADP), which is based on the interactions between the
various psychological elements of CBT. This method guides Large Language Models
(LLMs) to achieve a deeper understanding of the seeker's context and provide
more personalized assistance based on individual circumstances. Furthermore, we
construct a new dataset based on the MADP framework and use it to fine-tune
LLMs, resulting in a specialized model named MADP-LLM. We conduct extensive
experiments, including comparisons with multiple LLMs, human evaluations, and
automatic evaluations, to validate the effectiveness of the MADP framework and
MADP-LLM.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.15370v1' target='_blank'>Scaling Large Vision-Language Models for Enhanced Multimodal
  Comprehension In Biomedical Image Analysis</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Robinson Umeike, Neil Getty, Fangfang Xia, Rick Stevens</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-26 02:48:01</h6>
<p class='card-text'>Large language models (LLMs) have demonstrated immense capabilities in
understanding textual data and are increasingly being adopted to help
researchers accelerate scientific discovery through knowledge extraction
(information retrieval), knowledge distillation (summarizing key findings and
methodologies into concise forms), and knowledge synthesis (aggregating
information from multiple scientific sources to address complex queries,
generate hypothesis and formulate experimental plans). However, scientific data
often exists in both visual and textual modalities. Vision language models
(VLMs) address this by incorporating a pretrained vision backbone for
processing images and a cross-modal projector that adapts image tokens into the
LLM dimensional space, thereby providing richer multimodal comprehension.
Nevertheless, off-the-shelf VLMs show limited capabilities in handling
domain-specific data and are prone to hallucinations. We developed intelligent
assistants finetuned from LLaVA models to enhance multimodal understanding in
low-dose radiation therapy (LDRT)-a benign approach used in the treatment of
cancer-related illnesses. Using multilingual data from 42,673 articles, we
devise complex reasoning and detailed description tasks for visual question
answering (VQA) benchmarks. Our assistants, trained on 50,882 image-text pairs,
demonstrate superior performance over base models as evaluated using
LLM-as-a-judge approach, particularly in reducing hallucination and improving
domain-specific comprehension.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.15214v1' target='_blank'>Zero-shot Robotic Manipulation with Language-guided Instruction and
  Formal Task Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Junfeng Tang, Zihan Ye, Yuping Yan, Ziqi Zheng, Ting Gao, Yaochu Jin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-25 13:33:22</h6>
<p class='card-text'>Robotic manipulation is often challenging due to the long-horizon tasks and
the complex object relationships. A common solution is to develop a task and
motion planning framework that integrates planning for high-level task and
low-level motion. Recently, inspired by the powerful reasoning ability of Large
Language Models (LLMs), LLM-based planning approaches have achieved remarkable
progress. However, these methods still heavily rely on expert-specific
knowledge, often generating invalid plans for unseen and unfamiliar tasks. To
address this issue, we propose an innovative language-guided symbolic task
planning (LM-SymOpt) framework with optimization. It is the first expert-free
planning framework since we combine the world knowledge from LLMs with formal
reasoning, resulting in improved generalization capability to new tasks.
Specifically, differ to most existing work, our LM-SymOpt employs LLMs to
translate natural language instructions into symbolic representations, thereby
representing actions as high-level symbols and reducing the search space for
planning. Next, after evaluating the action probability of completing the task
using LLMs, a weighted random sampling method is introduced to generate
candidate plans. Their feasibility is assessed through symbolic reasoning and
their cost efficiency is then evaluated using trajectory optimization for
selecting the optimal planning. Our experimental results show that LM-SymOpt
outperforms existing LLM-based planning approaches.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.14654v2' target='_blank'>MedAgentBench: A Realistic Virtual EHR Environment to Benchmark Medical
  LLM Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yixing Jiang, Kameron C. Black, Gloria Geng, Danny Park, James Zou, Andrew Y. Ng, Jonathan H. Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-24 17:21:01</h6>
<p class='card-text'>Recent large language models (LLMs) have demonstrated significant
advancements, particularly in their ability to serve as agents thereby
surpassing their traditional role as chatbots. These agents can leverage their
planning and tool utilization capabilities to address tasks specified at a high
level. However, a standardized dataset to benchmark the agent capabilities of
LLMs in medical applications is currently lacking, making the evaluation of
LLMs on complex tasks in interactive healthcare environments challenging. To
address this gap, we introduce MedAgentBench, a broad evaluation suite designed
to assess the agent capabilities of large language models within medical
records contexts. MedAgentBench encompasses 300 patient-specific
clinically-derived tasks from 10 categories written by human physicians,
realistic profiles of 100 patients with over 700,000 data elements, a
FHIR-compliant interactive environment, and an accompanying codebase. The
environment uses the standard APIs and communication infrastructure used in
modern EMR systems, so it can be easily migrated into live EMR systems.
MedAgentBench presents an unsaturated agent-oriented benchmark that current
state-of-the-art LLMs exhibit some ability to succeed at. The best model
(Claude 3.5 Sonnet v2) achieves a success rate of 69.67%. However, there is
still substantial space for improvement which gives the community a next
direction to optimize. Furthermore, there is significant variation in
performance across task categories. MedAgentBench establishes this and is
publicly available at https://github.com/stanfordmlgroup/MedAgentBench ,
offering a valuable framework for model developers to track progress and drive
continuous improvements in the agent capabilities of large language models
within the medical domain.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.14497v2' target='_blank'>Evaluating and Improving Graph to Text Generation with Large Language
  Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jie He, Yijun Yang, Wanqiu Long, Deyi Xiong, Victor Gutierrez-Basulto, Jeff Z. Pan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-24 13:53:54</h6>
<p class='card-text'>Large language models (LLMs) have demonstrated immense potential across
various tasks. However, research for exploring and improving the capabilities
of LLMs in interpreting graph structures remains limited. To address this gap,
we conduct a comprehensive evaluation of prompting current open-source LLMs on
graph-to-text generation tasks. Although we explored the optimal prompting
strategies and proposed a novel and effective diversity-difficulty-based
few-shot sample selection method, we found that the improvements from
tuning-free approaches were incremental, as LLMs struggle with planning on
complex graphs, particularly those with a larger number of triplets. To further
improve LLMs in planning with graph sequences and grounding in truth, we
introduce a new graph-to-text dataset, PlanGTG, annotated with two sub-tasks:
reordering and attribution. Through extensive automatic and human evaluations,
we demonstrate significant improvements in the quality of generated text from
both few-shot learning and fine-tuning perspectives using the PlanGTG dataset.
Our study paves the way for new research directions in graph-to-text
generation. PlanGTG datasets can be found in https://github.com/probe2/kg_text.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.14304v2' target='_blank'>MASTER: A Multi-Agent System with LLM Specialized MCTS</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Bingzheng Gan, Yufan Zhao, Tianyi Zhang, Jing Huang, Yusu Li, Shu Xian Teo, Changwang Zhang, Wei Shi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-24 08:01:11</h6>
<p class='card-text'>Large Language Models (LLM) are increasingly being explored for
problem-solving tasks. However, their strategic planning capability is often
viewed with skepticism. Recent studies have incorporated the Monte Carlo Tree
Search (MCTS) algorithm to augment the planning capacity of LLM. Despite its
potential, MCTS relies on extensive sampling simulations to approximate the
true reward distribution, which leads to two primary issues. Firstly, MCTS is
effective for tasks like the Game of Go, where simulation results can yield
objective rewards (e.g., 1 for a win and 0 for a loss). However, for tasks such
as question answering, the result of a simulation is the answer to the
question, which cannot yield an objective reward without the ground truth.
Secondly, obtaining statistically significant reward estimations typically
requires a sample size exceeding 30 simulations, resulting in excessive token
usage and time consumption. To address these challenges, we present the
Multi-Agent System with Tactical Execution and Reasoning using LLM Specialized
MCTS (MASTER), a novel framework that coordinates agent recruitment and
communication through LLM specialized MCTS. This system autonomously adjusts
the number of agents based on task complexity and ensures focused communication
among them. Comprehensive experiments across various tasks demonstrate the
effectiveness of our proposed framework. It achieves 76% accuracy on HotpotQA
and 80% on WebShop, setting new state-of-the-art performance on these datasets.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.14179v1' target='_blank'>AI Chatbots as Professional Service Agents: Developing a Professional
  Identity</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wenwen Li, Kangwei Shi, Yidong Chai</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-24 02:12:08</h6>
<p class='card-text'>With the rapid expansion of large language model (LLM) applications, there is
an emerging shift in the role of LLM-based AI chatbots from serving merely as
general inquiry tools to acting as professional service agents. However,
current studies often overlook a critical aspect of professional service
agents: the act of communicating in a manner consistent with their professional
identities. This is of particular importance in the healthcare sector, where
effective communication with patients is essential for achieving professional
goals, such as promoting patient well-being by encouraging healthy behaviors.
To bridge this gap, we propose LAPI (LLM-based Agent with a Professional
Identity), a novel framework for designing professional service agent tailored
for medical question-and-answer (Q\&A) services, ensuring alignment with a
specific professional identity. Our method includes a theory-guided task
planning process that decomposes complex professional tasks into manageable
subtasks aligned with professional objectives and a pragmatic entropy method
designed to generate professional and ethical responses with low uncertainty.
Experiments on various LLMs show that the proposed approach outperforms
baseline methods, including few-shot prompting, chain-of-thought prompting,
across key metrics such as fluency, naturalness, empathy, patient-centricity,
and ROUGE-L scores. Additionally, the ablation study underscores the
contribution of each component to the overall effectiveness of the approach.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.14105v1' target='_blank'>MedSlice: Fine-Tuned Large Language Models for Secure Clinical Note
  Sectioning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Joshua Davis, Thomas Sounack, Kate Sciacca, Jessie M Brain, Brigitte N Durieux, Nicole D Agaronnik, Charlotta Lindvall</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-23 21:32:09</h6>
<p class='card-text'>Extracting sections from clinical notes is crucial for downstream analysis
but is challenging due to variability in formatting and labor-intensive nature
of manual sectioning. While proprietary large language models (LLMs) have shown
promise, privacy concerns limit their accessibility. This study develops a
pipeline for automated note sectioning using open-source LLMs, focusing on
three sections: History of Present Illness, Interval History, and Assessment
and Plan. We fine-tuned three open-source LLMs to extract sections using a
curated dataset of 487 progress notes, comparing results relative to
proprietary models (GPT-4o, GPT-4o mini). Internal and external validity were
assessed via precision, recall and F1 score. Fine-tuned Llama 3.1 8B
outperformed GPT-4o (F1=0.92). On the external validity test set, performance
remained high (F1= 0.85). Fine-tuned open-source LLMs can surpass proprietary
models in clinical note sectioning, offering advantages in cost, performance,
and accessibility.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.13766v2' target='_blank'>UGMathBench: A Diverse and Dynamic Benchmark for Undergraduate-Level
  Mathematical Reasoning with Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xin Xu, Jiaxin Zhang, Tianhao Chen, Zitong Chao, Jishan Hu, Can Yang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-23 15:46:43</h6>
<p class='card-text'>Large Language Models (LLMs) have made significant strides in mathematical
reasoning, underscoring the need for a comprehensive and fair evaluation of
their capabilities. However, existing benchmarks often fall short, either
lacking extensive coverage of undergraduate-level mathematical problems or
probably suffering from test-set contamination. To address these issues, we
introduce UGMathBench, a diverse and dynamic benchmark specifically designed
for evaluating undergraduate-level mathematical reasoning with LLMs.
UGMathBench comprises 5,062 problems across 16 subjects and 111 topics,
featuring 10 distinct answer types. Each problem includes three randomized
versions, with additional versions planned for release as leading open-source
LLMs become saturated in UGMathBench. Furthermore, we propose two key metrics:
effective accuracy (EAcc), which measures the percentage of correctly solved
problems across all three versions, and reasoning gap ($\Delta$), which
assesses reasoning robustness by calculating the difference between the average
accuracy across all versions and EAcc. Our extensive evaluation of 23 leading
LLMs reveals that the highest EAcc achieved is 56.3\% by OpenAI-o1-mini, with
large $\Delta$ values observed across different models. This highlights the
need for future research aimed at developing "large reasoning models" with high
EAcc and $\Delta = 0$. We anticipate that the release of UGMathBench, along
with its detailed evaluation codes, will serve as a valuable resource to
advance the development of LLMs in solving mathematical problems. Codes and
data are available at https://github.com/YangLabHKUST/UGMathBench</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.10411v1' target='_blank'>TrueReason: An Exemplar Personalised Learning System Integrating
  Reasoning with Foundational Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sahan Bulathwela, Daniel Van Niekerk, Jarrod Shipton, Maria Perez-Ortiz, Benjamin Rosman, John Shawe-Taylor</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-23 13:25:44</h6>
<p class='card-text'>Personalised education is one of the domains that can greatly benefit from
the most recent advances in Artificial Intelligence (AI) and Large Language
Models (LLM). However, it is also one of the most challenging applications due
to the cognitive complexity of teaching effectively while personalising the
learning experience to suit independent learners. We hypothesise that one
promising approach to excelling in such demanding use cases is using a
\emph{society of minds}. In this chapter, we present TrueReason, an exemplar
personalised learning system that integrates a multitude of specialised AI
models that can mimic micro skills that are composed together by a LLM to
operationalise planning and reasoning. The architecture of the initial
prototype is presented while describing two micro skills that have been
incorporated in the prototype. The proposed system demonstrates the first step
in building sophisticated AI systems that can take up very complex cognitive
tasks that are demanded by domains such as education.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.13545v1' target='_blank'>LLMs Can Plan Only If We Tell Them</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Bilgehan Sel, Ruoxi Jia, Ming Jin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-23 10:46:14</h6>
<p class='card-text'>Large language models (LLMs) have demonstrated significant capabilities in
natural language processing and reasoning, yet their effectiveness in
autonomous planning has been under debate. While existing studies have utilized
LLMs with external feedback mechanisms or in controlled environments for
planning, these approaches often involve substantial computational and
development resources due to the requirement for careful design and iterative
backprompting. Moreover, even the most advanced LLMs like GPT-4 struggle to
match human performance on standard planning benchmarks, such as the
Blocksworld, without additional support. This paper investigates whether LLMs
can independently generate long-horizon plans that rival human baselines. Our
novel enhancements to Algorithm-of-Thoughts (AoT), which we dub AoT+, help
achieve state-of-the-art results in planning benchmarks out-competing prior
methods and human baselines all autonomously.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.13411v1' target='_blank'>VulnBot: Autonomous Penetration Testing for A Multi-Agent Collaborative
  Framework</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:He Kong, Die Hu, Jingguo Ge, Liangxiong Li, Tong Li, Bingzhen Wu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-23 06:33:05</h6>
<p class='card-text'>Penetration testing is a vital practice for identifying and mitigating
vulnerabilities in cybersecurity systems, but its manual execution is
labor-intensive and time-consuming. Existing large language model
(LLM)-assisted or automated penetration testing approaches often suffer from
inefficiencies, such as a lack of contextual understanding and excessive,
unstructured data generation. This paper presents VulnBot, an automated
penetration testing framework that leverages LLMs to simulate the collaborative
workflow of human penetration testing teams through a multi-agent system. To
address the inefficiencies and reliance on manual intervention in traditional
penetration testing methods, VulnBot decomposes complex tasks into three
specialized phases: reconnaissance, scanning, and exploitation. These phases
are guided by a penetration task graph (PTG) to ensure logical task execution.
Key design features include role specialization, penetration path planning,
inter-agent communication, and generative penetration behavior. Experimental
results demonstrate that VulnBot outperforms baseline models such as GPT-4 and
Llama3 in automated penetration testing tasks, particularly showcasing its
potential in fully autonomous testing on real-world machines.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.13011v1' target='_blank'>MONA: Myopic Optimization with Non-myopic Approval Can Mitigate
  Multi-step Reward Hacking</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sebastian Farquhar, Vikrant Varma, David Lindner, David Elson, Caleb Biddulph, Ian Goodfellow, Rohin Shah</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-22 16:53:08</h6>
<p class='card-text'>Future advanced AI systems may learn sophisticated strategies through
reinforcement learning (RL) that humans cannot understand well enough to safely
evaluate. We propose a training method which avoids agents learning undesired
multi-step plans that receive high reward (multi-step "reward hacks") even if
humans are not able to detect that the behaviour is undesired. The method,
Myopic Optimization with Non-myopic Approval (MONA), works by combining
short-sighted optimization with far-sighted reward. We demonstrate that MONA
can prevent multi-step reward hacking that ordinary RL causes, even without
being able to detect the reward hacking and without any extra information that
ordinary RL does not get access to. We study MONA empirically in three settings
which model different misalignment failure modes including 2-step environments
with LLMs representing delegated oversight and encoded reasoning and
longer-horizon gridworld environments representing sensor tampering.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.12432v1' target='_blank'>Divide-Then-Aggregate: An Efficient Tool Learning Method via Parallel
  Tool Invocation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Dongsheng Zhu, Weixian Shi, Zhengliang Shi, Zhaochun Ren, Shuaiqiang Wang, Lingyong Yan, Dawei Yin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-21 16:49:08</h6>
<p class='card-text'>Although current Large Language Models (LLMs) exhibit impressive
capabilities, performing complex real-world tasks still requires tool learning.
Mainstream methods, such as CoT/ReAct, rely on step-by-step tool invocation to
interact with external environments, but they are limited in perceptual scope
and lack adequate task-planning capability. To address these limitations, other
studies introduce the first Search-based Decision Tree (DFSDT), which still
suffers from the high computational cost. In this paper, we introduce a novel
parallel tool invocation paradigm, DTA-Llama (Divide-Then-Aggregate Llama).
First, we transform traditional tree-based tool search paths into Directed
Acyclic Graph (DAG) structure, generating a high-quality parallel tool
invocation dataset. The DTA-Llama is then trained on the dataset to learn to
iteratively divide the current task into several parallel tool invocation
sub-tasks and aggregate the invocation results to decide the next actions.
Furthermore, we introduce an efficient inference framework inspired by the
Process/Threads mechanism when applying the DTA-Llama to practical tasks.
Experimental results show that our approach substantially enhances task
performance while reducing token consumption and inference time. Llama2-7B,
using our method, is comparable to the official parallel function calling
method of GPT-3.5. The relevant code, dataset, and model weights are available
at https://corn0205.github.io/</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.11864v1' target='_blank'>LLM-Agents Driven Automated Simulation Testing and Analysis of small
  Uncrewed Aerial Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Venkata Sai Aswath Duvvuru, Bohan Zhang, Michael Vierhauser, Ankit Agrawal</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-21 03:42:21</h6>
<p class='card-text'>Thorough simulation testing is crucial for validating the correct behavior of
small Uncrewed Aerial Systems (sUAS) across multiple scenarios, including
adverse weather conditions (such as wind, and fog), diverse settings (hilly
terrain, or urban areas), and varying mission profiles (surveillance,
tracking). While various sUAS simulation tools exist to support developers, the
entire process of creating, executing, and analyzing simulation tests remains a
largely manual and cumbersome task. Developers must identify test scenarios,
set up the simulation environment, integrate the System under Test (SuT) with
simulation tools, formulate mission plans, and collect and analyze results.
These labor-intensive tasks limit the ability of developers to conduct
exhaustive testing across a wide range of scenarios. To alleviate this problem,
in this paper, we propose AutoSimTest, a Large Language Model (LLM)-driven
framework, where multiple LLM agents collaborate to support the sUAS simulation
testing process. This includes: (1) creating test scenarios that subject the
SuT to unique environmental contexts; (2) preparing the simulation environment
as per the test scenario; (3) generating diverse sUAS missions for the SuT to
execute; and (4) analyzing simulation results and providing an interactive
analytics interface. Further, the design of the framework is flexible for
creating and testing scenarios for a variety of sUAS use cases, simulation
tools, and SuT input requirements. We evaluated our approach by (a) conducting
simulation testing of PX4 and ArduPilot flight-controller-based SuTs, (b)
analyzing the performance of each agent, and (c) gathering feedback from sUAS
developers. Our findings indicate that AutoSimTest significantly improves the
efficiency and scope of the sUAS testing process, allowing for more
comprehensive and varied scenario evaluations while reducing the manual effort.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.13121v1' target='_blank'>Episodic Memories Generation and Evaluation Benchmark for Large Language
  Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Alexis Huet, Zied Ben Houidi, Dario Rossi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-21 02:16:13</h6>
<p class='card-text'>Episodic memory -- the ability to recall specific events grounded in time and
space -- is a cornerstone of human cognition, enabling not only coherent
storytelling, but also planning and decision-making. Despite their remarkable
capabilities, Large Language Models (LLMs) lack a robust mechanism for episodic
memory: we argue that integrating episodic memory capabilities into LLM is
essential for advancing AI towards human-like cognition, increasing their
potential to reason consistently and ground their output in real-world episodic
events, hence avoiding confabulations. To address this challenge, we introduce
a comprehensive framework to model and evaluate LLM episodic memory
capabilities. Drawing inspiration from cognitive science, we develop a
structured approach to represent episodic events, encapsulating temporal and
spatial contexts, involved entities, and detailed descriptions. We synthesize a
unique episodic memory benchmark, free from contamination, and release open
source code and datasets to assess LLM performance across various recall and
episodic reasoning tasks. Our evaluation of state-of-the-art models, including
GPT-4 and Claude variants, Llama 3.1, and o1-mini, reveals that even the most
advanced LLMs struggle with episodic memory tasks, particularly when dealing
with multiple related events or complex spatio-temporal relationships -- even
in contexts as short as 10k-100k tokens.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.13955v1' target='_blank'>Guided Persona-based AI Surveys: Can we replicate personal mobility
  preferences at scale using LLMs?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ioannis Tzachristas, Santhanakrishnan Narayanan, Constantinos Antoniou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-20 15:11:03</h6>
<p class='card-text'>This study explores the potential of Large Language Models (LLMs) to generate
artificial surveys, with a focus on personal mobility preferences in Germany.
By leveraging LLMs for synthetic data creation, we aim to address the
limitations of traditional survey methods, such as high costs, inefficiency and
scalability challenges. A novel approach incorporating "Personas" -
combinations of demographic and behavioural attributes - is introduced and
compared to five other synthetic survey methods, which vary in their use of
real-world data and methodological complexity. The MiD 2017 dataset, a
comprehensive mobility survey in Germany, serves as a benchmark to assess the
alignment of synthetic data with real-world patterns. The results demonstrate
that LLMs can effectively capture complex dependencies between demographic
attributes and preferences while offering flexibility to explore hypothetical
scenarios. This approach presents valuable opportunities for transportation
planning and social science research, enabling scalable, cost-efficient and
privacy-preserving data generation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.11283v2' target='_blank'>Large Language Model Agents for Radio Map Generation and Wireless
  Network Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hongye Quan, Wanli Ni, Tong Zhang, Xiangyu Ye, Ziyi Xie, Shuai Wang, Yuanwei Liu, Hui Song</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-20 05:34:38</h6>
<p class='card-text'>Using commercial software for radio map generation and wireless network
planning often require complex manual operations, posing significant challenges
in terms of scalability, adaptability, and user-friendliness, due to heavy
manual operations. To address these issues, we propose an automated solution
that employs large language model (LLM) agents. These agents are designed to
autonomously generate radio maps and facilitate wireless network planning for
specified areas, thereby minimizing the necessity for extensive manual
intervention. To validate the effectiveness of our proposed solution, we
develop a software platform that integrates LLM agents. Experimental results
demonstrate that a large amount manual operations can be saved via the proposed
LLM agent, and the automated solutions can achieve an enhanced coverage and
signal-to-interference-noise ratio (SINR), especially in urban environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.11067v1' target='_blank'>IntellAgent: A Multi-Agent Framework for Evaluating Conversational AI
  Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Elad Levi, Ilan Kadar</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-19 14:58:35</h6>
<p class='card-text'>Large Language Models (LLMs) are transforming artificial intelligence,
evolving into task-oriented systems capable of autonomous planning and
execution. One of the primary applications of LLMs is conversational AI
systems, which must navigate multi-turn dialogues, integrate domain-specific
APIs, and adhere to strict policy constraints. However, evaluating these agents
remains a significant challenge, as traditional methods fail to capture the
complexity and variability of real-world interactions. We introduce
IntellAgent, a scalable, open-source multi-agent framework designed to evaluate
conversational AI systems comprehensively. IntellAgent automates the creation
of diverse, synthetic benchmarks by combining policy-driven graph modeling,
realistic event generation, and interactive user-agent simulations. This
innovative approach provides fine-grained diagnostics, addressing the
limitations of static and manually curated benchmarks with coarse-grained
metrics. IntellAgent represents a paradigm shift in evaluating conversational
AI. By simulating realistic, multi-policy scenarios across varying levels of
complexity, IntellAgent captures the nuanced interplay of agent capabilities
and policy constraints. Unlike traditional methods, it employs a graph-based
policy model to represent relationships, likelihoods, and complexities of
policy interactions, enabling highly detailed diagnostics. IntellAgent also
identifies critical performance gaps, offering actionable insights for targeted
optimization. Its modular, open-source design supports seamless integration of
new domains, policies, and APIs, fostering reproducibility and community
collaboration. Our findings demonstrate that IntellAgent serves as an effective
framework for advancing conversational AI by addressing challenges in bridging
research and deployment. The framework is available at
https://github.com/plurai-ai/intellagent</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.10839v1' target='_blank'>Systems Engineering for Autonomous Vehicles; Supervising AI using Large
  Language Models (SSuperLLM)</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Diomidis Katzourakis</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-18 18:19:49</h6>
<p class='card-text'>Generative Artificial Intelligence (GAI) and the idea to use hierarchical
models has been around for some years now. GAI has proved to be an extremely
useful tool for Autonomous Vehicles (AVs). AVs need to perform robustly in
their environment. Thus the AV behavior and short-term trajectory planning
needs to be: a) designed and architected using safeguarding and supervisory
systems and b) verified using proper Systems Engineering (SysEng) Principles.
Can AV Systems Engineering also use Large Language Models (LLM) to help
Autonomous vehicles (AV) development? This reader-friendly paper advocates the
use of LLMs in 1) requirements (Reqs) development and 2) Reqs verification and
3) provides a proof-of-concept of AV supervisory control. The latter uses a
simulation environment of a simple planar (bicycle) vehicle dynamics model and
a Linear Quadratic Regulator (LQR) control with an LLM Application Interface
(API). The Open-Source simulation SW is available from the author accessible to
the readers so that they can engage into the AV stack, LLM API and rules,
SysEng and Reqs and fundamental vehicle dynamics and control.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.10321v2' target='_blank'>Towards Human-Guided, Data-Centric LLM Co-Pilots</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Evgeny Saveliev, Jiashuo Liu, Nabeel Seedat, Anders Boyd, Mihaela van der Schaar</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-17 17:51:22</h6>
<p class='card-text'>Machine learning (ML) has the potential to revolutionize various domains, but
its adoption is often hindered by the disconnect between the needs of domain
experts and translating these needs into robust and valid ML tools. Despite
recent advances in LLM-based co-pilots to democratize ML for non-technical
domain experts, these systems remain predominantly focused on model-centric
aspects while overlooking critical data-centric challenges. This limitation is
problematic in complex real-world settings where raw data often contains
complex issues, such as missing values, label noise, and domain-specific
nuances requiring tailored handling. To address this we introduce CliMB-DC, a
human-guided, data-centric framework for LLM co-pilots that combines advanced
data-centric tools with LLM-driven reasoning to enable robust, context-aware
data processing. At its core, CliMB-DC introduces a novel, multi-agent
reasoning system that combines a strategic coordinator for dynamic planning and
adaptation with a specialized worker agent for precise execution. Domain
expertise is then systematically incorporated to guide the reasoning process
using a human-in-the-loop approach. To guide development, we formalize a
taxonomy of key data-centric challenges that co-pilots must address.
Thereafter, to address the dimensions of the taxonomy, we integrate
state-of-the-art data-centric tools into an extensible, open-source
architecture, facilitating the addition of new tools from the research
community. Empirically, using real-world healthcare datasets we demonstrate
CliMB-DC's ability to transform uncurated datasets into ML-ready formats,
significantly outperforming existing co-pilot baselines for handling
data-centric challenges. CliMB-DC promises to empower domain experts from
diverse domains -- healthcare, finance, social sciences and more -- to actively
participate in driving real-world impact using ML.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.10106v1' target='_blank'>LLM Reasoner and Automated Planner: A new NPC approach</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Israel Puerta-Merino, Jordi Sabater-Mir</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-17 10:47:11</h6>
<p class='card-text'>In domains requiring intelligent agents to emulate plausible human-like
behaviour, such as formative simulations, traditional techniques like behaviour
trees encounter significant challenges. Large Language Models (LLMs), despite
not always yielding optimal solutions, usually offer plausible and human-like
responses to a given problem. In this paper, we exploit this capability and
propose a novel architecture that integrates an LLM for decision-making with a
classical automated planner that can generate sound plans for that decision.
The combination aims to equip an agent with the ability to make decisions in
various situations, even if they were not anticipated during the design phase.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.09913v1' target='_blank'>Towards A Litmus Test for Common Sense</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hugo Latapie</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-17 02:02:12</h6>
<p class='card-text'>This paper is the second in a planned series aimed at envisioning a path to
safe and beneficial artificial intelligence. Building on the conceptual
insights of "Common Sense Is All You Need," we propose a more formal litmus
test for common sense, adopting an axiomatic approach that combines minimal
prior knowledge (MPK) constraints with diagonal or Godel-style arguments to
create tasks beyond the agent's known concept set. We discuss how this approach
applies to the Abstraction and Reasoning Corpus (ARC), acknowledging
training/test data constraints, physical or virtual embodiment, and large
language models (LLMs). We also integrate observations regarding emergent
deceptive hallucinations, in which more capable AI systems may intentionally
fabricate plausible yet misleading outputs to disguise knowledge gaps. The
overarching theme is that scaling AI without ensuring common sense risks
intensifying such deceptive tendencies, thereby undermining safety and trust.
Aligning with the broader goal of developing beneficial AI without causing
harm, our axiomatic litmus test not only diagnoses whether an AI can handle
truly novel concepts but also provides a stepping stone toward an ethical,
reliable foundation for future safe, beneficial, and aligned artificial
intelligence.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.09891v1' target='_blank'>Evolving Deeper LLM Thinking</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kuang-Huei Lee, Ian Fischer, Yueh-Hua Wu, Dave Marwood, Shumeet Baluja, Dale Schuurmans, Xinyun Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-17 00:41:44</h6>
<p class='card-text'>We explore an evolutionary search strategy for scaling inference time compute
in Large Language Models. The proposed approach, Mind Evolution, uses a
language model to generate, recombine and refine candidate responses. The
proposed approach avoids the need to formalize the underlying inference problem
whenever a solution evaluator is available. Controlling for inference cost, we
find that Mind Evolution significantly outperforms other inference strategies
such as Best-of-N and Sequential Revision in natural language planning tasks.
In the TravelPlanner and Natural Plan benchmarks, Mind Evolution solves more
than 98% of the problem instances using Gemini 1.5 Pro without the use of a
formal solver.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.09757v1' target='_blank'>Distilling Multi-modal Large Language Models for Autonomous Driving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Deepti Hegde, Rajeev Yasarla, Hong Cai, Shizhong Han, Apratim Bhattacharyya, Shweta Mahajan, Litian Liu, Risheek Garrepalli, Vishal M. Patel, Fatih Porikli</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-16 18:59:53</h6>
<p class='card-text'>Autonomous driving demands safe motion planning, especially in critical
"long-tail" scenarios. Recent end-to-end autonomous driving systems leverage
large language models (LLMs) as planners to improve generalizability to rare
events. However, using LLMs at test time introduces high computational costs.
To address this, we propose DiMA, an end-to-end autonomous driving system that
maintains the efficiency of an LLM-free (or vision-based) planner while
leveraging the world knowledge of an LLM. DiMA distills the information from a
multi-modal LLM to a vision-based end-to-end planner through a set of specially
designed surrogate tasks. Under a joint training strategy, a scene encoder
common to both networks produces structured representations that are
semantically grounded as well as aligned to the final planning objective.
Notably, the LLM is optional at inference, enabling robust planning without
compromising on efficiency. Training with DiMA results in a 37% reduction in
the L2 trajectory error and an 80% reduction in the collision rate of the
vision-based planner, as well as a 44% trajectory error reduction in longtail
scenarios. DiMA also achieves state-of-the-art performance on the nuScenes
planning benchmark.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.09781v1' target='_blank'>VideoWorld: Exploring Knowledge Learning from Unlabeled Videos</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhongwei Ren, Yunchao Wei, Xun Guo, Yao Zhao, Bingyi Kang, Jiashi Feng, Xiaojie Jin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-16 18:59:10</h6>
<p class='card-text'>This work explores whether a deep generative model can learn complex
knowledge solely from visual input, in contrast to the prevalent focus on
text-based models like large language models (LLMs). We develop VideoWorld, an
auto-regressive video generation model trained on unlabeled video data, and
test its knowledge acquisition abilities in video-based Go and robotic control
tasks. Our experiments reveal two key findings: (1) video-only training
provides sufficient information for learning knowledge, including rules,
reasoning and planning capabilities, and (2) the representation of visual
change is crucial for knowledge acquisition. To improve both the efficiency and
efficacy of this process, we introduce the Latent Dynamics Model (LDM) as a key
component of VideoWorld. Remarkably, VideoWorld reaches a 5-dan professional
level in the Video-GoBench with just a 300-million-parameter model, without
relying on search algorithms or reward mechanisms typical in reinforcement
learning. In robotic tasks, VideoWorld effectively learns diverse control
operations and generalizes across environments, approaching the performance of
oracle models in CALVIN and RLBench. This study opens new avenues for knowledge
acquisition from visual data, with all code, data, and models open-sourced for
further research.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.09316v1' target='_blank'>SOP-Agent: Empower General Purpose AI Agent with Domain-Specific SOPs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Anbang Ye, Qianran Ma, Jia Chen, Muqi Li, Tong Li, Fujiao Liu, Siqi Mai, Meichen Lu, Haitao Bao, Yang You</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-16 06:14:58</h6>
<p class='card-text'>Despite significant advancements in general-purpose AI agents, several
challenges still hinder their practical application in real-world scenarios.
First, the limited planning capabilities of Large Language Models (LLM)
restrict AI agents from effectively solving complex tasks that require
long-horizon planning. Second, general-purpose AI agents struggle to
efficiently utilize domain-specific knowledge and human expertise. In this
paper, we introduce the Standard Operational Procedure-guided Agent
(SOP-agent), a novel framework for constructing domain-specific agents through
pseudocode-style Standard Operational Procedures (SOPs) written in natural
language. Formally, we represent a SOP as a decision graph, which is traversed
to guide the agent in completing tasks specified by the SOP. We conduct
extensive experiments across tasks in multiple domains, including
decision-making, search and reasoning, code generation, data cleaning, and
grounded customer service. The SOP-agent demonstrates excellent versatility,
achieving performance superior to general-purpose agent frameworks and
comparable to domain-specific agent systems. Additionally, we introduce the
Grounded Customer Service Benchmark, the first benchmark designed to evaluate
the grounded decision-making capabilities of AI agents in customer service
scenarios based on SOPs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.09307v1' target='_blank'>RoboReflect: Robotic Reflective Reasoning for Grasping
  Ambiguous-Condition Objects</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhen Luo, Yixuan Yang, Chang Cai, Yanfu Zhang, Feng Zheng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-16 05:40:37</h6>
<p class='card-text'>As robotic technology rapidly develops, robots are being employed in an
increasing number of fields. However, due to the complexity of deployment
environments or the prevalence of ambiguous-condition objects, the practical
application of robotics still faces many challenges, leading to frequent
errors. Traditional methods and some LLM-based approaches, although improved,
still require substantial human intervention and struggle with autonomous error
correction in complex scenarios.In this work, we propose RoboReflect, a novel
framework leveraging large vision-language models (LVLMs) to enable
self-reflection and autonomous error correction in robotic grasping tasks.
RoboReflect allows robots to automatically adjust their strategies based on
unsuccessful attempts until successful execution is achieved.The corrected
strategies are saved in a memory for future task reference.We evaluate
RoboReflect through extensive testing on eight common objects prone to
ambiguous conditions of three categories.Our results demonstrate that
RoboReflect not only outperforms existing grasp pose estimation methods like
AnyGrasp and high-level action planning techniques using GPT-4V but also
significantly enhances the robot's ability to adapt and correct errors
independently. These findings underscore the critical importance of autonomous
selfreflection in robotic systems while effectively addressing the challenges
posed by ambiguous environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.09213v2' target='_blank'>FineMedLM-o1: Enhancing the Medical Reasoning Ability of LLM from
  Supervised Fine-Tuning to Test-Time Training</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hongzhou Yu, Tianhao Cheng, Ying Cheng, Rui Feng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-16 00:19:19</h6>
<p class='card-text'>Recent advancements in large language models (LLMs) have shown promise in
medical applications such as disease diagnosis and treatment planning. However,
most existing medical LLMs struggle with the advanced reasoning required for
complex clinical scenarios, such as differential diagnosis or personalized
treatment suggestions. We proposed FineMedLM-o1, which leverages high-quality
synthetic medical data and long-form reasoning data for Supervised Fine-Tuning
(SFT) and Direct Preference Optimization (DPO), enabling advanced dialogue and
deep reasoning capabilities. Additionally, we introduced Test-Time Training
(TTT) in the medical domain for the first time, facilitating domain adaptation
and ensuring reliable, accurate reasoning. Experimental results demonstrate
that FineMedLM-o1 achieves a 23% average performance improvement over prior
models on key medical benchmarks. Furthermore, the introduction of TTT provides
an additional 14% performance boost, highlighting its effectiveness in
enhancing medical reasoning capabilities. To support this process, we also
proposed a novel method for synthesizing medical dialogue. Compared to other
open-source datasets, our dataset stands out as superior in both quality and
complexity. The project and data will be released on GitHub.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.09136v3' target='_blank'>Agentic Retrieval-Augmented Generation: A Survey on Agentic RAG</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Aditi Singh, Abul Ehtesham, Saket Kumar, Tala Talaei Khoei</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-15 20:40:25</h6>
<p class='card-text'>Large Language Models (LLMs) have revolutionized artificial intelligence (AI)
by enabling human like text generation and natural language understanding.
However, their reliance on static training data limits their ability to respond
to dynamic, real time queries, resulting in outdated or inaccurate outputs.
Retrieval Augmented Generation (RAG) has emerged as a solution, enhancing LLMs
by integrating real time data retrieval to provide contextually relevant and
up-to-date responses. Despite its promise, traditional RAG systems are
constrained by static workflows and lack the adaptability required for
multistep reasoning and complex task management.
  Agentic Retrieval-Augmented Generation (Agentic RAG) transcends these
limitations by embedding autonomous AI agents into the RAG pipeline. These
agents leverage agentic design patterns reflection, planning, tool use, and
multiagent collaboration to dynamically manage retrieval strategies,
iteratively refine contextual understanding, and adapt workflows to meet
complex task requirements. This integration enables Agentic RAG systems to
deliver unparalleled flexibility, scalability, and context awareness across
diverse applications.
  This survey provides a comprehensive exploration of Agentic RAG, beginning
with its foundational principles and the evolution of RAG paradigms. It
presents a detailed taxonomy of Agentic RAG architectures, highlights key
applications in industries such as healthcare, finance, and education, and
examines practical implementation strategies. Additionally, it addresses
challenges in scaling these systems, ensuring ethical decision making, and
optimizing performance for real-world applications, while providing detailed
insights into frameworks and tools for implementing Agentic RAG.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.09004v1' target='_blank'>Aegis2.0: A Diverse AI Safety Dataset and Risks Taxonomy for Alignment
  of LLM Guardrails</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shaona Ghosh, Prasoon Varshney, Makesh Narsimhan Sreedhar, Aishwarya Padmakumar, Traian Rebedea, Jibin Rajan Varghese, Christopher Parisien</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-15 18:37:08</h6>
<p class='card-text'>As Large Language Models (LLMs) and generative AI become increasingly
widespread, concerns about content safety have grown in parallel. Currently,
there is a clear lack of high-quality, human-annotated datasets that address
the full spectrum of LLM-related safety risks and are usable for commercial
applications. To bridge this gap, we propose a comprehensive and adaptable
taxonomy for categorizing safety risks, structured into 12 top-level hazard
categories with an extension to 9 fine-grained subcategories. This taxonomy is
designed to meet the diverse requirements of downstream users, offering more
granular and flexible tools for managing various risk types. Using a hybrid
data generation pipeline that combines human annotations with a multi-LLM
"jury" system to assess the safety of responses, we obtain Aegis 2.0, a
carefully curated collection of 34,248 samples of human-LLM interactions,
annotated according to our proposed taxonomy. To validate its effectiveness, we
demonstrate that several lightweight models, trained using parameter-efficient
techniques on Aegis 2.0, achieve performance competitive with leading safety
models fully fine-tuned on much larger, non-commercial datasets. In addition,
we introduce a novel training blend that combines safety with topic following
data.This approach enhances the adaptability of guard models, enabling them to
generalize to new risk categories defined during inference. We plan to
open-source Aegis 2.0 data and models to the research community to aid in the
safety guardrailing of LLMs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.08897v1' target='_blank'>Leveraging Large Language Models as Knowledge-Driven Agents for Reliable
  Retrosynthesis Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Qinyu Ma, Yuhao Zhou, Jianfeng Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-15 16:06:10</h6>
<p class='card-text'>Identifying reliable synthesis pathways in materials chemistry is a complex
task, particularly in polymer science, due to the intricate and often
non-unique nomenclature of macromolecules. To address this challenge, we
propose an agent system that integrates large language models (LLMs) and
knowledge graphs (KGs). By leveraging LLMs' powerful capabilities for
extracting and recognizing chemical substance names, and storing the extracted
data in a structured knowledge graph, our system fully automates the retrieval
of relevant literatures, extraction of reaction data, database querying,
construction of retrosynthetic pathway trees, further expansion through the
retrieval of additional literature and recommendation of optimal reaction
pathways. A novel Multi-branched Reaction Pathway Search (MBRPS) algorithm
enables the exploration of all pathways, with a particular focus on
multi-branched ones, helping LLMs overcome weak reasoning in multi-branched
paths. This work represents the first attempt to develop a fully automated
retrosynthesis planning agent tailored specially for macromolecules powered by
LLMs. Applied to polyimide synthesis, our new approach constructs a
retrosynthetic pathway tree with hundreds of pathways and recommends optimized
routes, including both known and novel pathways, demonstrating its
effectiveness and potential for broader applications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.08603v3' target='_blank'>Monte Carlo Tree Search for Comprehensive Exploration in LLM-Based
  Automatic Heuristic Design</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhi Zheng, Zhuoliang Xie, Zhenkun Wang, Bryan Hooi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-15 06:00:50</h6>
<p class='card-text'>Handcrafting heuristics for solving complex optimization tasks (e.g., route
planning and task allocation) is a common practice but requires extensive
domain knowledge. Recently, Large Language Model (LLM)-based automatic
heuristic design (AHD) methods have shown promise in generating high-quality
heuristics without manual interventions. Existing LLM-based AHD methods employ
a population to maintain a fixed number of top-performing LLM-generated
heuristics and introduce evolutionary computation (EC) to iteratively enhance
the population. However, these population-based procedures cannot fully develop
the potential of each heuristic and are prone to converge into local optima. To
more comprehensively explore the space of heuristics, this paper proposes to
use Monte Carlo Tree Search (MCTS) for LLM-based heuristic evolution. The
proposed MCTS-AHD method organizes all LLM-generated heuristics in a tree
structure and can better develop the potential of temporarily underperforming
heuristics. In experiments, MCTS-AHD delivers significantly higher-quality
heuristics on various complex tasks. Our code is available.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.08328v2' target='_blank'>PokerBench: Training Large Language Models to become Professional Poker
  Players</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Richard Zhuang, Akshat Gupta, Richard Yang, Aniket Rahane, Zhengyu Li, Gopala Anumanchipalli</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-14 18:59:03</h6>
<p class='card-text'>We introduce PokerBench - a benchmark for evaluating the poker-playing
abilities of large language models (LLMs). As LLMs excel in traditional NLP
tasks, their application to complex, strategic games like poker poses a new
challenge. Poker, an incomplete information game, demands a multitude of skills
such as mathematics, reasoning, planning, strategy, and a deep understanding of
game theory and human psychology. This makes Poker the ideal next frontier for
large language models. PokerBench consists of a comprehensive compilation of
11,000 most important scenarios, split between pre-flop and post-flop play,
developed in collaboration with trained poker players. We evaluate prominent
models including GPT-4, ChatGPT 3.5, and various Llama and Gemma series models,
finding that all state-of-the-art LLMs underperform in playing optimal poker.
However, after fine-tuning, these models show marked improvements. We validate
PokerBench by having models with different scores compete with each other,
demonstrating that higher scores on PokerBench lead to higher win rates in
actual poker games. Through gameplay between our fine-tuned model and GPT-4, we
also identify limitations of simple supervised fine-tuning for learning optimal
playing strategy, suggesting the need for more advanced methodologies for
effectively training language models to excel in games. PokerBench thus
presents a unique benchmark for a quick and reliable evaluation of the
poker-playing ability of LLMs as well as a comprehensive benchmark to study the
progress of LLMs in complex game-playing scenarios.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.08068v1' target='_blank'>A Roadmap to Guide the Integration of LLMs in Hierarchical Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Israel Puerta-Merino, Carlos Núñez-Molina, Pablo Mesejo, Juan Fernández-Olivares</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-14 12:34:25</h6>
<p class='card-text'>Recent advances in Large Language Models (LLMs) are fostering their
integration into several reasoning-related fields, including Automated Planning
(AP). However, their integration into Hierarchical Planning (HP), a subfield of
AP that leverages hierarchical knowledge to enhance planning performance,
remains largely unexplored. In this preliminary work, we propose a roadmap to
address this gap and harness the potential of LLMs for HP. To this end, we
present a taxonomy of integration methods, exploring how LLMs can be utilized
within the HP life cycle. Additionally, we provide a benchmark with a
standardized dataset for evaluating the performance of future LLM-based HP
approaches, and present initial results for a state-of-the-art HP planner and
LLM planner. As expected, the latter exhibits limited performance (3\% correct
plans, and none with a correct hierarchical decomposition) but serves as a
valuable baseline for future approaches.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.07834v2' target='_blank'>Flow: Modularized Agentic Workflow Automation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Boye Niu, Yiliao Song, Kai Lian, Yifan Shen, Yu Yao, Kun Zhang, Tongliang Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-14 04:35:37</h6>
<p class='card-text'>Multi-agent frameworks powered by large language models (LLMs) have
demonstrated great success in automated planning and task execution. However,
the effective adjustment of agentic workflows during execution has not been
well studied. An effective workflow adjustment is crucial in real-world
scenarios, as the initial plan must adjust to unforeseen challenges and
changing conditions in real time to ensure the efficient execution of complex
tasks. In this paper, we define workflows as an activity-on-vertex (AOV) graph,
which allows continuous workflow refinement by LLM agents through dynamic
subtask allocation adjustment based on historical performance and previous
AOVs. To further enhance framework performance, we emphasize modularity in
workflow design based on evaluating parallelism and dependency complexity. With
this design, our proposed multi-agent framework achieves efficient concurrent
execution of subtasks, effective goal achievement, and enhanced error
tolerance. Empirical results across various practical tasks demonstrate
significant improvements in the efficiency of multi-agent frameworks through
dynamic workflow refinement and modularization. The code is available at:
https://github.com/tmllab/2025_ICLR_FLOW.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.13936v1' target='_blank'>Evaluating Computational Accuracy of Large Language Models in Numerical
  Reasoning Tasks for Healthcare Applications</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Arjun R. Malghan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-14 04:29:43</h6>
<p class='card-text'>Large Language Models (LLMs) have emerged as transformative tools in the
healthcare sector, demonstrating remarkable capabilities in natural language
understanding and generation. However, their proficiency in numerical
reasoning, particularly in high-stakes domains like in clinical applications,
remains underexplored. Numerical reasoning is critical in healthcare
applications, influencing patient outcomes, treatment planning, and resource
allocation. This study investigates the computational accuracy of LLMs in
numerical reasoning tasks within healthcare contexts. Using a curated dataset
of 1,000 numerical problems, encompassing real-world scenarios such as dosage
calculations and lab result interpretations, the performance of a refined LLM
based on the GPT-3 architecture was evaluated. The methodology includes prompt
engineering, integration of fact-checking pipelines, and application of
regularization techniques to enhance model accuracy and generalization. Key
metrics such as precision, recall, and F1-score were utilized to assess the
model's efficacy. The results indicate an overall accuracy of 84.10%, with
improved performance in straightforward numerical tasks and challenges in
multi-step reasoning. The integration of a fact-checking pipeline improved
accuracy by 11%, underscoring the importance of validation mechanisms. This
research highlights the potential of LLMs in healthcare numerical reasoning and
identifies avenues for further refinement to support critical decision-making
in clinical environments. The findings aim to contribute to the development of
reliable, interpretable, and contextually relevant AI tools for healthcare.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.07813v1' target='_blank'>Talk to Right Specialists: Routing and Planning in Multi-agent System
  for Question Answering</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Feijie Wu, Zitao Li, Fei Wei, Yaliang Li, Bolin Ding, Jing Gao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-14 03:25:26</h6>
<p class='card-text'>Leveraging large language models (LLMs), an agent can utilize
retrieval-augmented generation (RAG) techniques to integrate external knowledge
and increase the reliability of its responses. Current RAG-based agents
integrate single, domain-specific knowledge sources, limiting their ability and
leading to hallucinated or inaccurate responses when addressing cross-domain
queries. Integrating multiple knowledge bases into a unified RAG-based agent
raises significant challenges, including increased retrieval overhead and data
sovereignty when sensitive data is involved. In this work, we propose RopMura,
a novel multi-agent system that addresses these limitations by incorporating
highly efficient routing and planning mechanisms. RopMura features two key
components: a router that intelligently selects the most relevant agents based
on knowledge boundaries and a planner that decomposes complex multi-hop queries
into manageable steps, allowing for coordinating cross-domain responses.
Experimental results demonstrate that RopMura effectively handles both
single-hop and multi-hop queries, with the routing mechanism enabling precise
answers for single-hop queries and the combined routing and planning mechanisms
achieving accurate, multi-step resolutions for complex queries.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.07647v1' target='_blank'>BlobGEN-Vid: Compositional Text-to-Video Generation with Blob Video
  Representations</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Weixi Feng, Chao Liu, Sifei Liu, William Yang Wang, Arash Vahdat, Weili Nie</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-13 19:17:06</h6>
<p class='card-text'>Existing video generation models struggle to follow complex text prompts and
synthesize multiple objects, raising the need for additional grounding input
for improved controllability. In this work, we propose to decompose videos into
visual primitives - blob video representation, a general representation for
controllable video generation. Based on blob conditions, we develop a
blob-grounded video diffusion model named BlobGEN-Vid that allows users to
control object motions and fine-grained object appearance. In particular, we
introduce a masked 3D attention module that effectively improves regional
consistency across frames. In addition, we introduce a learnable module to
interpolate text embeddings so that users can control semantics in specific
frames and obtain smooth object transitions. We show that our framework is
model-agnostic and build BlobGEN-Vid based on both U-Net and DiT-based video
diffusion models. Extensive experimental results show that BlobGEN-Vid achieves
superior zero-shot video generation ability and state-of-the-art layout
controllability on multiple benchmarks. When combined with an LLM for layout
planning, our framework even outperforms proprietary text-to-video generators
in terms of compositional accuracy.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.07639v1' target='_blank'>SafePowerGraph-LLM: Novel Power Grid Graph Embedding and Optimization
  with Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Fabien Bernier, Jun Cao, Maxime Cordy, Salah Ghamizi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-13 19:01:58</h6>
<p class='card-text'>Efficiently solving Optimal Power Flow (OPF) problems in power systems is
crucial for operational planning and grid management. There is a growing need
for scalable algorithms capable of handling the increasing variability,
constraints, and uncertainties in modern power networks while providing
accurate and fast solutions. To address this, machine learning techniques,
particularly Graph Neural Networks (GNNs) have emerged as promising approaches.
This letter introduces SafePowerGraph-LLM, the first framework explicitly
designed for solving OPF problems using Large Language Models (LLM)s. The
proposed approach combines graph and tabular representations of power grids to
effectively query LLMs, capturing the complex relationships and constraints in
power systems. A new implementation of in-context learning and fine-tuning
protocols for LLMs is introduced, tailored specifically for the OPF problem.
SafePowerGraph-LLM demonstrates reliable performances using off-the-shelf LLM.
Our study reveals the impact of LLM architecture, size, and fine-tuning and
demonstrates our framework's ability to handle realistic grid components and
constraints.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.07531v1' target='_blank'>Evaluating Agent-based Program Repair at Google</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Pat Rondon, Renyao Wei, José Cambronero, Jürgen Cito, Aaron Sun, Siddhant Sanyam, Michele Tufano, Satish Chandra</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-13 18:09:25</h6>
<p class='card-text'>Agent-based program repair offers to automatically resolve complex bugs
end-to-end by combining the planning, tool use, and code generation abilities
of modern LLMs. Recent work has explored the use of agent-based repair
approaches on the popular open-source SWE-Bench, a collection of bugs from
highly-rated GitHub Python projects. In addition, various agentic approaches
such as SWE-Agent have been proposed to solve bugs in this benchmark. This
paper explores the viability of using an agentic approach to address bugs in an
enterprise context. To investigate this, we curate an evaluation set of 178
bugs drawn from Google's issue tracking system. This dataset spans both
human-reported (78) and machine-reported bugs (100).
  To establish a repair performance baseline on this benchmark, we implement
Passerine, an agent similar in spirit to SWE-Agent that can work within
Google's development environment. We show that with 20 trajectory samples and
Gemini 1.5 Pro, Passerine can produce a patch that passes bug tests (i.e.,
plausible) for 73% of machine-reported and 25.6% of human-reported bugs in our
evaluation set. After manual examination, we found that 43% of machine-reported
bugs and 17.9% of human-reported bugs have at least one patch that is
semantically equivalent to the ground-truth patch.
  These results establish a baseline on an industrially relevant benchmark,
which as we show, contains bugs drawn from a different distribution -- in terms
of language diversity, size, and spread of changes, etc. -- compared to those
in the popular SWE-Bench dataset.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.07108v1' target='_blank'>How GPT learns layer by layer</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jason Du, Kelly Hong, Alishba Imran, Erfan Jahanparast, Mehdi Khfifi, Kaichun Qiao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-13 07:42:55</h6>
<p class='card-text'>Large Language Models (LLMs) excel at tasks like language processing,
strategy games, and reasoning but struggle to build generalizable internal
representations essential for adaptive decision-making in agents. For agents to
effectively navigate complex environments, they must construct reliable world
models. While LLMs perform well on specific benchmarks, they often fail to
generalize, leading to brittle representations that limit their real-world
effectiveness. Understanding how LLMs build internal world models is key to
developing agents capable of consistent, adaptive behavior across tasks. We
analyze OthelloGPT, a GPT-based model trained on Othello gameplay, as a
controlled testbed for studying representation learning. Despite being trained
solely on next-token prediction with random valid moves, OthelloGPT shows
meaningful layer-wise progression in understanding board state and gameplay.
Early layers capture static attributes like board edges, while deeper layers
reflect dynamic tile changes. To interpret these representations, we compare
Sparse Autoencoders (SAEs) with linear probes, finding that SAEs offer more
robust, disentangled insights into compositional features, whereas linear
probes mainly detect features useful for classification. We use SAEs to decode
features related to tile color and tile stability, a previously unexamined
feature that reflects complex gameplay concepts like board control and
long-term planning. We study the progression of linear probe accuracy and tile
color using both SAE's and linear probes to compare their effectiveness at
capturing what the model is learning. Although we begin with a smaller language
model, OthelloGPT, this study establishes a framework for understanding the
internal representations learned by GPT models, transformers, and LLMs more
broadly. Our code is publicly available: https://github.com/ALT-JS/OthelloSAE.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.07054v1' target='_blank'>PoAct: Policy and Action Dual-Control Agent for Generalized Applications</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Guozhi Yuan, Youfeng Liu, Jingli Yang, Wei Jia, Kai Lin, Yansong Gao, Shan He, Zilin Ding, Haitao Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-13 04:28:40</h6>
<p class='card-text'>Based on their superior comprehension and reasoning capabilities, Large
Language Model (LLM) driven agent frameworks have achieved significant success
in numerous complex reasoning tasks. ReAct-like agents can solve various
intricate problems step-by-step through progressive planning and tool calls,
iteratively optimizing new steps based on environmental feedback. However, as
the planning capabilities of LLMs improve, the actions invoked by tool calls in
ReAct-like frameworks often misalign with complex planning and challenging data
organization. Code Action addresses these issues while also introducing the
challenges of a more complex action space and more difficult action
organization. To leverage Code Action and tackle the challenges of its
complexity, this paper proposes Policy and Action Dual-Control Agent (PoAct)
for generalized applications. The aim is to achieve higher-quality code actions
and more accurate reasoning paths by dynamically switching reasoning policies
and modifying the action space. Experimental results on the Agent Benchmark for
both legal and generic scenarios demonstrate the superior reasoning
capabilities and reduced token consumption of our approach in complex tasks. On
the LegalAgentBench, our method shows a 20 percent improvement over the
baseline while requiring fewer tokens. We conducted experiments and analyses on
the GPT-4o and GLM-4 series models, demonstrating the significant potential and
scalability of our approach to solve complex problems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.06835v1' target='_blank'>X-LeBench: A Benchmark for Extremely Long Egocentric Video Understanding</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wenqi Zhou, Kai Cao, Hao Zheng, Xinyi Zheng, Miao Liu, Per Ola Kristensson, Walterio Mayol-Cuevas, Fan Zhang, Weizhe Lin, Junxiao Shen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-12 15:07:03</h6>
<p class='card-text'>Long-form egocentric video understanding provides rich contextual information
and unique insights into long-term human behaviors, holding significant
potential for applications in embodied intelligence, long-term activity
analysis, and personalized assistive technologies. However, existing benchmark
datasets primarily focus on single, short-duration videos or moderately long
videos up to dozens of minutes, leaving a substantial gap in evaluating
extensive, ultra-long egocentric video recordings. To address this, we
introduce X-LeBench, a novel benchmark dataset specifically crafted for
evaluating tasks on extremely long egocentric video recordings. Leveraging the
advanced text processing capabilities of large language models (LLMs),
X-LeBench develops a life-logging simulation pipeline that produces realistic,
coherent daily plans aligned with real-world video data. This approach enables
the flexible integration of synthetic daily plans with real-world footage from
Ego4D-a massive-scale egocentric video dataset covers a wide range of daily
life scenarios-resulting in 432 simulated video life logs that mirror realistic
daily activities in contextually rich scenarios. The video life-log durations
span from 23 minutes to 16.4 hours. The evaluation of several baseline systems
and multimodal large language models (MLLMs) reveals their poor performance
across the board, highlighting the inherent challenges of long-form egocentric
video understanding and underscoring the need for more advanced models.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.06680v1' target='_blank'>Application of Vision-Language Model to Pedestrians Behavior and Scene
  Understanding in Autonomous Driving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Haoxiang Gao, Yu Zhao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-12 01:31:07</h6>
<p class='card-text'>Autonomous driving (AD) has experienced significant improvements in recent
years and achieved promising 3D detection, classification, and localization
results. However, many challenges remain, e.g. semantic understanding of
pedestrians' behaviors, and downstream handling for pedestrian interactions.
Recent studies in applications of Large Language Models (LLM) and
Vision-Language Models (VLM) have achieved promising results in scene
understanding and high-level maneuver planning in diverse traffic scenarios.
However, deploying the billion-parameter LLMs to vehicles requires significant
computation and memory resources. In this paper, we analyzed effective
knowledge distillation of semantic labels to smaller Vision networks, which can
be used for the semantic representation of complex scenes for downstream
decision-making for planning and control.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.06605v3' target='_blank'>RoboHorizon: An LLM-Assisted Multi-View World Model for Long-Horizon
  Robotic Manipulation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zixuan Chen, Jing Huo, Yangtao Chen, Yang Gao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-11 18:11:07</h6>
<p class='card-text'>Efficient control in long-horizon robotic manipulation is challenging due to
complex representation and policy learning requirements. Model-based visual
reinforcement learning (RL) has shown great potential in addressing these
challenges but still faces notable limitations, particularly in handling sparse
rewards and complex visual features in long-horizon environments. To address
these limitations, we propose the Recognize-Sense-Plan-Act (RSPA) pipeline for
long-horizon tasks and further introduce RoboHorizon, an LLM-assisted
multi-view world model tailored for long-horizon robotic manipulation. In
RoboHorizon, pre-trained LLMs generate dense reward structures for multi-stage
sub-tasks based on task language instructions, enabling robots to better
recognize long-horizon tasks. Keyframe discovery is then integrated into the
multi-view masked autoencoder (MAE) architecture to enhance the robot's ability
to sense critical task sequences, strengthening its multi-stage perception of
long-horizon processes. Leveraging these dense rewards and multi-view
representations, a robotic world model is constructed to efficiently plan
long-horizon tasks, enabling the robot to reliably act through RL algorithms.
Experiments on two representative benchmarks, RLBench and FurnitureBench, show
that RoboHorizon outperforms state-of-the-art visual model-based RL methods,
achieving a 23.35% improvement in task success rates on RLBench's 4
short-horizon tasks and a 29.23% improvement on 6 long-horizon tasks from
RLBench and 3 furniture assembly tasks from FurnitureBench.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.06458v1' target='_blank'>O1 Replication Journey -- Part 3: Inference-time Scaling for Medical
  Reasoning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhongzhen Huang, Gui Geng, Shengyi Hua, Zhen Huang, Haoyang Zou, Shaoting Zhang, Pengfei Liu, Xiaofan Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-11 07:10:23</h6>
<p class='card-text'>Building upon our previous investigations of O1 replication (Part 1: Journey
Learning [Qin et al., 2024] and Part 2: Distillation [Huang et al., 2024]),
this work explores the potential of inference-time scaling in large language
models (LLMs) for medical reasoning tasks, ranging from diagnostic
decision-making to treatment planning. Through extensive experiments on medical
benchmarks of varying complexity (MedQA, Medbullets, and JAMA Clinical
Challenges), our investigation reveals several key insights: (1) Increasing
inference time does lead to improved performance. With a modest training set of
500 samples, our model yields substantial performance improvements of 6%-11%.
(2) Task complexity directly correlates with the required length of reasoning
chains, confirming the necessity of extended thought processes for challenging
problems. (3) The differential diagnoses generated by our model adhere to the
principles of the hypothetico-deductive method, producing a list of potential
conditions that may explain a patient's symptoms and systematically narrowing
these possibilities by evaluating the evidence. These findings demonstrate the
promising synergy between inference-time scaling and journey learning in
advancing LLMs' real-world clinical reasoning capabilities.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.04880v1' target='_blank'>Leveraging Log Probabilities in Language Models to Forecast Future
  Events</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tommaso Soru, Jim Marshall</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-08 23:28:28</h6>
<p class='card-text'>In the constantly changing field of data-driven decision making, accurately
predicting future events is crucial for strategic planning in various sectors.
The emergence of Large Language Models (LLMs) marks a significant advancement
in this area, offering advanced tools that utilise extensive text data for
prediction. In this industry paper, we introduce a novel method for AI-driven
foresight using LLMs. Building on top of previous research, we employ data on
current trends and their trajectories for generating forecasts on 15 different
topics. Subsequently, we estimate their probabilities via a multi-step approach
based on log probabilities. We show we achieve a Brier score of 0.186, meaning
a +26% improvement over random chance and a +19% improvement over
widely-available AI systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.04306v1' target='_blank'>LLM4SR: A Survey on Large Language Models for Scientific Research</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ziming Luo, Zonglin Yang, Zexin Xu, Wei Yang, Xinya Du</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-08 06:44:02</h6>
<p class='card-text'>In recent years, the rapid advancement of Large Language Models (LLMs) has
transformed the landscape of scientific research, offering unprecedented
support across various stages of the research cycle. This paper presents the
first systematic survey dedicated to exploring how LLMs are revolutionizing the
scientific research process. We analyze the unique roles LLMs play across four
critical stages of research: hypothesis discovery, experiment planning and
implementation, scientific writing, and peer reviewing. Our review
comprehensively showcases the task-specific methodologies and evaluation
benchmarks. By identifying current challenges and proposing future research
directions, this survey not only highlights the transformative potential of
LLMs, but also aims to inspire and guide researchers and practitioners in
leveraging LLMs to advance scientific inquiry. Resources are available at the
following repository: https://github.com/du-nlp-lab/LLM4SR</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.06231v1' target='_blank'>Sustainable and Intelligent Public Facility Failure Management System
  Based on Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Siguo Bi, Jilong Zhang, Wei Ni</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-08 02:30:37</h6>
<p class='card-text'>This paper presents a new Large Language Model (LLM)-based Smart Device
Management framework, a pioneering approach designed to address the intricate
challenges of managing intelligent devices within public facilities, with a
particular emphasis on applications to libraries. Our framework leverages
state-of-the-art LLMs to analyze and predict device failures, thereby enhancing
operational efficiency and reliability. Through prototype validation in
real-world library settings, we demonstrate the framework's practical
applicability and its capacity to significantly reduce budgetary constraints on
public facilities. The advanced and innovative nature of our model is evident
from its successful implementation in prototype testing. We plan to extend the
framework's scope to include a wider array of public facilities and to
integrate it with cutting-edge cybersecurity technologies, such as Internet of
Things (IoT) security and machine learning algorithms for threat detection and
response. This will result in a comprehensive and proactive maintenance system
that not only bolsters the security of intelligent devices but also utilizes
machine learning for automated analysis and real-time threat mitigation. By
incorporating these advanced cybersecurity elements, our framework will be
well-positioned to tackle the dynamic challenges of modern public
infrastructure, ensuring robust protection against potential threats and
enabling facilities to anticipate and prevent failures, leading to substantial
cost savings and enhanced service quality.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.03968v2' target='_blank'>VLM-driven Behavior Tree for Context-aware Task Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Naoki Wake, Atsushi Kanehira, Jun Takamatsu, Kazuhiro Sasabuchi, Katsushi Ikeuchi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-07 18:06:27</h6>
<p class='card-text'>The use of Large Language Models (LLMs) for generating Behavior Trees (BTs)
has recently gained attention in the robotics community, yet remains in its
early stages of development. In this paper, we propose a novel framework that
leverages Vision-Language Models (VLMs) to interactively generate and edit BTs
that address visual conditions, enabling context-aware robot operations in
visually complex environments. A key feature of our approach lies in the
conditional control through self-prompted visual conditions. Specifically, the
VLM generates BTs with visual condition nodes, where conditions are expressed
as free-form text. Another VLM process integrates the text into its prompt and
evaluates the conditions against real-world images during robot execution. We
validated our framework in a real-world cafe scenario, demonstrating both its
feasibility and limitations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.03904v1' target='_blank'>Exploring the Potential of Large Language Models in Public
  Transportation: San Antonio Case Study</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ramya Jonnala, Gongbo Liang, Jeong Yang, Izzat Alsmadi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-07 16:18:55</h6>
<p class='card-text'>The integration of large language models (LLMs) into public transit systems
presents a transformative opportunity to enhance urban mobility. This study
explores the potential of LLMs to revolutionize public transportation
management within the context of San Antonio's transit system. Leveraging the
capabilities of LLMs in natural language processing and data analysis, we
investigate their capabilities to optimize route planning, reduce wait times,
and provide personalized travel assistance. By utilizing the General Transit
Feed Specification (GTFS) and other relevant data, this research aims to
demonstrate how LLMs can potentially improve resource allocation, elevate
passenger satisfaction, and inform data-driven decision-making in transit
operations. A comparative analysis of different ChatGPT models was conducted to
assess their ability to understand transportation information, retrieve
relevant data, and provide comprehensive responses. Findings from this study
suggest that while LLMs hold immense promise for public transit, careful
engineering and fine-tuning are essential to realizing their full potential.
San Antonio serves as a case study to inform the development of LLM-powered
transit systems in other urban environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.05478v1' target='_blank'>Language and Planning in Robotic Navigation: A Multilingual Evaluation
  of State-of-the-Art Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Malak Mansour, Ahmed Aly, Bahey Tharwat, Sarim Hashmi, Dong An, Ian Reid</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-07 16:01:25</h6>
<p class='card-text'>Large Language Models (LLMs) such as GPT-4, trained on huge amount of
datasets spanning multiple domains, exhibit significant reasoning,
understanding, and planning capabilities across various tasks. This study
presents the first-ever work in Arabic language integration within the
Vision-and-Language Navigation (VLN) domain in robotics, an area that has been
notably underexplored in existing research. We perform a comprehensive
evaluation of state-of-the-art multi-lingual Small Language Models (SLMs),
including GPT-4o mini, Llama 3 8B, and Phi-3 medium 14B, alongside the
Arabic-centric LLM, Jais. Our approach utilizes the NavGPT framework, a pure
LLM-based instruction-following navigation agent, to assess the impact of
language on navigation reasoning through zero-shot sequential action prediction
using the R2R dataset. Through comprehensive experiments, we demonstrate that
our framework is capable of high-level planning for navigation tasks when
provided with instructions in both English and Arabic. However, certain models
struggled with reasoning and planning in the Arabic language due to inherent
limitations in their capabilities, sub-optimal performance, and parsing issues.
These findings highlight the importance of enhancing planning and reasoning
capabilities in language models for effective navigation, emphasizing this as a
key area for further development while also unlocking the potential of
Arabic-language models for impactful real-world applications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.03035v4' target='_blank'>Quantization Meets Reasoning: Exploring LLM Low-Bit Quantization
  Degradation for Mathematical Reasoning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhen Li, Yupeng Su, Runming Yang, Congkai Xie, Zheng Wang, Zhongwei Xie, Ngai Wong, Hongxia Yang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-06 14:23:02</h6>
<p class='card-text'>Large language models have achieved significant advancements in complex
mathematical reasoning benchmarks, such as MATH. However, their substantial
computational requirements present challenges for practical deployment. Model
quantization has emerged as an effective strategy to reduce memory usage and
computational costs by employing lower precision and bit-width representations.
In this study, we systematically evaluate the impact of quantization on
mathematical reasoning tasks. Our results demonstrate that aggressive
quantization methods like AWQ and GPTQ introduce up to 32.39% accuracy
degradation (average 11.31%) on Llama-3 models, particularly in numerical
computation and reasoning planning. To address this, we introduce a
multidimensional evaluation framework combining qualitative capability analysis
and quantitative error assessment. We further develop targeted recovery
strategies, showing that fine-tuning quantized models on only 545 task-specific
examples for 3 minutes on 4 GPUs effectively restores reasoning capabilities to
near full-precision levels. Additionally, our error assessment pipeline
achieves 98.9% accuracy in diagnosing and localizing errors across 3,366
failure cases, providing actionable insights for mitigating
quantization-induced degradation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.15698v1' target='_blank'>Developing an Artificial Intelligence Tool for Personalized Breast
  Cancer Treatment Plans based on the NCCN Guidelines</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Abdul M. Mohammed, Iqtidar Mansoor, Sarah Blythe, Dennis Trujillo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-06 02:16:20</h6>
<p class='card-text'>Cancer treatments require personalized approaches based on a patient's
clinical condition, medical history, and evidence-based guidelines. The
National Comprehensive Cancer Network (NCCN) provides frequently updated,
complex guidelines through visuals like flowcharts and diagrams, which can be
time consuming for oncologists to stay current with treatment protocols. This
study presents an AI (Artificial Intelligence)-driven methodology to accurately
automate treatment regimens following NCCN guidelines for breast cancer
patients.
  We proposed two AI-driven methods: Agentic-RAG (Retrieval-Augmented
Generation) and Graph-RAG. Agentic-RAG used a three-step Large Language Model
(LLM) process to select clinical titles from NCCN guidelines, retrieve matching
JSON content, and iteratively refine recommendations based on insufficiency
checks. Graph-RAG followed a Microsoft-developed framework with proprietary
prompts, where JSON data was converted to text via an LLM, summarized, and
mapped into graph structures representing key treatment relationships. Final
recommendations were generated by querying relevant graph summaries. Both were
evaluated using a set of patient descriptions, each with four associated
questions.
  As shown in Table 1, Agentic RAG achieved a 100% adherence (24/24) with no
hallucinations or incorrect treatments. Graph-RAG had 95.8% adherence (23/24)
with one incorrect treatment and no hallucinations. Chat GPT-4 showed 91.6%
adherence (22/24) with two wrong treatments and no hallucinations. Both Agentic
RAG and Graph-RAG provided detailed treatment recommendations with accurate
references to relevant NCCN document page numbers.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.02486v2' target='_blank'>LLMPC: Large Language Model Predictive Control</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Gabriel Maher</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-05 09:37:23</h6>
<p class='card-text'>Recent advancements in prompting techniques for Large Language Models (LLMs)
have improved their reasoning, planning, and action abilities. This paper
examines these prompting techniques through the lens of model predictive
control (MPC). We show that LLMs act as implicit planning cost function
minimizers when planning prompts are used. We propose a unified MPC framework
for planning with LLMs and demonstrate improved performance over few shot
prompting on several planning benchmarks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.02348v1' target='_blank'>Thinking with Many Minds: Using Large Language Models for
  Multi-Perspective Problem-Solving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sanghyun Park, Boris Maciejovsky, Phanish Puranam</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-04 18:04:47</h6>
<p class='card-text'>Complex problem-solving requires cognitive flexibility--the capacity to
entertain multiple perspectives while preserving their distinctiveness. This
flexibility replicates the "wisdom of crowds" within a single individual,
allowing them to "think with many minds." While mental simulation enables
imagined deliberation, cognitive constraints limit its effectiveness. We
propose synthetic deliberation, a Large Language Model (LLM)-based method that
simulates discourse between agents embodying diverse perspectives, as a
solution. Using a custom GPT-based model, we showcase its benefits: concurrent
processing of multiple viewpoints without cognitive degradation, parallel
exploration of perspectives, and precise control over viewpoint synthesis. By
externalizing the deliberative process and distributing cognitive labor between
parallel search and integration, synthetic deliberation transcends mental
simulation's limitations. This approach shows promise for strategic planning,
policymaking, and conflict resolution.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.02152v1' target='_blank'>Table as Thought: Exploring Structured Thoughts in LLM Reasoning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhenjie Sun, Naihao Deng, Haofei Yu, Jiaxuan You</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-04 00:58:06</h6>
<p class='card-text'>Large language models' reasoning abilities benefit from methods that organize
their thought processes, such as chain-of-thought prompting, which employs a
sequential structure to guide the reasoning process step-by-step. However,
existing approaches focus primarily on organizing the sequence of thoughts,
leaving structure in individual thought steps underexplored. To address this
gap, we propose Table as Thought, a framework inspired by cognitive
neuroscience theories on human thought. Table as Thought organizes reasoning
within a tabular schema, where rows represent sequential thought steps and
columns capture critical constraints and contextual information to enhance
reasoning. The reasoning process iteratively populates the table until
self-verification ensures completeness and correctness. Our experiments show
that Table as Thought excels in planning tasks and demonstrates a strong
potential for enhancing LLM performance in mathematical reasoning compared to
unstructured thought baselines. This work provides a novel exploration of
refining thought representation within LLMs, paving the way for advancements in
reasoning and AI cognition.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.04040v2' target='_blank'>A Survey on Large Language Models with some Insights on their
  Capabilities and Limitations</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Andrea Matarazzo, Riccardo Torlone</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-03 21:04:49</h6>
<p class='card-text'>The rapid advancement of artificial intelligence, particularly with the
development of Large Language Models (LLMs) built on the transformer
architecture, has redefined the capabilities of natural language processing.
These models now exhibit remarkable performance across various language-related
tasks, such as text generation, question answering, translation, and
summarization, often rivaling human-like comprehension. More intriguingly, LLMs
have demonstrated emergent abilities extending beyond their core functions,
showing proficiency in tasks like commonsense reasoning, code generation, and
arithmetic. This survey paper explores the foundational components, scaling
mechanisms, and architectural strategies that drive these capabilities.
Emphasizing models like GPT and LLaMA, we analyze the impact of exponential
data and computational growth on LLM performance, while also addressing the
trade-offs associated with scaling. We also examine LLM applications across
sectors, such as healthcare, finance, education, and law, highlighting their
adaptability and potential to solve domain-specific challenges. Central to this
work are the questions of how LLMs generalize across diverse tasks, exhibit
planning, and reasoning abilities, and whether these emergent abilities can be
systematically elicited or enhanced. In particular, we provide some insights
into the CoT (Chain of Thought) and PoT (Plan of Thought) abilities within
LLMs, focusing on how pre-training data influences their emergence.
Additionally, we investigate LLM-modulo frameworks that integrate external
systems, allowing LLMs to handle complex, dynamic tasks. By analyzing these
factors, this paper aims to foster the ongoing discussion on the capabilities
and limits of LLMs, promoting their responsible development and application in
novel and increasingly complex environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.01205v1' target='_blank'>Harnessing Multi-Agent LLMs for Complex Engineering Problem-Solving: A
  Framework for Senior Design Projects</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Abdullah Mushtaq, Muhammad Rafay Naeem, Ibrahim Ghaznavi, Muhammad Imran Taj, Imran Hashmi, Junaid Qadir</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-01-02 11:25:45</h6>
<p class='card-text'>Multi-Agent Large Language Models (LLMs) are gaining significant attention
for their ability to harness collective intelligence in complex
problem-solving, decision-making, and planning tasks. This aligns with the
concept of the wisdom of crowds, where diverse agents contribute collectively
to generating effective solutions, making it particularly suitable for
educational settings. Senior design projects, also known as capstone or final
year projects, are pivotal in engineering education as they integrate
theoretical knowledge with practical application, fostering critical thinking,
teamwork, and real-world problem-solving skills. In this paper, we explore the
use of Multi-Agent LLMs in supporting these senior design projects undertaken
by engineering students, which often involve multidisciplinary considerations
and conflicting objectives, such as optimizing technical performance while
addressing ethical, social, and environmental concerns. We propose a framework
where distinct LLM agents represent different expert perspectives, such as
problem formulation agents, system complexity agents, societal and ethical
agents, or project managers, thus facilitating a holistic problem-solving
approach. This implementation leverages standard multi-agent system (MAS)
concepts such as coordination, cooperation, and negotiation, incorporating
prompt engineering to develop diverse personas for each agent. These agents
engage in rich, collaborative dialogues to simulate human engineering teams,
guided by principles from swarm AI to efficiently balance individual
contributions towards a unified solution. We adapt these techniques to create a
collaboration structure for LLM agents, encouraging interdisciplinary reasoning
and negotiation similar to real-world senior design projects. To assess the
efficacy of this framework, we collected six proposals of engineering and
computer science of...</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.00358v2' target='_blank'>Embodied VideoAgent: Persistent Memory from Egocentric Videos and
  Embodied Sensors Enables Dynamic Scene Understanding</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yue Fan, Xiaojian Ma, Rongpeng Su, Jun Guo, Rujie Wu, Xi Chen, Qing Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-31 09:22:38</h6>
<p class='card-text'>This paper investigates the problem of understanding dynamic 3D scenes from
egocentric observations, a key challenge in robotics and embodied AI. Unlike
prior studies that explored this as long-form video understanding and utilized
egocentric video only, we instead propose an LLM-based agent, Embodied
VideoAgent, which constructs scene memory from both egocentric video and
embodied sensory inputs (e.g. depth and pose sensing). We further introduce a
VLM-based approach to automatically update the memory when actions or
activities over objects are perceived. Embodied VideoAgent attains significant
advantages over counterparts in challenging reasoning and planning tasks in 3D
scenes, achieving gains of 4.9% on Ego4D-VQ3D, 5.8% on OpenEQA, and 11.7% on
EnvQA. We have also demonstrated its potential in various embodied AI tasks
including generating embodied interactions and perception for robot
manipulation. The code and demo will be made public.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.00316v1' target='_blank'>MapEval: A Map-Based Evaluation of Geo-Spatial Reasoning in Foundation
  Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mahir Labib Dihan, Md Tanvir Hassan, Md Tanvir Parvez, Md Hasebul Hasan, Md Almash Alam, Muhammad Aamir Cheema, Mohammed Eunus Ali, Md Rizwan Parvez</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-31 07:20:32</h6>
<p class='card-text'>Recent advancements in foundation models have enhanced AI systems'
capabilities in autonomous tool usage and reasoning. However, their ability in
location or map-based reasoning - which improves daily life by optimizing
navigation, facilitating resource discovery, and streamlining logistics - has
not been systematically studied. To bridge this gap, we introduce MapEval, a
benchmark designed to assess diverse and complex map-based user queries with
geo-spatial reasoning. MapEval features three task types (textual, API-based,
and visual) that require collecting world information via map tools, processing
heterogeneous geo-spatial contexts (e.g., named entities, travel distances,
user reviews or ratings, images), and compositional reasoning, which all
state-of-the-art foundation models find challenging. Comprising 700 unique
multiple-choice questions about locations across 180 cities and 54 countries,
MapEval evaluates foundation models' ability to handle spatial relationships,
map infographics, travel planning, and navigation challenges. Using MapEval, we
conducted a comprehensive evaluation of 28 prominent foundation models. While
no single model excelled across all tasks, Claude-3.5-Sonnet, GPT-4o, and
Gemini-1.5-Pro achieved competitive performance overall. However, substantial
performance gaps emerged, particularly in MapEval, where agents with
Claude-3.5-Sonnet outperformed GPT-4o and Gemini-1.5-Pro by 16% and 21%,
respectively, and the gaps became even more amplified when compared to
open-source LLMs. Our detailed analyses provide insights into the strengths and
weaknesses of current models, though all models still fall short of human
performance by more than 20% on average, struggling with complex map images and
rigorous geo-spatial reasoning. This gap highlights MapEval's critical role in
advancing general-purpose foundation models with stronger geo-spatial
understanding.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.00296v1' target='_blank'>Predicate Invention from Pixels via Pretrained Vision-Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ashay Athalye, Nishanth Kumar, Tom Silver, Yichao Liang, Tomás Lozano-Pérez, Leslie Pack Kaelbling</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-31 06:14:16</h6>
<p class='card-text'>Our aim is to learn to solve long-horizon decision-making problems in
highly-variable, combinatorially-complex robotics domains given raw sensor
input in the form of images. Previous work has shown that one way to achieve
this aim is to learn a structured abstract transition model in the form of
symbolic predicates and operators, and then plan within this model to solve
novel tasks at test time. However, these learned models do not ground directly
into pixels from just a handful of demonstrations. In this work, we propose to
invent predicates that operate directly over input images by leveraging the
capabilities of pretrained vision-language models (VLMs). Our key idea is that,
given a set of demonstrations, a VLM can be used to propose a set of predicates
that are potentially relevant for decision-making and then to determine the
truth values of these predicates in both the given demonstrations and new image
inputs. We build upon an existing framework for predicate invention, which
generates feature-based predicates operating on object-centric states, to also
generate visual predicates that operate on images. Experimentally, we show that
our approach -- pix2pred -- is able to invent semantically meaningful
predicates that enable generalization to novel, complex, and long-horizon tasks
across two simulated robotic environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.21154v1' target='_blank'>Aviary: training language agents on challenging scientific tasks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Siddharth Narayanan, James D. Braza, Ryan-Rhys Griffiths, Manu Ponnapati, Albert Bou, Jon Laurent, Ori Kabeli, Geemi Wellawatte, Sam Cox, Samuel G. Rodriques, Andrew D. White</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-30 18:33:28</h6>
<p class='card-text'>Solving complex real-world tasks requires cycles of actions and observations.
This is particularly true in science, where tasks require many cycles of
analysis, tool use, and experimentation. Language agents are promising for
automating intellectual tasks in science because they can interact with tools
via natural language or code. Yet their flexibility creates conceptual and
practical challenges for software implementations, since agents may comprise
non-standard components such as internal reasoning, planning, tool usage, as
well as the inherent stochasticity of temperature-sampled language models.
Here, we introduce Aviary, an extensible gymnasium for language agents. We
formalize agents as policies solving language-grounded partially observable
Markov decision processes, which we term language decision processes. We then
implement five environments, including three challenging scientific
environments: (1) manipulating DNA constructs for molecular cloning, (2)
answering research questions by accessing scientific literature, and (3)
engineering protein stability. These environments were selected for their focus
on multi-step reasoning and their relevance to contemporary biology research.
Finally, with online training and scaling inference-time compute, we show that
language agents backed by open-source, non-frontier LLMs can match and exceed
both frontier LLM agents and human experts on multiple tasks at up to 100x
lower inference cost.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.21051v1' target='_blank'>Toward Intelligent and Secure Cloud: Large Language Model Empowered
  Proactive Defense</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuyang Zhou, Guang Cheng, Kang Du, Zihan Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-30 16:09:28</h6>
<p class='card-text'>The rapid evolution of cloud computing technologies and the increasing number
of cloud applications have provided a large number of benefits in daily lives.
However, the diversity and complexity of different components pose a
significant challenge to cloud security, especially when dealing with
sophisticated and advanced cyberattacks. Recent advancements in generative
foundation models (GFMs), particularly in the large language models (LLMs),
offer promising solutions for security intelligence. By exploiting the powerful
abilities in language understanding, data analysis, task inference, action
planning, and code generation, we present LLM-PD, a novel proactive defense
architecture that defeats various threats in a proactive manner. LLM-PD can
efficiently make a decision through comprehensive data analysis and sequential
reasoning, as well as dynamically creating and deploying actionable defense
mechanisms on the target cloud. Furthermore, it can flexibly self-evolve based
on experience learned from previous interactions and adapt to new attack
scenarios without additional training. The experimental results demonstrate its
remarkable ability in terms of defense effectiveness and efficiency,
particularly highlighting an outstanding success rate when compared with other
existing methods.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.21033v1' target='_blank'>Plancraft: an evaluation dataset for planning with LLM agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Gautier Dagan, Frank Keller, Alex Lascarides</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-30 15:58:41</h6>
<p class='card-text'>We present Plancraft, a multi-modal evaluation dataset for LLM agents.
Plancraft has both a text-only and multi-modal interface, based on the
Minecraft crafting GUI. We include the Minecraft Wiki to evaluate tool use and
Retrieval Augmented Generation (RAG), as well as an oracle planner and oracle
RAG information extractor, to ablate the different components of a modern agent
architecture. To evaluate decision-making, Plancraft also includes a subset of
examples that are intentionally unsolvable, providing a realistic challenge
that requires the agent not only to complete tasks but also to decide whether
they are solvable at all. We benchmark both open-source and closed-source LLMs
and strategies on our task and compare their performance to a handcrafted
planner. We find that LLMs and VLMs struggle with the planning problems that
Plancraft introduces, and we offer suggestions on how to improve their
capabilities.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.20995v1' target='_blank'>KARPA: A Training-free Method of Adapting Knowledge Graph as References
  for Large Language Model's Reasoning Path Aggregation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Siyuan Fang, Kaijing Ma, Tianyu Zheng, Xinrun Du, Ningxuan Lu, Ge Zhang, Qingkun Tang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-30 14:58:46</h6>
<p class='card-text'>Large language models (LLMs) demonstrate exceptional performance across a
variety of tasks, yet they are often affected by hallucinations and the
timeliness of knowledge. Leveraging knowledge graphs (KGs) as external
knowledge sources has emerged as a viable solution, but existing methods for
LLM-based knowledge graph question answering (KGQA) are often limited by
step-by-step decision-making on KGs, restricting the global planning and
reasoning capabilities of LLMs, or they require fine-tuning or pre-training on
specific KGs. To address these challenges, we propose Knowledge graph Assisted
Reasoning Path Aggregation (KARPA), a novel framework that harnesses the global
planning abilities of LLMs for efficient and accurate KG reasoning. KARPA
operates in three steps: pre-planning relation paths using the LLM's global
planning capabilities, matching semantically relevant paths via an embedding
model, and reasoning over these paths to generate answers. Unlike existing KGQA
methods, KARPA avoids stepwise traversal, requires no additional training, and
is adaptable to various LLM architectures. Extensive experimental results show
that KARPA achieves state-of-the-art performance in KGQA tasks, delivering both
high efficiency and accuracy. Our code will be available on Github.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.20662v2' target='_blank'>Enhancing Table Recognition with Vision LLMs: A Benchmark and
  Neighbor-Guided Toolchain Reasoner</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yitong Zhou, Mingyue Cheng, Qingyang Mao, Qi Liu, Feiyang Xu, Xin Li, Enhong Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-30 02:40:19</h6>
<p class='card-text'>Pre-trained foundation models have recently significantly progressed in
structured table understanding and reasoning. However, despite advancements in
areas such as table semantic understanding and table question answering,
recognizing the structure and content of unstructured tables using Vision Large
Language Models (VLLMs) remains under-explored. In this work, we address this
research gap by employing VLLMs in a training-free reasoning paradigm. First,
we design a benchmark with various hierarchical dimensions relevant to table
recognition. Subsequently, we conduct in-depth evaluations using pre-trained
VLLMs, finding that low-quality image input is a significant bottleneck in the
recognition process. Drawing inspiration from these findings, we propose the
Neighbor-Guided Toolchain Reasoner (NGTR) framework, which is characterized by
integrating multiple lightweight models for low-level visual processing
operations aimed at mitigating issues with low-quality input images.
Specifically, we utilize a neighbor retrieval mechanism to guide the generation
of multiple tool invocation plans, transferring tool selection experiences from
similar neighbors to the given input, thereby facilitating suitable tool
selection. Additionally, we introduce a reflection module to supervise the tool
invocation process. Extensive experiments on public table recognition datasets
demonstrate that our approach significantly enhances the recognition
capabilities of the vanilla VLLMs. We believe that the designed benchmark and
the proposed NGTR framework could provide an alternative solution in table
recognition.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.20505v1' target='_blank'>Planning, Living and Judging: A Multi-agent LLM-based Framework for
  Cyclical Urban Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hang Ni, Yuzhi Wang, Hao Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-29 15:43:25</h6>
<p class='card-text'>Urban regeneration presents significant challenges within the context of
urbanization, requiring adaptive approaches to tackle evolving needs.
Leveraging advancements in large language models (LLMs), we propose Cyclical
Urban Planning (CUP), a new paradigm that continuously generates, evaluates,
and refines urban plans in a closed-loop. Specifically, our multi-agent
LLM-based framework consists of three key components: (1) Planning, where LLM
agents generate and refine urban plans based on contextual data; (2) Living,
where agents simulate the behaviors and interactions of residents, modeling
life in the urban environment; and (3) Judging, which involves evaluating plan
effectiveness and providing iterative feedback for improvement. The cyclical
process enables a dynamic and responsive planning approach. Experiments on the
real-world dataset demonstrate the effectiveness of our framework as a
continuous and adaptive planning process.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.20297v1' target='_blank'>FaGeL: Fabric LLMs Agent empowered Embodied Intelligence Evolution with
  Autonomous Human-Machine Collaboration</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jia Liu, Min Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-28 23:26:52</h6>
<p class='card-text'>Recent advancements in Large Language Models (LLMs) have enhanced the
reasoning capabilities of embodied agents, driving progress toward AGI-powered
robotics. While LLMs have been applied to tasks like semantic reasoning and
task generalization, their potential in open physical space exploration remains
underexplored. This paper introduces FaGeL (Fabric aGent empowered by embodied
intelligence with LLMs), an embodied agent integrating smart fabric technology
for seamless, non-intrusive human-agent interaction. FaGeL autonomously
generates tasks using multimodal data from wearable and ambient sensors,
refining its behavior based on implicit human feedback in generated text,
without explicit ratings or preferences. We also introduce a token-level
saliency map to visualize LLM fine-tuning, enhancing the interpretability of
token-level alignment. The system leverages dual feedback mechanisms to improve
token-level alignment and addresses challenges in non-intrusive human-machine
interaction and cognition evolution. Our contributions include FaGeL's
development, the DualCUT algorithm for AI alignment, and experimental
validation in cooperative tasks, demonstrating FaGeL's ability to adapt and
evolve autonomously through implicit feedback. In the future, we plan to
explore FaGeL's scalability in dynamic environments and its integration with
other AI systems to develop AGI agents that adapt seamlessly to diverse human
needs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.20145v2' target='_blank'>Efficient Multi-Agent Collaboration with Tool Use for Online Planning in
  Complex Table Question Answering</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wei Zhou, Mohsen Mesgar, Annemarie Friedrich, Heike Adel</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-28 13:13:33</h6>
<p class='card-text'>Complex table question answering (TQA) aims to answer questions that require
complex reasoning, such as multi-step or multi-category reasoning, over data
represented in tabular form. Previous approaches demonstrated notable
performance by leveraging either closed-source large language models (LLMs) or
fine-tuned open-weight LLMs. However, fine-tuning LLMs requires high-quality
training data, which is costly to obtain, and utilizing closed-source LLMs
poses accessibility challenges and leads to reproducibility issues. In this
paper, we propose Multi-Agent Collaboration with Tool use (MACT), a framework
that requires neither closed-source models nor fine-tuning. In MACT, a planning
agent and a coding agent that also make use of tools collaborate to answer
questions. Our experiments on four TQA benchmarks show that MACT outperforms
previous SoTA systems on three out of four benchmarks and that it performs
comparably to the larger and more expensive closed-source model GPT-4 on two
benchmarks, even when using only open-weight models without any fine-tuning. We
conduct extensive analyses to prove the effectiveness of MACT's multi-agent
collaboration in TQA.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.19139v2' target='_blank'>PlanLLM: Video Procedure Planning with Refinable Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Dejie Yang, Zijing Zhao, Yang Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-26 09:51:05</h6>
<p class='card-text'>Video procedure planning, i.e., planning a sequence of action steps given the
video frames of start and goal states, is an essential ability for embodied AI.
Recent works utilize Large Language Models (LLMs) to generate enriched action
step description texts to guide action step decoding. Although LLMs are
introduced, these methods decode the action steps into a closed-set of one-hot
vectors, limiting the model's capability of generalizing to new steps or tasks.
Additionally, fixed action step descriptions based on world-level commonsense
may contain noise in specific instances of visual states. In this paper, we
propose PlanLLM, a cross-modal joint learning framework with LLMs for video
procedure planning. We propose an LLM-Enhanced Planning module which fully uses
the generalization ability of LLMs to produce free-form planning output and to
enhance action step decoding. We also propose Mutual Information Maximization
module to connect world-level commonsense of step descriptions and
sample-specific information of visual states, enabling LLMs to employ the
reasoning ability to generate step sequences. With the assistance of LLMs, our
method can both closed-set and open vocabulary procedure planning tasks. Our
PlanLLM achieves superior performance on three benchmarks, demonstrating the
effectiveness of our designs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.18695v1' target='_blank'>TimelyLLM: Segmented LLM Serving System for Time-sensitive Robotic
  Applications</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Neiwen Ling, Guojun Chen, Lin Zhong</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-24 22:51:29</h6>
<p class='card-text'>Large Language Models (LLMs) such as GPT-4 and Llama3 can already comprehend
complex commands and process diverse tasks. This advancement facilitates their
application in controlling drones and robots for various tasks. However,
existing LLM serving systems typically employ a first-come, first-served (FCFS)
batching mechanism, which fails to address the time-sensitive requirements of
robotic applications. To address it, this paper proposes a new system named
TimelyLLM serving multiple robotic agents with time-sensitive requests.
TimelyLLM introduces novel mechanisms of segmented generation and scheduling
that optimally leverage redundancy between robot plan generation and execution
phases. We report an implementation of TimelyLLM on a widely-used LLM serving
framework and evaluate it on a range of robotic applications. Our evaluation
shows that TimelyLLM improves the time utility up to 1.97x, and reduces the
overall waiting time by 84%.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.18588v1' target='_blank'>A Paragraph is All It Takes: Rich Robot Behaviors from Interacting,
  Trusted LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:OpenMind, Shaohong Zhong, Adam Zhou, Boyuan Chen, Homin Luo, Jan Liphardt</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-24 18:41:15</h6>
<p class='card-text'>Large Language Models (LLMs) are compact representations of all public
knowledge of our physical environment and animal and human behaviors. The
application of LLMs to robotics may offer a path to highly capable robots that
perform well across most human tasks with limited or even zero tuning. Aside
from increasingly sophisticated reasoning and task planning, networks of
(suitably designed) LLMs offer ease of upgrading capabilities and allow humans
to directly observe the robot's thinking. Here we explore the advantages,
limitations, and particularities of using LLMs to control physical robots. The
basic system consists of four LLMs communicating via a human language data bus
implemented via web sockets and ROS2 message passing. Surprisingly, rich robot
behaviors and good performance across different tasks could be achieved despite
the robot's data fusion cycle running at only 1Hz and the central data bus
running at the extremely limited rates of the human brain, of around 40 bits/s.
The use of natural language for inter-LLM communication allowed the robot's
reasoning and decision making to be directly observed by humans and made it
trivial to bias the system's behavior with sets of rules written in plain
English. These rules were immutably written into Ethereum, a global, public,
and censorship resistant Turing-complete computer. We suggest that by using
natural language as the data bus among interacting AIs, and immutable public
ledgers to store behavior constraints, it is possible to build robots that
combine unexpectedly rich performance, upgradability, and durable alignment
with humans.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.18428v1' target='_blank'>Explainable Multi-Modal Data Exploration in Natural Language via LLM
  Agent</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Farhad Nooralahzadeh, Yi Zhang, Jonathan Furst, Kurt Stockinger</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-24 13:42:44</h6>
<p class='card-text'>International enterprises, organizations, or hospitals collect large amounts
of multi-modal data stored in databases, text documents, images, and videos.
While there has been recent progress in the separate fields of multi-modal data
exploration as well as in database systems that automatically translate natural
language questions to database query languages, the research challenge of
querying database systems combined with other unstructured modalities such as
images in natural language is widely unexplored.
  In this paper, we propose XMODE - a system that enables explainable,
multi-modal data exploration in natural language. Our approach is based on the
following research contributions: (1) Our system is inspired by a real-world
use case that enables users to explore multi-modal information systems. (2)
XMODE leverages a LLM-based agentic AI framework to decompose a natural
language question into subtasks such as text-to-SQL generation and image
analysis. (3) Experimental results on multi-modal datasets over relational data
and images demonstrate that our system outperforms state-of-the-art multi-modal
exploration systems, excelling not only in accuracy but also in various
performance metrics such as query latency, API costs, planning efficiency, and
explanation quality, thanks to the more effective utilization of the reasoning
capabilities of LLMs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.18371v2' target='_blank'>Defining and Detecting the Defects of the Large Language Model-based
  Autonomous Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kaiwen Ning, Jiachi Chen, Jingwen Zhang, Wei Li, Zexu Wang, Yuming Feng, Weizhe Zhang, Zibin Zheng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-24 11:54:14</h6>
<p class='card-text'>AI agents are systems capable of perceiving their environment, autonomously
planning and executing tasks. Recent advancements in LLM have introduced a
transformative paradigm for AI agents, enabling them to interact with external
resources and tools through prompts. In such agents, the workflow integrates
developer-written code, which manages framework construction and logic control,
with LLM-generated natural language that enhances dynamic decision-making and
interaction. However, discrepancies between developer-implemented logic and the
dynamically generated content of LLMs in terms of behavior and expected
outcomes can lead to defects, such as tool invocation failures and task
execution errors. These issues introduce specific risks, leading to various
defects in LLM-based AI Agents, such as service interruptions. Despite the
importance of these issues, there is a lack of systematic work that focuses on
analyzing LLM-based AI Agents to uncover defects in their code. In this paper,
we present the first study focused on identifying and detecting defects in LLM
Agents. We collected and analyzed 6,854 relevant posts from StackOverflow to
define 8 types of agent defects. For each type, we provided detailed
descriptions with an example. Then, we designed a static analysis tool, named
Agentable, to detect the defects. Agentable leverages Code Property Graphs and
LLMs to analyze Agent workflows by efficiently identifying specific code
patterns and analyzing natural language descriptions. To evaluate Agentable, we
constructed two datasets: AgentSet, consists of 84 real-world Agents, and
AgentTest, which contains 78 Agents specifically designed to include various
types of defects. Our results show that Agentable achieved an overall accuracy
of 88.79% and a recall rate of 91.03%. Furthermore, our analysis reveals the
889 defects of the AgentSet, highlighting the prevalence of these defects.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.06193v1' target='_blank'>A Novel Task-Driven Method with Evolvable Interactive Agents Using Event
  Trees for Enhanced Emergency Decision Support</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xingyu Xiao, Peng Chen, Ben Qi, Jingang Liang, Jiejuan Tong, Haitao Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-24 04:53:46</h6>
<p class='card-text'>As climate change and other global challenges increase the likelihood of
unforeseen emergencies, the limitations of human-driven strategies in critical
situations become more pronounced. Inadequate pre-established emergency plans
can lead operators to become overwhelmed during complex systems malfunctions.
This study addresses the urgent need for agile decision-making in response to
various unforeseen incidents through a novel approach, EvoTaskTree (a
task-driven method with evolvable interactive agents using event trees for
emergency decision support). This advanced approach integrates two types of
agents powered by large language models (LLMs): task executors, responsible for
executing critical procedures, and task validators, ensuring the efficacy of
those actions. By leveraging insights from event tree analysis, our framework
encompasses three crucial tasks: initiating event subevent analysis, event tree
header event analysis, and decision recommendations. The agents learn from both
successful and unsuccessful responses from these tasks. Finally, we use nuclear
power plants as a demonstration of a safety-critical system. Our findings
indicate that the designed agents are not only effective but also outperform
existing approaches, achieving an impressive accuracy rate of up to 100 % in
processing previously unencoun32 tered incident scenarios. This paper
demonstrates that EvoTaskTree significantly enhances the rapid formulation of
emergency decision-making.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.18100v1' target='_blank'>EvoPat: A Multi-LLM-based Patents Summarization and Analysis Agent</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Suyuan Wang, Xueqian Yin, Menghao Wang, Ruofeng Guo, Kai Nan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-24 02:21:09</h6>
<p class='card-text'>The rapid growth of scientific techniques and knowledge is reflected in the
exponential increase in new patents filed annually. While these patents drive
innovation, they also present significant burden for researchers and engineers,
especially newcomers. To avoid the tedious work of navigating a vast and
complex landscape to identify trends and breakthroughs, researchers urgently
need efficient tools to summarize, evaluate, and contextualize patents,
revealing their innovative contributions and underlying scientific
principles.To address this need, we present EvoPat, a multi-LLM-based patent
agent designed to assist users in analyzing patents through Retrieval-Augmented
Generation (RAG) and advanced search strategies. EvoPat leverages multiple
Large Language Models (LLMs), each performing specialized roles such as
planning, identifying innovations, and conducting comparative evaluations. The
system integrates data from local databases, including patents, literature,
product catalogous, and company repositories, and online searches to provide
up-to-date insights. The ability to collect information not included in
original database automatically is also implemented. Through extensive testing
in the natural language processing (NLP) domain, we demonstrate that EvoPat
outperforms GPT-4 in tasks such as patent summarization, comparative analysis,
and technical evaluation. EvoPat represents a significant step toward creating
AI-powered tools that empower researchers and engineers to efficiently navigate
the complexities of the patent landscape.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.18086v1' target='_blank'>Generating Traffic Scenarios via In-Context Learning to Learn Better
  Motion Planner</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Aizierjiang Aiersilan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-24 01:52:19</h6>
<p class='card-text'>Motion planning is a crucial component in autonomous driving.
State-of-the-art motion planners are trained on meticulously curated datasets,
which are not only expensive to annotate but also insufficient in capturing
rarely seen critical scenarios. Failing to account for such scenarios poses a
significant risk to motion planners and may lead to incidents during testing.
An intuitive solution is to manually compose such scenarios by programming and
executing a simulator (e.g., CARLA). However, this approach incurs substantial
human costs. Motivated by this, we propose an inexpensive method for generating
diverse critical traffic scenarios to train more robust motion planners. First,
we represent traffic scenarios as scripts, which are then used by the simulator
to generate traffic scenarios. Next, we develop a method that accepts
user-specified text descriptions, which a Large Language Model (LLM) translates
into scripts using in-context learning. The output scripts are sent to the
simulator that produces the corresponding traffic scenarios. As our method can
generate abundant safety-critical traffic scenarios, we use them as synthetic
training data for motion planners. To demonstrate the value of generated
scenarios, we train existing motion planners on our synthetic data, real-world
datasets, and a combination of both. Our experiments show that motion planners
trained with our data significantly outperform those trained solely on
real-world data, showing the usefulness of our synthetic data and the
effectiveness of our data generation method. Our source code is available at
https://ezharjan.github.io/AutoSceneGen.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.17288v1' target='_blank'>Multi-Modal Grounded Planning and Efficient Replanning For Learning
  Embodied Agents with A Few Examples</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Taewoong Kim, Byeonghwi Kim, Jonghyun Choi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-23 05:20:01</h6>
<p class='card-text'>Learning a perception and reasoning module for robotic assistants to plan
steps to perform complex tasks based on natural language instructions often
requires large free-form language annotations, especially for short high-level
instructions. To reduce the cost of annotation, large language models (LLMs)
are used as a planner with few data. However, when elaborating the steps, even
the state-of-the-art planner that uses LLMs mostly relies on linguistic common
sense, often neglecting the status of the environment at command reception,
resulting in inappropriate plans. To generate plans grounded in the
environment, we propose FLARE (Few-shot Language with environmental Adaptive
Replanning Embodied agent), which improves task planning using both language
command and environmental perception. As language instructions often contain
ambiguities or incorrect expressions, we additionally propose to correct the
mistakes using visual cues from the agent. The proposed scheme allows us to use
a few language pairs thanks to the visual cues and outperforms state-of-the-art
approaches. Our code is available at https://github.com/snumprlab/flare.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.16964v2' target='_blank'>System-2 Mathematical Reasoning via Enriched Instruction Tuning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Huanqia Cai, Yijun Yang, Zhifeng Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-22 10:49:27</h6>
<p class='card-text'>Solving complex mathematical problems via system-2 reasoning is a natural
human skill, yet it remains a significant challenge for current large language
models (LLMs). We identify the scarcity of deliberate multi-step reasoning data
as a primary limiting factor. To this end, we introduce Enriched Instruction
Tuning (EIT), a method that enriches existing human-annotated mathematical
datasets by synergizing human and AI feedback to create fine-grained reasoning
trajectories. These datasets are then used to fine-tune open-source LLMs,
enhancing their mathematical reasoning abilities without reliance on any
symbolic verification program. Concretely, EIT is composed of two critical
steps: Enriching with Reasoning Plan (ERP) and Enriching with Reasoning Step
(ERS). The former generates a high-level plan that breaks down complex
instructions into a sequence of simpler objectives, while ERS fills in
reasoning contexts often overlooked by human annotators, creating a smoother
reasoning trajectory for LLM fine-tuning. Unlike existing CoT prompting methods
that generate reasoning chains only depending on LLM's internal knowledge, our
method leverages human-annotated initial answers as ``meta-knowledge'' to help
LLMs generate more detailed and precise reasoning processes, leading to a more
trustworthy LLM expert for complex mathematical problems. In experiments, EIT
achieves an accuracy of 84.1% on GSM8K and 32.5% on MATH, surpassing
state-of-the-art fine-tuning and prompting methods, and even matching the
performance of tool-augmented methods.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.16633v2' target='_blank'>POEX: Understanding and Mitigating Policy Executable Jailbreak Attacks
  against Embodied AI</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xuancun Lu, Zhengxian Huang, Xinfeng Li, Xiaoyu ji, Wenyuan Xu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-21 13:58:27</h6>
<p class='card-text'>Embodied AI systems are rapidly evolving due to the integration of LLMs as
planning modules, which transform complex instructions into executable
policies. However, LLMs are vulnerable to jailbreak attacks, which can generate
malicious content. This paper investigates the feasibility and rationale behind
applying traditional LLM jailbreak attacks to EAI systems. We aim to answer
three questions: (1) Do traditional LLM jailbreak attacks apply to EAI systems?
(2) What challenges arise if they do not? and (3) How can we defend against EAI
jailbreak attacks? To this end, we first measure existing LLM-based EAI systems
using a newly constructed dataset, i.e., the Harmful-RLbench. Our study
confirms that traditional LLM jailbreak attacks are not directly applicable to
EAI systems and identifies two unique challenges. First, the harmful text does
not necessarily constitute harmful policies. Second, even if harmful policies
can be generated, they are not necessarily executable by the EAI systems, which
limits the potential risk. To facilitate a more comprehensive security
analysis, we refine and introduce POEX, a novel red teaming framework that
optimizes adversarial suffixes to induce harmful yet executable policies
against EAI systems. The design of POEX employs adversarial constraints, policy
evaluators, and suffix optimization to ensure successful policy execution while
evading safety detection inside an EAI system. Experiments on the real-world
robotic arm and simulator using Harmful-RLbench demonstrate the efficacy,
highlighting severe safety vulnerabilities and high transferability across
models. Finally, we propose prompt-based and model-based defenses, achieving an
85% success rate in mitigating attacks and enhancing safety awareness in EAI
systems. Our findings underscore the urgent need for robust security measures
to ensure the safe deployment of EAI in critical applications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.16533v1' target='_blank'>Self-guided Knowledgeable Network of Thoughts: Amplifying Reasoning with
  Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chao-Chi Chen, Chin-Yuan Yeh, Hsi-Wen Chen, De-Nian Yang, Ming-Syan Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-21 08:19:42</h6>
<p class='card-text'>We introduce Knowledgeable Network of Thoughts (kNoT): a prompt scheme that
advances the capabilities of large language models (LLMs) beyond existing
paradigms like Chain-of-Thought (CoT), Tree of Thoughts (ToT), and Graph of
Thoughts (GoT). The key innovation of kNoT is the LLM Workflow Template (LWT),
which allows for an executable plan to be specified by LLMs for LLMs. LWT
allows these plans to be arbitrary networks, where single-step LLM operations
are nodes, and edges correspond to message passing between these steps.
Furthermore, LWT supports selection of individual elements through indexing,
facilitating kNoT to produce intricate plans where each LLM operation can be
limited to elementary operations, greatly enhancing reliability over extended
task sequences. We demonstrate that kNoT significantly outperforms the state of
the art on six use cases, while reducing the need for extensive prompt
engineering. For instance, kNoT finds 92% accuracy for sorting 32 numbers over
12% and 31% for ToT and GoT, while utilizing up to 84.4% and 87.3% less
task-specific prompts, respectively.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.17861v1' target='_blank'>From Vocal Instructions to Household Tasks: The Inria Tiago++ in the
  euROBIN Service Robots Coopetition</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Fabio Amadio, Clemente Donoso, Dionis Totsila, Raphael Lorenzo, Quentin Rouxel, Olivier Rochel, Enrico Mingo Hoffman, Jean-Baptiste Mouret, Serena Ivaldi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-20 15:45:11</h6>
<p class='card-text'>This paper describes the Inria team's integrated robotics system used in the
1st euROBIN coopetition, during which service robots performed voice-activated
household tasks in a kitchen setting.The team developed a modified Tiago++
platform that leverages a whole-body control stack for autonomous and
teleoperated modes, and an LLM-based pipeline for instruction understanding and
task planning. The key contributions (opens-sourced) are the integration of
these components and the design of custom teleoperation devices, addressing
practical challenges in the deployment of service robots.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.15462v1' target='_blank'>TalkWithMachines: Enhancing Human-Robot Interaction for Interpretable
  Industrial Robotics Through Large/Vision Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ammar N. Abbas, Csaba Beleznai</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-19 23:43:40</h6>
<p class='card-text'>TalkWithMachines aims to enhance human-robot interaction by contributing to
interpretable industrial robotic systems, especially for safety-critical
applications. The presented paper investigates recent advancements in Large
Language Models (LLMs) and Vision Language Models (VLMs), in combination with
robotic perception and control. This integration allows robots to understand
and execute commands given in natural language and to perceive their
environment through visual and/or descriptive inputs. Moreover, translating the
LLM's internal states and reasoning into text that humans can easily understand
ensures that operators gain a clearer insight into the robot's current state
and intentions, which is essential for effective and safe operation. Our paper
outlines four LLM-assisted simulated robotic control workflows, which explore
(i) low-level control, (ii) the generation of language-based feedback that
describes the robot's internal states, (iii) the use of visual information as
additional input, and (iv) the use of robot structure information for
generating task plans and feedback, taking the robot's physical capabilities
and limitations into account. The proposed concepts are presented in a set of
experiments, along with a brief discussion. Project description, videos, and
supplementary materials will be available on the project website:
https://talk-machines.github.io.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.14989v1' target='_blank'>RoboCup@Home 2024 OPL Winner NimbRo: Anthropomorphic Service Robots
  using Foundation Models for Perception and Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Raphael Memmesheimer, Jan Nogga, Bastian Pätzold, Evgenii Kruzhkov, Simon Bultmann, Michael Schreiber, Jonas Bode, Bertan Karacora, Juhui Park, Alena Savinykh, Sven Behnke</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-19 16:00:43</h6>
<p class='card-text'>We present the approaches and contributions of the winning team NimbRo@Home
at the RoboCup@Home 2024 competition in the Open Platform League held in
Eindhoven, NL. Further, we describe our hardware setup and give an overview of
the results for the task stages and the final demonstration. For this year's
competition, we put a special emphasis on open-vocabulary object segmentation
and grasping approaches that overcome the labeling overhead of supervised
vision approaches, commonly used in RoboCup@Home. We successfully demonstrated
that we can segment and grasp non-labeled objects by text descriptions.
Further, we extensively employed LLMs for natural language understanding and
task planning. Throughout the competition, our approaches showed robustness and
generalization capabilities. A video of our performance can be found online.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.14986v1' target='_blank'>Chain-of-MetaWriting: Linguistic and Textual Analysis of How Small
  Language Models Write Young Students Texts</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ioana Buhnila, Georgeta Cislaru, Amalia Todirascu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-19 15:58:53</h6>
<p class='card-text'>Large Language Models (LLMs) have been used to generate texts in response to
different writing tasks: reports, essays, story telling. However, language
models do not have a meta-representation of the text writing process, nor
inherent communication learning needs, comparable to those of young human
students. This paper introduces a fine-grained linguistic and textual analysis
of multilingual Small Language Models' (SLMs) writing. With our method,
Chain-of-MetaWriting, SLMs can imitate some steps of the human writing process,
such as planning and evaluation. We mainly focused on short story and essay
writing tasks in French for schoolchildren and undergraduate students
respectively. Our results show that SLMs encounter difficulties in assisting
young students on sensitive topics such as violence in the schoolyard, and they
sometimes use words too complex for the target audience. In particular, the
output is quite different from the human produced texts in term of text
cohesion and coherence regarding temporal connectors, topic progression,
reference.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.14584v1' target='_blank'>Simulation-Free Hierarchical Latent Policy Planning for Proactive
  Dialogues</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tao He, Lizi Liao, Yixin Cao, Yuanxing Liu, Yiheng Sun, Zerui Chen, Ming Liu, Bing Qin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-19 07:06:01</h6>
<p class='card-text'>Recent advancements in proactive dialogues have garnered significant
attention, particularly for more complex objectives (e.g. emotion support and
persuasion). Unlike traditional task-oriented dialogues, proactive dialogues
demand advanced policy planning and adaptability, requiring rich scenarios and
comprehensive policy repositories to develop such systems. However, existing
approaches tend to rely on Large Language Models (LLMs) for user simulation and
online learning, leading to biases that diverge from realistic scenarios and
result in suboptimal efficiency. Moreover, these methods depend on manually
defined, context-independent, coarse-grained policies, which not only incur
high expert costs but also raise concerns regarding their completeness. In our
work, we highlight the potential for automatically discovering policies
directly from raw, real-world dialogue records. To this end, we introduce a
novel dialogue policy planning framework, LDPP. It fully automates the process
from mining policies in dialogue records to learning policy planning.
Specifically, we employ a variant of the Variational Autoencoder to discover
fine-grained policies represented as latent vectors. After automatically
annotating the data with these latent policy labels, we propose an Offline
Hierarchical Reinforcement Learning (RL) algorithm in the latent space to
develop effective policy planning capabilities. Our experiments demonstrate
that LDPP outperforms existing methods on two proactive scenarios, even
surpassing ChatGPT with only a 1.8-billion-parameter LLM.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.14222v1' target='_blank'>A Survey on Large Language Model-based Agents for Statistics and Data
  Science</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Maojun Sun, Ruijian Han, Binyan Jiang, Houduo Qi, Defeng Sun, Yancheng Yuan, Jian Huang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-18 15:03:26</h6>
<p class='card-text'>In recent years, data science agents powered by Large Language Models (LLMs),
known as "data agents," have shown significant potential to transform the
traditional data analysis paradigm. This survey provides an overview of the
evolution, capabilities, and applications of LLM-based data agents,
highlighting their role in simplifying complex data tasks and lowering the
entry barrier for users without related expertise. We explore current trends in
the design of LLM-based frameworks, detailing essential features such as
planning, reasoning, reflection, multi-agent collaboration, user interface,
knowledge integration, and system design, which enable agents to address
data-centric problems with minimal human intervention. Furthermore, we analyze
several case studies to demonstrate the practical applications of various data
agents in real-world scenarios. Finally, we identify key challenges and propose
future research directions to advance the development of data agents into
intelligent statistical analysis software.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.13774v1' target='_blank'>Designing an LLM-Based Copilot for Manufacturing Equipment Selection</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jonas Werheid, Oleksandr Melnychuk, Hans Zhou, Meike Huber, Christoph Rippe, Dominik Joosten, Zozan Keskin, Max Wittstamm, Sathya Subramani, Benny Drescher, Amon Göppert, Anas Abdelrazeq, Robert H. Schmitt</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-18 12:11:39</h6>
<p class='card-text'>Effective decision-making in automation equipment selection is critical for
reducing ramp-up time and maintaining production quality, especially in the
face of increasing product variation and market demands. However, limited
expertise and resource constraints often result in inefficiencies during the
ramp-up phase when new products are integrated into production lines. Existing
methods often lack structured and tailored solutions to support automation
engineers in reducing ramp-up time, leading to compromises in quality. This
research investigates whether large-language models (LLMs), combined with
Retrieval-Augmented Generation (RAG), can assist in streamlining equipment
selection in ramp-up planning. We propose a factual-driven copilot integrating
LLMs with structured and semi-structured knowledge retrieval for three
component types (robots, feeders and vision systems), providing a guided and
traceable state-machine process for decision-making in automation equipment
selection. The system was demonstrated to an industrial partner, who tested it
on three internal use-cases. Their feedback affirmed its capability to provide
logical and actionable recommendations for automation equipment. More
specifically, among 22 equipment prompts analyzed, 19 involved selecting the
correct equipment while considering most requirements, and in 6 cases, all
requirements were fully met.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.13682v2' target='_blank'>ChinaTravel: A Real-World Benchmark for Language Agents in Chinese
  Travel Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jie-Jing Shao, Xiao-Wen Yang, Bo-Wen Zhang, Baizhi Chen, Wen-Da Wei, Guohao Cai, Zhenhua Dong, Lan-Zhe Guo, Yu-feng Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-18 10:10:12</h6>
<p class='card-text'>Recent advances in LLMs, particularly in language reasoning and tool
integration, have rapidly sparked the real-world development of Language
Agents. Among these, travel planning represents a prominent domain, combining
academic challenges with practical value due to its complexity and market
demand. However, existing benchmarks fail to reflect the diverse, real-world
requirements crucial for deployment. To address this gap, we introduce
ChinaTravel, a benchmark specifically designed for authentic Chinese travel
planning scenarios. We collect the travel requirements from questionnaires and
propose a compositionally generalizable domain-specific language that enables a
scalable evaluation process, covering feasibility, constraint satisfaction, and
preference comparison. Empirical studies reveal the potential of neuro-symbolic
agents in travel planning, achieving a constraint satisfaction rate of 27.9%,
significantly surpassing purely neural models at 2.6%. Moreover, we identify
key challenges in real-world travel planning deployments, including open
language reasoning and unseen concept composition. These findings highlight the
significance of ChinaTravel as a pivotal milestone for advancing language
agents in complex, real-world planning scenarios.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.14212v1' target='_blank'>Tree-of-Code: A Hybrid Approach for Robust Complex Task Planning and
  Execution</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ziyi Ni, Yifan Li, Daxiang Dong</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-18 08:47:17</h6>
<p class='card-text'>The exceptional capabilities of large language models (LLMs) have
substantially accelerated the rapid rise and widespread adoption of agents.
Recent studies have demonstrated that generating Python code to consolidate
LLM-based agents' actions into a unified action space (CodeAct) is a promising
approach for developing real-world LLM agents. However, this step-by-step code
generation approach often lacks consistency and robustness, leading to
instability in agent applications, particularly for complex reasoning and
out-of-domain tasks. In this paper, we propose a novel approach called
Tree-of-Code (ToC) to tackle the challenges of complex problem planning and
execution with an end-to-end mechanism. By integrating key ideas from both
Tree-of-Thought and CodeAct, ToC combines their strengths to enhance solution
exploration. In our framework, each final code execution result is treated as a
node in the decision tree, with a breadth-first search strategy employed to
explore potential solutions. The final outcome is determined through a voting
mechanism based on the outputs of the nodes.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.13575v1' target='_blank'>Generating Long-form Story Using Dynamic Hierarchical Outlining with
  Memory-Enhancement</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Qianyue Wang, Jinwu Hu, Zhengping Li, Yufeng Wang, daiyuan li, Yu Hu, Mingkui Tan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-18 07:50:54</h6>
<p class='card-text'>Long-form story generation task aims to produce coherent and sufficiently
lengthy text, essential for applications such as novel writingand interactive
storytelling. However, existing methods, including LLMs, rely on rigid outlines
or lack macro-level planning, making it difficult to achieve both contextual
consistency and coherent plot development in long-form story generation. To
address this issues, we propose Dynamic Hierarchical Outlining with
Memory-Enhancement long-form story generation method, named DOME, to generate
the long-form story with coherent content and plot. Specifically, the Dynamic
Hierarchical Outline(DHO) mechanism incorporates the novel writing theory into
outline planning and fuses the plan and writing stages together, improving the
coherence of the plot by ensuring the plot completeness and adapting to the
uncertainty during story generation. A Memory-Enhancement Module (MEM) based on
temporal knowledge graphs is introduced to store and access the generated
content, reducing contextual conflicts and improving story coherence. Finally,
we propose a Temporal Conflict Analyzer leveraging temporal knowledge graphs to
automatically evaluate the contextual consistency of long-form story.
Experiments demonstrate that DOME significantly improves the fluency,
coherence, and overall quality of generated long stories compared to
state-of-the-art methods.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.13520v1' target='_blank'>ROMAS: A Role-Based Multi-Agent System for Database monitoring and
  Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yi Huang, Fangyin Cheng, Fan Zhou, Jiahui Li, Jian Gong, Hongjun Yang, Zhidong Fan, Caigao Jiang, Siqiao Xue, Faqiang Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-18 05:45:39</h6>
<p class='card-text'>In recent years, Large Language Models (LLMs) have demonstrated remarkable
capabilities in data analytics when integrated with Multi-Agent Systems (MAS).
However, these systems often struggle with complex tasks that involve diverse
functional requirements and intricate data processing challenges, necessitating
customized solutions that lack broad applicability. Furthermore, current MAS
fail to emulate essential human-like traits such as self-planning,
self-monitoring, and collaborative work in dynamic environments, leading to
inefficiencies and resource wastage. To address these limitations, we propose
ROMAS, a novel Role-Based M ulti-A gent System designed to adapt to various
scenarios while enabling low code development and one-click deployment. ROMAS
has been effectively deployed in DB-GPT [Xue et al., 2023a, 2024b], a
well-known project utilizing LLM-powered database analytics, showcasing its
practical utility in real-world scenarios. By integrating role-based
collaborative mechanisms for self-monitoring and self-planning, and leveraging
existing MAS capabilities to enhance database interactions, ROMAS offers a more
effective and versatile solution. Experimental evaluations of ROMAS demonstrate
its superiority across multiple scenarios, highlighting its potential to
advance the field of multi-agent data analytics.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.13178v3' target='_blank'>SafeAgentBench: A Benchmark for Safe Task Planning of Embodied LLM
  Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sheng Yin, Xianghe Pang, Yuanzhuo Ding, Menglan Chen, Yutong Bi, Yichen Xiong, Wenhao Huang, Zhen Xiang, Jing Shao, Siheng Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-17 18:55:58</h6>
<p class='card-text'>With the integration of large language models (LLMs), embodied agents have
strong capabilities to process the scene information and plan complicated
instructions in natural language, paving the way for the potential deployment
of embodied robots. However, a foreseeable issue is that those embodied agents
can also flawlessly execute some hazardous tasks, potentially causing damages
in the real world. To study this issue, we present SafeAgentBench-a new
benchmark for safety-aware task planning of embodied LLM agents. SafeAgentBench
includes: (1) a new dataset with 750 tasks, covering 10 potential hazards and 3
task types; (2) SafeAgentEnv, a universal embodied environment with a low-level
controller, supporting multi-agent execution with 17 high-level actions for 8
state-of-the-art baselines; and (3) reliable evaluation methods from both
execution and semantic perspectives. Experimental results show that, although
agents based on different design frameworks exhibit substantial differences in
task success rates, their overall safety awareness remains weak. The most
safety-conscious baseline achieves only a 10\% rejection rate for detailed
hazardous tasks. Moreover, simply replacing the LLM driving the agent does not
lead to notable improvements in safety awareness. More details and code are
available at https://github.com/shengyin1224/SafeAgentBench.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.12881v1' target='_blank'>RAG-Star: Enhancing Deliberative Reasoning with Retrieval Augmented
  Verification and Refinement</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jinhao Jiang, Jiayi Chen, Junyi Li, Ruiyang Ren, Shijie Wang, Wayne Xin Zhao, Yang Song, Tao Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-17 13:05:36</h6>
<p class='card-text'>Existing large language models (LLMs) show exceptional problem-solving
capabilities but might struggle with complex reasoning tasks. Despite the
successes of chain-of-thought and tree-based search methods, they mainly depend
on the internal knowledge of LLMs to search over intermediate reasoning steps,
limited to dealing with simple tasks involving fewer reasoning steps. In this
paper, we propose \textbf{RAG-Star}, a novel RAG approach that integrates the
retrieved information to guide the tree-based deliberative reasoning process
that relies on the inherent knowledge of LLMs. By leveraging Monte Carlo Tree
Search, RAG-Star iteratively plans intermediate sub-queries and answers for
reasoning based on the LLM itself. To consolidate internal and external
knowledge, we propose an retrieval-augmented verification that utilizes query-
and answer-aware reward modeling to provide feedback for the inherent reasoning
of LLMs. Our experiments involving Llama-3.1-8B-Instruct and GPT-4o demonstrate
that RAG-Star significantly outperforms previous RAG and reasoning methods.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.12839v1' target='_blank'>From An LLM Swarm To A PDDL-Empowered HIVE: Planning Self-Executed
  Instructions In A Multi-Modal Jungle</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kaustubh Vyas, Damien Graux, Yijun Yang, Sébastien Montella, Chenxin Diao, Wendi Zhou, Pavlos Vougiouklis, Ruofei Lai, Yang Ren, Keshuang Li, Jeff Z. Pan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-17 12:05:21</h6>
<p class='card-text'>In response to the call for agent-based solutions that leverage the
ever-increasing capabilities of the deep models' ecosystem, we introduce Hive
-- a comprehensive solution for selecting appropriate models and subsequently
planning a set of atomic actions to satisfy the end-users' instructions. Hive
operates over sets of models and, upon receiving natural language instructions
(i.e. user queries), schedules and executes explainable plans of atomic
actions. These actions can involve one or more of the available models to
achieve the overall task, while respecting end-users specific constraints.
Notably, Hive handles tasks that involve multi-modal inputs and outputs,
enabling it to handle complex, real-world queries. Our system is capable of
planning complex chains of actions while guaranteeing explainability, using an
LLM-based formal logic backbone empowered by PDDL operations. We introduce the
MuSE benchmark in order to offer a comprehensive evaluation of the multi-modal
capabilities of agent systems. Our findings show that our framework redefines
the state-of-the-art for task selection, outperforming other competing systems
that plan operations across multiple models while offering transparency
guarantees while fully adhering to user constraints.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.12653v1' target='_blank'>Predicting User Behavior in Smart Spaces with LLM-Enhanced Logs and
  Personalized Prompts (Data Description)</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yunpeng Song</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-17 08:20:56</h6>
<p class='card-text'>Enhancing the intelligence of smart systems, such as smart home, and smart
vehicle, and smart grids, critically depends on developing sophisticated
planning capabilities that can anticipate the next desired function based on
historical interactions. While existing methods view user behaviors as
sequential data and apply models like RNNs and Transformers to predict future
actions, they often fail to incorporate domain knowledge and capture
personalized user preferences. In this paper, we propose a novel approach that
incorporates LLM-enhanced logs and personalized prompts. Our approach first
constructs a graph that captures individual behavior preferences derived from
their interaction histories. This graph effectively transforms into a soft
continuous prompt that precedes the sequence of user behaviors. Then our
approach leverages the vast general knowledge and robust reasoning capabilities
of a pretrained LLM to enrich the oversimplified and incomplete log records. By
enhancing these logs semantically, our approach better understands the user's
actions and intentions, especially for those rare events in the dataset. We
evaluate the method across four real-world datasets from both smart vehicle and
smart home settings. The findings validate the effectiveness of our
LLM-enhanced description and personalized prompt, shedding light on potential
ways to advance the intelligence of smart space. Note: While this manuscript
provides description of the data, we are \textbf{not} permitted to make these
datasets publicly available due to restrictions imposed by the data provider.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.12643v1' target='_blank'>LLM-based Discriminative Reasoning for Knowledge Graph Question
  Answering</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mufan Xu, Kehai Chen, Xuefeng Bai, Muyun Yang, Tiejun Zhao, Min Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-17 08:07:16</h6>
<p class='card-text'>Large language models (LLMs) based on generative pre-trained Transformer have
achieved remarkable performance on knowledge graph question-answering (KGQA)
tasks. However, LLMs often produce ungrounded subgraph planning or reasoning
results in KGQA due to the hallucinatory behavior brought by the generative
paradigm, which may hinder the advancement of the LLM-based KGQA model. To deal
with the issue, we propose a novel LLM-based Discriminative Reasoning (LDR)
method to explicitly model the subgraph retrieval and answer inference process.
By adopting discriminative strategies, the proposed LDR method not only
enhances the capability of LLMs to retrieve question-related subgraphs but also
alleviates the issue of ungrounded reasoning brought by the generative paradigm
of LLMs. Experimental results show that the proposed approach outperforms
multiple strong comparison methods, along with achieving state-of-the-art
performance on two widely used WebQSP and CWQ benchmarks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.12513v1' target='_blank'>Generating Move Smart Contracts based on Concepts</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Rabimba Karanjai, Sam Blackshear, Lei Xu, Weidong Shi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-17 04:07:45</h6>
<p class='card-text'>The growing adoption of formal verification for smart contracts has spurred
the development of new verifiable languages like Move. However, the limited
availability of training data for these languages hinders effective code
generation by large language models (LLMs). This paper presents ConMover, a
novel framework that enhances LLM-based code generation for Move by leveraging
a knowledge graph of Move concepts and a small set of verified code examples.
ConMover integrates concept retrieval, planning, coding, and debugging agents
in an iterative process to refine generated code. Evaluations with various
open-source LLMs demonstrate substantial accuracy improvements over baseline
models. These results underscore ConMover's potential to address low-resource
code generation challenges, bridging the gap between natural language
descriptions and reliable smart contract development.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.12422v1' target='_blank'>Assessing the Limitations of Large Language Models in Clinical Fact
  Decomposition</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Monica Munnangi, Akshay Swaminathan, Jason Alan Fries, Jenelle Jindal, Sanjana Narayanan, Ivan Lopez, Lucia Tu, Philip Chung, Jesutofunmi A. Omiye, Mehr Kashyap, Nigam Shah</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-17 00:07:05</h6>
<p class='card-text'>Verifying factual claims is critical for using large language models (LLMs)
in healthcare. Recent work has proposed fact decomposition, which uses LLMs to
rewrite source text into concise sentences conveying a single piece of
information, as an approach for fine-grained fact verification. Clinical
documentation poses unique challenges for fact decomposition due to dense
terminology and diverse note types. To explore these challenges, we present
FactEHR, a dataset consisting of full document fact decompositions for 2,168
clinical notes spanning four types from three hospital systems. Our evaluation,
including review by clinicians, highlights significant variability in the
quality of fact decomposition for four commonly used LLMs, with some LLMs
generating 2.6x more facts per sentence than others. The results underscore the
need for better LLM capabilities to support factual verification in clinical
text. To facilitate future research in this direction, we plan to release our
code at \url{https://github.com/som-shahlab/factehr}.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.12386v1' target='_blank'>Interpretable LLM-based Table Question Answering</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Giang, Nguyen, Ivan Brugere, Shubham Sharma, Sanjay Kariyappa, Anh Totti Nguyen, Freddy Lecue</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-16 22:44:31</h6>
<p class='card-text'>Interpretability for Table Question Answering (Table QA) is critical,
particularly in high-stakes industries like finance or healthcare. Although
recent approaches using Large Language Models (LLMs) have significantly
improved Table QA performance, their explanations for how the answers are
generated are ambiguous. To fill this gap, we introduce Plan-of-SQLs ( or POS),
an interpretable, effective, and efficient approach to Table QA that answers an
input query solely with SQL executions. Through qualitative and quantitative
evaluations with human and LLM judges, we show that POS is most preferred among
explanation methods, helps human users understand model decision boundaries,
and facilitates model success and error identification. Furthermore, when
evaluated in standard benchmarks (TabFact, WikiTQ, and FetaQA), POS achieves
competitive or superior accuracy compared to existing methods, while
maintaining greater efficiency by requiring significantly fewer LLM calls and
database queries.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.19823v1' target='_blank'>A Survey on Large Language Models for Communication, Network, and
  Service Management: Application Insights, Challenges, and Future Directions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Gordon Owusu Boateng, Hani Sami, Ahmed Alagha, Hanae Elmekki, Ahmad Hammoud, Rabeb Mizouni, Azzam Mourad, Hadi Otrok, Jamal Bentahar, Sami Muhaidat, Chamseddine Talhi, Zbigniew Dziong, Mohsen Guizani</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-16 20:01:36</h6>
<p class='card-text'>The rapid evolution of communication networks in recent decades has
intensified the need for advanced Network and Service Management (NSM)
strategies to address the growing demands for efficiency, scalability, enhanced
performance, and reliability of these networks. Large Language Models (LLMs)
have received tremendous attention due to their unparalleled capabilities in
various Natural Language Processing (NLP) tasks and generating context-aware
insights, offering transformative potential for automating diverse
communication NSM tasks. Contrasting existing surveys that consider a single
network domain, this survey investigates the integration of LLMs across
different communication network domains, including mobile networks and related
technologies, vehicular networks, cloud-based networks, and fog/edge-based
networks. First, the survey provides foundational knowledge of LLMs, explicitly
detailing the generic transformer architecture, general-purpose and
domain-specific LLMs, LLM model pre-training and fine-tuning, and their
relation to communication NSM. Under a novel taxonomy of network monitoring and
reporting, AI-powered network planning, network deployment and distribution,
and continuous network support, we extensively categorize LLM applications for
NSM tasks in each of the different network domains, exploring existing
literature and their contributions thus far. Then, we identify existing
challenges and open issues, as well as future research directions for
LLM-driven communication NSM, emphasizing the need for scalable, adaptable, and
resource-efficient solutions that align with the dynamic landscape of
communication networks. We envision that this survey serves as a holistic
roadmap, providing critical insights for leveraging LLMs to enhance NSM.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.11761v1' target='_blank'>Harnessing Language for Coordination: A Framework and Benchmark for
  LLM-Driven Multi-Agent Control</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Timothée Anne, Noah Syrkis, Meriem Elhosni, Florian Turati, Franck Legendre, Alain Jaquier, Sebastian Risi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-16 13:25:42</h6>
<p class='card-text'>Large Language Models (LLMs) have demonstrated remarkable performance across
various tasks. A promising but largely under-explored area is their potential
to facilitate human coordination with many agents. Such capabilities would be
useful in domains including disaster response, urban planning, and real-time
strategy scenarios. In this work, we introduce (1) a real-time strategy game
benchmark designed to evaluate these abilities and (2) a novel framework we
term HIVE. HIVE empowers a single human to coordinate swarms of up to 2,000
agents using natural language dialog with an LLM. We present promising results
on this multi-agent benchmark, with our hybrid approach solving tasks such as
coordinating agent movements, exploiting unit weaknesses, leveraging human
annotations, and understanding terrain and strategic points. However, our
findings also highlight critical limitations of current models, including
difficulties in processing spatial visual information and challenges in
formulating long-term strategic plans. This work sheds light on the potential
and limitations of LLMs in human-swarm coordination, paving the way for future
research in this area. The HIVE project page, which includes videos of the
system in action, can be found here: hive.syrkis.com.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.11683v1' target='_blank'>Multimodal LLM for Intelligent Transportation Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Dexter Le, Aybars Yunusoglu, Karn Tiwari, Murat Isik, I. Can Dikmen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-16 11:50:30</h6>
<p class='card-text'>In the evolving landscape of transportation systems, integrating Large
Language Models (LLMs) offers a promising frontier for advancing intelligent
decision-making across various applications. This paper introduces a novel
3-dimensional framework that encapsulates the intersection of applications,
machine learning methodologies, and hardware devices, particularly emphasizing
the role of LLMs. Instead of using multiple machine learning algorithms, our
framework uses a single, data-centric LLM architecture that can analyze time
series, images, and videos. We explore how LLMs can enhance data interpretation
and decision-making in transportation. We apply this LLM framework to different
sensor datasets, including time-series data and visual data from sources like
Oxford Radar RobotCar, D-Behavior (D-Set), nuScenes by Motional, and Comma2k19.
The goal is to streamline data processing workflows, reduce the complexity of
deploying multiple models, and make intelligent transportation systems more
efficient and accurate. The study was conducted using state-of-the-art
hardware, leveraging the computational power of AMD RTX 3060 GPUs and Intel
i9-12900 processors. The experimental results demonstrate that our framework
achieves an average accuracy of 91.33\% across these datasets, with the highest
accuracy observed in time-series data (92.7\%), showcasing the model's
proficiency in handling sequential information essential for tasks such as
motion planning and predictive maintenance. Through our exploration, we
demonstrate the versatility and efficacy of LLMs in handling multimodal data
within the transportation sector, ultimately providing insights into their
application in real-world scenarios. Our findings align with the broader
conference themes, highlighting the transformative potential of LLMs in
advancing transportation technologies.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.11672v1' target='_blank'>LLM-DaaS: LLM-driven Drone-as-a-Service Operations from Text User
  Requests</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lillian Wassim, Kamal Mohamed, Ali Hamdi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-16 11:25:56</h6>
<p class='card-text'>We propose LLM-DaaS, a novel Drone-as-a-Service (DaaS) framework that
leverages Large Language Models (LLMs) to transform free-text user requests
into structured, actionable DaaS operation tasks. Our approach addresses the
key challenge of interpreting and structuring natural language input to
automate drone service operations under uncertain conditions. The system is
composed of three main components: free-text request processing, structured
request generation, and dynamic DaaS selection and composition. First, we
fine-tune different LLM models such as Phi-3.5, LLaMA-3.2 7b and Gemma 2b on a
dataset of text user requests mapped to structured DaaS requests. Users
interact with our model in a free conversational style, discussing package
delivery requests, while the fine-tuned LLM extracts DaaS metadata such as
delivery time, source and destination locations, and package weight. The DaaS
service selection model is designed to select the best available drone capable
of delivering the requested package from the delivery point to the nearest
optimal destination. Additionally, the DaaS composition model composes a
service from a set of the best available drones to deliver the package from the
source to the final destination. Second, the system integrates real-time
weather data to optimize drone route planning and scheduling, ensuring safe and
efficient operations. Simulations demonstrate the system's ability to
significantly improve task accuracy, operational efficiency, and establish
LLM-DaaS as a robust solution for DaaS operations in uncertain environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.11621v1' target='_blank'>VG-TVP: Multimodal Procedural Planning via Visually Grounded Text-Video
  Prompting</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Muhammet Furkan Ilaslan, Ali Koksal, Kevin Qinhong Lin, Burak Satar, Mike Zheng Shou, Qianli Xu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-16 10:08:38</h6>
<p class='card-text'>Large Language Model (LLM)-based agents have shown promise in procedural
tasks, but the potential of multimodal instructions augmented by texts and
videos to assist users remains under-explored. To address this gap, we propose
the Visually Grounded Text-Video Prompting (VG-TVP) method which is a novel
LLM-empowered Multimodal Procedural Planning (MPP) framework. It generates
cohesive text and video procedural plans given a specified high-level
objective. The main challenges are achieving textual and visual
informativeness, temporal coherence, and accuracy in procedural plans. VG-TVP
leverages the zero-shot reasoning capability of LLMs, the video-to-text
generation ability of the video captioning models, and the text-to-video
generation ability of diffusion models. VG-TVP improves the interaction between
modalities by proposing a novel Fusion of Captioning (FoC) method and using
Text-to-Video Bridge (T2V-B) and Video-to-Text Bridge (V2T-B). They allow LLMs
to guide the generation of visually-grounded text plans and textual-grounded
video plans. To address the scarcity of datasets suitable for MPP, we have
curated a new dataset called Daily-Life Task Procedural Plans (Daily-PP). We
conduct comprehensive experiments and benchmarks to evaluate human preferences
(regarding textual and visual informativeness, temporal coherence, and plan
accuracy). Our VG-TVP method outperforms unimodal baselines on the Daily-PP
dataset.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.11499v1' target='_blank'>Embodied CoT Distillation From LLM To Off-the-shelf Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wonje Choi, Woo Kyung Kim, Minjong Yoo, Honguk Woo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-16 07:18:02</h6>
<p class='card-text'>We address the challenge of utilizing large language models (LLMs) for
complex embodied tasks, in the environment where decision-making systems
operate timely on capacity-limited, off-the-shelf devices. We present DeDer, a
framework for decomposing and distilling the embodied reasoning capabilities
from LLMs to efficient, small language model (sLM)-based policies. In DeDer,
the decision-making process of LLM-based strategies is restructured into a
hierarchy with a reasoning-policy and planning-policy. The reasoning-policy is
distilled from the data that is generated through the embodied in-context
learning and self-verification of an LLM, so it can produce effective
rationales. The planning-policy, guided by the rationales, can render optimized
plans efficiently. In turn, DeDer allows for adopting sLMs for both policies,
deployed on off-the-shelf devices. Furthermore, to enhance the quality of
intermediate rationales, specific to embodied tasks, we devise the embodied
knowledge graph, and to generate multiple rationales timely through a single
inference, we also use the contrastively prompted attention model. Our
experiments with the ALFRED benchmark demonstrate that DeDer surpasses leading
language planning and distillation approaches, indicating the applicability and
efficiency of sLM-based embodied policies derived through DeDer.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.15249v1' target='_blank'>LLMs for Literature Review: Are we there yet?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shubham Agarwal, Gaurav Sahu, Abhay Puri, Issam H. Laradji, Krishnamurthy DJ Dvijotham, Jason Stanley, Laurent Charlin, Christopher Pal</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-15 01:12:26</h6>
<p class='card-text'>Literature reviews are an essential component of scientific research, but
they remain time-intensive and challenging to write, especially due to the
recent influx of research papers. This paper explores the zero-shot abilities
of recent Large Language Models (LLMs) in assisting with the writing of
literature reviews based on an abstract. We decompose the task into two
components: 1. Retrieving related works given a query abstract, and 2. Writing
a literature review based on the retrieved results. We analyze how effective
LLMs are for both components. For retrieval, we introduce a novel two-step
search strategy that first uses an LLM to extract meaningful keywords from the
abstract of a paper and then retrieves potentially relevant papers by querying
an external knowledge base. Additionally, we study a prompting-based re-ranking
mechanism with attribution and show that re-ranking doubles the normalized
recall compared to naive search methods, while providing insights into the
LLM's decision-making process. In the generation phase, we propose a two-step
approach that first outlines a plan for the review and then executes steps in
the plan to generate the actual review. To evaluate different LLM-based
literature review methods, we create test sets from arXiv papers using a
protocol designed for rolling use with newly released LLMs to avoid test set
contamination in zero-shot evaluations. We release this evaluation protocol to
promote additional research and development in this regard. Our empirical
results suggest that LLMs show promising potential for writing literature
reviews when the task is decomposed into smaller components of retrieval and
planning. Further, we demonstrate that our planning-based approach achieves
higher-quality reviews by minimizing hallucinated references in the generated
review by 18-26% compared to existing simpler LLM-based generation methods.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.10807v1' target='_blank'>Towards Action Hijacking of Large Language Model-based Agent</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuyang Zhang, Kangjie Chen, Xudong Jiang, Yuxiang Sun, Run Wang, Lina Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-14 12:11:26</h6>
<p class='card-text'>In the past few years, intelligent agents powered by large language models
(LLMs) have achieved remarkable progress in performing complex tasks. These
LLM-based agents receive queries as tasks and decompose them into various
subtasks via the equipped LLMs to guide the action of external entities (\eg{},
tools, AI-agents) to answer the questions from users. Empowered by their
exceptional capabilities of understanding and problem-solving, they are widely
adopted in labor-intensive sectors including healthcare, finance, code
completion, \etc{} At the same time, there are also concerns about the
potential misuse of these agents, prompting the built-in safety guards from
service providers. To circumvent the built-in guidelines, the prior studies
proposed a multitude of attacks including memory poisoning, jailbreak, and
prompt injection. These studies often fail to maintain effectiveness across
safety filters employed by agents due to the restricted privileges and the
harmful semantics in queries. In this paper, we introduce \Name, a novel
hijacking attack to manipulate the action plans of black-box agent system.
\Name first collects the action-aware memory through prompt theft from
long-term memory. It then leverages the internal memory retrieval mechanism of
the agent to provide an erroneous context. The huge gap between the latent
spaces of the retriever and safety filters allows our method to bypass the
detection easily. Extensive experimental results demonstrate the effectiveness
of our apporach (\eg{}, 99.67\% ASR). Besides, our approach achieved an average
bypass rate of 92.7\% for safety filters.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.10717v1' target='_blank'>HITgram: A Platform for Experimenting with n-gram Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shibaranjani Dasgupta, Chandan Maity, Somdip Mukherjee, Rohan Singh, Diptendu Dutta, Debasish Jana</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-14 07:20:35</h6>
<p class='card-text'>Large language models (LLMs) are powerful but resource intensive, limiting
accessibility. HITgram addresses this gap by offering a lightweight platform
for n-gram model experimentation, ideal for resource-constrained environments.
It supports unigrams to 4-grams and incorporates features like context
sensitive weighting, Laplace smoothing, and dynamic corpus management to
e-hance prediction accuracy, even for unseen word sequences. Experiments
demonstrate HITgram's efficiency, achieving 50,000 tokens/second and generating
2-grams from a 320MB corpus in 62 seconds. HITgram scales efficiently,
constructing 4-grams from a 1GB file in under 298 seconds on an 8 GB RAM
system. Planned enhancements include multilingual support, advanced smoothing,
parallel processing, and model saving, further broadening its utility.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.10675v1' target='_blank'>Chasing Progress, Not Perfection: Revisiting Strategies for End-to-End
  LLM Plan Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sukai Huang, Trevor Cohn, Nir Lipovetzky</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-14 04:23:14</h6>
<p class='card-text'>The capability of Large Language Models (LLMs) to plan remains a topic of
debate. Some critics argue that strategies to boost LLMs' reasoning skills are
ineffective in planning tasks, while others report strong outcomes merely from
training models on a planning corpus. This study reassesses recent strategies
by developing an end-to-end LLM planner and employing diverse metrics for a
thorough evaluation. We find that merely fine-tuning LLMs on a corpus of
planning instances does not lead to robust planning skills, as indicated by
poor performance on out-of-distribution test sets. At the same time, we find
that various strategies, including Chain-of-Thought, do enhance the probability
of a plan being executable. This indicates progress towards better plan
quality, despite not directly enhancing the final validity rate. Among the
strategies we evaluated, reinforcement learning with our novel `Longest
Contiguous Common Subsequence' reward emerged as the most effective,
contributing to both plan validity and executability. Overall, our research
addresses key misconceptions in the LLM-planning literature; we validate
incremental progress in plan executability, although plan validity remains a
challenge. Hence, future strategies should focus on both these aspects, drawing
insights from our findings.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.15242v1' target='_blank'>Script-Based Dialog Policy Planning for LLM-Powered Conversational
  Agents: A Basic Architecture for an "AI Therapist"</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Robert Wasenmüller, Kevin Hilbert, Christoph Benzmüller</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-13 12:12:47</h6>
<p class='card-text'>Large Language Model (LLM)-Powered Conversational Agents have the potential
to provide users with scaled behavioral healthcare support, and potentially
even deliver full-scale "AI therapy'" in the future. While such agents can
already conduct fluent and proactive emotional support conversations, they
inherently lack the ability to (a) consistently and reliably act by predefined
rules to align their conversation with an overarching therapeutic concept and
(b) make their decision paths inspectable for risk management and clinical
evaluation -- both essential requirements for an "AI Therapist".
  In this work, we introduce a novel paradigm for dialog policy planning in
conversational agents enabling them to (a) act according to an expert-written
"script" that outlines the therapeutic approach and (b) explicitly transition
through a finite set of states over the course of the conversation. The script
acts as a deterministic component, constraining the LLM's behavior in desirable
ways and establishing a basic architecture for an AI Therapist.
  We implement two variants of Script-Based Dialog Policy Planning using
different prompting techniques and synthesize a total of 100 conversations with
LLM-simulated patients. The results demonstrate the feasibility of this new
technology and provide insights into the efficiency and effectiveness of
different implementation variants.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.09879v2' target='_blank'>On the Limit of Language Models as Planning Formalizers</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Cassie Huang, Li Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-13 05:50:22</h6>
<p class='card-text'>Large Language Models have been shown to fail to create executable and
verifiable plans in grounded environments. An emerging line of work shows
success in using LLM as a formalizer to generate a formal representation (e.g.,
PDDL) of the planning domain, which can be deterministically solved to find a
plan. We systematically evaluate this methodology while bridging some major
gaps. While previous work only generates a partial PDDL representation given
templated and thus unrealistic environment descriptions, we generate the
complete representation given descriptions of various naturalness levels. Among
an array of observations critical to improve LLMs' formal planning ability, we
note that large enough models can effectively formalize descriptions as PDDL,
outperforming those directly generating plans, while being robust to lexical
perturbation. As the descriptions become more natural-sounding, we observe a
decrease in performance and provide detailed error analysis.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.09819v1' target='_blank'>FDM-Bench: A Comprehensive Benchmark for Evaluating Large Language
  Models in Additive Manufacturing Tasks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ahmadreza Eslaminia, Adrian Jackson, Beitong Tian, Avi Stern, Hallie Gordon, Rajiv Malhotra, Klara Nahrstedt, Chenhui Shao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-13 03:16:14</h6>
<p class='card-text'>Fused Deposition Modeling (FDM) is a widely used additive manufacturing (AM)
technique valued for its flexibility and cost-efficiency, with applications in
a variety of industries including healthcare and aerospace. Recent developments
have made affordable FDM machines accessible and encouraged adoption among
diverse users. However, the design, planning, and production process in FDM
require specialized interdisciplinary knowledge. Managing the complex
parameters and resolving print defects in FDM remain challenging. These
technical complexities form the most critical barrier preventing individuals
without technical backgrounds and even professional engineers without training
in other domains from participating in AM design and manufacturing. Large
Language Models (LLMs), with their advanced capabilities in text and code
processing, offer the potential for addressing these challenges in FDM.
However, existing research on LLM applications in this field is limited,
typically focusing on specific use cases without providing comprehensive
evaluations across multiple models and tasks. To this end, we introduce
FDM-Bench, a benchmark dataset designed to evaluate LLMs on FDM-specific tasks.
FDM-Bench enables a thorough assessment by including user queries across
various experience levels and G-code samples that represent a range of
anomalies. We evaluate two closed-source models (GPT-4o and Claude 3.5 Sonnet)
and two open-source models (Llama-3.1-70B and Llama-3.1-405B) on FDM-Bench. A
panel of FDM experts assess the models' responses to user queries in detail.
Results indicate that closed-source models generally outperform open-source
models in G-code anomaly detection, whereas Llama-3.1-405B demonstrates a
slight advantage over other models in responding to user queries. These
findings underscore FDM-Bench's potential as a foundational tool for advancing
research on LLM capabilities in FDM.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.09666v1' target='_blank'>Systematic Analysis of LLM Contributions to Planning: Solver, Verifier,
  Heuristic</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Haoming Li, Zhaoliang Chen, Songyuan Liu, Yiming Lu, Fei Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-12 18:16:46</h6>
<p class='card-text'>In this work, we provide a systematic analysis of how large language models
(LLMs) contribute to solving planning problems. In particular, we examine how
LLMs perform when they are used as problem solver, solution verifier, and
heuristic guidance to improve intermediate solutions. Our analysis reveals that
although it is difficult for LLMs to generate correct plans out-of-the-box,
LLMs are much better at providing feedback signals to intermediate/incomplete
solutions in the form of comparative heuristic functions. This evaluation
framework provides insights into how future work may design better LLM-based
tree-search algorithms to solve diverse planning and reasoning problems. We
also propose a novel benchmark to evaluate LLM's ability to learn user
preferences on the fly, which has wide applications in practical settings.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.06189v1' target='_blank'>A Multimodal Social Agent</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Athina Bikaki, Ioannis A. Kakadiaris</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-11 22:04:27</h6>
<p class='card-text'>In recent years, large language models (LLMs) have demonstrated remarkable
progress in common-sense reasoning tasks. This ability is fundamental to
understanding social dynamics, interactions, and communication. However, the
potential of integrating computers with these social capabilities is still
relatively unexplored. However, the potential of integrating computers with
these social capabilities is still relatively unexplored. This paper introduces
MuSA, a multimodal LLM-based agent that analyzes text-rich social content
tailored to address selected human-centric content analysis tasks, such as
question answering, visual question answering, title generation, and
categorization. It uses planning, reasoning, acting, optimizing, criticizing,
and refining strategies to complete a task. Our approach demonstrates that MuSA
can automate and improve social content analysis, helping decision-making
processes across various applications. We have evaluated our agent's
capabilities in question answering, title generation, and content
categorization tasks. MuSA performs substantially better than our baselines.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.08685v1' target='_blank'>ChatDyn: Language-Driven Multi-Actor Dynamics Generation in Street
  Scenes</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuxi Wei, Jingbo Wang, Yuwen Du, Dingju Wang, Liang Pan, Chenxin Xu, Yao Feng, Bo Dai, Siheng Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-11 18:58:48</h6>
<p class='card-text'>Generating realistic and interactive dynamics of traffic participants
according to specific instruction is critical for street scene simulation.
However, there is currently a lack of a comprehensive method that generates
realistic dynamics of different types of participants including vehicles and
pedestrians, with different kinds of interactions between them. In this paper,
we introduce ChatDyn, the first system capable of generating interactive,
controllable and realistic participant dynamics in street scenes based on
language instructions. To achieve precise control through complex language,
ChatDyn employs a multi-LLM-agent role-playing approach, which utilizes natural
language inputs to plan the trajectories and behaviors for different traffic
participants. To generate realistic fine-grained dynamics based on the
planning, ChatDyn designs two novel executors: the PedExecutor, a unified
multi-task executor that generates realistic pedestrian dynamics under
different task plannings; and the VehExecutor, a physical transition-based
policy that generates physically plausible vehicle dynamics. Extensive
experiments show that ChatDyn can generate realistic driving scene dynamics
with multiple vehicles and pedestrians, and significantly outperforms previous
methods on subtasks. Code and model will be available at
https://vfishc.github.io/chatdyn.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.08442v1' target='_blank'>From Multimodal LLMs to Generalist Embodied Agents: Methods and Lessons</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Andrew Szot, Bogdan Mazoure, Omar Attia, Aleksei Timofeev, Harsh Agrawal, Devon Hjelm, Zhe Gan, Zsolt Kira, Alexander Toshev</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-11 15:06:25</h6>
<p class='card-text'>We examine the capability of Multimodal Large Language Models (MLLMs) to
tackle diverse domains that extend beyond the traditional language and vision
tasks these models are typically trained on. Specifically, our focus lies in
areas such as Embodied AI, Games, UI Control, and Planning. To this end, we
introduce a process of adapting an MLLM to a Generalist Embodied Agent (GEA).
GEA is a single unified model capable of grounding itself across these varied
domains through a multi-embodiment action tokenizer. GEA is trained with
supervised learning on a large dataset of embodied experiences and with online
RL in interactive simulators. We explore the data and algorithmic choices
necessary to develop such a model. Our findings reveal the importance of
training with cross-domain data and online RL for building generalist agents.
The final GEA model achieves strong generalization performance to unseen tasks
across diverse benchmarks compared to other generalist models and
benchmark-specific approaches.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.08428v1' target='_blank'>SwarmGPT-Primitive: A Language-Driven Choreographer for Drone Swarms
  Using Safe Motion Primitive Composition</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Vedant Vyas, Martin Schuck, Dinushka O. Dahanaggamaarachchi, Siqi Zhou, Angela P. Schoellig</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-11 14:48:19</h6>
<p class='card-text'>Catalyzed by advancements in hardware and software, drone performances are
increasingly making their mark in the entertainment industry. However,
designing smooth and safe choreographies for drone swarms is complex and often
requires expert domain knowledge. In this work, we introduce
SwarmGPT-Primitive, a language-based choreographer that integrates the
reasoning capabilities of large language models (LLMs) with safe motion
planning to facilitate deployable drone swarm choreographies. The LLM composes
choreographies for a given piece of music by utilizing a library of motion
primitives; the language-based choreographer is augmented with an
optimization-based safety filter, which certifies the choreography for
real-world deployment by making minimal adjustments when feasibility and safety
constraints are violated. The overall SwarmGPT-Primitive framework decouples
choreographic design from safe motion planning, which allows non-expert users
to re-prompt and refine compositions without concerns about compliance with
constraints such as avoiding collisions or downwash effects or satisfying
actuation limits. We demonstrate our approach through simulations and
experiments with swarms of up to 20 drones performing choreographies designed
based on various songs, highlighting the system's ability to generate effective
and synchronized drone choreographies for real-world deployment.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.10434v1' target='_blank'>NAT-NL2GQL: A Novel Multi-Agent Framework for Translating Natural
  Language to Graph Query Language</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuanyuan Liang, Tingyu Xie, Gan Peng, Zihao Huang, Yunshi Lan, Weining Qian</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-11 04:14:09</h6>
<p class='card-text'>The emergence of Large Language Models (LLMs) has revolutionized many fields,
not only traditional natural language processing (NLP) tasks. Recently,
research on applying LLMs to the database field has been booming, and as a
typical non-relational database, the use of LLMs in graph database research has
naturally gained significant attention. Recent efforts have increasingly
focused on leveraging LLMs to translate natural language into graph query
language (NL2GQL). Although some progress has been made, these methods have
clear limitations, such as their reliance on streamlined processes that often
overlook the potential of LLMs to autonomously plan and collaborate with other
LLMs in tackling complex NL2GQL challenges. To address this gap, we propose
NAT-NL2GQL, a novel multi-agent framework for translating natural language to
graph query language. Specifically, our framework consists of three synergistic
agents: the Preprocessor agent, the Generator agent, and the Refiner agent. The
Preprocessor agent manages data processing as context, including tasks such as
name entity recognition, query rewriting, path linking, and the extraction of
query-related schemas. The Generator agent is a fine-tuned LLM trained on
NL-GQL data, responsible for generating corresponding GQL statements based on
queries and their related schemas. The Refiner agent is tasked with refining
the GQL or context using error information obtained from the GQL execution
results. Given the scarcity of high-quality open-source NL2GQL datasets based
on nGQL syntax, we developed StockGQL, a dataset constructed from a financial
market graph database. It is available at:
https://github.com/leonyuancode/StockGQL. Experimental results on the StockGQL
and SpCQL datasets reveal that our method significantly outperforms baseline
approaches, highlighting its potential for advancing NL2GQL research.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.07493v1' target='_blank'>Ontology-driven Prompt Tuning for LLM-based Task and Motion Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Muhayy Ud Din, Jan Rosell, Waseem Akram, Isiah Zaplana, Maximo A Roa, Lakmal Seneviratne, Irfan Hussain</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-10 13:18:45</h6>
<p class='card-text'>Performing complex manipulation tasks in dynamic environments requires
efficient Task and Motion Planning (TAMP) approaches, which combine high-level
symbolic plan with low-level motion planning. Advances in Large Language Models
(LLMs), such as GPT-4, are transforming task planning by offering natural
language as an intuitive and flexible way to describe tasks, generate symbolic
plans, and reason. However, the effectiveness of LLM-based TAMP approaches is
limited due to static and template-based prompting, which struggles in adapting
to dynamic environments and complex task contexts. To address these
limitations, this work proposes a novel ontology-driven prompt-tuning framework
that employs knowledge-based reasoning to refine and expand user prompts with
task contextual reasoning and knowledge-based environment state descriptions.
Integrating domain-specific knowledge into the prompt ensures semantically
accurate and context-aware task plans. The proposed framework demonstrates its
effectiveness by resolving semantic errors in symbolic plan generation, such as
maintaining logical temporal goal ordering in scenarios involving hierarchical
object placement. The proposed framework is validated through both simulation
and real-world scenarios, demonstrating significant improvements over the
baseline approach in terms of adaptability to dynamic environments, and the
generation of semantically correct task plans.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.10422v2' target='_blank'>AutoPrep: Natural Language Question-Aware Data Preparation with a
  Multi-Agent Framework</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Meihao Fan, Ju Fan, Nan Tang, Lei Cao, Guoliang Li, Xiaoyong Du</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-10 11:03:49</h6>
<p class='card-text'>Answering natural language (NL) questions about tables, known as Tabular
Question Answering (TQA), is crucial because it allows users to quickly and
efficiently extract meaningful insights from structured data, effectively
bridging the gap between human language and machine-readable formats. Many of
these tables are derived from web sources or real-world scenarios, which
require meticulous data preparation (or data prep) to ensure accurate
responses. However, preparing such tables for NL questions introduces new
requirements that extend beyond traditional data preparation. This
question-aware data preparation involves specific tasks such as column
augmentation and filtering tailored to particular questions, as well as
question-aware value normalization or conversion, highlighting the need for a
more nuanced approach in this context. Because each of the above tasks is
unique, a single model (or agent) may not perform effectively across all
scenarios. In this paper, we propose AutoPrep, a large language model
(LLM)-based multi-agent framework that leverages the strengths of multiple
agents, each specialized in a certain type of data prep, ensuring more accurate
and contextually relevant responses. Given an NL question over a table,
AutoPrep performs data prep through three key components. Planner: Determines a
logical plan, outlining a sequence of high-level operations. Programmer:
Translates this logical plan into a physical plan by generating the
corresponding low-level code. Executor: Executes the generated code to process
the table. To support this multi-agent framework, we design a novel
Chain-of-Clauses reasoning mechanism for high-level operation suggestion, and a
tool-augmented method for low-level code generation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.07207v2' target='_blank'>MAPLE: A Framework for Active Preference Learning Guided by Large
  Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Saaduddin Mahmud, Mason Nakamura, Shlomo Zilberstein</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-10 05:55:14</h6>
<p class='card-text'>The advent of large language models (LLMs) has sparked significant interest
in using natural language for preference learning. However, existing methods
often suffer from high computational burdens, taxing human supervision, and
lack of interpretability. To address these issues, we introduce MAPLE, a
framework for large language model-guided Bayesian active preference learning.
MAPLE leverages LLMs to model the distribution over preference functions,
conditioning it on both natural language feedback and conventional preference
learning feedback, such as pairwise trajectory rankings. MAPLE also employs
active learning to systematically reduce uncertainty in this distribution and
incorporates a language-conditioned active query selection mechanism to
identify informative and easy-to-answer queries, thus reducing human burden. We
evaluate MAPLE's sample efficiency and preference inference quality across two
benchmarks, including a real-world vehicle route planning benchmark using
OpenStreetMap data. Our results demonstrate that MAPLE accelerates the learning
process and effectively improves humans' ability to answer queries.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2501.05455v1' target='_blank'>Upstream and Downstream AI Safety: Both on the Same River?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:John McDermid, Yan Jia, Ibrahim Habli</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-09 23:33:31</h6>
<p class='card-text'>Traditional safety engineering assesses systems in their context of use, e.g.
the operational design domain (road layout, speed limits, weather, etc.) for
self-driving vehicles (including those using AI). We refer to this as
downstream safety. In contrast, work on safety of frontier AI, e.g. large
language models which can be further trained for downstream tasks, typically
considers factors that are beyond specific application contexts, such as the
ability of the model to evade human control, or to produce harmful content,
e.g. how to make bombs. We refer to this as upstream safety. We outline the
characteristics of both upstream and downstream safety frameworks then explore
the extent to which the broad AI safety community can benefit from synergies
between these frameworks. For example, can concepts such as common mode
failures from downstream safety be used to help assess the strength of AI
guardrails? Further, can the understanding of the capabilities and limitations
of frontier AI be used to inform downstream safety analysis, e.g. where LLMs
are fine-tuned to calculate voyage plans for autonomous vessels? The paper
identifies some promising avenues to explore and outlines some challenges in
achieving synergy, or a confluence, between upstream and downstream safety
frameworks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.06931v2' target='_blank'>Non-Prehensile Tool-Object Manipulation by Integrating LLM-Based
  Planning and Manoeuvrability-Driven Controls</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hoi-Yin Lee, Peng Zhou, Anqing Duan, Wanyu Ma, Chenguang Yang, David Navarro-Alarcon</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-09 19:21:05</h6>
<p class='card-text'>The ability to wield tools was once considered exclusive to human
intelligence, but it's now known that many other animals, like crows, possess
this capability. Yet, robotic systems still fall short of matching biological
dexterity. In this paper, we investigate the use of Large Language Models
(LLMs), tool affordances, and object manoeuvrability for non-prehensile
tool-based manipulation tasks. Our novel method leverages LLMs based on scene
information and natural language instructions to enable symbolic task planning
for tool-object manipulation. This approach allows the system to convert the
human language sentence into a sequence of feasible motion functions. We have
developed a novel manoeuvrability-driven controller using a new tool affordance
model derived from visual feedback. This controller helps guide the robot's
tool utilization and manipulation actions, even within confined areas, using a
stepping incremental approach. The proposed methodology is evaluated with
experiments to prove its effectiveness under various manipulation scenarios.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.06769v2' target='_blank'>Training Large Language Models to Reason in a Continuous Latent Space</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shibo Hao, Sainbayar Sukhbaatar, DiJia Su, Xian Li, Zhiting Hu, Jason Weston, Yuandong Tian</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-09 18:55:56</h6>
<p class='card-text'>Large language models (LLMs) are restricted to reason in the "language
space", where they typically express the reasoning process with a
chain-of-thought (CoT) to solve a complex reasoning problem. However, we argue
that language space may not always be optimal for reasoning. For example, most
word tokens are primarily for textual coherence and not essential for
reasoning, while some critical tokens require complex planning and pose huge
challenges to LLMs. To explore the potential of LLM reasoning in an
unrestricted latent space instead of using natural language, we introduce a new
paradigm Coconut (Chain of Continuous Thought). We utilize the last hidden
state of the LLM as a representation of the reasoning state (termed "continuous
thought"). Rather than decoding this into a word token, we feed it back to the
LLM as the subsequent input embedding directly in the continuous space.
Experiments show that Coconut can effectively augment the LLM on several
reasoning tasks. This novel latent reasoning paradigm leads to emergent
advanced reasoning patterns: the continuous thought can encode multiple
alternative next reasoning steps, allowing the model to perform a breadth-first
search (BFS) to solve the problem, rather than prematurely committing to a
single deterministic path like CoT. Coconut outperforms CoT in certain logical
reasoning tasks that require substantial backtracking during planning, with
fewer thinking tokens during inference. These findings demonstrate the promise
of latent reasoning and offer valuable insights for future research.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.06724v2' target='_blank'>AutoDCWorkflow: LLM-based Data Cleaning Workflow Auto-Generation and
  Benchmark</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lan Li, Liri Fang, Vetle I. Torvik</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-09 18:13:27</h6>
<p class='card-text'>We investigate the reasoning capabilities of large language models (LLMs) for
automatically generating data-cleaning workflows. To evaluate LLMs' ability to
complete data-cleaning tasks, we implemented a pipeline for LLM-based Auto Data
Cleaning Workflow (AutoDCWorkflow), prompting LLMs on data cleaning operations
to repair three types of data quality issues: duplicates, missing values, and
inconsistent data formats. Given a dirty table and a purpose (expressed as a
query), this pipeline generates a minimal, clean table sufficient to address
the purpose and the data cleaning workflow used to produce the table. The
planning process involves three main LLM-driven components: (1) Select Target
Columns: Identifies a set of target columns related to the purpose. (2) Inspect
Column Quality: Assesses the data quality for each target column and generates
a Data Quality Report as operation objectives. (3) Generate Operation &
Arguments: Predicts the next operation and arguments based on the data quality
report results. Additionally, we propose a data cleaning benchmark to evaluate
the capability of LLM agents to automatically generate workflows that address
data cleaning purposes of varying difficulty levels. The benchmark comprises
the annotated datasets as a collection of purpose, raw table, clean table, data
cleaning workflow, and answer set. In our experiments, we evaluated three LLMs
that auto-generate purpose-driven data cleaning workflows. The results indicate
that LLMs perform well in planning and generating data-cleaning workflows
without the need for fine-tuning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.19811v1' target='_blank'>LINKs: Large Language Model Integrated Management for 6G Empowered
  Digital Twin NetworKs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shufan Jiang, Bangyan Lin, Yue Wu, Yuan Gao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-09 17:41:23</h6>
<p class='card-text'>In the rapidly evolving landscape of digital twins (DT) and 6G networks, the
integration of large language models (LLMs) presents a novel approach to
network management. This paper explores the application of LLMs in managing
6G-empowered DT networks, with a focus on optimizing data retrieval and
communication efficiency in smart city scenarios. The proposed framework
leverages LLMs for intelligent DT problem analysis and radio resource
management (RRM) in fully autonomous way without any manual intervention. Our
proposed framework -- LINKs, builds up a lazy loading strategy which can
minimize transmission delay by selectively retrieving the relevant data. Based
on the data retrieval plan, LLMs transform the retrieval task into an numerical
optimization problem and utilizing solvers to build an optimal RRM, ensuring
efficient communication across the network. Simulation results demonstrate the
performance improvements in data planning and network management, highlighting
the potential of LLMs to enhance the integration of DT and 6G technologies.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.06229v1' target='_blank'>LLMs as Debate Partners: Utilizing Genetic Algorithms and Adversarial
  Search for Adaptive Arguments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Prakash Aryan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-09 06:03:48</h6>
<p class='card-text'>This paper introduces DebateBrawl, an innovative AI-powered debate platform
that integrates Large Language Models (LLMs), Genetic Algorithms (GA), and
Adversarial Search (AS) to create an adaptive and engaging debating experience.
DebateBrawl addresses the limitations of traditional LLMs in strategic planning
by incorporating evolutionary optimization and game-theoretic techniques. The
system demonstrates remarkable performance in generating coherent, contextually
relevant arguments while adapting its strategy in real-time. Experimental
results involving 23 debates show balanced outcomes between AI and human
participants, with the AI system achieving an average score of 2.72 compared to
the human average of 2.67 out of 10. User feedback indicates significant
improvements in debating skills and a highly satisfactory learning experience,
with 85% of users reporting improved debating abilities and 78% finding the AI
opponent appropriately challenging. The system's ability to maintain high
factual accuracy (92% compared to 78% in human-only debates) while generating
diverse arguments addresses critical concerns in AI-assisted discourse.
DebateBrawl not only serves as an effective educational tool but also
contributes to the broader goal of improving public discourse through
AI-assisted argumentation. The paper discusses the ethical implications of AI
in persuasive contexts and outlines the measures implemented to ensure
responsible development and deployment of the system, including robust
fact-checking mechanisms and transparency in decision-making processes.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.06162v1' target='_blank'>Query-Efficient Planning with Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Gonzalo Gonzalez-Pumariega, Wayne Chen, Kushal Kedia, Sanjiban Choudhury</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-09 02:51:21</h6>
<p class='card-text'>Planning in complex environments requires an agent to efficiently query a
world model to find a feasible sequence of actions from start to goal. Recent
work has shown that Large Language Models (LLMs), with their rich prior
knowledge and reasoning capabilities, can potentially help with planning by
searching over promising states and adapting to feedback from the world. In
this paper, we propose and study two fundamentally competing frameworks that
leverage LLMs for query-efficient planning. The first uses LLMs as a heuristic
within a search-based planner to select promising nodes to expand and propose
promising actions. The second uses LLMs as a generative planner to propose an
entire sequence of actions from start to goal, query a world model, and adapt
based on feedback. We show that while both approaches improve upon comparable
baselines, using an LLM as a generative planner results in significantly fewer
interactions. Our key finding is that the LLM as a planner can more rapidly
adapt its planning strategies based on immediate feedback than LLM as a
heuristic. We present evaluations and ablations on Robotouille and PDDL
planning benchmarks and discuss connections to existing theory on
query-efficient planning algorithms. Code is available at
https://github.com/portal-cornell/llms-for-planning</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.06089v1' target='_blank'>GraPE: A Generate-Plan-Edit Framework for Compositional T2I Synthesis</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ashish Goswami, Satyam Kumar Modi, Santhosh Rishi Deshineni, Harman Singh, Prathosh A. P, Parag Singla</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-08 22:29:56</h6>
<p class='card-text'>Text-to-image (T2I) generation has seen significant progress with diffusion
models, enabling generation of photo-realistic images from text prompts.
Despite this progress, existing methods still face challenges in following
complex text prompts, especially those requiring compositional and multi-step
reasoning. Given such complex instructions, SOTA models often make mistakes in
faithfully modeling object attributes, and relationships among them. In this
work, we present an alternate paradigm for T2I synthesis, decomposing the task
of complex multi-step generation into three steps, (a) Generate: we first
generate an image using existing diffusion models (b) Plan: we make use of
Multi-Modal LLMs (MLLMs) to identify the mistakes in the generated image
expressed in terms of individual objects and their properties, and produce a
sequence of corrective steps required in the form of an edit-plan. (c) Edit: we
make use of an existing text-guided image editing models to sequentially
execute our edit-plan over the generated image to get the desired image which
is faithful to the original instruction. Our approach derives its strength from
the fact that it is modular in nature, is training free, and can be applied
over any combination of image generation and editing models. As an added
contribution, we also develop a model capable of compositional editing, which
further helps improve the overall accuracy of our proposed approach. Our method
flexibly trades inference time compute with performance on compositional text
prompts. We perform extensive experimental evaluation across 3 benchmarks and
10 T2I models including DALLE-3 and the latest -- SD-3.5-Large. Our approach
not only improves the performance of the SOTA models, by upto 3 points, it also
reduces the performance gap between weaker and stronger models.
$\href{https://dair-iitd.github.io/GraPE/}{https://dair-iitd.github.io/GraPE/}$</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.05561v1' target='_blank'>Exploring the Use of LLMs for SQL Equivalence Checking</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Rajat Singh, Srikanta Bedathur</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-07 06:50:12</h6>
<p class='card-text'>Equivalence checking of two SQL queries is an intractable problem encountered
in diverse contexts ranging from grading student submissions in a DBMS course
to debugging query rewriting rules in an optimizer, and many more. While a lot
of progress has been made in recent years in developing practical solutions for
this problem, the existing methods can handle only a small subset of SQL, even
for bounded equivalence checking. They cannot support sophisticated SQL
expressions one encounters in practice. At the same time, large language models
(LLMs) -- such as GPT-4 -- have emerged as power generators of SQL from natural
language specifications. This paper explores whether LLMs can also demonstrate
the ability to reason with SQL queries and help advance SQL equivalence
checking. Towards this, we conducted a detailed evaluation of several LLMs over
collections with SQL pairs of varying levels of complexity. We explored the
efficacy of different prompting techniques, the utility of synthetic examples &
explanations, as well as logical plans generated by query parsers. Our main
finding is that with well-designed prompting using an unoptimized SQL Logical
Plan, LLMs can perform equivalence checking beyond the capabilities of current
techniques, achieving nearly 100% accuracy for equivalent pairs and up to 70%
for non-equivalent pairs of SQL queries. While LLMs lack the ability to
generate formal proofs, their synthetic examples and human-readable
explanations offer valuable insights to students (& instructors) in a classroom
setting and to database administrators (DBAs) managing large database
installations. Additionally, we also show that with careful fine-tuning, we can
close the performance gap between smaller (and efficient) models and larger
models such as GPT, thus paving the way for potential LLM-integration in
standalone data processing systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.05366v1' target='_blank'>ExploraCoder: Advancing code generation for multiple unseen APIs via
  planning and chained exploration</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yunkun Wang, Yue Zhang, Zhen Qin, Chen Zhi, Binhua Li, Fei Huang, Yongbin Li, Shuiguang Deng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-06 19:00:15</h6>
<p class='card-text'>Through training on publicly available source code libraries, large language
models (LLMs) can invoke multiple encapsulated APIs to solve complex
programming problems. However, existing models inherently cannot generalize to
use APIs that are unseen in their training corpora. As libraries continuously
evolve, it becomes impractical to exhaustively retrain LLMs with new API
knowledge. This limitation hampers LLMs from solving problems which require
newly introduced or privately maintained libraries. Human programmers often
explore unfamiliar APIs by writing experimental code before invoking them for a
more complex problem. Inspired by this behavior, we propose , a training-free
framework that empowers LLMs to invoke multiple unseen APIs in code solution by
(1) planning a complex problem into several API invocation subtasks, and (2)
exploring correct API usage through a novel chain-of-API-exploration.
Concretely, ExploraCoder guides the LLM to iteratively generate several
experimental API invocations for each simple subtask, where the promising
execution experience are exploited by subsequent subtasks. This forms a chained
exploration trace that ultimately guides LLM in generating the final solution.
We evaluate ExploraCoder on Torchdata-Github benchmark as well as a newly
constructed benchmark that involves more complex API interactions. Experimental
results demonstrate that ExploraCoder significantly improves performance for
models lacking prior API knowledge, achieving an absolute increase of 11.24%
over niave RAG approaches and 14.07% over pretraining methods in pass@10.
Moreover, the integration of a self-debug mechanism further boosts
ExploraCoder's performance on more challenging tasks. Comprehensive ablation
and case studies provide further insights into the effectiveness of
ExploraCoder.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.04645v1' target='_blank'>REL: Working out is all you need</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Toby Simonds, Jey Han Lau, Chaithanya Bandi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-05 22:32:01</h6>
<p class='card-text'>Recent developments, particularly OpenAI's O1 model, have demonstrated the
remarkable potential of Large Language Models (LLMs) for complex reasoning
tasks. Through analysis of O1's outputs and provided sample Chain-of-Thought
(CoT) demonstrations, we observe that it approaches problem-solving in a
distinctly human-like manner, systematically brainstorming ideas, testing
hypotheses, verifying results, and planning comprehensive solutions. These
sophisticated reasoning capabilities remain notably absent in other
state-of-the-art language models. In this paper, we hypothesize that this
performance gap stems from the limited availability of high-quality reasoning
process data in current training sets. We demonstrate that by constructing a
specialized dataset focused on explicit problem-solving workflows ("worked
solutions"), we can elicit substantially improved planning capabilities from
existing models. Additionally, we propose the Reasoning Enhancement Loop (REL),
a method for generating synthetic worked solutions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.04272v2' target='_blank'>PoTable: Programming Standardly on Table-based Reasoning Like a Human
  Analyst</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Qingyang Mao, Qi Liu, Zhi Li, Mingyue Cheng, Zheng Zhang, Rui Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-05 15:54:16</h6>
<p class='card-text'>Table-based reasoning has garnered substantial research interest,
particularly in its integration with Large Language Model (LLM) which has
revolutionized the general reasoning paradigm. Numerous LLM-based studies
introduce symbolic tools (e.g., databases, Python) as assistants to extend
human-like abilities in structured table understanding and complex arithmetic
computations. However, these studies can be improved better in simulating human
cognitive behavior when using symbolic tools, as they still suffer from
limitations of non-standard logical splits and constrained operation pools. In
this study, we propose PoTable as a novel table-based reasoning method that
simulates a human tabular analyst, which integrates a Python interpreter as the
real-time executor accompanied by an LLM-based operation planner and code
generator. Specifically, PoTable follows a human-like logical stage split and
extends the operation pool into an open-world space without any constraints.
Through planning and executing in each distinct stage, PoTable standardly
completes the entire reasoning process and produces superior reasoning results
along with highly accurate, steply commented and completely executable
programs. Accordingly, the effectiveness and explainability of PoTable are
fully demonstrated. Extensive experiments over three evaluation datasets from
two public benchmarks on two backbones show the outstanding performance of our
approach. In particular, GPT-based PoTable achieves over 4% higher absolute
accuracy than runner-ups on all evaluation datasets.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.04093v1' target='_blank'>Practical Considerations for Agentic LLM Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chris Sypherd, Vaishak Belle</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-05 11:57:49</h6>
<p class='card-text'>As the strength of Large Language Models (LLMs) has grown over recent years,
so too has interest in their use as the underlying models for autonomous
agents. Although LLMs demonstrate emergent abilities and broad expertise across
natural language domains, their inherent unpredictability makes the
implementation of LLM agents challenging, resulting in a gap between related
research and the real-world implementation of such systems. To bridge this gap,
this paper frames actionable insights and considerations from the research
community in the context of established application paradigms to enable the
construction and facilitate the informed deployment of robust LLM agents.
Namely, we position relevant research findings into four broad
categories--Planning, Memory, Tools, and Control Flow--based on common
practices in application-focused literature and highlight practical
considerations to make when designing agentic LLMs for real-world applications,
such as handling stochasticity and managing resources efficiently. While we do
not conduct empirical evaluations, we do provide the necessary background for
discussing critical aspects of agentic LLM designs, both in academia and
industry.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.03338v2' target='_blank'>AI-Driven Day-to-Day Route Choice</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Leizhen Wang, Peibo Duan, Zhengbing He, Cheng Lyu, Xin Chen, Nan Zheng, Li Yao, Zhenliang Ma</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-04 14:13:38</h6>
<p class='card-text'>Understanding travelers' route choices can help policymakers devise optimal
operational and planning strategies for both normal and abnormal circumstances.
However, existing choice modeling methods often rely on predefined assumptions
and struggle to capture the dynamic and adaptive nature of travel behavior.
Recently, Large Language Models (LLMs) have emerged as a promising alternative,
demonstrating remarkable ability to replicate human-like behaviors across
various fields. Despite this potential, their capacity to accurately simulate
human route choice behavior in transportation contexts remains doubtful. To
satisfy this curiosity, this paper investigates the potential of LLMs for route
choice modeling by introducing an LLM-empowered agent, "LLMTraveler." This
agent integrates an LLM as its core, equipped with a memory system that learns
from past experiences and makes decisions by balancing retrieved data and
personality traits. The study systematically evaluates the LLMTraveler's
ability to replicate human-like decision-making through two stages of
day-to-day (DTD) congestion games: (1) analyzing its route-switching behavior
in single origin-destination (OD) pair scenarios, where it demonstrates
patterns that align with laboratory data but cannot be fully explained by
traditional models, and (2) testing its capacity to model adaptive learning
behaviors in multi-OD scenarios on the Ortuzar and Willumsen (OW) network,
producing results comparable to Multinomial Logit (MNL) and Reinforcement
Learning (RL) models. These experiments demonstrate that the framework can
partially replicate human-like decision-making in route choice while providing
natural language explanations for its decisions. This capability offers
valuable insights for transportation policymaking, such as simulating traveler
responses to new policies or changes in the network.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.02655v1' target='_blank'>LLM-Enhanced Path Planning: Safe and Efficient Autonomous Navigation
  with Instructional Inputs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Pranav Doma, Aliasghar Arab, Xuesu Xiao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-03 18:29:37</h6>
<p class='card-text'>Autonomous navigation guided by natural language instructions is essential
for improving human-robot interaction and enabling complex operations in
dynamic environments. While large language models (LLMs) are not inherently
designed for planning, they can significantly enhance planning efficiency by
providing guidance and informing constraints to ensure safety. This paper
introduces a planning framework that integrates LLMs with 2D occupancy grid
maps and natural language commands to improve spatial reasoning and task
execution in resource-limited settings. By decomposing high-level commands and
real-time environmental data, the system generates structured navigation plans
for pick-and-place tasks, including obstacle avoidance, goal prioritization,
and adaptive behaviors. The framework dynamically recalculates paths to address
environmental changes and aligns with implicit social norms for seamless
human-robot interaction. Our results demonstrates the potential of LLMs to
design context-aware system to enhance navigation efficiency and safety in
industrial and dynamic environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.02205v2' target='_blank'>DataLab: A Unified Platform for LLM-Powered Business Intelligence</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Luoxuan Weng, Yinghao Tang, Yingchaojie Feng, Zhuo Chang, Peng Chen, Ruiqin Chen, Haozhe Feng, Chen Hou, Danqing Huang, Yang Li, Huaming Rao, Haonan Wang, Canshi Wei, Xiaofeng Yang, Yuhui Zhang, Yifeng Zheng, Xiuqi Huang, Minfeng Zhu, Yuxin Ma, Bin Cui, Wei Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-03 06:47:15</h6>
<p class='card-text'>Business intelligence (BI) transforms large volumes of data within modern
organizations into actionable insights for informed decision-making. Recently,
large language model (LLM)-based agents have streamlined the BI workflow by
automatically performing task planning, reasoning, and actions in executable
environments based on natural language (NL) queries. However, existing
approaches primarily focus on individual BI tasks such as NL2SQL and NL2VIS.
The fragmentation of tasks across different data roles and tools lead to
inefficiencies and potential errors due to the iterative and collaborative
nature of BI. In this paper, we introduce DataLab, a unified BI platform that
integrates a one-stop LLM-based agent framework with an augmented computational
notebook interface. DataLab supports a wide range of BI tasks for different
data roles by seamlessly combining LLM assistance with user customization
within a single environment. To achieve this unification, we design a domain
knowledge incorporation module tailored for enterprise-specific BI tasks, an
inter-agent communication mechanism to facilitate information sharing across
the BI workflow, and a cell-based context management strategy to enhance
context utilization efficiency in BI notebooks. Extensive experiments
demonstrate that DataLab achieves state-of-the-art performance on various BI
tasks across popular research benchmarks. Moreover, DataLab maintains high
effectiveness and efficiency on real-world datasets from Tencent, achieving up
to a 58.58% increase in accuracy and a 61.65% reduction in token cost on
enterprise-specific BI tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.02193v1' target='_blank'>LayoutVLM: Differentiable Optimization of 3D Layout via Vision-Language
  Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Fan-Yun Sun, Weiyu Liu, Siyi Gu, Dylan Lim, Goutam Bhat, Federico Tombari, Manling Li, Nick Haber, Jiajun Wu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-03 06:15:04</h6>
<p class='card-text'>Open-universe 3D layout generation arranges unlabeled 3D assets conditioned
on language instruction. Large language models (LLMs) struggle with generating
physically plausible 3D scenes and adherence to input instructions,
particularly in cluttered scenes. We introduce LayoutVLM, a framework and scene
layout representation that exploits the semantic knowledge of Vision-Language
Models (VLMs) and supports differentiable optimization to ensure physical
plausibility. LayoutVLM employs VLMs to generate two mutually reinforcing
representations from visually marked images, and a self-consistent decoding
process to improve VLMs spatial planning. Our experiments show that LayoutVLM
addresses the limitations of existing LLM and constraint-based approaches,
producing physically plausible 3D layouts better aligned with the semantic
intent of input language instructions. We also demonstrate that fine-tuning
VLMs with the proposed scene layout representation extracted from existing
scene datasets can improve performance.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.01946v3' target='_blank'>The Reality of AI and Biorisk</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Aidan Peppin, Anka Reuel, Stephen Casper, Elliot Jones, Andrew Strait, Usman Anwar, Anurag Agrawal, Sayash Kapoor, Sanmi Koyejo, Marie Pellat, Rishi Bommasani, Nick Frosst, Sara Hooker</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-02 20:14:46</h6>
<p class='card-text'>To accurately and confidently answer the question 'could an AI model or
system increase biorisk', it is necessary to have both a sound theoretical
threat model for how AI models or systems could increase biorisk and a robust
method for testing that threat model. This paper provides an analysis of
existing available research surrounding two AI and biorisk threat models: 1)
access to information and planning via large language models (LLMs), and 2) the
use of AI-enabled biological tools (BTs) in synthesizing novel biological
artifacts. We find that existing studies around AI-related biorisk are nascent,
often speculative in nature, or limited in terms of their methodological
maturity and transparency. The available literature suggests that current LLMs
and BTs do not pose an immediate risk, and more work is needed to develop
rigorous approaches to understanding how future models could increase biorisks.
We end with recommendations about how empirical work can be expanded to more
precisely target biorisk and ensure rigor and validity of findings.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.12119v1' target='_blank'>Mastering Board Games by External and Internal Planning with Language
  Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:John Schultz, Jakub Adamek, Matej Jusup, Marc Lanctot, Michael Kaisers, Sarah Perrin, Daniel Hennes, Jeremy Shar, Cannada Lewis, Anian Ruoss, Tom Zahavy, Petar Veličković, Laurel Prince, Satinder Singh, Eric Malmi, Nenad Tomašev</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-02 18:56:51</h6>
<p class='card-text'>While large language models perform well on a range of complex tasks (e.g.,
text generation, question answering, summarization), robust multi-step planning
and reasoning remains a considerable challenge for them. In this paper we show
that search-based planning can significantly improve LLMs' playing strength
across several board games (Chess, Fischer Random / Chess960, Connect Four, and
Hex). We introduce, compare and contrast two major approaches: In external
search, the model guides Monte Carlo Tree Search (MCTS) rollouts and
evaluations without calls to an external engine, and in internal search, the
model directly generates in-context a linearized tree of potential futures and
a resulting final choice. Both build on a language model pre-trained on
relevant domain knowledge, capturing the transition and value functions across
these games. We find that our pre-training method minimizes hallucinations, as
our model is highly accurate regarding state prediction and legal moves.
Additionally, both internal and external search indeed improve win-rates
against state-of-the-art bots, even reaching Grandmaster-level performance in
chess while operating on a similar move count search budget per decision as
human Grandmasters. The way we combine search with domain knowledge is not
specific to board games, suggesting direct extensions into more general
language model inference and training techniques.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.01709v1' target='_blank'>Query Performance Explanation through Large Language Model for HTAP
  Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Haibo Xiu, Li Zhang, Tieying Zhang, Jun Yang, Jianjun Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-02 16:55:07</h6>
<p class='card-text'>In hybrid transactional and analytical processing (HTAP) systems, users often
struggle to understand why query plans from one engine (OLAP or OLTP) perform
significantly slower than those from another. Although optimizers provide plan
details via the EXPLAIN function, these explanations are frequently too
technical for non-experts and offer limited insights into performance
differences across engines. To address this, we propose a novel framework that
leverages large language models (LLMs) to explain query performance in HTAP
systems. Built on Retrieval-Augmented Generation (RAG), our framework
constructs a knowledge base that stores historical query executions and
expert-curated explanations. To enable efficient retrieval of relevant
knowledge, query plans are embedded using a lightweight tree-CNN classifier.
This augmentation allows the LLM to generate clear, context-aware explanations
of performance differences between engines. Our approach demonstrates the
potential of LLMs in hybrid engine systems, paving the way for further
advancements in database optimization and user support.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.01663v1' target='_blank'>DaDu-E: Rethinking the Role of Large Language Model in Robotic Computing
  Pipeline</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wenhao Sun, Sai Hou, Zixuan Wang, Bo Yu, Shaoshan Liu, Xu Yang, Shuai Liang, Yiming Gan, Yinhe Han</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-02 16:14:05</h6>
<p class='card-text'>Performing complex tasks in open environments remains challenging for robots,
even when using large language models (LLMs) as the core planner. Many
LLM-based planners are inefficient due to their large number of parameters and
prone to inaccuracies because they operate in open-loop systems. We think the
reason is that only applying LLMs as planners is insufficient. In this work, we
propose DaDu-E, a robust closed-loop planning framework for embodied AI robots.
Specifically, DaDu-E is equipped with a relatively lightweight LLM, a set of
encapsulated robot skill instructions, a robust feedback system, and memory
augmentation. Together, these components enable DaDu-E to (i) actively perceive
and adapt to dynamic environments, (ii) optimize computational costs while
maintaining high performance, and (iii) recover from execution failures using
its memory and feedback mechanisms. Extensive experiments on real-world and
simulated tasks show that DaDu-E achieves task success rates comparable to
embodied AI robots with larger models as planners like COME-Robot, while
reducing computational requirements by $6.6 \times$. Users are encouraged to
explore our system at: \url{https://rlc-lab.github.io/dadu-e/}.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.01417v1' target='_blank'>Learning Elementary Cellular Automata with Transformers</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mikhail Burtsev</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-02 11:57:49</h6>
<p class='card-text'>Large Language Models demonstrate remarkable mathematical capabilities but at
the same time struggle with abstract reasoning and planning. In this study, we
explore whether Transformers can learn to abstract and generalize the rules
governing Elementary Cellular Automata. By training Transformers on state
sequences generated with random initial conditions and local rules, we show
that they can generalize across different Boolean functions of fixed arity,
effectively abstracting the underlying rules. While the models achieve high
accuracy in next-state prediction, their performance declines sharply in
multi-step planning tasks without intermediate context. Our analysis reveals
that including future states or rule prediction in the training loss enhances
the models' ability to form internal representations of the rules, leading to
improved performance in longer planning horizons and autoregressive generation.
Furthermore, we confirm that increasing the model's depth plays a crucial role
in extended sequential computations required for complex reasoning tasks. This
highlights the potential to improve LLM with inclusion of longer horizons in
loss function, as well as incorporating recurrence and adaptive computation
time for dynamic control of model depth.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.00627v2' target='_blank'>ARChef: An iOS-Based Augmented Reality Cooking Assistant Powered by
  Multimodal Gemini LLM</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Rithik Vir, Parsa Madinei</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-12-01 00:52:51</h6>
<p class='card-text'>Cooking meals can be difficult, causing many to resort to cookbooks and
online recipes. However, relying on these traditional methods of cooking often
results in missing ingredients, nutritional hazards, and unsatisfactory meals.
Using Augmented Reality (AR) can address these issues; however, current AR
cooking applications have poor user interfaces and limited accessibility. This
paper proposes a prototype of an iOS application that integrates AR and
Computer Vision (CV) into the cooking process. We leverage Google's Gemini
Large Language Model (LLM) to identify ingredients in the camera's field of
vision and generate recipe choices with detailed nutritional information.
Additionally, this application uses Apple's ARKit to create an AR user
interface compatible with iOS devices. Users can personalize their meal
suggestions by inputting their dietary preferences and rating each meal. The
application's effectiveness is evaluated through three rounds of user
experience surveys. This application advances the field of accessible cooking
assistance technologies, aiming to reduce food wastage and improve the meal
planning experience.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.00435v1' target='_blank'>Benchmark Real-time Adaptation and Communication Capabilities of
  Embodied Agent in Collaborative Scenarios</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shipeng Liu, Boshen Zhang, Zhehui Huang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-30 11:17:17</h6>
<p class='card-text'>Advancements in Large Language Models (LLMs) have opened transformative
possibilities for human-robot interaction, especially in collaborative
environments. However, Real-time human-AI collaboration requires agents to
adapt to unseen human behaviors while maintaining effective communication
dynamically. Existing benchmarks fall short in evaluating such adaptability for
embodied agents, focusing mostly on the task performance of the agent itself.
To address this gap, we propose a novel benchmark that assesses agents'
reactive adaptability and instantaneous communication capabilities at every
step. Based on this benchmark, we propose a Monitor-then-Adapt framework
(MonTA), combining strong adaptability and communication with real-time
execution. MonTA contains three key LLM modules, a lightweight \textit{Monitor}
for monitoring the need for adaptation in high frequency, and two proficient
\textit{Adapters} for subtask and path adaptation reasoning in low frequency.
Our results demonstrate that MonTA outperforms other baseline agents on our
proposed benchmark. Further user studies confirm the high reasonability
adaptation plan and consistent language instruction provided by our framework.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.00300v1' target='_blank'>PlanCritic: Formal Planning with Human Feedback</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Owen Burns, Dana Hughes, Katia Sycara</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-30 00:58:48</h6>
<p class='card-text'>Real world planning problems are often too complex to be effectively tackled
by a single unaided human. To alleviate this, some recent work has focused on
developing a collaborative planning system to assist humans in complex domains,
with bridging the gap between the system's problem representation and the real
world being a key consideration. Transferring the speed and correctness formal
planners provide to real-world planning problems is greatly complicated by the
dynamic and online nature of such tasks. Formal specifications of task and
environment dynamics frequently lack constraints on some behaviors or goal
conditions relevant to the way a human operator prefers a plan to be carried
out. While adding constraints to the representation with the objective of
increasing its realism risks slowing down the planner, we posit that the same
benefits can be realized without sacrificing speed by modeling this problem as
an online preference learning task. As part of a broader cooperative planning
system, we present a feedback-driven plan critic. This method makes use of
reinforcement learning with human feedback in conjunction with a genetic
algorithm to directly optimize a plan with respect to natural-language user
preferences despite the non-differentiability of traditional planners. Directly
optimizing the plan bridges the gap between research into more efficient
planners and research into planning with language models by utilizing the
convenience of natural language to guide the output of formal planners. We
demonstrate the effectiveness of our plan critic at adhering to user
preferences on a disaster recovery task, and observe improved performance
compared to an llm-only neurosymbolic approach.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.00224v1' target='_blank'>An AI-Driven Data Mesh Architecture Enhancing Decision-Making in
  Infrastructure Construction and Public Procurement</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Saurabh Mishra, Mahendra Shinde, Aniket Yadav, Bilal Ayyub, Anand Rao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-29 19:33:51</h6>
<p class='card-text'>Infrastructure construction, often dubbed an "industry of industries," is
closely linked with government spending and public procurement, offering
significant opportunities for improved efficiency and productivity through
better transparency and information access. By leveraging these opportunities,
we can achieve notable gains in productivity, cost savings, and broader
economic benefits. Our approach introduces an integrated software ecosystem
utilizing Data Mesh and Service Mesh architectures. This system includes the
largest training dataset for infrastructure and procurement, encompassing over
100 billion tokens, scientific publications, activities, and risk data, all
structured by a systematic AI framework. Supported by a Knowledge Graph linked
to domain-specific multi-agent tasks and Q&A capabilities, our platform
standardizes and ingests diverse data sources, transforming them into
structured knowledge. Leveraging large language models (LLMs) and automation,
our system revolutionizes data structuring and knowledge creation, aiding
decision-making in early-stage project planning, detailed research, market
trend analysis, and qualitative assessments. Its web-scalable architecture
delivers domain-curated information, enabling AI agents to facilitate reasoning
and manage uncertainties, while preparing for future expansions with
specialized agents targeting particular challenges. This integration of AI with
domain expertise not only boosts efficiency and decision-making in construction
and infrastructure but also establishes a framework for enhancing government
efficiency and accelerating the transition of traditional industries to digital
workflows. This work is poised to significantly influence AI-driven initiatives
in this sector and guide best practices in AI Operations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.19921v1' target='_blank'>SIMS: Simulating Human-Scene Interactions with Real World Script
  Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wenjia Wang, Liang Pan, Zhiyang Dou, Zhouyingcheng Liao, Yuke Lou, Lei Yang, Jingbo Wang, Taku Komura</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-29 18:36:15</h6>
<p class='card-text'>Simulating long-term human-scene interaction is a challenging yet fascinating
task. Previous works have not effectively addressed the generation of long-term
human scene interactions with detailed narratives for physics-based animation.
This paper introduces a novel framework for the planning and controlling of
long-horizon physical plausible human-scene interaction. On the one hand, films
and shows with stylish human locomotions or interactions with scenes are
abundantly available on the internet, providing a rich source of data for
script planning. On the other hand, Large Language Models (LLMs) can understand
and generate logical storylines.
  This motivates us to marry the two by using an LLM-based pipeline to extract
scripts from videos, and then employ LLMs to imitate and create new scripts,
capturing complex, time-series human behaviors and interactions with
environments. By leveraging this, we utilize a dual-aware policy that achieves
both language comprehension and scene understanding to guide character motions
within contextual and spatial constraints. To facilitate training and
evaluation, we contribute a comprehensive planning dataset containing diverse
motion sequences extracted from real-world videos and expand them with large
language models. We also collect and re-annotate motion clips from existing
kinematic datasets to enable our policy learn diverse skills. Extensive
experiments demonstrate the effectiveness of our framework in versatile task
execution and its generalization ability to various scenarios, showing
remarkably enhanced performance compared with existing methods. Our code and
data will be publicly available soon.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.19886v1' target='_blank'>PDDLFuse: A Tool for Generating Diverse Planning Domains</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Vedant Khandelwal, Amit Sheth, Forest Agostinelli</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-29 17:52:39</h6>
<p class='card-text'>Various real-world challenges require planning algorithms that can adapt to a
broad range of domains. Traditionally, the creation of planning domains has
relied heavily on human implementation, which limits the scale and diversity of
available domains. While recent advancements have leveraged generative AI
technologies such as large language models (LLMs) for domain creation, these
efforts have predominantly focused on translating existing domains from natural
language descriptions rather than generating novel ones. In contrast, the
concept of domain randomization, which has been highly effective in
reinforcement learning, enhances performance and generalizability by training
on a diverse array of randomized new domains. Inspired by this success, our
tool, PDDLFuse, aims to bridge this gap in Planning Domain Definition Language
(PDDL). PDDLFuse is designed to generate new, diverse planning domains that can
be used to validate new planners or test foundational planning models. We have
developed methods to adjust the domain generators parameters to modulate the
difficulty of the domains it generates. This adaptability is crucial as
existing domain-independent planners often struggle with more complex problems.
Initial tests indicate that PDDLFuse efficiently creates intricate and varied
domains, representing a significant advancement over traditional domain
generation methods and making a contribution towards planning research.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.19554v1' target='_blank'>Unimib Assistant: designing a student-friendly RAG-based chatbot for all
  their needs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chiara Antico, Stefano Giordano, Cansu Koyuturk, Dimitri Ognibene</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-29 09:07:21</h6>
<p class='card-text'>Natural language processing skills of Large Language Models (LLMs) are
unprecedented, having wide diffusion and application in different tasks. This
pilot study focuses on specializing ChatGPT behavior through a
Retrieval-Augmented Generation (RAG) system using the OpenAI custom GPTs
feature. The purpose of our chatbot, called Unimib Assistant, is to provide
information and solutions to the specific needs of University of Milano-Bicocca
(Unimib) students through a question-answering approach. We provided the system
with a prompt highlighting its specific purpose and behavior, as well as
university-related documents and links obtained from an initial need-finding
phase, interviewing six students. After a preliminary customization phase, a
qualitative usability test was conducted with six other students to identify
the strengths and weaknesses of the chatbot, with the goal of improving it in a
subsequent redesign phase. While the chatbot was appreciated for its
user-friendly experience, perceived general reliability, well-structured
responses, and conversational tone, several significant technical and
functional limitations emerged. In particular, the satisfaction and overall
experience of the users was impaired by the system's inability to always
provide fully accurate information. Moreover, it would often neglect to report
relevant information even if present in the materials uploaded and prompt
given. Furthermore, it sometimes generated unclickable links, undermining its
trustworthiness, since providing the source of information was an important
aspect for our users. Further in-depth studies and feedback from other users as
well as implementation iterations are planned to refine our Unimib Assistant.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.19443v1' target='_blank'>Auto-RAG: Autonomous Retrieval-Augmented Generation for Large Language
  Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tian Yu, Shaolei Zhang, Yang Feng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-29 03:01:05</h6>
<p class='card-text'>Iterative retrieval refers to the process in which the model continuously
queries the retriever during generation to enhance the relevance of the
retrieved knowledge, thereby improving the performance of Retrieval-Augmented
Generation (RAG). Existing work typically employs few-shot prompting or
manually constructed rules to implement iterative retrieval. This introduces
additional inference overhead and overlooks the remarkable reasoning
capabilities of Large Language Models (LLMs). In this paper, we introduce
Auto-RAG, an autonomous iterative retrieval model centered on the LLM's
powerful decision-making capabilities. Auto-RAG engages in multi-turn dialogues
with the retriever, systematically planning retrievals and refining queries to
acquire valuable knowledge. This process continues until sufficient external
information is gathered, at which point the results are presented to the user.
To this end, we develop a method for autonomously synthesizing reasoning-based
decision-making instructions in iterative retrieval and fine-tuned the latest
open-source LLMs. The experimental results indicate that Auto-RAG is capable of
autonomous iterative interaction with the retriever, effectively leveraging the
remarkable reasoning and decision-making abilities of LLMs, which lead to
outstanding performance across six benchmarks. Further analysis reveals that
Auto-RAG can autonomously adjust the number of iterations based on the
difficulty of the questions and the utility of the retrieved knowledge, without
requiring any human intervention. Moreover, Auto-RAG expresses the iterative
retrieval process in natural language, enhancing interpretability while
providing users with a more intuitive experience\footnote{Code is available at
\url{https://github.com/ictnlp/Auto-RAG}.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.00114v1' target='_blank'>SceneTAP: Scene-Coherent Typographic Adversarial Planner against
  Vision-Language Models in Real-World Environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yue Cao, Yun Xing, Jie Zhang, Di Lin, Tianwei Zhang, Ivor Tsang, Yang Liu, Qing Guo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-28 05:55:13</h6>
<p class='card-text'>Large vision-language models (LVLMs) have shown remarkable capabilities in
interpreting visual content. While existing works demonstrate these models'
vulnerability to deliberately placed adversarial texts, such texts are often
easily identifiable as anomalous. In this paper, we present the first approach
to generate scene-coherent typographic adversarial attacks that mislead
advanced LVLMs while maintaining visual naturalness through the capability of
the LLM-based agent. Our approach addresses three critical questions: what
adversarial text to generate, where to place it within the scene, and how to
integrate it seamlessly. We propose a training-free, multi-modal LLM-driven
scene-coherent typographic adversarial planning (SceneTAP) that employs a
three-stage process: scene understanding, adversarial planning, and seamless
integration. The SceneTAP utilizes chain-of-thought reasoning to comprehend the
scene, formulate effective adversarial text, strategically plan its placement,
and provide detailed instructions for natural integration within the image.
This is followed by a scene-coherent TextDiffuser that executes the attack
using a local diffusion mechanism. We extend our method to real-world scenarios
by printing and placing generated patches in physical environments,
demonstrating its practical implications. Extensive experiments show that our
scene-coherent adversarial text successfully misleads state-of-the-art LVLMs,
including ChatGPT-4o, even after capturing new images of physical setups. Our
evaluations demonstrate a significant increase in attack success rates while
maintaining visual naturalness and contextual appropriateness. This work
highlights vulnerabilities in current vision-language models to sophisticated,
scene-coherent adversarial attacks and provides insights into potential defense
mechanisms.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.18915v3' target='_blank'>MATATA: A weakly-supervised MAthematical Tool-Assisted reasoning for
  Tabular Applications</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Vishnou Vinayagame, Gregory Senay, Luis Martí</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-28 05:12:17</h6>
<p class='card-text'>Mathematical reasoning capabilities are increasing with tool-augmented
language agents, but methods often rely either on closed-source or large
models, external data, or extensive prompt engineering. This work introduces
MATATA, a novel cost-effective method to train LLM agents for tabular data
problems through reasoning, planning, and tool use. With a progressive
self-improvement paradigm and an iterative weak supervision, it empowers
3.8B/8B Small Language Models (SLMs), particularly suited for local hosting and
sensitive business contexts where data privacy is crucial. By employing a
flexible and reusable tools across different datasets, it achieves robust
performance with effective scalability across shared tasks. Experiments show
that MATATA reaches state-of-the-art performances on FinQA and TAT-QA among
reasoning frameworks based on open-source models. Moreover, MATATA models
compete with GPT-4 based frameworks on TabMWP, while being SLMs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.09632v2' target='_blank'>Methods to Assess the UK Government's Current Role as a Data Provider
  for AI</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Neil Majithia, Elena Simperl</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-27 19:53:05</h6>
<p class='card-text'>Governments typically collect and steward a vast amount of high-quality data
on their citizens and institutions, and the UK government is exploring how it
can better publish and provision this data to the benefit of the AI landscape.
However, the compositions of generative AI training corpora remain closely
guarded secrets, making the planning of data sharing initiatives difficult. To
address this, we devise two methods to assess UK government data usage for the
training of Large Language Models (LLMs) and 'peek behind the curtain' in order
to observe the UK government's current contributions as a data provider for AI.
The first method, an ablation study that utilises LLM 'unlearning', seeks to
examine the importance of the information held on UK government websites for
LLMs and their performance in citizen query tasks. The second method, an
information leakage study, seeks to ascertain whether LLMs are aware of the
information held in the datasets published on the UK government's open data
initiative data$.$gov$.$uk. Our findings indicate that UK government websites
are important data sources for AI (heterogenously across subject matters) while
data$.$gov$.$uk is not. This paper serves as a technical report, explaining
in-depth the designs, mechanics, and limitations of the above experiments. It
is accompanied by a complementary non-technical report on the ODI website in
which we summarise the experiments and key findings, interpret them, and build
a set of actionable recommendations for the UK government to take forward as it
seeks to design AI policy. While we focus on UK open government data, we
believe that the methods introduced in this paper present a reproducible
approach to tackle the opaqueness of AI training corpora and provide
organisations a framework to evaluate and maximize their contributions to AI
development.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.18711v1' target='_blank'>Evaluating Vision-Language Models as Evaluators in Path Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mohamed Aghzal, Xiang Yue, Erion Plaku, Ziyu Yao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-27 19:32:03</h6>
<p class='card-text'>Despite their promise to perform complex reasoning, large language models
(LLMs) have been shown to have limited effectiveness in end-to-end planning.
This has inspired an intriguing question: if these models cannot plan well, can
they still contribute to the planning framework as a helpful plan evaluator? In
this work, we generalize this question to consider LLMs augmented with visual
understanding, i.e., Vision-Language Models (VLMs). We introduce PathEval, a
novel benchmark evaluating VLMs as plan evaluators in complex path-planning
scenarios. Succeeding in the benchmark requires a VLM to be able to abstract
traits of optimal paths from the scenario description, demonstrate precise
low-level perception on each path, and integrate this information to decide the
better path. Our analysis of state-of-the-art VLMs reveals that these models
face significant challenges on the benchmark. We observe that the VLMs can
precisely abstract given scenarios to identify the desired traits and exhibit
mixed performance in integrating the provided information. Yet, their vision
component presents a critical bottleneck, with models struggling to perceive
low-level details about a path. Our experimental results show that this issue
cannot be trivially addressed via end-to-end fine-tuning; rather, task-specific
discriminative adaptation of these vision encoders is needed for these VLMs to
become effective path evaluators.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.18013v1' target='_blank'>FASIONAD : FAst and Slow FusION Thinking Systems for Human-Like
  Autonomous Driving with Adaptive Feedback</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kangan Qian, Zhikun Ma, Yangfan He, Ziang Luo, Tianyu Shi, Tianze Zhu, Jiayin Li, Jianhui Wang, Ziyu Chen, Xiao He, Yining Shi, Zheng Fu, Xinyu Jiao, Kun Jiang, Diange Yang, Takafumi Matsumaru</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-27 03:14:16</h6>
<p class='card-text'>Ensuring safe, comfortable, and efficient navigation is a critical goal for
autonomous driving systems. While end-to-end models trained on large-scale
datasets excel in common driving scenarios, they often struggle with rare,
long-tail events. Recent progress in large language models (LLMs) has
introduced enhanced reasoning capabilities, but their computational demands
pose challenges for real-time decision-making and precise planning. This paper
presents FASIONAD, a novel dual-system framework inspired by the cognitive
model "Thinking, Fast and Slow." The fast system handles routine navigation
tasks using rapid, data-driven path planning, while the slow system focuses on
complex reasoning and decision-making in challenging or unfamiliar situations.
A dynamic switching mechanism based on score distribution and feedback allows
seamless transitions between the two systems. Visual prompts generated by the
fast system enable human-like reasoning in the slow system, which provides
high-quality feedback to enhance the fast system's decision-making. To evaluate
FASIONAD, we introduce a new benchmark derived from the nuScenes dataset,
specifically designed to differentiate fast and slow scenarios. FASIONAD
achieves state-of-the-art performance on this benchmark, establishing a new
standard for frameworks integrating fast and slow cognitive processes in
autonomous driving. This approach paves the way for more adaptive, human-like
autonomous driving systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.17912v2' target='_blank'>Can LLMs plan paths in the real world?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wanyi Chen, Meng-Wen Su, Nafisa Mehjabin, Mary L. Cummings</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-26 22:06:39</h6>
<p class='card-text'>As large language models (LLMs) increasingly integrate into vehicle
navigation systems, understanding their path-planning capability is crucial. We
tested three LLMs through six real-world path-planning scenarios in various
settings and with various difficulties. Our experiments showed that all LLMs
made numerous errors in all scenarios, revealing that they are unreliable path
planners. We suggest that future work focus on implementing mechanisms for
reality checks, enhancing model transparency, and developing smaller models.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.17651v1' target='_blank'>Toward High-Performance LLM Serving: A Simulation-Based Approach for
  Identifying Optimal Parallelism</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yi-Chien Lin, Woosuk Kwon, Ronald Pineda, Fanny Nina Paravecino</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-26 18:16:56</h6>
<p class='card-text'>Serving Large Language Models (LLMs) efficiently has become crucial. LLMs are
often served with multiple devices using techniques like data, pipeline, and
tensor parallelisms. Each parallelism presents trade-offs between computation,
memory, and communication overhead, making it challenging to determine the
optimal parallel execution plan. Moreover, input workloads also impact
parallelism strategies. Tasks with long prompts like article summarization are
compute-intensive, while tasks with long generation lengths like code
generation are often memory-intensive; these differing characteristics result
in distinct optimal execution plans. Since searching for the optimal plan via
actual deployment is prohibitively expensive, we propose APEX, an LLM serving
system simulator that efficiently identifies an optimal parallel execution
plan. APEX captures the complex characteristics of iteration-level batching, a
technique widely used in SOTA LLM serving systems. APEX leverages the
repetitive structure of LLMs to reduce design space, maintaining a similar
simulation overhead, even when scaling to trillion scale models. APEX supports
a wide range of LLMs, device clusters, etc., and it can be easily extended
through its high-level templates. We run APEX simulations using a CPU and
evaluate the identified optimal plans using 8 H100 GPUs, encompassing a wide
range of LLMs and input workloads. We show that APEX can find optimal execution
plans that are up to 4.42x faster than heuristic plans in terms of end-to-end
serving latency. APEX also reports a set of metrics used in LLM serving
systems, such as time per output token and time to first token. Furthermore,
APEX can identify an optimal parallel execution plan within 15 minutes using a
CPU. This is 71x faster and 1234x more cost-effective than actual deployment on
a GPU cluster using cloud services. APEX will be open-sourced upon acceptance.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.17636v1' target='_blank'>MALMM: Multi-Agent Large Language Models for Zero-Shot Robotics
  Manipulation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Harsh Singh, Rocktim Jyoti Das, Mingfei Han, Preslav Nakov, Ivan Laptev</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-26 17:53:44</h6>
<p class='card-text'>Large Language Models (LLMs) have demonstrated remarkable planning abilities
across various domains, including robotics manipulation and navigation. While
recent efforts in robotics have leveraged LLMs both for high-level and
low-level planning, these approaches often face significant challenges, such as
hallucinations in long-horizon tasks and limited adaptability due to the
generation of plans in a single pass without real-time feedback. To address
these limitations, we propose a novel multi-agent LLM framework, Multi-Agent
Large Language Model for Manipulation (MALMM) that distributes high-level
planning and low-level control code generation across specialized LLM agents,
supervised by an additional agent that dynamically manages transitions. By
incorporating observations from the environment after each step, our framework
effectively handles intermediate failures and enables adaptive re-planning.
Unlike existing methods, our approach does not rely on pre-trained skill
policies or in-context learning examples and generalizes to a variety of new
tasks. We evaluate our approach on nine RLBench tasks, including long-horizon
tasks, and demonstrate its ability to solve robotics manipulation in a
zero-shot setting, thereby overcoming key limitations of existing LLM-based
manipulation methods.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.17255v2' target='_blank'>APT: Architectural Planning and Text-to-Blueprint Construction Using
  Large Language Models for Open-World Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jun Yu Chen, Tao Gao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-26 09:31:28</h6>
<p class='card-text'>We present APT, an advanced Large Language Model (LLM)-driven framework that
enables autonomous agents to construct complex and creative structures within
the Minecraft environment. Unlike previous approaches that primarily
concentrate on skill-based open-world tasks or rely on image-based diffusion
models for generating voxel-based structures, our method leverages the
intrinsic spatial reasoning capabilities of LLMs. By employing chain-of-thought
decomposition along with multimodal inputs, the framework generates detailed
architectural layouts and blueprints that the agent can execute under zero-shot
or few-shot learning scenarios. Our agent incorporates both memory and
reflection modules to facilitate lifelong learning, adaptive refinement, and
error correction throughout the building process. To rigorously evaluate the
agent's performance in this emerging research area, we introduce a
comprehensive benchmark consisting of diverse construction tasks designed to
test creativity, spatial reasoning, adherence to in-game rules, and the
effective integration of multimodal instructions. Experimental results using
various GPT-based LLM backends and agent configurations demonstrate the agent's
capacity to accurately interpret extensive instructions involving numerous
items, their positions, and orientations. The agent successfully produces
complex structures complete with internal functionalities such as
Redstone-powered systems. A/B testing indicates that the inclusion of a memory
module leads to a significant increase in performance, emphasizing its role in
enabling continuous learning and the reuse of accumulated experience.
Additionally, the agent's unexpected emergence of scaffolding behavior
highlights the potential of future LLM-driven agents to utilize subroutine
planning and leverage the emergence ability of LLMs to autonomously develop
human-like problem-solving techniques.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2412.04492v1' target='_blank'>Socio-Emotional Response Generation: A Human Evaluation Protocol for
  LLM-Based Conversational Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lorraine Vanel, Ariel R. Ramos Vela, Alya Yacoubi, Chloé Clavel</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-26 08:15:36</h6>
<p class='card-text'>Conversational systems are now capable of producing impressive and generally
relevant responses. However, we have no visibility nor control of the
socio-emotional strategies behind state-of-the-art Large Language Models
(LLMs), which poses a problem in terms of their transparency and thus their
trustworthiness for critical applications. Another issue is that current
automated metrics are not able to properly evaluate the quality of generated
responses beyond the dataset's ground truth. In this paper, we propose a neural
architecture that includes an intermediate step in planning socio-emotional
strategies before response generation. We compare the performance of
open-source baseline LLMs to the outputs of these same models augmented with
our planning module. We also contrast the outputs obtained from automated
metrics and evaluation results provided by human annotators. We describe a
novel evaluation protocol that includes a coarse-grained consistency
evaluation, as well as a finer-grained annotation of the responses on various
social and emotional criteria. Our study shows that predicting a sequence of
expected strategy labels and using this sequence to generate a response yields
better results than a direct end-to-end generation scheme. It also highlights
the divergences and the limits of current evaluation metrics for generated
content. The code for the annotation platform and the annotated data are made
publicly available for the evaluation of future models.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.17089v1' target='_blank'>Efficient LLM Inference with I/O-Aware Partial KV Cache Recomputation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chaoyi Jiang, Lei Gao, Hossein Entezari Zarch, Murali Annavaram</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-26 04:03:14</h6>
<p class='card-text'>Inference for Large Language Models (LLMs) is computationally demanding. To
reduce the cost of auto-regressive decoding, Key-Value (KV) caching is used to
store intermediate activations, enabling GPUs to perform only the incremental
computation required for each new token. This approach significantly lowers the
computational overhead for token generation. However, the memory required for
KV caching grows rapidly, often exceeding the capacity of GPU memory. A
cost-effective alternative is to offload KV cache to CPU memory, which
alleviates GPU memory pressure but shifts the bottleneck to the limited
bandwidth of the PCIe connection between the CPU and GPU. Existing methods
attempt to address these issues by overlapping GPU computation with I/O or
employing CPU-GPU heterogeneous execution, but they are hindered by excessive
data movement and dependence on CPU capabilities. In this paper, we introduce
an efficient CPU-GPU I/O-aware LLM inference method that avoids transferring
the entire KV cache from CPU to GPU by recomputing partial KV cache from
activations while concurrently transferring the remaining KV cache via PCIe
bus. This approach overlaps GPU recomputation with data transfer to minimize
idle GPU time and maximize inference performance. Our method is fully automated
by integrating a profiler module that utilizes input characteristics and system
hardware information, a scheduler module to optimize the distribution of
computation and communication workloads, and a runtime module to efficiently
execute the derived execution plan. Experimental results show that our method
achieves up to 35.8% lower latency and 46.2% higher throughput during decoding
compared to state-of-the-art approaches.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.16657v2' target='_blank'>DreamRunner: Fine-Grained Storytelling Video Generation with
  Retrieval-Augmented Motion Adaptation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zun Wang, Jialu Li, Han Lin, Jaehong Yoon, Mohit Bansal</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-25 18:41:56</h6>
<p class='card-text'>Storytelling video generation (SVG) has recently emerged as a task to create
long, multi-motion, multi-scene videos that consistently represent the story
described in the input text script. SVG holds great potential for diverse
content creation in media and entertainment; however, it also presents
significant challenges: (1) objects must exhibit a range of fine-grained,
complex motions, (2) multiple objects need to appear consistently across
scenes, and (3) subjects may require multiple motions with seamless transitions
within a single scene. To address these challenges, we propose DreamRunner, a
novel story-to-video generation method: First, we structure the input script
using a large language model (LLM) to facilitate both coarse-grained scene
planning as well as fine-grained object-level layout and motion planning. Next,
DreamRunner presents retrieval-augmented test-time adaptation to capture target
motion priors for objects in each scene, supporting diverse motion
customization based on retrieved videos, thus facilitating the generation of
new videos with complex, scripted motions. Lastly, we propose a novel
spatial-temporal region-based 3D attention and prior injection module SR3AI for
fine-grained object-motion binding and frame-by-frame semantic control. We
compare DreamRunner with various SVG baselines, demonstrating state-of-the-art
performance in character consistency, text alignment, and smooth transitions.
Additionally, DreamRunner exhibits strong fine-grained condition-following
ability in compositional text-to-video generation, significantly outperforming
baselines on T2V-ComBench. Finally, we validate DreamRunner's robust ability to
generate multi-object interactions with qualitative examples.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.16587v2' target='_blank'>Large Language Model-based Decision-making for COLREGs and the Control
  of Autonomous Surface Vehicles</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Klinsmann Agyei, Pouria Sarhadi, Wasif Naeem</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-25 17:22:10</h6>
<p class='card-text'>In the field of autonomous surface vehicles (ASVs), devising decision-making
and obstacle avoidance solutions that address maritime COLREGs (Collision
Regulations), primarily defined for human operators, has long been a pressing
challenge. Recent advancements in explainable Artificial Intelligence (AI) and
machine learning have shown promise in enabling human-like decision-making.
Notably, significant developments have occurred in the application of Large
Language Models (LLMs) to the decision-making of complex systems, such as
self-driving cars. The textual and somewhat ambiguous nature of COLREGs (from
an algorithmic perspective), however, poses challenges that align well with the
capabilities of LLMs, suggesting that LLMs may become increasingly suitable for
this application soon. This paper presents and demonstrates the first
application of LLM-based decision-making and control for ASVs. The proposed
method establishes a high-level decision-maker that uses online collision risk
indices and key measurements to make decisions for safe manoeuvres. A tailored
design and runtime structure is developed to support training and real-time
action generation on a realistic ASV model. Local planning and control
algorithms are integrated to execute the commands for waypoint following and
collision avoidance at a lower level. To the authors' knowledge, this study
represents the first attempt to apply explainable AI to the dynamic control
problem of maritime systems recognising the COLREGs rules, opening new avenues
for research in this challenging area. Results obtained across multiple test
scenarios demonstrate the system's ability to maintain online COLREGs
compliance, accurate waypoint tracking, and feasible control, while providing
human-interpretable reasoning for each decision.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.16495v3' target='_blank'>AtomR: Atomic Operator-Empowered Large Language Models for Heterogeneous
  Knowledge Reasoning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Amy Xin, Jinxin Liu, Zijun Yao, Zhicheng Lee, Shulin Cao, Lei Hou, Juanzi Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-25 15:35:51</h6>
<p class='card-text'>Despite the outstanding capabilities of large language models (LLMs),
knowledge-intensive reasoning still remains a challenging task due to LLMs'
limitations in compositional reasoning and the hallucination problem. A
prevalent solution is to employ chain-of-thought (CoT) with retrieval-augmented
generation (RAG), which first formulates a reasoning plan by decomposing
complex questions into simpler sub-questions, and then applies iterative RAG at
each sub-question. However, prior works exhibit two crucial problems:
inadequate reasoning planning and poor incorporation of heterogeneous
knowledge. In this paper, we introduce AtomR, a framework for LLMs to conduct
accurate heterogeneous knowledge reasoning at the atomic level. Inspired by how
knowledge graph query languages model compositional reasoning through combining
predefined operations, we propose three atomic knowledge operators, a unified
set of operators for LLMs to retrieve and manipulate knowledge from
heterogeneous sources. First, in the reasoning planning stage, AtomR decomposes
a complex question into a reasoning tree where each leaf node corresponds to an
atomic knowledge operator, achieving question decomposition that is highly
fine-grained and orthogonal. Subsequently, in the reasoning execution stage,
AtomR executes each atomic knowledge operator, which flexibly selects,
retrieves, and operates atomic level knowledge from heterogeneous sources. We
also introduce BlendQA, a challenging benchmark specially tailored for
heterogeneous knowledge reasoning. Experiments on three single-source and two
multi-source datasets show that AtomR outperforms state-of-the-art baselines by
a large margin, with F1 score improvements of 9.4% on 2WikiMultihop and 9.5% on
BlendQA. We release our code and datasets.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.16313v1' target='_blank'>CATP-LLM: Empowering Large Language Models for Cost-Aware Tool Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Duo Wu, Jinghe Wang, Yuan Meng, Yanning Zhang, Le Sun, Zhi Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-25 12:05:49</h6>
<p class='card-text'>Utilizing large language models (LLMs) for tool planning has emerged as a
promising avenue for developing general AI systems, where LLMs automatically
schedule external tools (e.g. vision models) to tackle complex tasks based on
task descriptions. To push this paradigm toward practical applications, it is
crucial for LLMs to consider tool execution costs (e.g. execution time) for
tool planning. Unfortunately, prior studies overlook the tool execution costs,
leading to the generation of expensive plans of which the costs outweigh task
performance. To fill this gap, we propose the Cost-Aware Tool Planning with
LLMs (CATP-LLM) framework, which for the first time provides a coherent design
to empower LLMs for cost-aware tool planning. Specifically, CATP-LLM
incorporates a tool planning language to enhance the LLM to generate
non-sequential plans of multiple branches for efficient concurrent tool
execution and cost reduction. Moreover, it further designs a cost-aware offline
reinforcement learning algorithm to fine-tune the LLM to optimize the
performance-cost trade-off in tool planning. In lack of public cost-related
datasets, we further present OpenCATP, the first platform for cost-aware
planning evaluation. Experiments on OpenCATP show that CATP-LLM outperforms
GPT-4 even when using Llama2-7B as its backbone, with the average improvement
of 28.2%-30.2% higher plan performance and 24.7%-45.8% lower costs even on the
challenging planning tasks. The codes of CATP-LLM and OpenCATP will be publicly
available.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.16116v1' target='_blank'>LLM Augmentations to support Analytical Reasoning over Multiple
  Documents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Raquib Bin Yousuf, Nicholas Defelice, Mandar Sharma, Shengzhe Xu, Naren Ramakrishnan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-25 06:00:42</h6>
<p class='card-text'>Building on their demonstrated ability to perform a variety of tasks, we
investigate the application of large language models (LLMs) to enhance in-depth
analytical reasoning within the context of intelligence analysis. Intelligence
analysts typically work with massive dossiers to draw connections between
seemingly unrelated entities, and uncover adversaries' plans and motives. We
explore if and how LLMs can be helpful to analysts for this task and develop an
architecture to augment the capabilities of an LLM with a memory module called
dynamic evidence trees (DETs) to develop and track multiple investigation
threads. Through extensive experiments on multiple datasets, we highlight how
LLMs, as-is, are still inadequate to support intelligence analysts and offer
recommendations to improve LLMs for such intricate reasoning applications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.15998v1' target='_blank'>PIANIST: Learning Partially Observable World Models with LLMs for
  Multi-Agent Decision Making</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jonathan Light, Sixue Xing, Yuanzhe Liu, Weiqin Chen, Min Cai, Xiusi Chen, Guanzhi Wang, Wei Cheng, Yisong Yue, Ziniu Hu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-24 22:36:34</h6>
<p class='card-text'>Effective extraction of the world knowledge in LLMs for complex
decision-making tasks remains a challenge. We propose a framework PIANIST for
decomposing the world model into seven intuitive components conducive to
zero-shot LLM generation. Given only the natural language description of the
game and how input observations are formatted, our method can generate a
working world model for fast and efficient MCTS simulation. We show that our
method works well on two different games that challenge the planning and
decision making skills of the agent for both language and non-language based
action taking, without any training on domain-specific training data or
explicitly defined world model.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.15871v1' target='_blank'>Hiding Communication Cost in Distributed LLM Training via Micro-batch
  Co-execution</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Haiquan Wang, Chaoyi Ruan, Jia He, Jiaqi Ruan, Chengjie Tang, Xiaosong Ma, Cheng Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-24 15:15:46</h6>
<p class='card-text'>The growth of Large Language Models (LLMs) has necessitated large-scale
distributed training. Highly optimized frameworks, however, still suffer
significant losses in Model FLOPS utilization (often below 50%) due to large
communication volumes. Meanwhile, our comprehensive profiling shows that the
computation- and communication-intensive operators overlap well.
  This paper introduces DHelix, a novel micro-structure that dramatically
improves the efficiency of LLM training inspired by the DNA structure. Central
to DHelix's design is Strand Interleaving (SI), which views the continuous
stream of training micro-batches through a GPU as two strands. DHelix
juxtaposes the forward and backward passes of the two strands and performs a
systematic optimization for an SI plan that co-schedules the operators from the
opposite strands, enabled by operator-level overlap profiling results and a
dynamic-programming based search algorithm. Meanwhile, DHelix enables the two
strands to share model states and space for activation data, effectively
accommodating two micro-batches with under 3% extra memory space. Dhelix
seamlessly integrates with all forms of existing data/model parallelism, the
most challenging being pipeline parallelism, thanks to its unique model folding
design that results in a W-shaped pipeline.
  We evaluate DHelix training with the popular Llama and GPT dense models, plus
the Phi Mixture of Expert (MoE) model, across 3 GPU clusters (A40, A800, and
H100). Results show that it achieves 12-40% (up to 58% MFU) and 2-29% (up to
71% MFU) improvement on the 64-A40 and 64-A800 clusters, respectively,
significantly outperforming state-of-the-art methods. On the H100 cluster,
though the faster network reduces DHelix's profit margin, it makes cross-node
tensor parallelism promising, a practice currently prohibitive due to
communication costs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.15758v1' target='_blank'>Decoding Urban Industrial Complexity: Enhancing Knowledge-Driven
  Insights via IndustryScopeGPT</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Siqi Wang, Chao Liang, Yunfan Gao, Yang Liu, Jing Li, Haofen Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-24 08:33:19</h6>
<p class='card-text'>Industrial parks are critical to urban economic growth. Yet, their
development often encounters challenges stemming from imbalances between
industrial requirements and urban services, underscoring the need for strategic
planning and operations. This paper introduces IndustryScopeKG, a pioneering
large-scale multi-modal, multi-level industrial park knowledge graph, which
integrates diverse urban data including street views, corporate,
socio-economic, and geospatial information, capturing the complex relationships
and semantics within industrial parks. Alongside this, we present the
IndustryScopeGPT framework, which leverages Large Language Models (LLMs) with
Monte Carlo Tree Search to enhance tool-augmented reasoning and decision-making
in Industrial Park Planning and Operation (IPPO). Our work significantly
improves site recommendation and functional planning, demonstrating the
potential of combining LLMs with structured datasets to advance industrial park
management. This approach sets a new benchmark for intelligent IPPO research
and lays a robust foundation for advancing urban industrial development. The
dataset and related code are available at
https://github.com/Tongji-KGLLM/IndustryScope.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.16723v1' target='_blank'>Two Heads Are Better Than One: Collaborative LLM Embodied Agents for
  Human-Robot Interaction</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mitchell Rosser, Marc. G Carmichael</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-23 02:47:12</h6>
<p class='card-text'>With the recent development of natural language generation models - termed as
large language models (LLMs) - a potential use case has opened up to improve
the way that humans interact with robot assistants. These LLMs should be able
to leverage their large breadth of understanding to interpret natural language
commands into effective, task appropriate and safe robot task executions.
However, in reality, these models suffer from hallucinations, which may cause
safety issues or deviations from the task. In other domains, these issues have
been improved through the use of collaborative AI systems where multiple LLM
agents can work together to collectively plan, code and self-check outputs. In
this research, multiple collaborative AI systems were tested against a single
independent AI agent to determine whether the success in other domains would
translate into improved human-robot interaction performance. The results show
that there is no defined trend between the number of agents and the success of
the model. However, it is clear that some collaborative AI agent architectures
can exhibit a greatly improved capacity to produce error-free code and to solve
abstract problems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.15356v2' target='_blank'>Regulator-Manufacturer AI Agents Modeling: Mathematical Feedback-Driven
  Multi-Agent LLM Framework</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yu Han, Zekun Guo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-22 22:02:56</h6>
<p class='card-text'>The increasing complexity of regulatory updates from global authorities
presents significant challenges for medical device manufacturers, necessitating
agile strategies to sustain compliance and maintain market access.
Concurrently, regulatory bodies must effectively monitor manufacturers'
responses and develop strategic surveillance plans. This study employs a
multi-agent modeling approach, enhanced with Large Language Models (LLMs), to
simulate regulatory dynamics and examine the adaptive behaviors of key actors,
including regulatory bodies, manufacturers, and competitors. These agents
operate within a simulated environment governed by regulatory flow theory,
capturing the impacts of regulatory changes on compliance decisions, market
adaptation, and innovation strategies. Our findings illuminate the influence of
regulatory shifts on industry behaviour and identify strategic opportunities
for improving regulatory practices, optimizing compliance, and fostering
innovation. By leveraging the integration of multi-agent systems and LLMs, this
research provides a novel perspective and offers actionable insights for
stakeholders navigating the evolving regulatory landscape of the medical device
industry.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.15033v1' target='_blank'>One to rule them all: natural language to bind communication, perception
  and action</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Simone Colombani, Dimitri Ognibene, Giuseppe Boccignone</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-22 16:05:54</h6>
<p class='card-text'>In recent years, research in the area of human-robot interaction has focused
on developing robots capable of understanding complex human instructions and
performing tasks in dynamic and diverse environments. These systems have a wide
range of applications, from personal assistance to industrial robotics,
emphasizing the importance of robots interacting flexibly, naturally and safely
with humans. This paper presents an advanced architecture for robotic action
planning that integrates communication, perception, and planning with Large
Language Models (LLMs). Our system is designed to translate commands expressed
in natural language into executable robot actions, incorporating environmental
information and dynamically updating plans based on real-time feedback. The
Planner Module is the core of the system where LLMs embedded in a modified
ReAct framework are employed to interpret and carry out user commands. By
leveraging their extensive pre-trained knowledge, LLMs can effectively process
user requests without the need to introduce new knowledge on the changing
environment. The modified ReAct framework further enhances the execution space
by providing real-time environmental perception and the outcomes of physical
actions. By combining robust and dynamic semantic map representations as graphs
with control components and failure explanations, this architecture enhances a
robot adaptability, task execution, and seamless collaboration with human users
in shared and dynamic environments. Through the integration of continuous
feedback loops with the environment the system can dynamically adjusts the plan
to accommodate unexpected changes, optimizing the robot ability to perform
tasks. Using a dataset of previous experience is possible to provide detailed
feedback about the failure. Updating the LLMs context of the next iteration
with suggestion on how to overcame the issue.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.15027v1' target='_blank'>Time is on my sight: scene graph filtering for dynamic environment
  perception in an LLM-driven robot</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Simone Colombani, Luca Brini, Dimitri Ognibene, Giuseppe Boccignone</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-22 15:58:26</h6>
<p class='card-text'>Robots are increasingly being used in dynamic environments like workplaces,
hospitals, and homes. As a result, interactions with robots must be simple and
intuitive, with robots perception adapting efficiently to human-induced
changes. This paper presents a robot control architecture that addresses key
challenges in human-robot interaction, with a particular focus on the dynamic
creation and continuous update of the robot state representation. The
architecture uses Large Language Models to integrate diverse information
sources, including natural language commands, robotic skills representation,
real-time dynamic semantic mapping of the perceived scene. This enables
flexible and adaptive robotic behavior in complex, dynamic environments.
Traditional robotic systems often rely on static, pre-programmed instructions
and settings, limiting their adaptability to dynamic environments and real-time
collaboration. In contrast, this architecture uses LLMs to interpret complex,
high-level instructions and generate actionable plans that enhance human-robot
collaboration. At its core, the system Perception Module generates and
continuously updates a semantic scene graph using RGB-D sensor data, providing
a detailed and structured representation of the environment. A particle filter
is employed to ensure accurate object localization in dynamic, real-world
settings. The Planner Module leverages this up-to-date semantic map to break
down high-level tasks into sub-tasks and link them to robotic skills such as
navigation, object manipulation (e.g., PICK and PLACE), and movement (e.g.,
GOTO). By combining real-time perception, state tracking, and LLM-driven
communication and task planning, the architecture enhances adaptability, task
efficiency, and human-robot collaboration in dynamic environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.15004v2' target='_blank'>ScribeAgent: Towards Specialized Web Agents Using Production-Scale
  Workflow Data</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Junhong Shen, Atishay Jain, Zedian Xiao, Ishan Amlekar, Mouad Hadji, Aaron Podolny, Ameet Talwalkar</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-22 15:26:23</h6>
<p class='card-text'>Large Language Model (LLM) agents are rapidly improving to handle
increasingly complex web-based tasks. Most of these agents rely on
general-purpose, proprietary models like GPT-4 and focus on designing better
prompts to improve their planning abilities. However, general-purpose LLMs are
not specifically trained to understand specialized web contexts such as HTML,
and they often struggle with long-horizon planning. We explore an alternative
approach that fine-tunes open-source LLMs using production-scale workflow data
collected from over 250 domains corresponding to 6 billion tokens. This simple
yet effective approach shows substantial gains over prompting-based agents on
existing benchmarks -- ScribeAgent achieves state-of-the-art direct generation
performance on Mind2Web and improves the task success rate by 7.3% over the
previous best text-only web agents on WebArena. We further perform detailed
ablation studies on various fine-tuning design choices and provide insights
into LLM selection, training recipes, context window optimization, and effect
of dataset sizes.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.14917v1' target='_blank'>Task-Aware Robotic Grasping by evaluating Quality Diversity Solutions
  through Foundation Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Aurel X. Appius, Emiland Garrabe, Francois Helenon, Mahdi Khoramshahi, Stephane Doncieux</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-22 13:18:41</h6>
<p class='card-text'>Task-aware robotic grasping is a challenging problem that requires the
integration of semantic understanding and geometric reasoning. Traditional
grasp planning approaches focus on stable or feasible grasps, often
disregarding the specific tasks the robot needs to accomplish. This paper
proposes a novel framework that leverages Large Language Models (LLMs) and
Quality Diversity (QD) algorithms to enable zero-shot task-conditioned grasp
selection. The framework segments objects into meaningful subparts and labels
each subpart semantically, creating structured representations that can be used
to prompt an LLM. By coupling semantic and geometric representations of an
object's structure, the LLM's knowledge about tasks and which parts to grasp
can be applied in the physical world. The QD-generated grasp archive provides a
diverse set of grasps, allowing us to select the most suitable grasp based on
the task. We evaluate the proposed method on a subset of the YCB dataset, where
a Franka Emika robot is assigned to perform various actions based on
object-specific task requirements. We created a ground truth by conducting a
survey with six participants to determine the best grasp region for each
task-object combination according to human intuition. The model was evaluated
on 12 different objects across 4--7 object-specific tasks, achieving a weighted
intersection over union (IoU) of 76.4% when compared to the survey data.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.14503v2' target='_blank'>Planning-Driven Programming: A Large Language Model Programming Workflow</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chao Lei, Yanchuan Chang, Nir Lipovetzky, Krista A. Ehinger</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-21 08:31:06</h6>
<p class='card-text'>The strong performance of large language models (LLMs) raises extensive
discussion on their application to code generation. Recent research suggests
continuous program refinements through visible tests to improve code generation
accuracy in LLMs. However, these methods suffer from LLMs' inefficiency and
limited reasoning capacity. In this work, we propose an LLM programming
workflow (LPW) designed to improve both initial code generation and subsequent
refinements within a structured two-phase workflow. Specifically, the solution
generation phase formulates a solution plan, which is then verified through
visible tests to specify the intended natural language solution. Subsequently,
the code implementation phase drafts an initial code according to the solution
plan and its verification. If the generated code fails the visible tests, the
plan verification serves as the intended solution to consistently inform the
refinement process for correcting bugs. Compared to state-of-the-art methods
across various existing LLMs, LPW significantly improves the Pass@1 accuracy by
up to 16.4% on well-established text-to-code generation benchmarks. LPW also
sets new state-of-the-art Pass@1 accuracy, achieving 98.2% on HumanEval, 84.8%
on MBPP, 59.3% on LiveCode, 62.6% on APPS, and 34.7% on CodeContest, using
GPT-4o as the backbone.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.13904v1' target='_blank'>Towards Full Delegation: Designing Ideal Agentic Behaviors for Travel
  Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Song Jiang, Da JU, Andrew Cohen, Sasha Mitts, Aaron Foss, Justine T Kao, Xian Li, Yuandong Tian</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-21 07:30:02</h6>
<p class='card-text'>How are LLM-based agents used in the future? While many of the existing work
on agents has focused on improving the performance of a specific family of
objective and challenging tasks, in this work, we take a different perspective
by thinking about full delegation: agents take over humans' routine
decision-making processes and are trusted by humans to find solutions that fit
people's personalized needs and are adaptive to ever-changing context. In order
to achieve such a goal, the behavior of the agents, i.e., agentic behaviors,
should be evaluated not only on their achievements (i.e., outcome evaluation),
but also how they achieved that (i.e., procedure evaluation). For this, we
propose APEC Agent Constitution, a list of criteria that an agent should follow
for good agentic behaviors, including Accuracy, Proactivity, Efficiency and
Credibility. To verify whether APEC aligns with human preferences, we develop
APEC-Travel, a travel planning agent that proactively extracts hidden
personalized needs via multi-round dialog with travelers. APEC-Travel is
constructed purely from synthetic data generated by Llama3.1-405B-Instruct with
a diverse set of travelers' persona to simulate rich distribution of dialogs.
Iteratively fine-tuned to follow APEC Agent Constitution, APEC-Travel surpasses
baselines by 20.7% on rule-based metrics and 9.1% on LLM-as-a-Judge scores
across the constitution axes.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.13826v1' target='_blank'>Interactive and Expressive Code-Augmented Planning with Large Language
  Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Anthony Z. Liu, Xinhe Wang, Jacob Sansom, Yao Fu, Jongwook Choi, Sungryull Sohn, Jaekyeom Kim, Honglak Lee</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-21 04:23:17</h6>
<p class='card-text'>Large Language Models (LLMs) demonstrate strong abilities in common-sense
reasoning and interactive decision-making, but often struggle with complex,
long-horizon planning tasks. Recent techniques have sought to structure LLM
outputs using control flow and other code-adjacent techniques to improve
planning performance. These techniques include using variables (to track
important information) and functions (to divide complex tasks into smaller
re-usable sub-tasks). However, purely code-based approaches can be error-prone
and insufficient for handling ambiguous or unstructured data. To address these
challenges, we propose REPL-Plan, an LLM planning approach that is fully
code-expressive (it can utilize all the benefits of code) while also being
dynamic (it can flexibly adapt from errors and use the LLM for fuzzy
situations). In REPL-Plan, an LLM solves tasks by interacting with a
Read-Eval-Print Loop (REPL), which iteratively executes and evaluates code,
similar to language shells or interactive code notebooks, allowing the model to
flexibly correct errors and handle tasks dynamically. We demonstrate that
REPL-Plan achieves strong results across various planning domains compared to
previous methods.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.13779v1' target='_blank'>NewsInterview: a Dataset and a Playground to Evaluate LLMs' Ground Gap
  via Informational Interviews</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Michael Lu, Hyundong Justin Cho, Weiyan Shi, Jonathan May, Alexander Spangher</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-21 01:37:38</h6>
<p class='card-text'>Large Language Models (LLMs) have demonstrated impressive capabilities in
generating coherent text but often struggle with grounding language and
strategic dialogue. To address this gap, we focus on journalistic interviews, a
domain rich in grounding communication and abundant in data. We curate a
dataset of 40,000 two-person informational interviews from NPR and CNN, and
reveal that LLMs are significantly less likely than human interviewers to use
acknowledgements and to pivot to higher-level questions. Realizing that a
fundamental deficit exists in multi-turn planning and strategic thinking, we
develop a realistic simulated environment, incorporating source personas and
persuasive elements, in order to facilitate the development of agents with
longer-horizon rewards. Our experiments show that while source LLMs mimic human
behavior in information sharing, interviewer LLMs struggle with recognizing
when questions are answered and engaging persuasively, leading to suboptimal
information extraction across model size and capability. These findings
underscore the need for enhancing LLMs' strategic dialogue capabilities.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.13724v1' target='_blank'>Exploring Large Language Models for Climate Forecasting</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yang Wang, Hassan A. Karimi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-20 21:58:19</h6>
<p class='card-text'>With the increasing impacts of climate change, there is a growing demand for
accessible tools that can provide reliable future climate information to
support planning, finance, and other decision-making applications. Large
language models (LLMs), such as GPT-4, present a promising approach to bridging
the gap between complex climate data and the general public, offering a way for
non-specialist users to obtain essential climate insights through natural
language interaction. However, an essential challenge remains under-explored:
evaluating the ability of LLMs to provide accurate and reliable future climate
predictions, which is crucial for applications that rely on anticipating
climate trends. In this study, we investigate the capability of GPT-4 in
predicting rainfall at short-term (15-day) and long-term (12-month) scales. We
designed a series of experiments to assess GPT's performance under different
conditions, including scenarios with and without expert data inputs. Our
results indicate that GPT, when operating independently, tends to generate
conservative forecasts, often reverting to historical averages in the absence
of clear trend signals. This study highlights both the potential and challenges
of applying LLMs for future climate predictions, providing insights into their
integration with climate-related applications and suggesting directions for
enhancing their predictive capabilities in the field.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.13543v1' target='_blank'>BALROG: Benchmarking Agentic LLM and VLM Reasoning On Games</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Davide Paglieri, Bartłomiej Cupiał, Samuel Coward, Ulyana Piterbarg, Maciej Wolczyk, Akbir Khan, Eduardo Pignatelli, Łukasz Kuciński, Lerrel Pinto, Rob Fergus, Jakob Nicolaus Foerster, Jack Parker-Holder, Tim Rocktäschel</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-20 18:54:32</h6>
<p class='card-text'>Large Language Models (LLMs) and Vision Language Models (VLMs) possess
extensive knowledge and exhibit promising reasoning abilities; however, they
still struggle to perform well in complex, dynamic environments. Real-world
tasks require handling intricate interactions, advanced spatial reasoning,
long-term planning, and continuous exploration of new strategies-areas in which
we lack effective methodologies for comprehensively evaluating these
capabilities. To address this gap, we introduce BALROG, a novel benchmark
designed to assess the agentic capabilities of LLMs and VLMs through a diverse
set of challenging games. Our benchmark incorporates a range of existing
reinforcement learning environments with varying levels of difficulty,
including tasks that are solvable by non-expert humans in seconds to extremely
challenging ones that may take years to master (e.g., the NetHack Learning
Environment). We devise fine-grained metrics to measure performance and conduct
an extensive evaluation of several popular open-source and closed-source LLMs
and VLMs. Our findings indicate that while current models achieve partial
success in the easier games, they struggle significantly with more challenging
tasks. Notably, we observe severe deficiencies in vision-based decision-making,
as models perform worse when visual representations of the environments are
provided. We release BALROG as an open and user-friendly benchmark to
facilitate future research and development in the agentic community.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.14484v1' target='_blank'>Robust Planning with Compound LLM Architectures: An LLM-Modulo Approach</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Atharva Gundawar, Karthik Valmeekam, Mudit Verma, Subbarao Kambhampati</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-20 02:04:09</h6>
<p class='card-text'>Previous work has attempted to boost Large Language Model (LLM) performance
on planning and scheduling tasks through a variety of prompt engineering
techniques. While these methods can work within the distributions tested, they
are neither robust nor predictable. This limitation can be addressed through
compound LLM architectures where LLMs work in conjunction with other components
to ensure reliability. In this paper, we present a technical evaluation of a
compound LLM architecture--the LLM-Modulo framework. In this framework, an LLM
is paired with a complete set of sound verifiers that validate its output,
re-prompting it if it fails. This approach ensures that the system can never
output any fallacious output, and therefore that every output generated is
guaranteed correct--something previous techniques have not been able to claim.
Our results, evaluated across four scheduling domains, demonstrate significant
performance gains with the LLM-Modulo framework using various models.
Additionally, we explore modifications to the base configuration of the
framework and assess their impact on overall system performance.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.12924v2' target='_blank'>Human-In-the-Loop Software Development Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wannita Takerngsaksiri, Jirat Pasuksmit, Patanamon Thongtanunam, Chakkrit Tantithamthavorn, Ruixiong Zhang, Fan Jiang, Jing Li, Evan Cook, Kun Chen, Ming Wu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-19 23:22:33</h6>
<p class='card-text'>Recently, Large Language Models (LLMs)-based multi-agent paradigms for
software engineering are introduced to automatically resolve software
development tasks (e.g., from a given issue to source code). However, existing
work is evaluated based on historical benchmark datasets, rarely considers
human feedback at each stage of the automated software development process, and
has not been deployed in practice. In this paper, we introduce a
Human-in-the-loop LLM-based Agents framework (HULA) for software development
that allows software engineers to refine and guide LLMs when generating coding
plans and source code for a given task. We design, implement, and deploy the
HULA framework into Atlassian JIRA for internal uses. Through a multi-stage
evaluation of the HULA framework, Atlassian software engineers perceive that
HULA can minimize the overall development time and effort, especially in
initiating a coding plan and writing code for straightforward tasks. On the
other hand, challenges around code quality remain a concern in some cases. We
draw lessons learned and discuss opportunities for future work, which will pave
the way for the advancement of LLM-based agents in software development.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.12279v3' target='_blank'>HouseLLM: LLM-Assisted Two-Phase Text-to-Floorplan Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ziyang Zong, Zhaohuan Zhan, Guang Tan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-19 06:57:45</h6>
<p class='card-text'>This paper proposes a two-phase text-to-floorplan generation method, which
guides a Large Language Model (LLM) to generate an initial layout (Layout-LLM)
and refines them into the final floorplans through conditional diffusion model.
We incorporate a Chain-of-Thought approach to prompt the LLM based on user text
specifications, enabling a more user-friendly and intuitive house layout
design. This method allows users to describe their needs in natural language,
enhancing accessibility and providing clearer geometric constraints. The final
floorplans generated by Layout-LLM through conditional diffusion refinement are
more accurate and better meet user requirements. Experimental results
demonstrate that our approach achieves state-of-the-art performance across all
metrics, validating its effectiveness in practical home design applications. We
plan to release our code for public use.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.11844v2' target='_blank'>Generative World Explorer</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Taiming Lu, Tianmin Shu, Alan Yuille, Daniel Khashabi, Jieneng Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-18 18:59:31</h6>
<p class='card-text'>Planning with partial observation is a central challenge in embodied AI. A
majority of prior works have tackled this challenge by developing agents that
physically explore their environment to update their beliefs about the world
state. In contrast, humans can $\textit{imagine}$ unseen parts of the world
through a mental exploration and $\textit{revise}$ their beliefs with imagined
observations. Such updated beliefs can allow them to make more informed
decisions, without necessitating the physical exploration of the world at all
times. To achieve this human-like ability, we introduce the $\textit{Generative
World Explorer (Genex)}$, an egocentric world exploration framework that allows
an agent to mentally explore a large-scale 3D world (e.g., urban scenes) and
acquire imagined observations to update its belief. This updated belief will
then help the agent to make a more informed decision at the current step. To
train $\textit{Genex}$, we create a synthetic urban scene dataset, Genex-DB.
Our experimental results demonstrate that (1) $\textit{Genex}$ can generate
high-quality and consistent observations during long-horizon exploration of a
large virtual physical world and (2) the beliefs updated with the generated
observations can inform an existing decision-making model (e.g., an LLM agent)
to make better plans.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.11714v1' target='_blank'>Semantic-Geometric-Physical-Driven Robot Manipulation Skill Transfer via
  Skill Library and Tactile Representation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mingchao Qi, Yuanjin Li, Xing Liu, Zhengxiong Liu, Panfeng Huang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-18 16:42:07</h6>
<p class='card-text'>Deploying robots in open-world environments involves complex tasks
characterized by long sequences and rich interactions, necessitating efficient
transfer of robotic skills across diverse and complex scenarios. To address
this challenge, we propose a skill library framework based on knowledge graphs,
which endows robots with high-level skill awareness and spatial semantic
understanding. The framework hierarchically organizes operational knowledge by
constructing a "task graph" and a "scene graph" to represent task and scene
semantic information, respectively. We introduce a "state graph" to facilitate
interaction between high-level task planning and low-level scene information.
Furthermore, we propose a hierarchical transfer framework for operational
skills. At the task level, the framework integrates contextual learning and
chain-of-thought prompting within a four-stage prompt paradigm, leveraging
large language models' (LLMs) reasoning and generalization capabilities to
achieve task-level subtask sequence transfer. At the motion level, an adaptive
trajectory transfer method is developed using the A* algorithm and the skill
library, enabling motion-level adaptive trajectory transfer. At the physical
level, we introduce an adaptive contour extraction and posture perception
method based on tactile perception. This method dynamically obtains
high-precision contour and posture information from visual-tactile texture data
and adjusts transferred skills, such as contact positions and postures, to
ensure effectiveness in new environments. Experimental results validate the
effectiveness of the proposed methods. Project
website:https://github.com/MingchaoQi/skill_transfer</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.11323v1' target='_blank'>SayComply: Grounding Field Robotic Tasks in Operational Compliance
  through Retrieval-Based Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Muhammad Fadhil Ginting, Dong-Ki Kim, Sung-Kyun Kim, Bandi Jai Krishna, Mykel J. Kochenderfer, Shayegan Omidshafiei, Ali-akbar Agha-mohammadi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-18 06:33:05</h6>
<p class='card-text'>This paper addresses the problem of task planning for robots that must comply
with operational manuals in real-world settings. Task planning under these
constraints is essential for enabling autonomous robot operation in domains
that require adherence to domain-specific knowledge. Current methods for
generating robot goals and plans rely on common sense knowledge encoded in
large language models. However, these models lack grounding of robot plans to
domain-specific knowledge and are not easily transferable between multiple
sites or customers with different compliance needs. In this work, we present
SayComply, which enables grounding robotic task planning with operational
compliance using retrieval-based language models. We design a hierarchical
database of operational, environment, and robot embodiment manuals and
procedures to enable efficient retrieval of the relevant context under the
limited context length of the LLMs. We then design a task planner using a
tree-based retrieval augmented generation (RAG) technique to generate robot
tasks that follow user instructions while simultaneously complying with the
domain knowledge in the database. We demonstrate the benefits of our approach
through simulations and hardware experiments in real-world scenarios that
require precise context retrieval across various types of context,
outperforming the standard RAG method. Our approach bridges the gap in
deploying robots that consistently adhere to operational protocols, offering a
scalable and edge-deployable solution for ensuring compliance across varied and
complex real-world environments. Project website: saycomply.github.io.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.10446v2' target='_blank'>VeriGraph: Scene Graphs for Execution Verifiable Robot Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Daniel Ekpo, Mara Levy, Saksham Suri, Chuong Huynh, Abhinav Shrivastava</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-15 18:59:51</h6>
<p class='card-text'>Recent advancements in vision-language models (VLMs) offer potential for
robot task planning, but challenges remain due to VLMs' tendency to generate
incorrect action sequences. To address these limitations, we propose VeriGraph,
a novel framework that integrates VLMs for robotic planning while verifying
action feasibility. VeriGraph employs scene graphs as an intermediate
representation, capturing key objects and spatial relationships to improve plan
verification and refinement. The system generates a scene graph from input
images and uses it to iteratively check and correct action sequences generated
by an LLM-based task planner, ensuring constraints are respected and actions
are executable. Our approach significantly enhances task completion rates
across diverse manipulation scenarios, outperforming baseline methods by 58%
for language-based tasks and 30% for image-based tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.10184v1' target='_blank'>Agentic LLMs in the Supply Chain: Towards Autonomous Multi-Agent
  Consensus-Seeking</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Valeria Jannelli, Stefan Schoepf, Matthias Bickel, Torbjørn Netland, Alexandra Brintrup</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-15 13:33:10</h6>
<p class='card-text'>This paper explores how Large Language Models (LLMs) can automate
consensus-seeking in supply chain management (SCM), where frequent decisions on
problems such as inventory levels and delivery times require coordination among
companies. Traditional SCM relies on human consensus in decision-making to
avoid emergent problems like the bullwhip effect. Some routine consensus
processes, especially those that are time-intensive and costly, can be
automated. Existing solutions for automated coordination have faced challenges
due to high entry barriers locking out SMEs, limited capabilities, and limited
adaptability in complex scenarios. However, recent advances in Generative AI,
particularly LLMs, show promise in overcoming these barriers. LLMs, trained on
vast datasets can negotiate, reason, and plan, facilitating near-human-level
consensus at scale with minimal entry barriers. In this work, we identify key
limitations in existing approaches and propose autonomous LLM agents to address
these gaps. We introduce a series of novel, supply chain-specific
consensus-seeking frameworks tailored for LLM agents and validate the
effectiveness of our approach through a case study in inventory management. To
accelerate progress within the SCM community, we open-source our code,
providing a foundation for further advancements in LLM-powered autonomous
supply chain solutions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.09823v1' target='_blank'>Architect: Generating Vivid and Interactive 3D Scenes with Hierarchical
  2D Inpainting</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yian Wang, Xiaowen Qiu, Jiageng Liu, Zhehuan Chen, Jiting Cai, Yufei Wang, Tsun-Hsuan Wang, Zhou Xian, Chuang Gan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-14 22:15:48</h6>
<p class='card-text'>Creating large-scale interactive 3D environments is essential for the
development of Robotics and Embodied AI research. Current methods, including
manual design, procedural generation, diffusion-based scene generation, and
large language model (LLM) guided scene design, are hindered by limitations
such as excessive human effort, reliance on predefined rules or training
datasets, and limited 3D spatial reasoning ability. Since pre-trained 2D image
generative models better capture scene and object configuration than LLMs, we
address these challenges by introducing Architect, a generative framework that
creates complex and realistic 3D embodied environments leveraging
diffusion-based 2D image inpainting. In detail, we utilize foundation visual
perception models to obtain each generated object from the image and leverage
pre-trained depth estimation models to lift the generated 2D image to 3D space.
Our pipeline is further extended to a hierarchical and iterative inpainting
process to continuously generate placement of large furniture and small objects
to enrich the scene. This iterative structure brings the flexibility for our
method to generate or refine scenes from various starting points, such as text,
floor plans, or pre-arranged environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.08794v1' target='_blank'>Evaluating World Models with LLM for Decision Making</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chang Yang, Xinrun Wang, Junzhe Jiang, Qinggang Zhang, Xiao Huang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-13 17:19:32</h6>
<p class='card-text'>World model emerges as a key module in decision making, where MuZero and
Dreamer achieve remarkable successes in complex tasks. Recent work leverages
Large Language Models (LLMs) as general world simulators to simulate the
dynamics of the world due to their generalizability. LLMs also serve as the
world model for deliberative reasoning in Reasoning via Planning (RAP) and Tree
of Thought (ToT). However, the world models are either evaluated as a general
world simulator, or as a functional module of the agent, i.e., predicting the
transitions to assist the planning. In this work, we propose a comprehensive
evaluation of the world models with LLMs from the decision making perspective.
Specifically, we leverage the 31 diverse environments from (Wang et al.,
2023;2024) and curate the rule-based policy of each environment for the diverse
evaluation. Then, we design three main tasks, i.e., policy verification, action
proposal, and policy planning, where the world models can be used for decision
making solely. Finally, we conduct the comprehensive evaluation of the advanced
LLMs, i.e., GPT-4o and GPT-4o-mini, on the environments for the three main
tasks under various settings. The key observations include: i) GPT-4o
significantly outperforms GPT-4o-mini on the three main tasks, especially for
the tasks which require the domain knowledge, ii) the performance of the world
model with LLM will be decreased for long-term decision-making tasks, and iii)
the combination of different functionalities of the world model will brings
additional unstabilities of the performance.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.07690v1' target='_blank'>World Models: The Safety Perspective</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zifan Zeng, Chongzhe Zhang, Feng Liu, Joseph Sifakis, Qunli Zhang, Shiming Liu, Peng Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-12 10:15:11</h6>
<p class='card-text'>With the proliferation of the Large Language Model (LLM), the concept of
World Models (WM) has recently attracted a great deal of attention in the AI
research community, especially in the context of AI agents. It is arguably
evolving into an essential foundation for building AI agent systems. A WM is
intended to help the agent predict the future evolution of environmental states
or help the agent fill in missing information so that it can plan its actions
and behave safely. The safety property of WM plays a key role in their
effective use in critical applications. In this work, we review and analyze the
impacts of the current state-of-the-art in WM technology from the point of view
of trustworthiness and safety based on a comprehensive survey and the fields of
application envisaged. We provide an in-depth analysis of state-of-the-art WMs
and derive technical research challenges and their impact in order to call on
the research community to collaborate on improving the safety and
trustworthiness of WM.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.07464v2' target='_blank'>BudgetMLAgent: A Cost-Effective LLM Multi-Agent system for Automating
  Machine Learning Tasks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shubham Gandhi, Manasi Patwardhan, Lovekesh Vig, Gautam Shroff</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-12 00:57:30</h6>
<p class='card-text'>Large Language Models (LLMs) excel in diverse applications including
generation of code snippets, but often struggle with generating code for
complex Machine Learning (ML) tasks. Although existing LLM single-agent based
systems give varying performance depending on the task complexity, they purely
rely on larger and expensive models such as GPT-4. Our investigation reveals
that no-cost and low-cost models such as Gemini-Pro, Mixtral and CodeLlama
perform far worse than GPT-4 in a single-agent setting. With the motivation of
developing a cost-efficient LLM based solution for solving ML tasks, we propose
an LLM Multi-Agent based system which leverages combination of experts using
profiling, efficient retrieval of past observations, LLM cascades, and
ask-the-expert calls. Through empirical analysis on ML engineering tasks in the
MLAgentBench benchmark, we demonstrate the effectiveness of our system, using
no-cost models, namely Gemini as the base LLM, paired with GPT-4 in cascade and
expert to serve occasional ask-the-expert calls for planning. With 94.2\%
reduction in the cost (from \$0.931 per run cost averaged over all tasks for
GPT-4 single agent system to \$0.054), our system is able to yield better
average success rate of 32.95\% as compared to GPT-4 single-agent system
yielding 22.72\% success rate averaged over all the tasks of MLAgentBench.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.06805v1' target='_blank'>AssistRAG: Boosting the Potential of Large Language Models with an
  Intelligent Information Assistant</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yujia Zhou, Zheng Liu, Zhicheng Dou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-11 09:03:52</h6>
<p class='card-text'>The emergence of Large Language Models (LLMs) has significantly advanced
natural language processing, but these models often generate factually
incorrect information, known as "hallucination". Initial retrieval-augmented
generation (RAG) methods like the "Retrieve-Read" framework was inadequate for
complex reasoning tasks. Subsequent prompt-based RAG strategies and Supervised
Fine-Tuning (SFT) methods improved performance but required frequent retraining
and risked altering foundational LLM capabilities. To cope with these
challenges, we propose Assistant-based Retrieval-Augmented Generation
(AssistRAG), integrating an intelligent information assistant within LLMs. This
assistant manages memory and knowledge through tool usage, action execution,
memory building, and plan specification. Using a two-phase training approach,
Curriculum Assistant Learning and Reinforced Preference Optimization. AssistRAG
enhances information retrieval and decision-making. Experiments show AssistRAG
significantly outperforms benchmarks, especially benefiting less advanced LLMs,
by providing superior reasoning capabilities and accurate responses.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.06559v1' target='_blank'>Is Your LLM Secretly a World Model of the Internet? Model-Based Planning
  for Web Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yu Gu, Boyuan Zheng, Boyu Gou, Kai Zhang, Cheng Chang, Sanjari Srivastava, Yanan Xie, Peng Qi, Huan Sun, Yu Su</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-10 18:50:51</h6>
<p class='card-text'>Language agents have demonstrated promising capabilities in automating
web-based tasks, though their current reactive approaches still underperform
largely compared to humans. While incorporating advanced planning algorithms,
particularly tree search methods, could enhance these agents' performance,
implementing tree search directly on live websites poses significant safety
risks and practical constraints due to irreversible actions such as confirming
a purchase. In this paper, we introduce a novel paradigm that augments language
agents with model-based planning, pioneering the innovative use of large
language models (LLMs) as world models in complex web environments. Our method,
WebDreamer, builds on the key insight that LLMs inherently encode comprehensive
knowledge about website structures and functionalities. Specifically,
WebDreamer uses LLMs to simulate outcomes for each candidate action (e.g.,
"what would happen if I click this button?") using natural language
descriptions, and then evaluates these imagined outcomes to determine the
optimal action at each step. Empirical results on two representative web agent
benchmarks with online interaction -- VisualWebArena and Mind2Web-live --
demonstrate that WebDreamer achieves substantial improvements over reactive
baselines. By establishing the viability of LLMs as world models in web
environments, this work lays the groundwork for a paradigm shift in automated
web interaction. More broadly, our findings open exciting new avenues for
future research into 1) optimizing LLMs specifically for world modeling in
complex, dynamic environments, and 2) model-based speculative planning for
language agents.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.05651v1' target='_blank'>LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning
  and Execution</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuheng Zhao, Junjie Wang, Linbin Xiang, Xiaowen Zhang, Zifei Guo, Cagatay Turkay, Yu Zhang, Siming Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-08 15:46:10</h6>
<p class='card-text'>Visual analytics (VA) requires analysts to iteratively propose analysis tasks
based on observations and execute tasks by creating visualizations and
interactive exploration to gain insights. This process demands skills in
programming, data processing, and visualization tools, highlighting the need
for a more intelligent, streamlined VA approach. Large language models (LLMs)
have recently been developed as agents to handle various tasks with dynamic
planning and tool-using capabilities, offering the potential to enhance the
efficiency and versatility of VA. We propose LightVA, a lightweight VA
framework that supports task decomposition, data analysis, and interactive
exploration through human-agent collaboration. Our method is designed to help
users progressively translate high-level analytical goals into low-level tasks,
producing visualizations and deriving insights. Specifically, we introduce an
LLM agent-based task planning and execution strategy, employing a recursive
process involving a planner, executor, and controller. The planner is
responsible for recommending and decomposing tasks, the executor handles task
execution, including data analysis, visualization generation and multi-view
composition, and the controller coordinates the interaction between the planner
and executor. Building on the framework, we develop a system with a hybrid user
interface that includes a task flow diagram for monitoring and managing the
task planning process, a visualization panel for interactive data exploration,
and a chat view for guiding the model through natural language instructions. We
examine the effectiveness of our method through a usage scenario and an expert
study.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.05892v1' target='_blank'>Identifying and Decomposing Compound Ingredients in Meal Plans Using
  Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Leon Kopitar, Leon Bedrac, Larissa J Strath, Jiang Bian, Gregor Stiglic</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-08 12:38:10</h6>
<p class='card-text'>This study explores the effectiveness of Large Language Models in meal
planning, focusing on their ability to identify and decompose compound
ingredients. We evaluated three models-GPT-4o, Llama-3 (70b), and Mixtral
(8x7b)-to assess their proficiency in recognizing and breaking down complex
ingredient combinations. Preliminary results indicate that while Llama-3 (70b)
and GPT-4o excels in accurate decomposition, all models encounter difficulties
with identifying essential elements like seasonings and oils. Despite strong
overall performance, variations in accuracy and completeness were observed
across models. These findings underscore LLMs' potential to enhance
personalized nutrition but highlight the need for further refinement in
ingredient decomposition. Future research should address these limitations to
improve nutritional recommendations and health outcomes.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.05474v1' target='_blank'>Enhancing Robustness in Language-Driven Robotics: A Modular Approach to
  Failure Reduction</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Émiland Garrabé, Pierre Teixeira, Mahdi Khoramshahi, Stéphane Doncieux</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-08 11:00:05</h6>
<p class='card-text'>Recent advances in large language models (LLMs) have led to significant
progress in robotics, enabling embodied agents to better understand and execute
open-ended tasks. However, existing approaches using LLMs face limitations in
grounding their outputs within the physical environment and aligning with the
capabilities of the robot. This challenge becomes even more pronounced with
smaller language models, which are more computationally efficient but less
robust in task planning and execution. In this paper, we present a novel
modular architecture designed to enhance the robustness of LLM-driven robotics
by addressing these grounding and alignment issues. We formalize the task
planning problem within a goal-conditioned POMDP framework, identify key
failure modes in LLM-driven planning, and propose targeted design principles to
mitigate these issues. Our architecture introduces an ``expected outcomes''
module to prevent mischaracterization of subgoals and a feedback mechanism to
enable real-time error recovery. Experimental results, both in simulation and
on physical robots, demonstrate that our approach significantly improves task
success rates for pick-and-place and manipulation tasks compared to both larger
LLMs and standard baselines. Through hardware experiments, we also demonstrate
how our architecture can be run efficiently and locally. This work highlights
the potential of smaller, locally-executable LLMs in robotics and provides a
scalable, efficient solution for robust task execution.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.05451v1' target='_blank'>WorkflowLLM: Enhancing Workflow Orchestration Capability of Large
  Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shengda Fan, Xin Cong, Yuepeng Fu, Zhong Zhang, Shuyan Zhang, Yuanwei Liu, Yesai Wu, Yankai Lin, Zhiyuan Liu, Maosong Sun</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-08 09:58:02</h6>
<p class='card-text'>Recent advancements in large language models (LLMs) have driven a
revolutionary paradigm shift in process automation from Robotic Process
Automation to Agentic Process Automation by automating the workflow
orchestration procedure based on LLMs. However, existing LLMs (even the
advanced OpenAI GPT-4o) are confined to achieving satisfactory capability in
workflow orchestration. To address this limitation, we present WorkflowLLM, a
data-centric framework elaborately designed to enhance the capability of LLMs
in workflow orchestration. It first constructs a large-scale fine-tuning
dataset WorkflowBench with 106,763 samples, covering 1,503 APIs from 83
applications across 28 categories. Specifically, the construction process can
be divided into three phases: (1) Data Collection: we collect real-world
workflow data from Apple Shortcuts and RoutineHub, transcribing them into
Python-style code. We further equip them with generated hierarchical thought
via ChatGPT. (2) Query Expansion: we prompt ChatGPT to generate more task
queries to enrich the diversity and complexity of workflows. (3) Workflow
Generation: we leverage an annotator model trained on collected data to
generate workflows for synthesized queries. Finally, we merge the synthetic
samples that pass quality confirmation with the collected samples to obtain the
WorkflowBench. Based on WorkflowBench, we fine-tune Llama-3.1-8B to obtain
WorkflowLlama. Our experiments show that WorkflowLlama demonstrates a strong
capacity to orchestrate complex workflows, while also achieving notable
generalization performance on previously unseen APIs. Additionally,
WorkflowBench exhibits robust zero-shot generalization capabilities on an
out-of-distribution task planning dataset, T-Eval. Our data and code are
available at https://github.com/OpenBMB/WorkflowLLM.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.05212v1' target='_blank'>RT-Grasp: Reasoning Tuning Robotic Grasping via Multi-modal Large
  Language Model</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jinxuan Xu, Shiyu Jin, Yutian Lei, Yuqian Zhang, Liangjun Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-07 22:17:53</h6>
<p class='card-text'>Recent advances in Large Language Models (LLMs) have showcased their
remarkable reasoning capabilities, making them influential across various
fields. However, in robotics, their use has primarily been limited to
manipulation planning tasks due to their inherent textual output. This paper
addresses this limitation by investigating the potential of adopting the
reasoning ability of LLMs for generating numerical predictions in robotics
tasks, specifically for robotic grasping. We propose Reasoning Tuning, a novel
method that integrates a reasoning phase before prediction during training,
leveraging the extensive prior knowledge and advanced reasoning abilities of
LLMs. This approach enables LLMs, notably with multi-modal capabilities, to
generate accurate numerical outputs like grasp poses that are context-aware and
adaptable through conversations. Additionally, we present the Reasoning Tuning
VLM Grasp dataset, carefully curated to facilitate the adaptation of LLMs to
robotic grasping. Extensive validation on both grasping datasets and real-world
experiments underscores the adaptability of multi-modal LLMs for numerical
prediction tasks in robotics. This not only expands their applicability but
also bridges the gap between text-based planning and direct robot control,
thereby maximizing the potential of LLMs in robotics.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.05192v1' target='_blank'>Explaining Mixtures of Sources in News Articles</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Alexander Spangher, James Youn, Matt DeButts, Nanyun Peng, Emilio Ferrara, Jonathan May</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-07 21:34:05</h6>
<p class='card-text'>Human writers plan, then write. For large language models (LLMs) to play a
role in longer-form article generation, we must understand the planning steps
humans make before writing. We explore one kind of planning, source-selection
in news, as a case-study for evaluating plans in long-form generation. We ask:
why do specific stories call for specific kinds of sources? We imagine a
generative process for story writing where a source-selection schema is first
selected by a journalist, and then sources are chosen based on categories in
that schema. Learning the article's plan means predicting the schema initially
chosen by the journalist. Working with professional journalists, we adapt five
existing schemata and introduce three new ones to describe journalistic plans
for the inclusion of sources in documents. Then, inspired by Bayesian
latent-variable modeling, we develop metrics to select the most likely plan, or
schema, underlying a story, which we use to compare schemata. We find that two
schemata: stance and social affiliation best explain source plans in most
documents. However, other schemata like textual entailment explain source plans
in factually rich topics like "Science". Finally, we find we can predict the
most suitable schema given just the article's headline with reasonable
accuracy. We see this as an important case-study for human planning, and
provides a framework and approach for evaluating other kinds of plans. We
release a corpora, NewsSources, with annotations for 4M articles.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.04679v1' target='_blank'>CaPo: Cooperative Plan Optimization for Efficient Embodied Multi-Agent
  Cooperation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jie Liu, Pan Zhou, Yingjun Du, Ah-Hwee Tan, Cees G. M. Snoek, Jan-Jakob Sonke, Efstratios Gavves</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-07 13:08:04</h6>
<p class='card-text'>In this work, we address the cooperation problem among large language model
(LLM) based embodied agents, where agents must cooperate to achieve a common
goal. Previous methods often execute actions extemporaneously and incoherently,
without long-term strategic and cooperative planning, leading to redundant
steps, failures, and even serious repercussions in complex tasks like
search-and-rescue missions where discussion and cooperative plan are crucial.
To solve this issue, we propose Cooperative Plan Optimization (CaPo) to enhance
the cooperation efficiency of LLM-based embodied agents. Inspired by human
cooperation schemes, CaPo improves cooperation efficiency with two phases: 1)
meta-plan generation, and 2) progress-adaptive meta-plan and execution. In the
first phase, all agents analyze the task, discuss, and cooperatively create a
meta-plan that decomposes the task into subtasks with detailed steps, ensuring
a long-term strategic and coherent plan for efficient coordination. In the
second phase, agents execute tasks according to the meta-plan and dynamically
adjust it based on their latest progress (e.g., discovering a target object)
through multi-turn discussions. This progress-based adaptation eliminates
redundant actions, improving the overall cooperation efficiency of agents.
Experimental results on the ThreeDworld Multi-Agent Transport and Communicative
Watch-And-Help tasks demonstrate that CaPo achieves much higher task completion
rate and efficiency compared with state-of-the-arts.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.04496v1' target='_blank'>Thanos: Enhancing Conversational Agents with Skill-of-Mind-Infused Large
  Language Model</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Young-Jun Lee, Dokyong Lee, Junyoung Youn, Kyeongjin Oh, Ho-Jin Choi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-07 07:46:06</h6>
<p class='card-text'>To increase social bonding with interlocutors, humans naturally acquire the
ability to respond appropriately in a given situation by considering which
conversational skill is most suitable for the response - a process we call
skill-of-mind. For large language model (LLM)-based conversational agents,
planning appropriate conversational skills, as humans do, is challenging due to
the complexity of social dialogue, especially in interactive scenarios. To
address this, we propose a skill-of-mind-annotated conversation dataset, named
Multifaceted Skill-of-Mind, which includes multi-turn and multifaceted
conversational skills across various interactive scenarios (e.g., long-term,
counseling, task-oriented), grounded in diverse social contexts (e.g.,
demographics, persona, rules of thumb). This dataset consists of roughly 100K
conversations. Using this dataset, we introduce a new family of
skill-of-mind-infused LLMs, named Thanos, with model sizes of 1B, 3B, and 8B
parameters. With extensive experiments, these models successfully demonstrate
the skill-of-mind process and exhibit strong generalizability in inferring
multifaceted skills across a variety of domains. Moreover, we show that Thanos
significantly enhances the quality of responses generated by LLM-based
conversational agents and promotes prosocial behavior in human evaluations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.04329v2' target='_blank'>CodeTree: Agent-guided Tree Search for Code Generation with Large
  Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jierui Li, Hung Le, Yingbo Zhou, Caiming Xiong, Silvio Savarese, Doyen Sahoo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-07 00:09:54</h6>
<p class='card-text'>Pre-trained on massive amounts of code and text data, large language models
(LLMs) have demonstrated remarkable achievements in performing code generation
tasks. With additional execution-based feedback, these models can act as agents
with capabilities to self-refine and improve generated code autonomously.
However, on challenging coding tasks with extremely large search space, current
agentic approaches still struggle with multi-stage planning, generating, and
debugging. To address this problem, we propose CodeTree, a framework for LLM
agents to efficiently explore the search space in different stages of the code
generation process. Specifically, we adopted a unified tree structure to
explicitly explore different coding strategies, generate corresponding coding
solutions, and subsequently refine the solutions. In each stage, critical
decision-making (ranking, termination, expanding) of the exploration process is
guided by both the environmental execution-based feedback and
LLM-agent-generated feedback. We comprehensively evaluated CodeTree on 7 code
generation benchmarks and demonstrated the significant performance gains of
CodeTree against strong baselines. Using GPT-4o as the base model, we
consistently achieved top results of 95.1 on HumanEval, 98.7 on MBPP, and 43.0
on CodeContests. On the challenging SWEBench benchmark, our approach led to
significant performance gains.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.04105v3' target='_blank'>How Transformers Solve Propositional Logic Problems: A Mechanistic
  Analysis</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Guan Zhe Hong, Nishanth Dikkala, Enming Luo, Cyrus Rashtchian, Xin Wang, Rina Panigrahy</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-06 18:35:32</h6>
<p class='card-text'>Large language models (LLMs) have shown amazing performance on tasks that
require planning and reasoning. Motivated by this, we investigate the internal
mechanisms that underpin a network's ability to perform complex logical
reasoning. We first construct a synthetic propositional logic problem that
serves as a concrete test-bed for network training and evaluation. Crucially,
this problem demands nontrivial planning to solve. We perform our study on two
fronts. First, we pursue an understanding of precisely how a three-layer
transformer, trained from scratch and attains perfect test accuracy, solves
this problem. We are able to identify certain "planning" and "reasoning"
mechanisms in the network that necessitate cooperation between the attention
blocks to implement the desired logic. Second, we study how pretrained LLMs,
namely Mistral-7B and Gemma-2-9B, solve this problem. We characterize their
reasoning circuits through causal intervention experiments, providing necessity
and sufficiency evidence for the circuits. We find evidence suggesting that the
two models' latent reasoning strategies are surprisingly similar, and
human-like. Overall, our work systemically uncovers novel aspects of small and
large transformers, and continues the study of how they plan and reason.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.03743v1' target='_blank'>Automating Exploratory Proteomics Research via Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ning Ding, Shang Qu, Linhai Xie, Yifei Li, Zaoqu Liu, Kaiyan Zhang, Yibai Xiong, Yuxin Zuo, Zhangren Chen, Ermo Hua, Xingtai Lv, Youbang Sun, Yang Li, Dong Li, Fuchu He, Bowen Zhou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-06 08:16:56</h6>
<p class='card-text'>With the development of artificial intelligence, its contribution to science
is evolving from simulating a complex problem to automating entire research
processes and producing novel discoveries. Achieving this advancement requires
both specialized general models grounded in real-world scientific data and
iterative, exploratory frameworks that mirror human scientific methodologies.
In this paper, we present PROTEUS, a fully automated system for scientific
discovery from raw proteomics data. PROTEUS uses large language models (LLMs)
to perform hierarchical planning, execute specialized bioinformatics tools, and
iteratively refine analysis workflows to generate high-quality scientific
hypotheses. The system takes proteomics datasets as input and produces a
comprehensive set of research objectives, analysis results, and novel
biological hypotheses without human intervention. We evaluated PROTEUS on 12
proteomics datasets collected from various biological samples (e.g. immune
cells, tumors) and different sample types (single-cell and bulk), generating
191 scientific hypotheses. These were assessed using both automatic LLM-based
scoring on 5 metrics and detailed reviews from human experts. Results
demonstrate that PROTEUS consistently produces reliable, logically coherent
results that align well with existing literature while also proposing novel,
evaluable hypotheses. The system's flexible architecture facilitates seamless
integration of diverse analysis tools and adaptation to different proteomics
data types. By automating complex proteomics analysis workflows and hypothesis
generation, PROTEUS has the potential to considerably accelerate the pace of
scientific discovery in proteomics research, enabling researchers to
efficiently explore large-scale datasets and uncover biological insights.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.03395v1' target='_blank'>Exploring Large Language Models for Specialist-level Oncology Care</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Anil Palepu, Vikram Dhillon, Polly Niravath, Wei-Hung Weng, Preethi Prasad, Khaled Saab, Ryutaro Tanno, Yong Cheng, Hanh Mai, Ethan Burns, Zainub Ajmal, Kavita Kulkarni, Philip Mansfield, Dale Webster, Joelle Barral, Juraj Gottweis, Mike Schaekermann, S. Sara Mahdavi, Vivek Natarajan, Alan Karthikesalingam, Tao Tu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-05 18:30:13</h6>
<p class='card-text'>Large language models (LLMs) have shown remarkable progress in encoding
clinical knowledge and responding to complex medical queries with appropriate
clinical reasoning. However, their applicability in subspecialist or complex
medical settings remains underexplored. In this work, we probe the performance
of AMIE, a research conversational diagnostic AI system, in the subspecialist
domain of breast oncology care without specific fine-tuning to this challenging
domain. To perform this evaluation, we curated a set of 50 synthetic breast
cancer vignettes representing a range of treatment-naive and
treatment-refractory cases and mirroring the key information available to a
multidisciplinary tumor board for decision-making (openly released with this
work). We developed a detailed clinical rubric for evaluating management plans,
including axes such as the quality of case summarization, safety of the
proposed care plan, and recommendations for chemotherapy, radiotherapy, surgery
and hormonal therapy. To improve performance, we enhanced AMIE with the
inference-time ability to perform web search retrieval to gather relevant and
up-to-date clinical knowledge and refine its responses with a multi-stage
self-critique pipeline. We compare response quality of AMIE with internal
medicine trainees, oncology fellows, and general oncology attendings under both
automated and specialist clinician evaluations. In our evaluations, AMIE
outperformed trainees and fellows demonstrating the potential of the system in
this challenging and important domain. We further demonstrate through
qualitative examples, how systems such as AMIE might facilitate conversational
interactions to assist clinicians in their decision making. However, AMIE's
performance was overall inferior to attending oncologists suggesting that
further research is needed prior to consideration of prospective uses.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.03287v1' target='_blank'>The Future of Intelligent Healthcare: A Systematic Analysis and
  Discussion on the Integration and Impact of Robots Using Large Language
  Models for Healthcare</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Souren Pashangpour, Goldie Nejat</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-05 17:36:32</h6>
<p class='card-text'>The potential use of large language models (LLMs) in healthcare robotics can
help address the significant demand put on healthcare systems around the world
with respect to an aging demographic and a shortage of healthcare
professionals. Even though LLMs have already been integrated into medicine to
assist both clinicians and patients, the integration of LLMs within healthcare
robots has not yet been explored for clinical settings. In this perspective
paper, we investigate the groundbreaking developments in robotics and LLMs to
uniquely identify the needed system requirements for designing health specific
LLM based robots in terms of multi modal communication through human robot
interactions (HRIs), semantic reasoning, and task planning. Furthermore, we
discuss the ethical issues, open challenges, and potential future research
directions for this emerging innovative field.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.02938v1' target='_blank'>Multi-Modal 3D Scene Graph Updater for Shared and Dynamic Environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Emilio Olivastri, Jonathan Francis, Alberto Pretto, Niko Sünderhauf, Krishan Rana</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-05 09:31:30</h6>
<p class='card-text'>The advent of generalist Large Language Models (LLMs) and Large Vision Models
(VLMs) have streamlined the construction of semantically enriched maps that can
enable robots to ground high-level reasoning and planning into their
representations. One of the most widely used semantic map formats is the 3D
Scene Graph, which captures both metric (low-level) and semantic (high-level)
information. However, these maps often assume a static world, while real
environments, like homes and offices, are dynamic. Even small changes in these
spaces can significantly impact task performance. To integrate robots into
dynamic environments, they must detect changes and update the scene graph in
real-time. This update process is inherently multimodal, requiring input from
various sources, such as human agents, the robot's own perception system, time,
and its actions. This work proposes a framework that leverages these multimodal
inputs to maintain the consistency of scene graphs during real-time operation,
presenting promising initial results and outlining a roadmap for future
research.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.02862v1' target='_blank'>The Unreasonable Effectiveness of LLMs for Query Optimization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Peter Akioyamen, Zixuan Yi, Ryan Marcus</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-05 07:10:00</h6>
<p class='card-text'>Recent work in database query optimization has used complex machine learning
strategies, such as customized reinforcement learning schemes. Surprisingly, we
show that LLM embeddings of query text contain useful semantic information for
query optimization. Specifically, we show that a simple binary classifier
deciding between alternative query plans, trained only on a small number of
labeled embedded query vectors, can outperform existing heuristic systems.
Although we only present some preliminary results, an LLM-powered query
optimizer could provide significant benefits, both in terms of performance and
simplicity.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.01829v1' target='_blank'>Formal Theorem Proving by Rewarding LLMs to Decompose Proofs
  Hierarchically</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kefan Dong, Arvind Mahankali, Tengyu Ma</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-04 05:57:40</h6>
<p class='card-text'>Mathematical theorem proving is an important testbed for large language
models' deep and abstract reasoning capability. This paper focuses on improving
LLMs' ability to write proofs in formal languages that permit automated proof
verification/evaluation. Most previous results provide human-written lemmas to
the theorem prover, which is an arguably oversimplified setting that does not
sufficiently test the provers' planning and decomposition capabilities.
Instead, we work in a more natural setup where the lemmas that are directly
relevant to the theorem are not given to the theorem prover at test time. We
design an RL-based training algorithm that encourages the model to decompose a
theorem into lemmas, prove the lemmas, and then prove the theorem by using the
lemmas. Our reward mechanism is inspired by how mathematicians train
themselves: even if a theorem is too challenging to be proved by the current
model, a positive reward is still given to the model for any correct and novel
lemmas that are proposed and proved in this process. During training, our model
proposes and proves lemmas that are not in the training dataset. In fact, these
newly-proposed correct lemmas consist of 37.7% of the training replay buffer
when we train on the dataset extracted from Archive of Formal Proofs (AFP). The
model trained by our RL algorithm outperforms that trained by supervised
finetuning, improving the pass rate from 40.8% to 45.5% on AFP test set, and
from 36.5% to 39.5% on an out-of-distribution test set.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.01807v1' target='_blank'>Can Language Models Enable In-Context Database?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yu Pan, Hongfeng Yu, Tianjiao Zhao, Jianxin Sun</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-04 05:25:39</h6>
<p class='card-text'>Large language models (LLMs) are emerging as few-shot learners capable of
handling a variety of tasks, including comprehension, planning, reasoning,
question answering, arithmetic calculations, and more. At the core of these
capabilities is LLMs' proficiency in representing and understanding structural
or semi-structural data, such as tables and graphs. Numerous studies have
demonstrated that reasoning on tabular data or graphs is not only feasible for
LLMs but also gives a promising research direction which treats these data as
in-context data. The lightweight and human readable characteristics of
in-context database can potentially make it an alternative for the traditional
database in typical RAG (Retrieval Augmented Generation) settings. However,
almost all current work focuses on static in-context data, which does not allow
dynamic update. In this paper, to enable dynamic database update, delta
encoding of database is proposed. We explore how data stored in traditional
RDBMS can be encoded as in-context text and evaluate LLMs' proficiency for CRUD
(Create, Read, Update and Delete) operations on in-context databases. A
benchmark named InConDB is presented and extensive experiments are conducted to
show the performance of different language models in enabling in-context
database by varying the database encoding method, prompting method, operation
type and input data distribution, revealing both the proficiency and
limitations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.01790v1' target='_blank'>Thinking Forward and Backward: Effective Backward Planning with Large
  Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Allen Z. Ren, Brian Ichter, Anirudha Majumdar</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-04 04:26:03</h6>
<p class='card-text'>Large language models (LLMs) have exhibited remarkable reasoning and planning
capabilities. Most prior work in this area has used LLMs to reason through
steps from an initial to a goal state or criterion, thereby effectively
reasoning in a forward direction. Nonetheless, many planning problems exhibit
an inherent asymmetry such that planning backward from the goal is
significantly easier -- for example, if there are bottlenecks close to the
goal. We take inspiration from this observation and demonstrate that this bias
holds for LLM planning as well: planning performance in one direction
correlates with the planning complexity of the problem in that direction.
However, our experiments also reveal systematic biases which lead to poor
planning in the backward direction. With this knowledge, we propose a backward
planning algorithm for LLMs that first flips the problem and then plans forward
in the flipped problem. This helps avoid the backward bias, generate more
diverse candidate plans, and exploit asymmetries between the forward and
backward directions in planning problems -- we find that combining planning in
both directions with self-verification improves the overall planning success
rates by 4-24% in three planning domains.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.01747v1' target='_blank'>DynaSaur: Large Language Agents Beyond Predefined Actions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Dang Nguyen, Viet Dac Lai, Seunghyun Yoon, Ryan A. Rossi, Handong Zhao, Ruiyi Zhang, Puneet Mathur, Nedim Lipka, Yu Wang, Trung Bui, Franck Dernoncourt, Tianyi Zhou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-04 02:08:59</h6>
<p class='card-text'>Existing LLM agent systems typically select actions from a fixed and
predefined set at every step. While this approach is effective in closed,
narrowly-scoped environments, we argue that it presents two major challenges
when deploying LLM agents in real-world scenarios: (1) selecting from a fixed
set of actions significantly restricts the planning and acting capabilities of
LLM agents, and (2) this approach requires substantial human effort to
enumerate and implement all possible actions, which becomes impractical in
complex environments with a vast number of potential actions. In this work, we
propose an LLM agent framework that enables the dynamic creation and
composition of actions in an online manner. In this framework, the agent
interacts with the environment by generating and executing programs written in
a general-purpose programming language at each step. Furthermore, generated
actions are accumulated over time for future reuse. Our extensive experiments
on the GAIA benchmark demonstrate that this framework offers significantly
greater flexibility and outperforms previous methods. Notably, it allows an LLM
agent to recover in scenarios where no relevant action exists in the predefined
set or when existing actions fail due to unforeseen edge cases. At the time of
writing, we hold the top position on the GAIA public leaderboard. Our code can
be found in
\href{https://github.com/adobe-research/dynasaur}{https://github.com/adobe-research/dynasaur}.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.01063v2' target='_blank'>InterTrans: Leveraging Transitive Intermediate Translations to Enhance
  LLM-based Code Translation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Marcos Macedo, Yuan Tian, Pengyu Nie, Filipe R. Cogo, Bram Adams</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-01 22:31:32</h6>
<p class='card-text'>Code translation aims to convert a program from one programming language (PL)
to another. This long-standing software engineering task is crucial for
modernizing legacy systems, ensuring cross-platform compatibility, enhancing
performance, and more. However, automating this process remains challenging due
to many syntactic and semantic differences between PLs. Recent studies show
that even advanced techniques such as large language models (LLMs), especially
open-source LLMs, still struggle with the task. Currently, code LLMs are
trained with source code from multiple programming languages, thus presenting
multilingual capabilities.
  In this paper, we investigate whether such multilingual capabilities can be
harnessed to enhance code translation. To achieve this goal, we introduce
InterTrans, an LLM-based automated code translation approach that, in contrast
to existing approaches, leverages intermediate translations across PLs to
bridge the syntactic and semantic gaps between source and target PLs.
  InterTrans contains two stages. It first utilizes a novel Tree of Code
Translation (ToCT) algorithm to plan transitive intermediate translation
sequences between a given source and target PL, then validates them in a
specific order. We evaluate InterTrans with three open LLMs on three benchmarks
(i.e., CodeNet, HumanEval-X, and TransCoder) involving six PLs. Results show an
absolute improvement between 18.3% to 43.3% in Computation Accuracy (CA) for
InterTrans over Direct Translation with 10 attempts. The best-performing
variant of InterTrans (with Magicoder LLM) achieved an average CA of
87.3%-95.4% on three benchmarks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.00927v1' target='_blank'>ReSpAct: Harmonizing Reasoning, Speaking, and Acting Towards Building
  Large Language Model-Based Conversational AI Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Vardhan Dongre, Xiaocheng Yang, Emre Can Acikgoz, Suvodip Dey, Gokhan Tur, Dilek Hakkani-Tür</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-01 15:57:45</h6>
<p class='card-text'>Large language model (LLM)-based agents have been increasingly used to
interact with external environments (e.g., games, APIs, etc.) and solve tasks.
However, current frameworks do not enable these agents to work with users and
interact with them to align on the details of their tasks and reach
user-defined goals; instead, in ambiguous situations, these agents may make
decisions based on assumptions. This work introduces ReSpAct (Reason, Speak,
and Act), a novel framework that synergistically combines the essential skills
for building task-oriented "conversational" agents. ReSpAct addresses this need
for agents, expanding on the ReAct approach. The ReSpAct framework enables
agents to interpret user instructions, reason about complex tasks, execute
appropriate actions, and engage in dynamic dialogue to seek guidance, clarify
ambiguities, understand user preferences, resolve problems, and use the
intermediate feedback and responses of users to update their plans. We
evaluated ReSpAct in environments supporting user interaction, such as
task-oriented dialogue (MultiWOZ) and interactive decision-making (AlfWorld,
WebShop). ReSpAct is flexible enough to incorporate dynamic user feedback and
addresses prevalent issues like error propagation and agents getting stuck in
reasoning loops. This results in more interpretable, human-like task-solving
trajectories than relying solely on reasoning traces. In two interactive
decision-making benchmarks, AlfWorld and WebShop, ReSpAct outperform the strong
reasoning-only method ReAct by an absolute success rate of 6% and 4%,
respectively. In the task-oriented dialogue benchmark MultiWOZ, ReSpAct
improved Inform and Success scores by 5.5% and 3%, respectively.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.00640v1' target='_blank'>Adding Error Bars to Evals: A Statistical Approach to Language Model
  Evaluations</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Evan Miller</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-11-01 14:57:16</h6>
<p class='card-text'>Evaluations are critical for understanding the capabilities of large language
models (LLMs). Fundamentally, evaluations are experiments; but the literature
on evaluations has largely ignored the literature from other sciences on
experiment analysis and planning. This article shows researchers with some
training in statistics how to think about and analyze data from language model
evaluations. Conceptualizing evaluation questions as having been drawn from an
unseen super-population, we present formulas for analyzing evaluation data,
measuring differences between two models, and planning an evaluation
experiment. We make a number of specific recommendations for running language
model evaluations and reporting experiment results in a way that minimizes
statistical noise and maximizes informativeness.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.00208v2' target='_blank'>Using Large Language Models for a standard assessment mapping for
  sustainable communities</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Luc Jonveaux</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-31 21:07:58</h6>
<p class='card-text'>This paper presents a new approach to urban sustainability assessment through
the use of Large Language Models (LLMs) to streamline the use of the ISO 37101
framework to automate and standardise the assessment of urban initiatives
against the six "sustainability purposes" and twelve "issues" outlined in the
standard. The methodology includes the development of a custom prompt based on
the standard definitions and its application to two different datasets: 527
projects from the Paris Participatory Budget and 398 activities from the
PROBONO Horizon 2020 project. The results show the effectiveness of LLMs in
quickly and consistently categorising different urban initiatives according to
sustainability criteria. The approach is particularly promising when it comes
to breaking down silos in urban planning by providing a holistic view of the
impact of projects. The paper discusses the advantages of this method over
traditional human-led assessments, including significant time savings and
improved consistency. However, it also points out the importance of human
expertise in interpreting results and ethical considerations. This study
hopefully can contribute to the growing body of work on AI applications in
urban planning and provides a novel method for operationalising standardised
sustainability frameworks in different urban contexts.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.00188v1' target='_blank'>Building Multi-Agent Copilot towards Autonomous Agricultural Data
  Management and Analysis</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yu Pan, Jianxin Sun, Hongfeng Yu, Joe Luck, Geng Bai, Nipuna Chamara, Yufeng Ge, Tala Awada</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-31 20:15:14</h6>
<p class='card-text'>Current agricultural data management and analysis paradigms are to large
extent traditional, in which data collecting, curating, integration, loading,
storing, sharing and analyzing still involve too much human effort and
know-how. The experts, researchers and the farm operators need to understand
the data and the whole process of data management pipeline to make fully use of
the data. The essential problem of the traditional paradigm is the lack of a
layer of orchestrational intelligence which can understand, organize and
coordinate the data processing utilities to maximize data management and
analysis outcome. The emerging reasoning and tool mastering abilities of large
language models (LLM) make it a potentially good fit to this position, which
helps a shift from the traditional user-driven paradigm to AI-driven paradigm.
In this paper, we propose and explore the idea of a LLM based copilot for
autonomous agricultural data management and analysis. Based on our previously
developed platform of Agricultural Data Management and Analytics (ADMA), we
build a proof-of-concept multi-agent system called ADMA Copilot, which can
understand user's intent, makes plans for data processing pipeline and
accomplishes tasks automatically, in which three agents: a LLM based
controller, an input formatter and an output formatter collaborate together.
Different from existing LLM based solutions, by defining a meta-program graph,
our work decouples control flow and data flow to enhance the predictability of
the behaviour of the agents. Experiments demonstrates the intelligence,
autonomy, efficacy, efficiency, extensibility, flexibility and privacy of our
system. Comparison is also made between ours and existing systems to show the
superiority and potential of our system.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2411.00081v1' target='_blank'>PARTNR: A Benchmark for Planning and Reasoning in Embodied Multi-agent
  Tasks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Matthew Chang, Gunjan Chhablani, Alexander Clegg, Mikael Dallaire Cote, Ruta Desai, Michal Hlavac, Vladimir Karashchuk, Jacob Krantz, Roozbeh Mottaghi, Priyam Parashar, Siddharth Patki, Ishita Prasad, Xavier Puig, Akshara Rai, Ram Ramrakhya, Daniel Tran, Joanne Truong, John M. Turner, Eric Undersander, Tsung-Yen Yang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-31 17:53:12</h6>
<p class='card-text'>We present a benchmark for Planning And Reasoning Tasks in humaN-Robot
collaboration (PARTNR) designed to study human-robot coordination in household
activities. PARTNR tasks exhibit characteristics of everyday tasks, such as
spatial, temporal, and heterogeneous agent capability constraints. We employ a
semi-automated task generation pipeline using Large Language Models (LLMs),
incorporating simulation in the loop for grounding and verification. PARTNR
stands as the largest benchmark of its kind, comprising 100,000 natural
language tasks, spanning 60 houses and 5,819 unique objects. We analyze
state-of-the-art LLMs on PARTNR tasks, across the axes of planning, perception
and skill execution. The analysis reveals significant limitations in SoTA
models, such as poor coordination and failures in task tracking and recovery
from errors. When LLMs are paired with real humans, they require 1.5x as many
steps as two humans collaborating and 1.1x more steps than a single human,
underscoring the potential for improvement in these models. We further show
that fine-tuning smaller LLMs with planning data can achieve performance on par
with models 9 times larger, while being 8.6x faster at inference. Overall,
PARTNR highlights significant challenges facing collaborative embodied agents
and aims to drive research in this direction.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.23968v1' target='_blank'>EmbodiedRAG: Dynamic 3D Scene Graph Retrieval for Efficient and Scalable
  Robot Task Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Meghan Booker, Grayson Byrd, Bethany Kemp, Aurora Schmidt, Corban Rivera</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-31 14:22:20</h6>
<p class='card-text'>Recent advances in Large Language Models (LLMs) have helped facilitate
exciting progress for robotic planning in real, open-world environments. 3D
scene graphs (3DSGs) offer a promising environment representation for grounding
such LLM-based planners as they are compact and semantically rich. However, as
the robot's environment scales (e.g., number of entities tracked) and the
complexity of scene graph information increases (e.g., maintaining more
attributes), providing the 3DSG as-is to an LLM-based planner quickly becomes
infeasible due to input token count limits and attentional biases present in
LLMs. Inspired by the successes of Retrieval-Augmented Generation (RAG) methods
that retrieve query-relevant document chunks for LLM question and answering, we
adapt the paradigm for our embodied domain. Specifically, we propose a 3D scene
subgraph retrieval framework, called EmbodiedRAG, that we augment an LLM-based
planner with for executing natural language robotic tasks. Notably, our
retrieved subgraphs adapt to changes in the environment as well as changes in
task-relevancy as the robot executes its plan. We demonstrate EmbodiedRAG's
ability to significantly reduce input token counts (by an order of magnitude)
and planning time (up to 70% reduction in average time per planning step) while
improving success rates on AI2Thor simulated household tasks with a single-arm,
mobile manipulator. Additionally, we implement EmbodiedRAG on a quadruped with
a manipulator to highlight the performance benefits for robot deployment at the
edge in real environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.23875v1' target='_blank'>Plan-on-Graph: Self-Correcting Adaptive Planning of Large Language Model
  on Knowledge Graphs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Liyi Chen, Panrong Tong, Zhongming Jin, Ying Sun, Jieping Ye, Hui Xiong</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-31 12:37:24</h6>
<p class='card-text'>Large Language Models (LLMs) have shown remarkable reasoning capabilities on
complex tasks, but they still suffer from out-of-date knowledge,
hallucinations, and opaque decision-making. In contrast, Knowledge Graphs (KGs)
can provide explicit and editable knowledge for LLMs to alleviate these issues.
Existing paradigm of KG-augmented LLM manually predefines the breadth of
exploration space and requires flawless navigation in KGs. However, this
paradigm cannot adaptively explore reasoning paths in KGs based on the question
semantics and self-correct erroneous reasoning paths, resulting in a bottleneck
in efficiency and effect. To address these limitations, we propose a novel
self-correcting adaptive planning paradigm for KG-augmented LLM named
Plan-on-Graph (PoG), which first decomposes the question into several
sub-objectives and then repeats the process of adaptively exploring reasoning
paths, updating memory, and reflecting on the need to self-correct erroneous
reasoning paths until arriving at the answer. Specifically, three important
mechanisms of Guidance, Memory, and Reflection are designed to work together,
to guarantee the adaptive breadth of self-correcting planning for graph
reasoning. Finally, extensive experiments on three real-world datasets
demonstrate the effectiveness and efficiency of PoG.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.23511v2' target='_blank'>Dynamic Strategy Planning for Efficient Question Answering with Large
  Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tanmay Parekh, Pradyot Prakash, Alexander Radovic, Akshay Shekher, Denis Savenkov</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-30 23:35:21</h6>
<p class='card-text'>Research has shown the effectiveness of reasoning (e.g., Chain-of-Thought),
planning (e.g., SelfAsk), and retrieval augmented generation strategies to
improve the performance of Large Language Models (LLMs) on various tasks, such
as question answering. However, using a single fixed strategy to answer
different kinds of questions is suboptimal in performance and inefficient in
terms of generated output tokens and performed retrievals. In our work, we
propose a novel technique DyPlan, to induce a dynamic strategy selection
process in LLMs, to improve performance and reduce costs in question-answering.
DyPlan incorporates an initial decision step to select the most suitable
strategy conditioned on the input question and guides the LLM's response
generation accordingly. We extend DyPlan to DyPlan-verify, adding an internal
verification and correction process to further enrich the generated answer.
Experiments on three prominent multi-hop question answering (MHQA) datasets
reveal how DyPlan can improve model performance by 7-13% while reducing the
cost by 11-32% relative to the best baseline model.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.23230v2' target='_blank'>Aligning Audio-Visual Joint Representations with an Agentic Workflow</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shentong Mo, Yibing Song</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-30 17:18:53</h6>
<p class='card-text'>Visual content and accompanied audio signals naturally formulate a joint
representation to improve audio-visual (AV) related applications. While studies
develop various AV representation learning frameworks, the importance of AV
data alignment is usually undermined for achieving high-quality representation.
We observe that an audio signal may contain background noise interference.
Also, non-synchronization may appear between audio and video streams. These
non-strict data alignment limits representation quality and downgrade
application performance. In this paper, we propose to improve AV joint
representations from a data-centric perspective by aligning audio signals to
visual data. Our alignment is conducted in an agentic workflow controlled by an
LLM-based assistant named AVAgent. For each input AV data pair, our AVAgent
uses a multi-modal LLM to convert audio and visual data into language
descriptions separately (i.e., tool use). Then, AVAgent reasons whether this
paired data is aligned well and plans to edit the audio signal if needed (i.e.,
planning). The audio editing is executed by predefined actions that filter
noise or augment data. Moreover, we use a VLM to evaluate how modified audio
signals match the visual content and provide feedback to AVAgent (i.e.,
reflection). The tool use, planning, and reflection steps operate cyclically to
become an agentic workflow where audio signals are gradually aligned to visual
content. To this end, existing methods can directly leverage the aligned AV
data via our agentic workflow to improve AV joint representations. The
experimental results comprehensively demonstrate the state-of-the-art
performance of the proposed approach against previous baselines in diverse
downstream tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.22997v2' target='_blank'>A Comparison of Prompt Engineering Techniques for Task Planning and
  Execution in Service Robotics</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jonas Bode, Bastian Pätzold, Raphael Memmesheimer, Sven Behnke</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-30 13:22:55</h6>
<p class='card-text'>Recent advances in LLM have been instrumental in autonomous robot control and
human-robot interaction by leveraging their vast general knowledge and
capabilities to understand and reason across a wide range of tasks and
scenarios. Previous works have investigated various prompt engineering
techniques for improving the performance of LLM to accomplish tasks, while
others have proposed methods that utilize LLMs to plan and execute tasks based
on the available functionalities of a given robot platform. In this work, we
consider both lines of research by comparing prompt engineering techniques and
combinations thereof within the application of high-level task planning and
execution in service robotics. We define a diverse set of tasks and a simple
set of functionalities in simulation, and measure task completion accuracy and
execution time for several state-of-the-art models.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.22662v2' target='_blank'>EMOS: Embodiment-aware Heterogeneous Multi-robot Operating System with
  LLM Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Junting Chen, Checheng Yu, Xunzhe Zhou, Tianqi Xu, Yao Mu, Mengkang Hu, Wenqi Shao, Yikai Wang, Guohao Li, Lin Shao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-30 03:20:01</h6>
<p class='card-text'>Heterogeneous multi-robot systems (HMRS) have emerged as a powerful approach
for tackling complex tasks that single robots cannot manage alone. Current
large-language-model-based multi-agent systems (LLM-based MAS) have shown
success in areas like software development and operating systems, but applying
these systems to robot control presents unique challenges. In particular, the
capabilities of each agent in a multi-robot system are inherently tied to the
physical composition of the robots, rather than predefined roles. To address
this issue, we introduce a novel multi-agent framework designed to enable
effective collaboration among heterogeneous robots with varying embodiments and
capabilities, along with a new benchmark named Habitat-MAS. One of our key
designs is $\textit{Robot Resume}$: Instead of adopting human-designed role
play, we propose a self-prompted approach, where agents comprehend robot URDF
files and call robot kinematics tools to generate descriptions of their physics
capabilities to guide their behavior in task planning and action execution. The
Habitat-MAS benchmark is designed to assess how a multi-agent framework handles
tasks that require embodiment-aware reasoning, which includes 1) manipulation,
2) perception, 3) navigation, and 4) comprehensive multi-floor object
rearrangement. The experimental results indicate that the robot's resume and
the hierarchical design of our multi-agent system are essential for the
effective operation of the heterogeneous multi-robot system within this
intricate problem context.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.22584v1' target='_blank'>BENCHAGENTS: Automated Benchmark Creation with Agent Interaction</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Natasha Butt, Varun Chandrasekaran, Neel Joshi, Besmira Nushi, Vidhisha Balachandran</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-29 22:56:18</h6>
<p class='card-text'>Evaluations are limited by benchmark availability. As models evolve, there is
a need to create benchmarks that can measure progress on new generative
capabilities. However, creating new benchmarks through human annotations is
slow and expensive, restricting comprehensive evaluations for any capability.
We introduce BENCHAGENTS, a framework that methodically leverages large
language models (LLMs) to automate benchmark creation for complex capabilities
while inherently ensuring data and metric quality. BENCHAGENTS decomposes the
benchmark creation process into planning, generation, data verification, and
evaluation, each of which is executed by an LLM agent. These agents interact
with each other and utilize human-in-the-loop feedback from benchmark
developers to explicitly improve and flexibly control data diversity and
quality. We use BENCHAGENTS to create benchmarks to evaluate capabilities
related to planning and constraint satisfaction during text generation. We then
use these benchmarks to study seven state-of-the-art models and extract new
insights on common failure modes and model differences.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.22225v1' target='_blank'>CaStL: Constraints as Specifications through LLM Translation for
  Long-Horizon Task and Motion Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Weihang Guo, Zachary Kingston, Lydia E. Kavraki</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-29 16:54:15</h6>
<p class='card-text'>Large Language Models (LLMs) have demonstrated remarkable ability in
long-horizon Task and Motion Planning (TAMP) by translating clear and
straightforward natural language problems into formal specifications such as
the Planning Domain Definition Language (PDDL). However, real-world problems
are often ambiguous and involve many complex constraints. In this paper, we
introduce Constraints as Specifications through LLMs (CaStL), a framework that
identifies constraints such as goal conditions, action ordering, and action
blocking from natural language in multiple stages. CaStL translates these
constraints into PDDL and Python scripts, which are solved using an custom PDDL
solver. Tested across three PDDL domains, CaStL significantly improves
constraint handling and planning success rates from natural language
specification in complex scenarios.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.21909v1' target='_blank'>SceneGenAgent: Precise Industrial Scene Generation with Coding Agent</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xiao Xia, Dan Zhang, Zibo Liao, Zhenyu Hou, Tianrui Sun, Jing Li, Ling Fu, Yuxiao Dong</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-29 10:01:40</h6>
<p class='card-text'>The modeling of industrial scenes is essential for simulations in industrial
manufacturing. While large language models (LLMs) have shown significant
progress in generating general 3D scenes from textual descriptions, generating
industrial scenes with LLMs poses a unique challenge due to their demand for
precise measurements and positioning, requiring complex planning over spatial
arrangement. To address this challenge, we introduce SceneGenAgent, an
LLM-based agent for generating industrial scenes through C# code. SceneGenAgent
ensures precise layout planning through a structured and calculable format,
layout verification, and iterative refinement to meet the quantitative
requirements of industrial scenarios. Experiment results demonstrate that LLMs
powered by SceneGenAgent exceed their original performance, reaching up to
81.0% success rate in real-world industrial scene generation tasks and
effectively meeting most scene generation requirements. To further enhance
accessibility, we construct SceneInstruct, a dataset designed for fine-tuning
open-source LLMs to integrate into SceneGenAgent. Experiments show that
fine-tuning open-source LLMs on SceneInstruct yields significant performance
improvements, with Llama3.1-70B approaching the capabilities of GPT-4o. Our
code and data are available at https://github.com/THUDM/SceneGenAgent .</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.22376v2' target='_blank'>Rare-to-Frequent: Unlocking Compositional Generation Power of Diffusion
  Models on Rare Concepts with LLM Guidance</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Dongmin Park, Sebin Kim, Taehong Moon, Minkyu Kim, Kangwook Lee, Jaewoong Cho</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-29 07:43:39</h6>
<p class='card-text'>State-of-the-art text-to-image (T2I) diffusion models often struggle to
generate rare compositions of concepts, e.g., objects with unusual attributes.
In this paper, we show that the compositional generation power of diffusion
models on such rare concepts can be significantly enhanced by the Large
Language Model (LLM) guidance. We start with empirical and theoretical
analysis, demonstrating that exposing frequent concepts relevant to the target
rare concepts during the diffusion sampling process yields more accurate
concept composition. Based on this, we propose a training-free approach, R2F,
that plans and executes the overall rare-to-frequent concept guidance
throughout the diffusion inference by leveraging the abundant semantic
knowledge in LLMs. Our framework is flexible across any pre-trained diffusion
models and LLMs, and can be seamlessly integrated with the region-guided
diffusion approaches. Extensive experiments on three datasets, including our
newly proposed benchmark, RareBench, containing various prompts with rare
compositions of concepts, R2F significantly surpasses existing models including
SD3.0 and FLUX by up to 28.1%p in T2I alignment. Code is available at
https://github.com/krafton-ai/Rare-to-Frequent.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.21591v1' target='_blank'>Can Large Language Models Replace Data Scientists in Clinical Research?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zifeng Wang, Benjamin Danek, Ziwei Yang, Zheng Chen, Jimeng Sun</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-28 22:48:06</h6>
<p class='card-text'>Data science plays a critical role in clinical research, but it requires
professionals with expertise in coding and medical data analysis. Large
language models (LLMs) have shown great potential in supporting medical tasks
and performing well in general coding tests. However, these tests do not assess
LLMs' ability to handle data science tasks in medicine, nor do they explore
their practical utility in clinical research. To address this, we developed a
dataset consisting of 293 real-world data science coding tasks, based on 39
published clinical studies, covering 128 tasks in Python and 165 tasks in R.
This dataset simulates realistic clinical research scenarios using patient
data. Our findings reveal that cutting-edge LLMs struggle to generate perfect
solutions, frequently failing to follow input instructions, understand target
data, and adhere to standard analysis practices. Consequently, LLMs are not yet
ready to fully automate data science tasks. We benchmarked advanced adaptation
methods and found two to be particularly effective: chain-of-thought prompting,
which provides a step-by-step plan for data analysis, which led to a 60%
improvement in code accuracy; and self-reflection, enabling LLMs to iteratively
refine their code, yielding a 38% accuracy improvement. Building on these
insights, we developed a platform that integrates LLMs into the data science
workflow for medical professionals. In a user study with five medical doctors,
we found that while LLMs cannot fully automate coding tasks, they significantly
streamline the programming process. We found that 80% of their submitted code
solutions were incorporated from LLM-generated code, with up to 96% reuse in
some cases. Our analysis highlights the potential of LLMs, when integrated into
expert workflows, to enhance data science efficiency in clinical research.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.21490v1' target='_blank'>Can Large Language Models Act as Symbolic Reasoners?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Rob Sullivan, Nelly Elsayed</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-28 20:01:50</h6>
<p class='card-text'>The performance of Large language models (LLMs) across a broad range of
domains has been impressive but have been critiqued as not being able to reason
about their process and conclusions derived. This is to explain the conclusions
draw, and also for determining a plan or strategy for their approach. This
paper explores the current research in investigating symbolic reasoning and
LLMs, and whether an LLM can inherently provide some form of reasoning or
whether supporting components are necessary, and, if there is evidence for a
reasoning capability, is this evident in a specific domain or is this a general
capability? In addition, this paper aims to identify the current research gaps
and future trends of LLM explainability, presenting a review of the literature,
identifying current research into this topic and suggests areas for future
work.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.21040v1' target='_blank'>LiP-LLM: Integrating Linear Programming and dependency graph with Large
  Language Models for multi-robot task planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kazuma Obata, Tatsuya Aoki, Takato Horii, Tadahiro Taniguchi, Takayuki Nagai</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-28 13:57:25</h6>
<p class='card-text'>This study proposes LiP-LLM: integrating linear programming and dependency
graph with large language models (LLMs) for multi-robot task planning. In order
for multiple robots to perform tasks more efficiently, it is necessary to
manage the precedence dependencies between tasks. Although multi-robot
decentralized and centralized task planners using LLMs have been proposed, none
of these studies focus on precedence dependencies from the perspective of task
efficiency or leverage traditional optimization methods. It addresses key
challenges in managing dependencies between skills and optimizing task
allocation. LiP-LLM consists of three steps: skill list generation and
dependency graph generation by LLMs, and task allocation using linear
programming. The LLMs are utilized to generate a comprehensive list of skills
and to construct a dependency graph that maps the relationships and sequential
constraints among these skills. To ensure the feasibility and efficiency of
skill execution, the skill list is generated by calculated likelihood, and
linear programming is used to optimally allocate tasks to each robot.
Experimental evaluations in simulated environments demonstrate that this method
outperforms existing task planners, achieving higher success rates and
efficiency in executing complex, multi-robot tasks. The results indicate the
potential of combining LLMs with optimization techniques to enhance the
capabilities of multi-robot systems in executing coordinated tasks accurately
and efficiently. In an environment with two robots, a maximum success rate
difference of 0.82 is observed in the language instruction group with a change
in the object name.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.20749v1' target='_blank'>Matryoshka: Learning to Drive Black-Box LLMs with LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Changhao Li, Yuchen Zhuang, Rushi Qiang, Haotian Sun, Hanjun Dai, Chao Zhang, Bo Dai</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-28 05:28:51</h6>
<p class='card-text'>Despite the impressive generative abilities of black-box large language
models (LLMs), their inherent opacity hinders further advancements in
capabilities such as reasoning, planning, and personalization. Existing works
aim to enhance LLM capabilities via domain-specific adaptation or in-context
learning, which require additional training on accessible model parameters, an
infeasible option for black-box LLMs. To address this challenge, we introduce
Matryoshika, a lightweight white-box LLM controller that guides a large-scale
black-box LLM generator by decomposing complex tasks into a series of
intermediate outputs. Specifically, we consider the black-box LLM as an
environment, with Matryoshika serving as a policy to provide intermediate
guidance through prompts for driving the black-box LLM. Matryoshika is trained
to pivot the outputs of the black-box LLM aligning with preferences during
iterative interaction, which enables controllable multi-turn generation and
self-improvement in optimizing intermediate guidance. Empirical evaluations on
three diverse tasks demonstrate that Matryoshika effectively enhances the
capabilities of black-box LLMs in complex, long-horizon tasks, including
reasoning, planning, and personalization. By leveraging this pioneering
controller-generator framework to mitigate dependence on model parameters,
Matryoshika provides a transparent and practical solution for improving
black-box LLMs through controllable multi-turn generation using white-box LLMs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.20666v1' target='_blank'>Guide-LLM: An Embodied LLM Agent and Text-Based Topological Map for
  Robotic Guidance of People with Visual Impairments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sangmim Song, Sarath Kodagoda, Amal Gunatilake, Marc G. Carmichael, Karthick Thiyagarajan, Jodi Martin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-28 01:58:21</h6>
<p class='card-text'>Navigation presents a significant challenge for persons with visual
impairments (PVI). While traditional aids such as white canes and guide dogs
are invaluable, they fall short in delivering detailed spatial information and
precise guidance to desired locations. Recent developments in large language
models (LLMs) and vision-language models (VLMs) offer new avenues for enhancing
assistive navigation. In this paper, we introduce Guide-LLM, an embodied
LLM-based agent designed to assist PVI in navigating large indoor environments.
Our approach features a novel text-based topological map that enables the LLM
to plan global paths using a simplified environmental representation, focusing
on straight paths and right-angle turns to facilitate navigation. Additionally,
we utilize the LLM's commonsense reasoning for hazard detection and
personalized path planning based on user preferences. Simulated experiments
demonstrate the system's efficacy in guiding PVI, underscoring its potential as
a significant advancement in assistive technology. The results highlight
Guide-LLM's ability to offer efficient, adaptive, and personalized navigation
assistance, pointing to promising advancements in this field.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.21337v2' target='_blank'>Fine-tuned Large Language Models (LLMs): Improved Prompt Injection
  Attacks Detection</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Md Abdur Rahman, Fan Wu, Alfredo Cuzzocrea, Sheikh Iqbal Ahamed</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-28 00:36:21</h6>
<p class='card-text'>Large language models (LLMs) are becoming a popular tool as they have
significantly advanced in their capability to tackle a wide range of
language-based tasks. However, LLMs applications are highly vulnerable to
prompt injection attacks, which poses a critical problem. These attacks target
LLMs applications through using carefully designed input prompts to divert the
model from adhering to original instruction, thereby it could execute
unintended actions. These manipulations pose serious security threats which
potentially results in data leaks, biased outputs, or harmful responses. This
project explores the security vulnerabilities in relation to prompt injection
attacks. To detect whether a prompt is vulnerable or not, we follows two
approaches: 1) a pre-trained LLM, and 2) a fine-tuned LLM. Then, we conduct a
thorough analysis and comparison of the classification performance. Firstly, we
use pre-trained XLM-RoBERTa model to detect prompt injections using test
dataset without any fine-tuning and evaluate it by zero-shot classification.
Then, this proposed work will apply supervised fine-tuning to this pre-trained
LLM using a task-specific labeled dataset from deepset in huggingface, and this
fine-tuned model achieves impressive results with 99.13\% accuracy, 100\%
precision, 98.33\% recall and 99.15\% F1-score thorough rigorous
experimentation and evaluation. We observe that our approach is highly
efficient in detecting prompt injection attacks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.20285v4' target='_blank'>SWE-Search: Enhancing Software Agents with Monte Carlo Tree Search and
  Iterative Refinement</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Antonis Antoniades, Albert Örwall, Kexun Zhang, Yuxi Xie, Anirudh Goyal, William Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-26 22:45:56</h6>
<p class='card-text'>Software engineers operating in complex and dynamic environments must
continuously adapt to evolving requirements, learn iteratively from experience,
and reconsider their approaches based on new insights. However, current large
language model (LLM)-based software agents often rely on rigid processes and
tend to repeat ineffective actions without the capacity to evaluate their
performance or adapt their strategies over time. To address these challenges,
we propose SWE-Search, a multi-agent framework that integrates Monte Carlo Tree
Search (MCTS) with a self-improvement mechanism to enhance software agents'
performance on repository-level software tasks. SWE-Search extends traditional
MCTS by incorporating a hybrid value function that leverages LLMs for both
numerical value estimation and qualitative evaluation. This enables
self-feedback loops where agents iteratively refine their strategies based on
both quantitative numerical evaluations and qualitative natural language
assessments of pursued trajectories. The framework includes a SWE-Agent for
adaptive exploration, a Value Agent for iterative feedback, and a Discriminator
Agent that facilitates multi-agent debate for collaborative decision-making.
Applied to the SWE-bench benchmark, our approach demonstrates a 23% relative
improvement in performance across five models compared to standard open-source
agents without MCTS. Our analysis reveals how performance scales with increased
search depth and identifies key factors that facilitate effective
self-evaluation in software agents. This work highlights the potential of
self-evaluation driven search techniques to enhance agent reasoning and
planning in complex, dynamic software engineering environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.20215v1' target='_blank'>DAWN-ICL: Strategic Planning of Problem-solving Trajectories for
  Zero-Shot In-Context Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xinyu Tang, Xiaolei Wang, Wayne Xin Zhao, Ji-Rong Wen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-26 16:17:02</h6>
<p class='card-text'>Zero-shot in-context learning (ZS-ICL) aims to conduct in-context learning
(ICL) without using human-annotated demonstrations. Most ZS-ICL methods use
large language models (LLMs) to generate (input, label) pairs as
pseudo-demonstrations and leverage historical pseudo-demonstrations to help
solve the current problem. They assume that problems are from the same task and
traverse them in a random order. However, in real-world scenarios, problems
usually come from diverse tasks, and only a few belong to the same task. The
random traversing order may generate unreliable pseudo-demonstrations and lead
to error accumulation. To address this problem, we reformulate ZS-ICL as a
planning problem and propose a Demonstration-aware Monte Carlo Tree Search
(MCTS) approach (DAWN-ICL), which leverages MCTS to strategically plan the
problem-solving trajectories for ZS-ICL. In addition, to achieve effective and
efficient Q value estimation, we propose a novel demonstration-aware Q-value
function and use it to enhance the selection phase and accelerate the expansion
and simulation phases in MCTS. Extensive experiments demonstrate the
effectiveness and efficiency of DAWN-ICL on in-domain and cross-domain
scenarios, and it even outperforms ICL using human-annotated labels. The code
is available at https://github.com/RUCAIBox/MCTS4ZSICL.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.20007v1' target='_blank'>Cooperative Strategic Planning Enhances Reasoning Capabilities in Large
  Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Danqing Wang, Zhuorui Ye, Fei Fang, Lei Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-25 23:32:48</h6>
<p class='card-text'>Enhancing the reasoning capabilities of large language models (LLMs) is
crucial for enabling them to tackle complex, multi-step problems. Multi-agent
frameworks have shown great potential in enhancing LLMs' reasoning
capabilities. However, the lack of effective cooperation between LLM agents
hinders their performance, especially for multi-step reasoning tasks. This
paper proposes a novel cooperative multi-agent reasoning framework (CoPlanner)
by separating reasoning steps and assigning distinct duties to different
agents. CoPlanner consists of two LLM agents: a planning agent and a reasoning
agent. The planning agent provides high-level strategic hints, while the
reasoning agent follows these hints and infers answers. By training the
planning agent's policy through the interactive reasoning process via Proximal
Policy Optimization (PPO), the LLaMA-3-8B-based CoPlanner outperforms the
previous best method by 9.94\% on LogiQA and 3.09\% on BBH. Our results
demonstrate that the guidance from the planning agent and the effective
cooperation between the agents contribute to the superior performance of
CoPlanner in tackling multi-step reasoning problems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.19923v1' target='_blank'>Language Agents Meet Causality -- Bridging LLMs and Causal World Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:John Gkountouras, Matthias Lindemann, Phillip Lippe, Efstratios Gavves, Ivan Titov</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-25 18:36:37</h6>
<p class='card-text'>Large Language Models (LLMs) have recently shown great promise in planning
and reasoning applications. These tasks demand robust systems, which arguably
require a causal understanding of the environment. While LLMs can acquire and
reflect common sense causal knowledge from their pretraining data, this
information is often incomplete, incorrect, or inapplicable to a specific
environment. In contrast, causal representation learning (CRL) focuses on
identifying the underlying causal structure within a given environment. We
propose a framework that integrates CRLs with LLMs to enable causally-aware
reasoning and planning. This framework learns a causal world model, with causal
variables linked to natural language expressions. This mapping provides LLMs
with a flexible interface to process and generate descriptions of actions and
states in text form. Effectively, the causal world model acts as a simulator
that the LLM can query and interact with. We evaluate the framework on causal
inference and planning tasks across temporal scales and environmental
complexities. Our experiments demonstrate the effectiveness of the approach,
with the causally-aware method outperforming LLM-based reasoners, especially
for longer planning horizons.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.19727v1' target='_blank'>FISHNET: Financial Intelligence from Sub-querying, Harmonizing,
  Neural-Conditioning, Expert Swarms, and Task Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nicole Cho, Nishan Srishankar, Lucas Cecchi, William Watson</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-25 17:53:47</h6>
<p class='card-text'>Financial intelligence generation from vast data sources has typically relied
on traditional methods of knowledge-graph construction or database engineering.
Recently, fine-tuned financial domain-specific Large Language Models (LLMs),
have emerged. While these advancements are promising, limitations such as high
inference costs, hallucinations, and the complexity of concurrently analyzing
high-dimensional financial data, emerge. This motivates our invention FISHNET
(Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning,
Expert swarming, and Task planning), an agentic architecture that accomplishes
highly complex analytical tasks for more than 98,000 regulatory filings that
vary immensely in terms of semantics, data hierarchy, or format. FISHNET shows
remarkable performance for financial insight generation (61.8% success rate
over 5.0% Routing, 45.6% RAG R-Precision). We conduct rigorous ablations to
empirically prove the success of FISHNET, each agent's importance, and the
optimized performance of assembling all agents. Our modular architecture can be
leveraged for a myriad of use-cases, enabling scalability, flexibility, and
data integrity that are critical for financial tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.19656v1' target='_blank'>APRICOT: Active Preference Learning and Constraint-Aware Task Planning
  with LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Huaxiaoyue Wang, Nathaniel Chin, Gonzalo Gonzalez-Pumariega, Xiangwan Sun, Neha Sunkara, Maximus Adrian Pace, Jeannette Bohg, Sanjiban Choudhury</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-25 16:08:05</h6>
<p class='card-text'>Home robots performing personalized tasks must adeptly balance user
preferences with environmental affordances. We focus on organization tasks
within constrained spaces, such as arranging items into a refrigerator, where
preferences for placement collide with physical limitations. The robot must
infer user preferences based on a small set of demonstrations, which is easier
for users to provide than extensively defining all their requirements. While
recent works use Large Language Models (LLMs) to learn preferences from user
demonstrations, they encounter two fundamental challenges. First, there is
inherent ambiguity in interpreting user actions, as multiple preferences can
often explain a single observed behavior. Second, not all user preferences are
practically feasible due to geometric constraints in the environment. To
address these challenges, we introduce APRICOT, a novel approach that merges
LLM-based Bayesian active preference learning with constraint-aware task
planning. APRICOT refines its generated preferences by actively querying the
user and dynamically adapts its plan to respect environmental constraints. We
evaluate APRICOT on a dataset of diverse organization tasks and demonstrate its
effectiveness in real-world scenarios, showing significant improvements in both
preference satisfaction and plan feasibility. The project website is at
https://portal-cornell.github.io/apricot/</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.18963v1' target='_blank'>OSCAR: Operating System Control via State-Aware Reasoning and
  Re-Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xiaoqiang Wang, Bang Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-24 17:58:08</h6>
<p class='card-text'>Large language models (LLMs) and large multimodal models (LMMs) have shown
great potential in automating complex tasks like web browsing and gaming.
However, their ability to generalize across diverse applications remains
limited, hindering broader utility. To address this challenge, we present
OSCAR: Operating System Control via state-Aware reasoning and Re-planning.
OSCAR is a generalist agent designed to autonomously navigate and interact with
various desktop and mobile applications through standardized controls, such as
mouse and keyboard inputs, while processing screen images to fulfill user
commands. OSCAR translates human instructions into executable Python code,
enabling precise control over graphical user interfaces (GUIs). To enhance
stability and adaptability, OSCAR operates as a state machine, equipped with
error-handling mechanisms and dynamic task re-planning, allowing it to
efficiently adjust to real-time feedback and exceptions. We demonstrate OSCAR's
effectiveness through extensive experiments on diverse benchmarks across
desktop and mobile platforms, where it transforms complex workflows into simple
natural language commands, significantly boosting user productivity. Our code
will be open-source upon publication.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.18893v1' target='_blank'>Creating and Repairing Robot Programs in Open-World Domains</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Claire Schlesinger, Arjun Guha, Joydeep Biswas</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-24 16:30:14</h6>
<p class='card-text'>Using Large Language Models (LLMs) to produce robot programs from natural
language has allowed for robot systems that can complete a higher diversity of
tasks. However, LLM-generated programs may be faulty, either due to ambiguity
in instructions, misinterpretation of the desired task, or missing information
about the world state. As these programs run, the state of the world changes
and they gather new information. When a failure occurs, it is important that
they recover from the current world state and avoid repeating steps that they
they previously completed successfully. We propose RoboRepair, a system which
traces the execution of a program up until error, and then runs an LLM-produced
recovery program that minimizes repeated actions.
  To evaluate the efficacy of our system, we create a benchmark consisting of
eleven tasks with various error conditions that require the generation of a
recovery program. We compare the efficiency of the recovery program to a plan
built with an oracle that has foreknowledge of future errors.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.18447v1' target='_blank'>ToolFlow: Boosting LLM Tool-Calling Through Natural and Coherent
  Dialogue Synthesis</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zezhong Wang, Xingshan Zeng, Weiwen Liu, Liangyou Li, Yasheng Wang, Lifeng Shang, Xin Jiang, Qun Liu, Kam-Fai Wong</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-24 05:45:04</h6>
<p class='card-text'>Supervised fine-tuning (SFT) is a common method to enhance the tool calling
capabilities of Large Language Models (LLMs), with the training data often
being synthesized. The current data synthesis process generally involves
sampling a set of tools, formulating a requirement based on these tools, and
generating the call statements. However, tools sampled randomly lack relevance,
making them difficult to combine and thus reducing the diversity of the data.
Additionally, current work overlooks the coherence between turns of dialogues,
leading to a gap between the synthesized data and real-world scenarios. To
address these issues, we propose a Graph-based Sampling strategy to sample more
relevant tool combinations, and a Planned-generation strategy to create plans
that guide the synthesis of coherent dialogues. We integrate these two
strategies and enable multiple agents to synthesize the dialogue data
interactively, resulting in our tool-calling data synthesis pipeline ToolFlow.
Data quality assessments demonstrate improvements in the naturalness and
coherence of our synthesized dialogues. Finally, we apply SFT on LLaMA-3.1-8B
using 8,000 synthetic dialogues generated with ToolFlow. Results show that the
model achieves tool-calling performance comparable to or even surpassing GPT-4,
while maintaining strong general capabilities.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.17602v1' target='_blank'>Integrating Large Language Models for UAV Control in Simulated
  Environments: A Modular Interaction Approach</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Abhishek Phadke, Alihan Hadimlioglu, Tianxing Chu, Chandra N Sekharan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-23 06:56:53</h6>
<p class='card-text'>The intersection of LLMs (Large Language Models) and UAV (Unoccupied Aerial
Vehicles) technology represents a promising field of research with the
potential to enhance UAV capabilities significantly. This study explores the
application of LLMs in UAV control, focusing on the opportunities for
integrating advanced natural language processing into autonomous aerial
systems. By enabling UAVs to interpret and respond to natural language
commands, LLMs simplify the UAV control and usage, making them accessible to a
broader user base and facilitating more intuitive human-machine interactions.
The paper discusses several key areas where LLMs can impact UAV technology,
including autonomous decision-making, dynamic mission planning, enhanced
situational awareness, and improved safety protocols. Through a comprehensive
review of current developments and potential future directions, this study aims
to highlight how LLMs can transform UAV operations, making them more adaptable,
responsive, and efficient in complex environments. A template development
framework for integrating LLMs in UAV control is also described. Proof of
Concept results that integrate existing LLM models and popular robotic
simulation platforms are demonstrated. The findings suggest that while there
are substantial technical and ethical challenges to address, integrating LLMs
into UAV control holds promising implications for advancing autonomous aerial
systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.17422v2' target='_blank'>Multimodal LLM Guided Exploration and Active Mapping using Fisher
  Information</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wen Jiang, Boshu Lei, Katrina Ashton, Kostas Daniilidis</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-22 20:51:45</h6>
<p class='card-text'>We present an active mapping system that could plan for long-horizon
exploration goals and short-term actions with a 3D Gaussian Splatting (3DGS)
representation. Existing methods either did not take advantage of recent
developments in multimodal Large Language Models (LLM) or did not consider
challenges in localization uncertainty, which is critical in embodied agents.
We propose employing multimodal LLMs for long-horizon planning in conjunction
with detailed motion planning using our information-based algorithm. By
leveraging high-quality view synthesis from our 3DGS representation, our method
employs a multimodal LLM as a zero-shot planner for long-horizon exploration
goals from the semantic perspective. We also introduce an uncertainty-aware
path proposal and selection algorithm that balances the dual objectives of
maximizing the information gain for the environment while minimizing the cost
of localization errors. Experiments conducted on the Gibson and
Habitat-Matterport 3D datasets demonstrate state-of-the-art results of the
proposed method.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.17333v1' target='_blank'>Are Large Language Models Ready for Travel Planning?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ruiping Ren, Xing Yao, Shu Cole, Haining Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-22 18:08:25</h6>
<p class='card-text'>While large language models (LLMs) show promise in hospitality and tourism,
their ability to provide unbiased service across demographic groups remains
unclear. This paper explores gender and ethnic biases when LLMs are utilized as
travel planning assistants. To investigate this issue, we apply machine
learning techniques to analyze travel suggestions generated from three
open-source LLMs. Our findings reveal that the performance of race and gender
classifiers substantially exceeds random chance, indicating differences in how
LLMs engage with varied subgroups. Specifically, outputs align with cultural
expectations tied to certain races and genders. To minimize the effect of these
stereotypes, we used a stop-word classification strategy, which decreased
identifiable differences, with no disrespectful terms found. However,
hallucinations related to African American and gender minority groups were
noted. In conclusion, while LLMs can generate travel plans seemingly free from
bias, it remains essential to verify the accuracy and appropriateness of their
recommendations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.17195v3' target='_blank'>Non-myopic Generation of Language Models for Reasoning and Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chang Ma, Haiteng Zhao, Junlei Zhang, Junxian He, Lingpeng Kong</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-22 17:13:38</h6>
<p class='card-text'>Large Language Models have demonstrated remarkable abilities in reasoning and
planning by breaking down complex problems into sequential steps. Despite their
success in various domains like mathematical problem-solving and coding, LLMs
face challenges in ensuring reliable and optimal planning due to their inherent
myopic nature of autoregressive decoding. This paper revisits LLM reasoning
from an optimal-control perspective, proposing a novel method,
Predictive-Decoding, that leverages Model Predictive Control to enhance
planning accuracy. By re-weighting LLM distributions based on foresight
trajectories, Predictive-Decoding aims to mitigate early errors and promote
non-myopic planning. Our experiments show significant improvements in a wide
range of tasks for math, coding, and agents. Furthermore, Predictive-Decoding
demonstrates computational efficiency, outperforming search baselines with
reduced computational resources. This study provides insights into optimizing
LLM planning capabilities.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.16919v1' target='_blank'>EnvBridge: Bridging Diverse Environments with Cross-Environment
  Knowledge Transfer for Embodied AI</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tomoyuki Kagaya, Yuxuan Lou, Thong Jing Yuan, Subramanian Lakshmi, Jayashree Karlekar, Sugiri Pranata, Natsuki Murakami, Akira Kinose, Koki Oguri, Felix Wick, Yang You</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-22 11:52:22</h6>
<p class='card-text'>In recent years, Large Language Models (LLMs) have demonstrated high
reasoning capabilities, drawing attention for their applications as agents in
various decision-making processes. One notably promising application of LLM
agents is robotic manipulation. Recent research has shown that LLMs can
generate text planning or control code for robots, providing substantial
flexibility and interaction capabilities. However, these methods still face
challenges in terms of flexibility and applicability across different
environments, limiting their ability to adapt autonomously. Current approaches
typically fall into two categories: those relying on environment-specific
policy training, which restricts their transferability, and those generating
code actions based on fixed prompts, which leads to diminished performance when
confronted with new environments. These limitations significantly constrain the
generalizability of agents in robotic manipulation. To address these
limitations, we propose a novel method called EnvBridge. This approach involves
the retention and transfer of successful robot control codes from source
environments to target environments. EnvBridge enhances the agent's
adaptability and performance across diverse settings by leveraging insights
from multiple environments. Notably, our approach alleviates environmental
constraints, offering a more flexible and generalizable solution for robotic
manipulation tasks. We validated the effectiveness of our method using robotic
manipulation benchmarks: RLBench, MetaWorld, and CALVIN. Our experiments
demonstrate that LLM agents can successfully leverage diverse knowledge sources
to solve complex tasks. Consequently, our approach significantly enhances the
adaptability and robustness of robotic manipulation agents in planning across
diverse environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.16456v1' target='_blank'>To the Globe (TTG): Towards Language-Driven Guaranteed Travel Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Da JU, Song Jiang, Andrew Cohen, Aaron Foss, Sasha Mitts, Arman Zharmagambetov, Brandon Amos, Xian Li, Justine T Kao, Maryam Fazel-Zarandi, Yuandong Tian</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-21 19:30:05</h6>
<p class='card-text'>Travel planning is a challenging and time-consuming task that aims to find an
itinerary which satisfies multiple, interdependent constraints regarding
flights, accommodations, attractions, and other travel arrangements. In this
paper, we propose To the Globe (TTG), a real-time demo system that takes
natural language requests from users, translates it to symbolic form via a
fine-tuned Large Language Model, and produces optimal travel itineraries with
Mixed Integer Linear Programming solvers. The overall system takes ~5 seconds
to reply to the user request with guaranteed itineraries. To train TTG, we
develop a synthetic data pipeline that generates user requests, flight and
hotel information in symbolic form without human annotations, based on the
statistics of real-world datasets, and fine-tune an LLM to translate NL user
requests to their symbolic form, which is sent to the symbolic solver to
compute optimal itineraries. Our NL-symbolic translation achieves ~91% exact
match in a backtranslation metric (i.e., whether the estimated symbolic form of
generated natural language matches the groundtruth), and its returned
itineraries have a ratio of 0.979 compared to the optimal cost of the ground
truth user request. When evaluated by users, TTG achieves consistently high Net
Promoter Scores (NPS) of 35-40% on generated itinerary.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.15665v3' target='_blank'>Long Term Memory: The Foundation of AI Self-Evolution</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xun Jiang, Feng Li, Han Zhao, Jiaying Wang, Jun Shao, Shihao Xu, Shu Zhang, Weiling Chen, Xavier Tang, Yize Chen, Mengyue Wu, Weizhi Ma, Mengdi Wang, Tianqiao Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-21 06:09:30</h6>
<p class='card-text'>Large language models (LLMs) like GPTs, trained on vast datasets, have
demonstrated impressive capabilities in language understanding, reasoning, and
planning, achieving human-level performance in various tasks. Most studies
focus on enhancing these models by training on ever-larger datasets to build
more powerful foundation models. While training stronger models is important,
enabling models to evolve during inference is equally crucial, a process we
refer to as AI self-evolution. Unlike large-scale training, self-evolution may
rely on limited data or interactions. Inspired by the columnar organization of
the human cerebral cortex, we hypothesize that AI models could develop
cognitive abilities and build internal representations through iterative
interactions with their environment. To achieve this, models need long-term
memory (LTM) to store and manage processed interaction data. LTM supports
self-evolution by representing diverse experiences across environments and
agents. In this report, we explore AI self-evolution and its potential to
enhance models during inference. We examine LTM's role in lifelong learning,
allowing models to evolve based on accumulated interactions. We outline the
structure of LTM and the systems needed for effective data retention and
representation. We also classify approaches for building personalized models
with LTM data and show how these models achieve self-evolution through
interaction. Using LTM, our multi-agent framework OMNE achieved first place on
the GAIA benchmark, demonstrating LTM's potential for AI self-evolution.
Finally, we present a roadmap for future research, emphasizing the importance
of LTM for advancing AI technology and its practical applications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.15222v1' target='_blank'>AutoFLUKA: A Large Language Model Based Framework for Automating Monte
  Carlo Simulations in FLUKA</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zavier Ndum Ndum, Jian Tao, John Ford, Yang Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-19 21:50:11</h6>
<p class='card-text'>Monte Carlo (MC) simulations, particularly using FLUKA, are essential for
replicating real-world scenarios across scientific and engineering fields.
Despite the robustness and versatility, FLUKA faces significant limitations in
automation and integration with external post-processing tools, leading to
workflows with a steep learning curve, which are time-consuming and prone to
human errors. Traditional methods involving the use of shell and Python
scripts, MATLAB, and Microsoft Excel require extensive manual intervention and
lack flexibility, adding complexity to evolving scenarios. This study explores
the potential of Large Language Models (LLMs) and AI agents to address these
limitations. AI agents, integrate natural language processing with autonomous
reasoning for decision-making and adaptive planning, making them ideal for
automation. We introduce AutoFLUKA, an AI agent application developed using the
LangChain Python Framework to automate typical MC simulation workflows in
FLUKA. AutoFLUKA can modify FLUKA input files, execute simulations, and
efficiently process results for visualization, significantly reducing human
labor and error. Our case studies demonstrate that AutoFLUKA can handle both
generalized and domain-specific cases, such as Microdosimetry, with an
streamlined automated workflow, showcasing its scalability and flexibility. The
study also highlights the potential of Retrieval Augmentation Generation (RAG)
tools to act as virtual assistants for FLUKA, further improving user
experience, time and efficiency. In conclusion, AutoFLUKA represents a
significant advancement in automating MC simulation workflows, offering a
robust solution to the inherent limitations. This innovation not only saves
time and resources but also opens new paradigms for research and development in
high energy physics, medical physics, nuclear engineering space and
environmental science.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.14853v1' target='_blank'>DFlow: Diverse Dialogue Flow Simulation with Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wanyu Du, Song Feng, James Gung, Lijia Sun, Yi Zhang, Saab Mansour, Yanjun Qi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-18 20:35:28</h6>
<p class='card-text'>Developing language model-based dialogue agents requires effective data to
train models that can follow specific task logic. However, most existing data
augmentation methods focus on increasing diversity in language, topics, or
dialogue acts at the utterance level, largely neglecting a critical aspect of
task logic diversity at the dialogue level. This paper proposes a novel data
augmentation method designed to enhance the diversity of synthetic dialogues by
focusing on task execution logic. Our method uses LLMs to generate decision
tree-structured task plans, which enables the derivation of diverse dialogue
trajectories for a given task. Each trajectory, referred to as a "dialog flow",
guides the generation of a multi-turn dialogue that follows a unique
trajectory. We apply this method to generate a task-oriented dialogue dataset
comprising 3,886 dialogue flows across 15 different domains. We validate the
effectiveness of this dataset using the next action prediction task, where
models fine-tuned on our dataset outperform strong baselines, including GPT-4.
Upon acceptance of this paper, we plan to release the code and data publicly.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.14594v2' target='_blank'>Toolshed: Scale Tool-Equipped Agents with Advanced RAG-Tool Fusion and
  Tool Knowledge Bases</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Elias Lumer, Vamse Kumar Subbiah, James A. Burke, Pradeep Honaganahalli Basavaraju, Austin Huber</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-18 16:44:22</h6>
<p class='card-text'>Recent advancements in tool-equipped Agents (LLMs) have enabled complex tasks
like secure database interactions and multi-agent code development. However,
scaling tool capacity beyond agent reasoning or model limits remains a
challenge. In this paper, we address these challenges by introducing Toolshed
Knowledge Bases, a tool knowledge base (vector database) designed to store
enhanced tool representations and optimize tool selection for large-scale
tool-equipped Agents. Additionally, we propose Advanced RAG-Tool Fusion, a
novel ensemble of tool-applied advanced retrieval-augmented generation (RAG)
techniques across the pre-retrieval, intra-retrieval, and post-retrieval
phases, without requiring model fine-tuning. During pre-retrieval, tool
documents are enhanced with key information and stored in the Toolshed
Knowledge Base. Intra-retrieval focuses on query planning and transformation to
increase retrieval accuracy. Post-retrieval refines the retrieved tool
documents and enables self-reflection. Furthermore, by varying both the total
number of tools (tool-M) an Agent has access to and the tool selection
threshold (top-k), we address trade-offs between retrieval accuracy, agent
performance, and token cost. Our approach achieves 46%, 56%, and 47% absolute
improvements on the ToolE single-tool, ToolE multi-tool and Seal-Tools
benchmark datasets, respectively (Recall@5).</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.14569v3' target='_blank'>When LLMs Go Online: The Emerging Threat of Web-Enabled LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hanna Kim, Minkyoo Song, Seung Ho Na, Seungwon Shin, Kimin Lee</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-18 16:16:34</h6>
<p class='card-text'>Recent advancements in Large Language Models (LLMs) have established them as
agentic systems capable of planning and interacting with various tools. These
LLM agents are often paired with web-based tools, enabling access to diverse
sources and real-time information. Although these advancements offer
significant benefits across various applications, they also increase the risk
of malicious use, particularly in cyberattacks involving personal information.
In this work, we investigate the risks associated with misuse of LLM agents in
cyberattacks involving personal data. Specifically, we aim to understand: 1)
how potent LLM agents can be when directed to conduct cyberattacks, 2) how
cyberattacks are enhanced by web-based tools, and 3) how affordable and easy it
becomes to launch cyberattacks using LLM agents. We examine three attack
scenarios: the collection of Personally Identifiable Information (PII), the
generation of impersonation posts, and the creation of spear-phishing emails.
Our experiments reveal the effectiveness of LLM agents in these attacks: LLM
agents achieved a precision of up to 95.9% in collecting PII, generated
impersonation posts where 93.9% of them were deemed authentic, and boosted
click rate of phishing links in spear phishing emails by 46.67%. Additionally,
our findings underscore the limitations of existing safeguards in contemporary
commercial LLMs, emphasizing the urgent need for robust security measures to
prevent the misuse of LLM agents.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.14545v1' target='_blank'>Tell me what I need to know: Exploring LLM-based (Personalized)
  Abstractive Multi-Source Meeting Summarization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Frederic Kirstein, Terry Ruas, Robert Kratel, Bela Gipp</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-18 15:40:48</h6>
<p class='card-text'>Meeting summarization is crucial in digital communication, but existing
solutions struggle with salience identification to generate personalized,
workable summaries, and context understanding to fully comprehend the meetings'
content. Previous attempts to address these issues by considering related
supplementary resources (e.g., presentation slides) alongside transcripts are
hindered by models' limited context sizes and handling the additional
complexities of the multi-source tasks, such as identifying relevant
information in additional files and seamlessly aligning it with the meeting
content. This work explores multi-source meeting summarization considering
supplementary materials through a three-stage large language model approach:
identifying transcript passages needing additional context, inferring relevant
details from supplementary materials and inserting them into the transcript,
and generating a summary from this enriched transcript. Our multi-source
approach enhances model understanding, increasing summary relevance by ~9% and
producing more content-rich outputs. We introduce a personalization protocol
that extracts participant characteristics and tailors summaries accordingly,
improving informativeness by ~10%. This work further provides insights on
performance-cost trade-offs across four leading model families, including
edge-device capable options. Our approach can be extended to similar complex
generative tasks benefitting from additional resources and personalization,
such as dialogue systems and action planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.14255v2' target='_blank'>Nova: An Iterative Planning and Search Approach to Enhance Novelty and
  Diversity of LLM Generated Ideas</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xiang Hu, Hongyu Fu, Jinge Wang, Yifeng Wang, Zhikun Li, Renjun Xu, Yu Lu, Yaochu Jin, Lili Pan, Zhenzhong Lan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-18 08:04:36</h6>
<p class='card-text'>Scientific innovation is pivotal for humanity, and harnessing large language
models (LLMs) to generate research ideas could transform discovery. However,
existing LLMs often produce simplistic and repetitive suggestions due to their
limited ability in acquiring external knowledge for innovation. To address this
problem, we introduce an enhanced planning and search methodology designed to
boost the creative potential of LLM-based systems. Our approach involves an
iterative process to purposely plan the retrieval of external knowledge,
progressively enriching the idea generation with broader and deeper insights.
Validation through automated and human assessments indicates that our framework
substantially elevates the quality of generated ideas, particularly in novelty
and diversity. The number of unique novel ideas produced by our framework is
3.4 times higher than without it. Moreover, our method outperforms the current
state-of-the-art, generating at least 2.5 times more top-rated ideas based on
170 seed papers in a Swiss Tournament evaluation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.13768v1' target='_blank'>Rapid and Automated Alloy Design with Graph Neural Network-Powered
  LLM-Driven Multi-Agent Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Alireza Ghafarollahi, Markus J. Buehler</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-17 17:06:26</h6>
<p class='card-text'>A multi-agent AI model is used to automate the discovery of new metallic
alloys, integrating multimodal data and external knowledge including insights
from physics via atomistic simulations. Our multi-agent system features three
key components: (a) a suite of LLMs responsible for tasks such as reasoning and
planning, (b) a group of AI agents with distinct roles and expertise that
dynamically collaborate, and (c) a newly developed graph neural network (GNN)
model for rapid retrieval of key physical properties. A set of LLM-driven AI
agents collaborate to automate the exploration of the vast design space of
MPEAs, guided by predictions from the GNN. We focus on the NbMoTa family of
body-centered cubic (bcc) alloys, modeled using an ML-based interatomic
potential, and target two key properties: the Peierls barrier and solute/screw
dislocation interaction energy. Our GNN model accurately predicts these
atomic-scale properties, providing a faster alternative to costly brute-force
calculations and reducing the computational burden on multi-agent systems for
physics retrieval. This AI system revolutionizes materials discovery by
reducing reliance on human expertise and overcoming the limitations of direct
all-atom simulations. By synergizing the predictive power of GNNs with the
dynamic collaboration of LLM-based agents, the system autonomously navigates
vast alloy design spaces, identifying trends in atomic-scale material
properties and predicting macro-scale mechanical strength, as demonstrated by
several computational experiments. This approach accelerates the discovery of
advanced alloys and holds promise for broader applications in other complex
systems, marking a significant step forward in automated materials design.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.13639v2' target='_blank'>A Comparative Study on Reasoning Patterns of OpenAI's o1 Model</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Siwei Wu, Zhongyuan Peng, Xinrun Du, Tuney Zheng, Minghao Liu, Jialong Wu, Jiachen Ma, Yizhi Li, Jian Yang, Wangchunshu Zhou, Qunshu Lin, Junbo Zhao, Zhaoxiang Zhang, Wenhao Huang, Ge Zhang, Chenghua Lin, J. H. Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-17 15:09:03</h6>
<p class='card-text'>Enabling Large Language Models (LLMs) to handle a wider range of complex
tasks (e.g., coding, math) has drawn great attention from many researchers. As
LLMs continue to evolve, merely increasing the number of model parameters
yields diminishing performance improvements and heavy computational costs.
Recently, OpenAI's o1 model has shown that inference strategies (i.e.,
Test-time Compute methods) can also significantly enhance the reasoning
capabilities of LLMs. However, the mechanisms behind these methods are still
unexplored. In our work, to investigate the reasoning patterns of o1, we
compare o1 with existing Test-time Compute methods (BoN, Step-wise BoN, Agent
Workflow, and Self-Refine) by using OpenAI's GPT-4o as a backbone on general
reasoning benchmarks in three domains (i.e., math, coding, commonsense
reasoning). Specifically, first, our experiments show that the o1 model has
achieved the best performance on most datasets. Second, as for the methods of
searching diverse responses (e.g., BoN), we find the reward models' capability
and the search space both limit the upper boundary of these methods. Third, as
for the methods that break the problem into many sub-problems, the Agent
Workflow has achieved better performance than Step-wise BoN due to the
domain-specific system prompt for planning better reasoning processes. Fourth,
it is worth mentioning that we have summarized six reasoning patterns of o1,
and provided a detailed analysis on several reasoning benchmarks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.13501v1' target='_blank'>Integrating Large Language Models and Reinforcement Learning for
  Non-Linear Reasoning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yoav Alon, Cristina David</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-17 12:47:31</h6>
<p class='card-text'>Large Language Models (LLMs) were shown to struggle with long-term planning,
which may be caused by the limited way in which they explore the space of
possible solutions. We propose an architecture where a Reinforcement Learning
(RL) Agent guides an LLM's space exploration: (1) the Agent has access to
domain-specific information, and can therefore make decisions about the quality
of candidate solutions based on specific and relevant metrics, which were not
explicitly considered by the LLM's training objective; (2) the LLM can focus on
generating immediate next steps, without the need for long-term planning. We
allow non-linear reasoning by exploring alternative paths and backtracking. We
evaluate this architecture on the program equivalence task, and compare it
against Chain of Thought (CoT) and Tree of Thoughts (ToT). We assess both the
downstream task, denoting the binary classification, and the intermediate
reasoning steps. Our approach compares positively against CoT and ToT.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.13384v1' target='_blank'>RescueADI: Adaptive Disaster Interpretation in Remote Sensing Images
  with Autonomous Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhuoran Liu, Danpei Zhao, Bo Yuan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-17 09:36:52</h6>
<p class='card-text'>Current methods for disaster scene interpretation in remote sensing images
(RSIs) mostly focus on isolated tasks such as segmentation, detection, or
visual question-answering (VQA). However, current interpretation methods often
fail at tasks that require the combination of multiple perception methods and
specialized tools. To fill this gap, this paper introduces Adaptive Disaster
Interpretation (ADI), a novel task designed to solve requests by planning and
executing multiple sequentially correlative interpretation tasks to provide a
comprehensive analysis of disaster scenes. To facilitate research and
application in this area, we present a new dataset named RescueADI, which
contains high-resolution RSIs with annotations for three connected aspects:
planning, perception, and recognition. The dataset includes 4,044 RSIs, 16,949
semantic masks, 14,483 object bounding boxes, and 13,424 interpretation
requests across nine challenging request types. Moreover, we propose a new
disaster interpretation method employing autonomous agents driven by large
language models (LLMs) for task planning and execution, proving its efficacy in
handling complex disaster interpretations. The proposed agent-based method
solves various complex interpretation requests such as counting, area
calculation, and path-finding without human intervention, which traditional
single-task approaches cannot handle effectively. Experimental results on
RescueADI demonstrate the feasibility of the proposed task and show that our
method achieves an accuracy 9% higher than existing VQA methods, highlighting
its advantages over conventional disaster interpretation approaches. The
dataset will be publicly available.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.12952v1' target='_blank'>Facilitating Multi-turn Function Calling for LLMs via Compositional
  Instruction Tuning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mingyang Chen, Haoze Sun, Tianpeng Li, Fan Yang, Hao Liang, Keer Lu, Bin Cui, Wentao Zhang, Zenan Zhou, Weipeng Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-16 18:40:26</h6>
<p class='card-text'>Large Language Models (LLMs) have exhibited significant potential in
performing diverse tasks, including the ability to call functions or use
external tools to enhance their performance. While current research on function
calling by LLMs primarily focuses on single-turn interactions, this paper
addresses the overlooked necessity for LLMs to engage in multi-turn function
calling--critical for handling compositional, real-world queries that require
planning with functions but not only use functions. To facilitate this, we
introduce an approach, BUTTON, which generates synthetic compositional
instruction tuning data via bottom-up instruction construction and top-down
trajectory generation. In the bottom-up phase, we generate simple atomic tasks
based on real-world scenarios and build compositional tasks using heuristic
strategies based on atomic tasks. Corresponding functions are then developed
for these compositional tasks. The top-down phase features a multi-agent
environment where interactions among simulated humans, assistants, and tools
are utilized to gather multi-turn function calling trajectories. This approach
ensures task compositionality and allows for effective function and trajectory
generation by examining atomic tasks within compositional tasks. We produce a
dataset BUTTONInstruct comprising 8k data points and demonstrate its
effectiveness through extensive experiments across various LLMs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.12492v1' target='_blank'>End-to-end Planner Training for Language Modeling</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nathan Cornille, Florian Mai, Jingyuan Sun, Marie-Francine Moens</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-16 12:14:29</h6>
<p class='card-text'>Through end-to-end training to predict the next token, LLMs have become
valuable tools for various tasks. Enhancing their core training in language
modeling can improve numerous downstream applications. A successful approach to
enhance language modeling uses a separate planning module to predict abstract
labels of future sentences and conditions the LM on these predictions. However,
this method is non-differentiable, preventing joint end-to-end tuning of the
planner with the LM. We propose an effective method to improve this approach by
enabling joint fine-tuning of the planner and the LM. We show that a naive way
of approximating the gradient of selecting a label via the straight-through
estimator is not effective. Instead, we propose to use the predicted label
probabilities as mixing weights to condition the LM on a weighted average of
label embeddings in a differentiable manner. This not only enables joint
fine-tuning of the planner and the LM, but also allows the LM to draw on the
full label distribution predicted by the planner, retaining more information.
Our experimental results show consistent improvements in perplexity.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.12475v2' target='_blank'>Aegis:An Advanced LLM-Based Multi-Agent for Intelligent Functional
  Safety Engineering</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lu Shi, Bin Qi, Jiarui Luo, Yang Zhang, Zhanzhao Liang, Zhaowei Gao, Wenke Deng, Lin Sun</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-16 11:43:17</h6>
<p class='card-text'>Functional safety is a critical aspect of automotive engineering,
encompassing all phases of a vehicle's lifecycle, including design,
development, production, operation, and decommissioning. This domain involves
highly knowledge-intensive tasks. This paper introduces Aegis: An Advanced
LLM-Based Multi-Agent for Intelligent Functional Safety Engineering. Aegis is
specifically designed to support complex functional safety tasks within the
automotive sector. It is tailored to perform Hazard Analysis and Risk
Assessment(HARA), document Functional Safety Requirements(FSR), and plan test
cases for Automatic Emergency Braking(AEB) systems. The most advanced version,
Aegis-Max, leverages Retrieval-Augmented Generation(RAG) and reflective
mechanisms to enhance its capability in managing complex, knowledge-intensive
tasks. Additionally, targeted prompt refinement by professional functional
safety practitioners can significantly optimize Aegis's performance in the
functional safety domain. This paper demonstrates the potential of Aegis to
improve the efficiency and effectiveness of functional safety processes in
automotive engineering.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.12468v2' target='_blank'>Evaluating Software Development Agents: Patch Patterns, Code Quality,
  and Issue Complexity in Real-World GitHub Scenarios</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhi Chen, Lingxiao Jiang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-16 11:33:57</h6>
<p class='card-text'>In recent years, AI-based software engineering has progressed from
pre-trained models to advanced agentic workflows, with Software Development
Agents representing the next major leap. These agents, capable of reasoning,
planning, and interacting with external environments, offer promising solutions
to complex software engineering tasks. However, while much research has
evaluated code generated by large language models (LLMs), comprehensive studies
on agent-generated patches, particularly in real-world settings, are lacking.
This study addresses that gap by evaluating 4,892 patches from 10 top-ranked
agents on 500 real-world GitHub issues from SWE-Bench Verified, focusing on
their impact on code quality. Our analysis shows no single agent dominated,
with 170 issues unresolved, indicating room for improvement. Even for patches
that passed unit tests and resolved issues, agents made different file and
function modifications compared to the gold patches from repository developers,
revealing limitations in the benchmark's test case coverage. Most agents
maintained code reliability and security, avoiding new bugs or vulnerabilities;
while some agents increased code complexity, many reduced code duplication and
minimized code smells. Finally, agents performed better on simpler codebases,
suggesting that breaking complex tasks into smaller sub-tasks could improve
effectiveness. This study provides the first comprehensive evaluation of
agent-generated patches on real-world GitHub issues, offering insights to
advance AI-driven software development.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.12409v1' target='_blank'>Revealing the Barriers of Language Agents in Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jian Xie, Kexun Zhang, Jiangjie Chen, Siyu Yuan, Kai Zhang, Yikai Zhang, Lei Li, Yanghua Xiao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-16 09:44:38</h6>
<p class='card-text'>Autonomous planning has been an ongoing pursuit since the inception of
artificial intelligence. Based on curated problem solvers, early planning
agents could deliver precise solutions for specific tasks but lacked
generalization. The emergence of large language models (LLMs) and their
powerful reasoning capabilities has reignited interest in autonomous planning
by automatically generating reasonable solutions for given tasks. However,
prior research and our experiments show that current language agents still lack
human-level planning abilities. Even the state-of-the-art reasoning model,
OpenAI o1, achieves only 15.6% on one of the complex real-world planning
benchmarks. This highlights a critical question: What hinders language agents
from achieving human-level planning? Although existing studies have highlighted
weak performance in agent planning, the deeper underlying issues and the
mechanisms and limitations of the strategies proposed to address them remain
insufficiently understood. In this work, we apply the feature attribution study
and identify two key factors that hinder agent planning: the limited role of
constraints and the diminishing influence of questions. We also find that
although current strategies help mitigate these challenges, they do not fully
resolve them, indicating that agents still have a long way to go before
reaching human-level intelligence.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.12323v2' target='_blank'>Reversal of Thought: Enhancing Large Language Models with
  Preference-Guided Reverse Reasoning Warm-up</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiahao Yuan, Dehui Du, Hao Zhang, Zixiang Di, Usman Naseem</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-16 07:44:28</h6>
<p class='card-text'>Large language models (LLMs) have shown remarkable performance in reasoning
tasks but face limitations in mathematical and complex logical reasoning.
Existing methods to improve LLMs' logical capabilities either involve traceable
or verifiable logical sequences that generate more reliable responses by
constructing logical structures yet increase computational costs, or introduces
rigid logic template rules, reducing flexibility. In this paper, we propose
Reversal of Thought (RoT), a plug-and-play and cost-effective reasoning
framework designed to enhance the logical reasoning abilities of LLMs during
the warm-up phase prior to batch inference. RoT utilizes a Preference-Guided
Reverse Reasoning warm-up strategy, which integrates logical symbols for
pseudocode planning through meta-cognitive mechanisms and pairwise preference
self-evaluation to generate task-specific prompts solely through
demonstrations, aligning with LLMs' cognitive preferences shaped by RLHF.
Through reverse reasoning, we utilize a Cognitive Preference Manager to assess
knowledge boundaries and further expand LLMs' reasoning capabilities by
aggregating solution logic for known tasks and stylistic templates for unknown
tasks. Experiments across various tasks demonstrate that RoT surpasses existing
baselines in both reasoning accuracy and efficiency.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.12189v2' target='_blank'>DocETL: Agentic Query Rewriting and Evaluation for Complex Document
  Processing</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shreya Shankar, Tristan Chambers, Tarak Shah, Aditya G. Parameswaran, Eugene Wu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-16 03:22:35</h6>
<p class='card-text'>Analyzing unstructured data has been a persistent challenge in data
processing. Large Language Models (LLMs) have shown promise in this regard,
leading to recent proposals for declarative frameworks for LLM-powered
processing of unstructured data. However, these frameworks focus on reducing
cost when executing user-specified operations using LLMs, rather than improving
accuracy, executing most operations as-is (in a single LLM call). This is
problematic for complex tasks and data, where LLM outputs for user-defined
operations are often inaccurate, even with optimized prompts. For example, an
LLM may struggle to identify {\em all} instances of specific clauses, like
force majeure or indemnification, in lengthy legal documents, requiring
decomposition of the data, the task, or both.
  We present DocETL, a system that optimizes complex document processing
pipelines, while accounting for LLM shortcomings. DocETL offers a declarative
interface for users to define such pipelines and uses an agent-based approach
to automatically optimize them, leveraging novel agent-based rewrites (that we
call rewrite directives), as well as an optimization and evaluation framework.
We introduce (i) logical rewriting of pipelines, tailored for LLM-based tasks,
(ii) an agent-guided plan evaluation mechanism that synthesizes and
orchestrates task-specific validation prompts, and (iii) an optimization
algorithm that efficiently finds promising plans, considering the latencies of
agent-based plan generation and evaluation. Our evaluation on four different
unstructured document analysis tasks demonstrates that DocETL finds plans with
outputs that are 25 to 80% more accurate than well-engineered baselines,
addressing a critical gap in unstructured data analysis. DocETL is open-source
at docetl.org, and as of November 2024, has amassed over 1.3k GitHub Stars,
with users spanning a variety of domains.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.12112v2' target='_blank'>Planning Anything with Rigor: General-Purpose Zero-Shot Planning with
  LLM-based Formalized Programming</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yilun Hao, Yang Zhang, Chuchu Fan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-15 23:20:54</h6>
<p class='card-text'>While large language models (LLMs) have recently demonstrated strong
potential in solving planning problems, there is a trade-off between
flexibility and complexity. LLMs, as zero-shot planners themselves, are still
not capable of directly generating valid plans for complex planning problems
such as multi-constraint or long-horizon tasks. On the other hand, many
frameworks aiming to solve complex planning problems often rely on
task-specific preparatory efforts, such as task-specific in-context examples
and pre-defined critics/verifiers, which limits their cross-task generalization
capability. In this paper, we tackle these challenges by observing that the
core of many planning problems lies in optimization problems: searching for the
optimal solution (best plan) with goals subject to constraints (preconditions
and effects of decisions). With LLMs' commonsense, reasoning, and programming
capabilities, this opens up the possibilities of a universal LLM-based approach
to planning problems. Inspired by this observation, we propose LLMFP, a
general-purpose framework that leverages LLMs to capture key information from
planning problems and formally formulate and solve them as optimization
problems from scratch, with no task-specific examples needed. We apply LLMFP to
9 planning problems, ranging from multi-constraint decision making to
multi-step planning problems, and demonstrate that LLMFP achieves on average
83.7% and 86.8% optimal rate across 9 tasks for GPT-4o and Claude 3.5 Sonnet,
significantly outperforming the best baseline (direct planning with OpenAI
o1-preview) with 37.6% and 40.7% improvements. We also validate components of
LLMFP with ablation experiments and analyzed the underlying success and failure
reasons. Project page: https://sites.google.com/view/llmfp.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.11564v1' target='_blank'>PAVLM: Advancing Point Cloud based Affordance Understanding Via
  Vision-Language Model</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shang-Ching Liu, Van Nhiem Tran, Wenkai Chen, Wei-Lun Cheng, Yen-Lin Huang, I-Bin Liao, Yung-Hui Li, Jianwei Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-15 12:53:42</h6>
<p class='card-text'>Affordance understanding, the task of identifying actionable regions on 3D
objects, plays a vital role in allowing robotic systems to engage with and
operate within the physical world. Although Visual Language Models (VLMs) have
excelled in high-level reasoning and long-horizon planning for robotic
manipulation, they still fall short in grasping the nuanced physical properties
required for effective human-robot interaction. In this paper, we introduce
PAVLM (Point cloud Affordance Vision-Language Model), an innovative framework
that utilizes the extensive multimodal knowledge embedded in pre-trained
language models to enhance 3D affordance understanding of point cloud. PAVLM
integrates a geometric-guided propagation module with hidden embeddings from
large language models (LLMs) to enrich visual semantics. On the language side,
we prompt Llama-3.1 models to generate refined context-aware text, augmenting
the instructional input with deeper semantic cues. Experimental results on the
3D-AffordanceNet benchmark demonstrate that PAVLM outperforms baseline methods
for both full and partial point clouds, particularly excelling in its
generalization to novel open-world affordance tasks of 3D objects. For more
information, visit our project site: pavlm-source.github.io.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.11387v3' target='_blank'>LLM2Swarm: Robot Swarms that Responsively Reason, Plan, and Collaborate
  through LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Volker Strobel, Marco Dorigo, Mario Fritz</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-15 08:24:05</h6>
<p class='card-text'>Robot swarms are composed of many simple robots that communicate and
collaborate to fulfill complex tasks. Robot controllers usually need to be
specified by experts on a case-by-case basis via programming code. This process
is time-consuming, prone to errors, and unable to take into account all
situations that may be encountered during deployment. On the other hand, recent
Large Language Models (LLMs) have demonstrated reasoning and planning
capabilities, introduced new ways to interact with and program machines, and
incorporate both domain-specific and commonsense knowledge. Hence, we propose
to address the aforementioned challenges by integrating LLMs with robot swarms
and show the potential in proofs of concept (showcases). For this integration,
we explore two approaches. The first approach is 'indirect integration,' where
LLMs are used to synthesize and validate the robot controllers. This approach
may reduce development time and human error before deployment. Moreover, during
deployment, it could be used for on-the-fly creation of new robot behaviors.
The second approach is 'direct integration,' where each robot locally executes
a separate LLM instance during deployment for robot-robot collaboration and
human-swarm interaction. These local LLM instances enable each robot to reason,
plan, and collaborate using natural language, as demonstrated in our showcases
where the robots are able to detect a variety of anomalies, without prior
information about the nature of these anomalies. To enable further research on
our mainly conceptual contribution, we release the software and videos for our
LLM2Swarm system: https://github.com/Pold87/LLM2Swarm.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.11377v1' target='_blank'>A Framework for Adapting Human-Robot Interaction to Diverse User Groups</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Theresa Pekarek Rosin, Vanessa Hassouna, Xiaowen Sun, Luca Krohm, Henri-Leon Kordt, Michael Beetz, Stefan Wermter</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-15 08:16:43</h6>
<p class='card-text'>To facilitate natural and intuitive interactions with diverse user groups in
real-world settings, social robots must be capable of addressing the varying
requirements and expectations of these groups while adapting their behavior
based on user feedback. While previous research often focuses on specific
demographics, we present a novel framework for adaptive Human-Robot Interaction
(HRI) that tailors interactions to different user groups and enables individual
users to modulate interactions through both minor and major interruptions. Our
primary contributions include the development of an adaptive, ROS-based HRI
framework with an open-source code base. This framework supports natural
interactions through advanced speech recognition and voice activity detection,
and leverages a large language model (LLM) as a dialogue bridge. We validate
the efficiency of our framework through module tests and system trials,
demonstrating its high accuracy in age recognition and its robustness to
repeated user inputs and plan changes.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.11908v1' target='_blank'>ChatHouseDiffusion: Prompt-Guided Generation and Editing of Floor Plans</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sizhong Qin, Chengyu He, Qiaoyun Chen, Sen Yang, Wenjie Liao, Yi Gu, Xinzheng Lu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-15 02:41:46</h6>
<p class='card-text'>The generation and editing of floor plans are critical in architectural
planning, requiring a high degree of flexibility and efficiency. Existing
methods demand extensive input information and lack the capability for
interactive adaptation to user modifications. This paper introduces
ChatHouseDiffusion, which leverages large language models (LLMs) to interpret
natural language input, employs graphormer to encode topological relationships,
and uses diffusion models to flexibly generate and edit floor plans. This
approach allows iterative design adjustments based on user ideas, significantly
enhancing design efficiency. Compared to existing models, ChatHouseDiffusion
achieves higher Intersection over Union (IoU) scores, permitting precise,
localized adjustments without the need for complete redesigns, thus offering
greater practicality. Experiments demonstrate that our model not only strictly
adheres to user specifications but also facilitates a more intuitive design
process through its interactive capabilities.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.11900v4' target='_blank'>FLARE: Faithful Logic-Aided Reasoning and Exploration</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Erik Arakelyan, Pasquale Minervini, Pat Verga, Patrick Lewis, Isabelle Augenstein</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-14 19:39:11</h6>
<p class='card-text'>Modern Question Answering (QA) and Reasoning approaches based on Large
Language Models (LLMs) commonly use prompting techniques, such as
Chain-of-Thought (CoT), assuming the resulting generation will have a more
granular exploration and reasoning over the question space and scope. However,
such methods struggle with generating outputs that are faithful to the
intermediate chain of reasoning produced by the model. On the other end of the
spectrum, neuro-symbolic methods such as Faithful CoT (F-CoT) propose to
combine LLMs with external symbolic solvers. While such approaches boast a high
degree of faithfulness, they usually require a model trained for code
generation and struggle with tasks that are ambiguous or hard to formalise
strictly. We introduce $\textbf{F}$aithful $\textbf{L}$ogic-$\textbf{A}$ided
$\textbf{R}$easoning and $\textbf{E}$xploration ($\textbf{FLARE}$), a novel
interpretable approach for traversing the problem space using task
decompositions. We use the LLM to plan a solution, soft-formalise the query
into facts and predicates using a logic programming code and simulate that code
execution using an exhaustive multi-hop search over the defined space. Our
method allows us to compute the faithfulness of the reasoning process w.r.t.
the generated code and analyse the steps of the multi-hop search without
relying on external solvers. Our methods achieve SOTA results on $\mathbf{7}$
out of $\mathbf{9}$ diverse reasoning benchmarks. We also show that model
faithfulness positively correlates with overall performance and further
demonstrate that $\textbf{FLARE}$ allows pinpointing the decisive factors
sufficient for and leading to the correct answer with optimal reasoning during
the multi-hop search.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.10630v1' target='_blank'>Thinking LLMs: General Instruction Following with Thought Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tianhao Wu, Janice Lan, Weizhe Yuan, Jiantao Jiao, Jason Weston, Sainbayar Sukhbaatar</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-14 15:38:56</h6>
<p class='card-text'>LLMs are typically trained to answer user questions or follow instructions
similarly to how human experts respond. However, in the standard alignment
framework they lack the basic ability of explicit thinking before answering.
Thinking is important for complex questions that require reasoning and planning
-- but can be applied to any task. We propose a training method for equipping
existing LLMs with such thinking abilities for general instruction following
without use of additional human data. We achieve this by an iterative search
and optimization procedure that explores the space of possible thought
generations, allowing the model to learn how to think without direct
supervision. For each instruction, the thought candidates are scored using a
judge model to evaluate their responses only, and then optimized via preference
optimization. We show that this procedure leads to superior performance on
AlpacaEval and Arena-Hard, and shows gains from thinking on non-reasoning
categories such as marketing, health and general knowledge, in addition to more
traditional reasoning & problem-solving tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.10577v1' target='_blank'>Words to Wheels: Vision-Based Autonomous Driving Understanding Human
  Language Instructions Using Foundation Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chanhoe Ryu, Hyunki Seong, Daegyu Lee, Seongwoo Moon, Sungjae Min, D. Hyunchul Shim</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-14 14:51:27</h6>
<p class='card-text'>This paper introduces an innovative application of foundation models,
enabling Unmanned Ground Vehicles (UGVs) equipped with an RGB-D camera to
navigate to designated destinations based on human language instructions.
Unlike learning-based methods, this approach does not require prior training
but instead leverages existing foundation models, thus facilitating
generalization to novel environments. Upon receiving human language
instructions, these are transformed into a 'cognitive route description' using
a large language model (LLM)-a detailed navigation route expressed in human
language. The vehicle then decomposes this description into landmarks and
navigation maneuvers. The vehicle also determines elevation costs and
identifies navigability levels of different regions through a terrain
segmentation model, GANav, trained on open datasets. Semantic elevation costs,
which take both elevation and navigability levels into account, are estimated
and provided to the Model Predictive Path Integral (MPPI) planner, responsible
for local path planning. Concurrently, the vehicle searches for target
landmarks using foundation models, including YOLO-World and EfficientViT-SAM.
Ultimately, the vehicle executes the navigation commands to reach the
designated destination, the final landmark. Our experiments demonstrate that
this application successfully guides UGVs to their destinations following human
language instructions in novel environments, such as unfamiliar terrain or
urban settings.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.12870v1' target='_blank'>Skill Learning Using Process Mining for Large Language Model Plan
  Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Andrei Cosmin Redis, Mohammadreza Fani Sani, Bahram Zarrin, Andrea Burattin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-14 12:48:42</h6>
<p class='card-text'>Large language models (LLMs) hold promise for generating plans for complex
tasks, but their effectiveness is limited by sequential execution, lack of
control flow models, and difficulties in skill retrieval. Addressing these
issues is crucial for improving the efficiency and interpretability of plan
generation as LLMs become more central to automation and decision-making. We
introduce a novel approach to skill learning in LLMs by integrating process
mining techniques, leveraging process discovery for skill acquisition, process
models for skill storage, and conformance checking for skill retrieval. Our
methods enhance text-based plan generation by enabling flexible skill
discovery, parallel execution, and improved interpretability. Experimental
results suggest the effectiveness of our approach, with our skill retrieval
method surpassing state-of-the-art accuracy baselines under specific
conditions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.10045v1' target='_blank'>VQ-CNMP: Neuro-Symbolic Skill Learning for Bi-Level Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hakan Aktas, Emre Ugur</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-13 23:29:46</h6>
<p class='card-text'>This paper proposes a novel neural network model capable of discovering
high-level skill representations from unlabeled demonstration data. We also
propose a bi-level planning pipeline that utilizes our model using a
gradient-based planning approach. While extracting high-level representations,
our model also preserves the low-level information, which can be used for
low-level action planning. In the experiments, we tested the skill discovery
performance of our model under different conditions, tested whether Multi-Modal
LLMs can be utilized to label the learned high-level skill representations, and
finally tested the high-level and low-level planning performance of our
pipeline.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.09874v1' target='_blank'>ImagineNav: Prompting Vision-Language Models as Embodied Navigator
  through Scene Imagination</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xinxin Zhao, Wenzhe Cai, Likun Tang, Teng Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-13 15:31:31</h6>
<p class='card-text'>Visual navigation is an essential skill for home-assistance robots, providing
the object-searching ability to accomplish long-horizon daily tasks. Many
recent approaches use Large Language Models (LLMs) for commonsense inference to
improve exploration efficiency. However, the planning process of LLMs is
limited within texts and it is difficult to represent the spatial occupancy and
geometry layout only by texts. Both are important for making rational
navigation decisions. In this work, we seek to unleash the spatial perception
and planning ability of Vision-Language Models (VLMs), and explore whether the
VLM, with only on-board camera captured RGB/RGB-D stream inputs, can
efficiently finish the visual navigation tasks in a mapless manner. We achieve
this by developing the imagination-powered navigation framework ImagineNav,
which imagines the future observation images at valuable robot views and
translates the complex navigation planning process into a rather simple
best-view image selection problem for VLM. To generate appropriate candidate
robot views for imagination, we introduce the Where2Imagine module, which is
distilled to align with human navigation habits. Finally, to reach the VLM
preferred views, an off-the-shelf point-goal navigation policy is utilized.
Empirical experiments on the challenging open-vocabulary object navigation
benchmarks demonstrates the superiority of our proposed system.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.11890v1' target='_blank'>Online Digital Investigative Journalism using SociaLens</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hasan M. Jamil, Sajratul Y. Rubaiat</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-13 07:20:47</h6>
<p class='card-text'>Media companies witnessed a significant transformation with the rise of the
internet, bigdata, machine learning (ML) and AI. Recent emergence of large
language models (LLM) have added another aspect to this transformation.
Researchers believe that with the help of these technologies, investigative
digital journalism will enter a new era. Using a smart set of data gathering
and analysis tools, journalists will be able to create data driven contents and
insights in unprecedented ways. In this paper, we introduce a versatile and
autonomous investigative journalism tool, called {\em SociaLens}, for
identifying and extracting query specific data from online sources, responding
to probing queries and drawing conclusions entailed by large volumes of data
using ML analytics fully autonomously. We envision its use in investigative
journalism, law enforcement and social policy planning. The proposed system
capitalizes on the integration of ML technology with LLMs and advanced bigdata
search techniques. We illustrate the functionality of SociaLens using a focused
case study on rape incidents in a developing country and demonstrate that
journalists can gain nuanced insights without requiring coding expertise they
might lack. SociaLens is designed as a ChatBot that is capable of contextual
conversation, find and collect data relevant to queries, initiate ML tasks to
respond to queries, generate textual and visual reports, all fully autonomously
within the ChatBot environment.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.10896v2' target='_blank'>AT-MoE: Adaptive Task-planning Mixture of Experts via LoRA Approach</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xurui Li, Juanjuan Yao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-12 13:03:15</h6>
<p class='card-text'>The advent of Large Language Models (LLMs) has ushered in a new era of
artificial intelligence, with the potential to transform various sectors
through automation and insightful analysis. The Mixture of Experts (MoE)
architecture has been proposed as a solution to enhance model performance in
complex tasks. Yet, existing MoE models struggle with task-specific learning
and interpretability, especially in fields like medicine where precision is
critical. This paper introduces the Adaptive Task-planing Mixture of
Experts(AT-MoE), an innovative architecture designed to address these
limitations. We first train task-specific experts via LoRA approach to enhance
problem-solving capabilities and interpretability in specialized areas.
Subsequently, we introduce a layer-wise adaptive grouped routing module that
optimizes module fusion based on complex task instructions, ensuring optimal
task resolution. The grouped routing module first perform overall weight
allocation from the dimension of the expert group, and then conduct local
weight normalization adjustments within the group. This design maintains
multi-dimensional balance, controllability, and interpretability, while
facilitating task-specific fusion in response to complex instructions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.09407v1' target='_blank'>CAMPHOR: Collaborative Agents for Multi-input Planning and High-Order
  Reasoning On Device</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yicheng Fu, Raviteja Anantha, Jianpeng Cheng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-12 07:28:10</h6>
<p class='card-text'>While server-side Large Language Models (LLMs) demonstrate proficiency in
function calling and complex reasoning, deploying Small Language Models (SLMs)
directly on devices brings opportunities to improve latency and privacy but
also introduces unique challenges for accuracy and memory. We introduce
CAMPHOR, an innovative on-device SLM multi-agent framework designed to handle
multiple user inputs and reason over personal context locally, ensuring privacy
is maintained. CAMPHOR employs a hierarchical architecture where a high-order
reasoning agent decomposes complex tasks and coordinates expert agents
responsible for personal context retrieval, tool interaction, and dynamic plan
generation. By implementing parameter sharing across agents and leveraging
prompt compression, we significantly reduce model size, latency, and memory
usage. To validate our approach, we present a novel dataset capturing
multi-agent task trajectories centered on personalized mobile assistant
use-cases. Our experiments reveal that fine-tuned SLM agents not only surpass
closed-source LLMs in task completion F1 by~35\% but also eliminate the need
for server-device communication, all while enhancing privacy.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.09252v1' target='_blank'>ReasonPlanner: Enhancing Autonomous Planning in Dynamic Environments
  with Temporal Knowledge Graphs and LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Minh Pham Dinh, Munira Syed, Michael G Yankoski, Trenton W. Ford</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-11 20:58:51</h6>
<p class='card-text'>Planning and performing interactive tasks, such as conducting experiments to
determine the melting point of an unknown substance, is straightforward for
humans but poses significant challenges for autonomous agents. We introduce
ReasonPlanner, a novel generalist agent designed for reflective thinking,
planning, and interactive reasoning. This agent leverages LLMs to plan
hypothetical trajectories by building a World Model based on a Temporal
Knowledge Graph. The agent interacts with the environment using a natural
language actor-critic module, where the actor translates the imagined
trajectory into a sequence of actionable steps, and the critic determines if
replanning is necessary. ReasonPlanner significantly outperforms previous
state-of-the-art prompting-based methods on the ScienceWorld benchmark by more
than 1.8 times, while being more sample-efficient and interpretable. It relies
solely on frozen weights thus requiring no gradient updates. ReasonPlanner can
be deployed and utilized without specialized knowledge of Machine Learning,
making it accessible to a wide range of users.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.09234v1' target='_blank'>Fine-Tuning In-House Large Language Models to Infer Differential
  Diagnosis from Radiology Reports</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Luoyao Chen, Revant Teotia, Antonio Verdone, Aidan Cardall, Lakshay Tyagi, Yiqiu Shen, Sumit Chopra</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-11 20:16:25</h6>
<p class='card-text'>Radiology reports summarize key findings and differential diagnoses derived
from medical imaging examinations. The extraction of differential diagnoses is
crucial for downstream tasks, including patient management and treatment
planning. However, the unstructured nature of these reports, characterized by
diverse linguistic styles and inconsistent formatting, presents significant
challenges. Although proprietary large language models (LLMs) such as GPT-4 can
effectively retrieve clinical information, their use is limited in practice by
high costs and concerns over the privacy of protected health information (PHI).
This study introduces a pipeline for developing in-house LLMs tailored to
identify differential diagnoses from radiology reports. We first utilize GPT-4
to create 31,056 labeled reports, then fine-tune open source LLM using this
dataset. Evaluated on a set of 1,067 reports annotated by clinicians, the
proposed model achieves an average F1 score of 92.1\%, which is on par with
GPT-4 (90.8\%). Through this study, we provide a methodology for constructing
in-house LLMs that: match the performance of GPT, reduce dependence on
expensive proprietary models, and enhance the privacy and security of PHI.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.09181v1' target='_blank'>Can a large language model be a gaslighter?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wei Li, Luyao Zhu, Yang Song, Ruixi Lin, Rui Mao, Yang You</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-11 18:35:27</h6>
<p class='card-text'>Large language models (LLMs) have gained human trust due to their
capabilities and helpfulness. However, this in turn may allow LLMs to affect
users' mindsets by manipulating language. It is termed as gaslighting, a
psychological effect. In this work, we aim to investigate the vulnerability of
LLMs under prompt-based and fine-tuning-based gaslighting attacks. Therefore,
we propose a two-stage framework DeepCoG designed to: 1) elicit gaslighting
plans from LLMs with the proposed DeepGaslighting prompting template, and 2)
acquire gaslighting conversations from LLMs through our Chain-of-Gaslighting
method. The gaslighting conversation dataset along with a corresponding safe
dataset is applied to fine-tuning-based attacks on open-source LLMs and
anti-gaslighting safety alignment on these LLMs. Experiments demonstrate that
both prompt-based and fine-tuning-based attacks transform three open-source
LLMs into gaslighters. In contrast, we advanced three safety alignment
strategies to strengthen (by 12.05%) the safety guardrail of LLMs. Our safety
alignment strategies have minimal impacts on the utility of LLMs. Empirical
studies indicate that an LLM may be a potential gaslighter, even if it passed
the harmfulness test on general dangerous queries.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.09038v2' target='_blank'>SimpleStrat: Diversifying Language Model Generation with Stratification</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Justin Wong, Yury Orlovskiy, Michael Luo, Sanjit A. Seshia, Joseph E. Gonzalez</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-11 17:54:14</h6>
<p class='card-text'>Generating diverse responses from large language models (LLMs) is crucial for
applications such as planning/search and synthetic data generation, where
diversity provides distinct answers across generations. Prior approaches rely
on increasing temperature to increase diversity. However, contrary to popular
belief, we show not only does this approach produce lower quality individual
generations as temperature increases, but it depends on model's next-token
probabilities being similar to the true distribution of answers. We propose
SimpleStrat, an alternative approach that uses the language model itself to
partition the space into strata. At inference, a random stratum is selected and
a sample drawn from within the strata. To measure diversity, we introduce
CoverageQA, a dataset of underspecified questions with multiple equally
plausible answers, and assess diversity by measuring KL Divergence between the
output distribution and uniform distribution over valid ground truth answers.
As computing probability per response/solution for proprietary models is
infeasible, we measure recall on ground truth solutions. Our evaluation show
using SimpleStrat achieves higher recall by 0.05 compared to GPT-4o and 0.36
average reduction in KL Divergence compared to Llama 3.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.07869v3' target='_blank'>Benchmarking Agentic Workflow Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shuofei Qiao, Runnan Fang, Zhisong Qiu, Xiaobin Wang, Ningyu Zhang, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-10 12:41:19</h6>
<p class='card-text'>Large Language Models (LLMs), with their exceptional ability to handle a wide
range of tasks, have driven significant advancements in tackling reasoning and
planning tasks, wherein decomposing complex problems into executable workflows
is a crucial step in this process. Existing workflow evaluation frameworks
either focus solely on holistic performance or suffer from limitations such as
restricted scenario coverage, simplistic workflow structures, and lax
evaluation standards. To this end, we introduce WorfBench, a unified workflow
generation benchmark with multi-faceted scenarios and intricate graph workflow
structures. Additionally, we present WorfEval, a systemic evaluation protocol
utilizing subsequence and subgraph matching algorithms to accurately quantify
the LLM agent's workflow generation capabilities. Through comprehensive
evaluations across different types of LLMs, we discover distinct gaps between
the sequence planning capabilities and graph planning capabilities of LLM
agents, with even GPT-4 exhibiting a gap of around 15%. We also train two
open-source models and evaluate their generalization abilities on held-out
tasks. Furthermore, we observe that the generated workflows can enhance
downstream tasks, enabling them to achieve superior performance with less time
during inference. Code and dataset are available at
https://github.com/zjunlp/WorfBench.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.07765v1' target='_blank'>GameTraversalBenchmark: Evaluating Planning Abilities Of Large Language
  Models Through Traversing 2D Game Maps</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Muhammad Umair Nasir, Steven James, Julian Togelius</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-10 09:54:28</h6>
<p class='card-text'>Large language models (LLMs) have recently demonstrated great success in
generating and understanding natural language. While they have also shown
potential beyond the domain of natural language, it remains an open question as
to what extent and in which way these LLMs can plan. We investigate their
planning capabilities by proposing GameTraversalBenchmark (GTB), a benchmark
consisting of diverse 2D grid-based game maps. An LLM succeeds if it can
traverse through given objectives, with a minimum number of steps and a minimum
number of generation errors. We evaluate a number of LLMs on GTB and found that
GPT-4-Turbo achieved the highest score of 44.97% on GTB\_Score (GTBS), a
composite score that combines the three above criteria. Furthermore, we
preliminarily test large reasoning models, namely o1, which scores $67.84\%$ on
GTBS, indicating that the benchmark remains challenging for current models.
Code, data, and documentation are available at
https://github.com/umair-nasir14/Game-Traversal-Benchmark.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.07627v1' target='_blank'>Automatic Curriculum Expert Iteration for Reliable LLM Reasoning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zirui Zhao, Hanze Dong, Amrita Saha, Caiming Xiong, Doyen Sahoo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-10 05:43:07</h6>
<p class='card-text'>Hallucinations (i.e., generating plausible but inaccurate content) and
laziness (i.e. excessive refusals or defaulting to "I don't know") persist as
major challenges in LLM reasoning. Current efforts to reduce hallucinations
primarily focus on factual errors in knowledge-grounded tasks, often neglecting
hallucinations related to faulty reasoning. Meanwhile, some approaches render
LLMs overly conservative, limiting their problem-solving capabilities. To
mitigate hallucination and laziness in reasoning tasks, we propose Automatic
Curriculum Expert Iteration (Auto-CEI) to enhance LLM reasoning and align
responses to the model's capabilities--assertively answering within its limits
and declining when tasks exceed them. In our method, Expert Iteration explores
the reasoning trajectories near the LLM policy, guiding incorrect paths back on
track to reduce compounding errors and improve robustness; it also promotes
appropriate "I don't know" responses after sufficient reasoning attempts. The
curriculum automatically adjusts rewards, incentivizing extended reasoning
before acknowledging incapability, thereby pushing the limits of LLM reasoning
and aligning its behaviour with these limits. We compare Auto-CEI with various
SOTA baselines across logical reasoning, mathematics, and planning tasks, where
Auto-CEI achieves superior alignment by effectively balancing assertiveness and
conservativeness.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.19743v1' target='_blank'>AppBench: Planning of Multiple APIs from Various APPs for Complex User
  Instruction</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hongru Wang, Rui Wang, Boyang Xue, Heming Xia, Jingtao Cao, Zeming Liu, Jeff Z. Pan, Kam-Fai Wong</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-10 04:03:13</h6>
<p class='card-text'>Large Language Models (LLMs) can interact with the real world by connecting
with versatile external APIs, resulting in better problem-solving and task
automation capabilities. Previous research primarily focuses on APIs with
limited arguments from a single source or overlooks the complex dependency
relationship between different APIs. However, it is essential to utilize
multiple APIs collaboratively from various sources (e.g., different Apps in the
iPhone), especially for complex user instructions. In this paper, we introduce
\texttt{AppBench}, the first benchmark to evaluate LLMs' ability to plan and
execute multiple APIs from various sources in order to complete the user's
task. Specifically, we consider two significant challenges in multiple APIs:
\textit{1) graph structures:} some APIs can be executed independently while
others need to be executed one by one, resulting in graph-like execution order;
and \textit{2) permission constraints:} which source is authorized to execute
the API call. We have experimental results on 9 distinct LLMs; e.g., GPT-4o
achieves only a 2.0\% success rate at the most complex instruction, revealing
that the existing state-of-the-art LLMs still cannot perform well in this
situation even with the help of in-context learning and finetuning. Our code
and data are publicly available at https://github.com/ruleGreen/AppBench.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.12844v1' target='_blank'>TextLap: Customizing Language Models for Text-to-Layout Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jian Chen, Ruiyi Zhang, Yufan Zhou, Jennifer Healey, Jiuxiang Gu, Zhiqiang Xu, Changyou Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-09 19:51:38</h6>
<p class='card-text'>Automatic generation of graphical layouts is crucial for many real-world
applications, including designing posters, flyers, advertisements, and
graphical user interfaces. Given the incredible ability of Large language
models (LLMs) in both natural language understanding and generation, we believe
that we could customize an LLM to help people create compelling graphical
layouts starting with only text instructions from the user. We call our method
TextLap (text-based layout planning). It uses a curated instruction-based
layout planning dataset (InsLap) to customize LLMs as a graphic designer. We
demonstrate the effectiveness of TextLap and show that it outperforms strong
baselines, including GPT-4 based methods, for image generation and graphical
design benchmarks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.07331v2' target='_blank'>DA-Code: Agent Data Science Code Generation Benchmark for Large Language
  Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yiming Huang, Jianwen Luo, Yan Yu, Yitong Zhang, Fangyu Lei, Yifan Wei, Shizhu He, Lifu Huang, Xiao Liu, Jun Zhao, Kang Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-09 18:00:05</h6>
<p class='card-text'>We introduce DA-Code, a code generation benchmark specifically designed to
assess LLMs on agent-based data science tasks. This benchmark features three
core elements: First, the tasks within DA-Code are inherently challenging,
setting them apart from traditional code generation tasks and demanding
advanced coding skills in grounding and planning. Second, examples in DA-Code
are all based on real and diverse data, covering a wide range of complex data
wrangling and analytics tasks. Third, to solve the tasks, the models must
utilize complex data science programming languages, to perform intricate data
processing and derive the answers. We set up the benchmark in a controllable
and executable environment that aligns with real-world data analysis scenarios
and is scalable. The annotators meticulously design the evaluation suite to
ensure the accuracy and robustness of the evaluation. We develop the DA-Agent
baseline. Experiments show that although the baseline performs better than
other existing frameworks, using the current best LLMs achieves only 30.5%
accuracy, leaving ample room for improvement. We release our benchmark at
https://da-code-bench.github.io.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.07166v3' target='_blank'>Embodied Agent Interface: Benchmarking LLMs for Embodied Decision Making</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Manling Li, Shiyu Zhao, Qineng Wang, Kangrui Wang, Yu Zhou, Sanjana Srivastava, Cem Gokmen, Tony Lee, Li Erran Li, Ruohan Zhang, Weiyu Liu, Percy Liang, Li Fei-Fei, Jiayuan Mao, Jiajun Wu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-09 17:59:00</h6>
<p class='card-text'>We aim to evaluate Large Language Models (LLMs) for embodied decision making.
While a significant body of work has been leveraging LLMs for decision making
in embodied environments, we still lack a systematic understanding of their
performance because they are usually applied in different domains, for
different purposes, and built based on different inputs and outputs.
Furthermore, existing evaluations tend to rely solely on a final success rate,
making it difficult to pinpoint what ability is missing in LLMs and where the
problem lies, which in turn blocks embodied agents from leveraging LLMs
effectively and selectively. To address these limitations, we propose a
generalized interface (Embodied Agent Interface) that supports the
formalization of various types of tasks and input-output specifications of
LLM-based modules. Specifically, it allows us to unify 1) a broad set of
embodied decision-making tasks involving both state and temporally extended
goals, 2) four commonly-used LLM-based modules for decision making: goal
interpretation, subgoal decomposition, action sequencing, and transition
modeling, and 3) a collection of fine-grained metrics which break down
evaluation into various types of errors, such as hallucination errors,
affordance errors, various types of planning errors, etc. Overall, our
benchmark offers a comprehensive assessment of LLMs' performance for different
subtasks, pinpointing the strengths and weaknesses in LLM-powered embodied AI
systems, and providing insights for effective and selective use of LLMs in
embodied decision making.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.06328v2' target='_blank'>Auto-Evolve: Enhancing Large Language Model's Performance via
  Self-Reasoning Framework</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Krishna Aswani, Huilin Lu, Pranav Patankar, Priya Dhalwani, Iris Tan, Jayant Ganeshmohan, Simon Lacasse</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-08 20:07:47</h6>
<p class='card-text'>Recent advancements in prompt engineering strategies, such as
Chain-of-Thought (CoT) and Self-Discover, have demonstrated significant
potential in improving the reasoning abilities of Large Language Models (LLMs).
However, these state-of-the-art (SOTA) prompting strategies rely on single or
fixed set of static seed reasoning modules like "think step by step" or "break
down this problem" intended to simulate human approach to problem-solving. This
constraint limits the flexibility of models in tackling diverse problems
effectively. In this paper, we introduce Auto-Evolve, a novel framework that
enables LLMs to self-create dynamic reasoning modules and downstream action
plan, resulting in significant improvements over current SOTA methods. We
evaluate Auto-Evolve on the challenging BigBench-Hard (BBH) dataset with Claude
2.0, Claude 3 Sonnet, Mistral Large, and GPT 4, where it consistently
outperforms the SOTA prompt strategies. Auto-Evolve outperforms CoT by up to
10.4% and on an average by 7% across these four models. Our framework
introduces two innovations: a) Auto-Evolve dynamically generates reasoning
modules for each task while aligning with human reasoning paradigm, thus
eliminating the need for predefined templates. b) We introduce an iterative
refinement component, that incrementally refines instruction guidance for LLMs
and helps boost performance by average 2.8% compared to doing it in a single
step.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.06239v2' target='_blank'>OrionNav: Online Planning for Robot Autonomy with Context-Aware LLM and
  Open-Vocabulary Semantic Scene Graphs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Venkata Naren Devarakonda, Raktim Gautam Goswami, Ali Umut Kaypak, Naman Patel, Rooholla Khorrambakht, Prashanth Krishnamurthy, Farshad Khorrami</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-08 17:54:11</h6>
<p class='card-text'>Enabling robots to autonomously navigate unknown, complex, dynamic
environments and perform diverse tasks remains a fundamental challenge in
developing robust autonomous physical agents. These agents must effectively
perceive their surroundings while leveraging world knowledge for
decision-making. Although recent approaches utilize vision-language and large
language models for scene understanding and planning, they often rely on
offline processing, offboard compute, make simplifying assumptions about the
environment and perception, limiting real-world applicability. We present a
novel framework for real-time onboard autonomous navigation in unknown
environments that change over time by integrating multi-level abstraction in
both perception and planning pipelines. Our system fuses data from multiple
onboard sensors for localization and mapping and integrates it with
open-vocabulary semantics to generate hierarchical scene graphs from
continuously updated semantic object map. The LLM-based planner uses these
graphs to create multi-step plans that guide low-level controllers in executing
navigation tasks specified in natural language. The system's real-time
operation enables the LLM to adjust its plans based on updates to the scene
graph and task execution status, ensuring continuous adaptation to new
situations or when the current plan cannot accomplish the task, a key advantage
over static or rule-based systems. We demonstrate our system's efficacy on a
quadruped navigating dynamic environments, showcasing its adaptability and
robustness in diverse scenarios.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.06215v2' target='_blank'>DataEnvGym: Data Generation Agents in Teacher Environments with Student
  Feedback</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zaid Khan, Elias Stengel-Eskin, Jaemin Cho, Mohit Bansal</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-08 17:20:37</h6>
<p class='card-text'>The process of creating training data to teach models is currently driven by
humans, who manually analyze model weaknesses and plan how to create data that
improves a student model. Approaches using LLMs as annotators reduce human
effort, but still require humans to interpret feedback from evaluations and
control the LLM to produce data the student needs. Automating this
labor-intensive process by creating autonomous data generation agents - or
teachers - is desirable, but requires environments that can simulate the
feedback-driven, iterative, closed loop of data creation. To enable rapid,
scalable testing for such agents and their modules, we introduce DataEnvGym, a
testbed of teacher environments for data generation agents. DataEnvGym frames
data generation as a sequential decision-making task, involving an agent
consisting of a data generation policy (which generates a plan for creating
training data) and a data generation engine (which transforms the plan into
data), inside an environment that provides student feedback. The agent's goal
is to improve student performance. Students are iteratively trained and
evaluated on generated data, and their feedback (in the form of errors or weak
skills) is reported to the agent after each iteration. DataEnvGym includes
multiple teacher environment instantiations across 3 levels of structure in the
state representation and action space. More structured environments are based
on inferred skills and offer more interpretability and curriculum control. We
support 4 domains (math, code, VQA, and tool-use) and test multiple students
and teachers. Example agents in our teaching environments can iteratively
improve students across tasks and settings. Moreover, we show that environments
teach different skill levels and test variants of key modules, pointing to
future work in improving data generation agents, engines, and feedback
mechanisms.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.06203v1' target='_blank'>Integrating Planning into Single-Turn Long-Form Text Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yi Liang, You Wu, Honglei Zhuang, Li Chen, Jiaming Shen, Yiling Jia, Zhen Qin, Sumit Sanghai, Xuanhui Wang, Carl Yang, Michael Bendersky</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-08 17:02:40</h6>
<p class='card-text'>Generating high-quality, in-depth textual documents, such as academic papers,
news articles, Wikipedia entries, and books, remains a significant challenge
for Large Language Models (LLMs). In this paper, we propose to use planning to
generate long form content. To achieve our goal, we generate intermediate steps
via an auxiliary task that teaches the LLM to plan, reason and structure before
generating the final text. Our main novelty lies in a single auxiliary task
that does not require multiple rounds of prompting or planning. To overcome the
scarcity of training data for these intermediate steps, we leverage LLMs to
generate synthetic intermediate writing data such as outlines, key information
and summaries from existing full articles. Our experiments demonstrate on two
datasets from different domains, namely the scientific news dataset SciNews and
Wikipedia datasets in KILT-Wiki and FreshWiki, that LLMs fine-tuned with the
auxiliary task generate higher quality documents. We observed +2.5% improvement
in ROUGE-Lsum, and a strong 3.60 overall win/loss ratio via human SxS
evaluation, with clear wins in organization, relevance, and verifiability.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.06153v3' target='_blank'>AgentSquare: Automatic LLM Agent Search in Modular Design Space</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yu Shang, Yu Li, Keyu Zhao, Likai Ma, Jiahe Liu, Fengli Xu, Yong Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-08 15:52:42</h6>
<p class='card-text'>Recent advancements in Large Language Models (LLMs) have led to a rapid
growth of agentic systems capable of handling a wide range of complex tasks.
However, current research largely relies on manual, task-specific design,
limiting their adaptability to novel tasks. In this paper, we introduce a new
research problem: Modularized LLM Agent Search (MoLAS). We propose a modular
design space that abstracts existing LLM agent designs into four fundamental
modules with uniform IO interface: Planning, Reasoning, Tool Use, and Memory.
Building on this design space, we present a novel LLM agent search framework
called AgentSquare, which introduces two core mechanisms, i.e., module
evolution and recombination, to efficiently search for optimized LLM agents. To
further accelerate the process, we design a performance predictor that uses
in-context surrogate models to skip unpromising agent designs. Extensive
experiments across six benchmarks, covering the diverse scenarios of web,
embodied, tool use and game applications, show that AgentSquare substantially
outperforms hand-crafted agents, achieving an average performance gain of 17.2%
against best-known human designs. Moreover, AgentSquare can generate
interpretable design insights, enabling a deeper understanding of agentic
architecture and its impact on task performance. We believe that the modular
design space and AgentSquare search framework offer a platform for fully
exploiting the potential of prior successful designs and consolidating the
collective efforts of research community. Code repo is available at
https://github.com/tsinghua-fib-lab/AgentSquare.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.06108v1' target='_blank'>ConceptAgent: LLM-Driven Precondition Grounding and Tree Search for
  Robust Task Planning and Execution</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Corban Rivera, Grayson Byrd, William Paul, Tyler Feldman, Meghan Booker, Emma Holmes, David Handelman, Bethany Kemp, Andrew Badger, Aurora Schmidt, Krishna Murthy Jatavallabhula, Celso M de Melo, Lalithkumar Seenivasan, Mathias Unberath, Rama Chellappa</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-08 15:05:40</h6>
<p class='card-text'>Robotic planning and execution in open-world environments is a complex
problem due to the vast state spaces and high variability of task embodiment.
Recent advances in perception algorithms, combined with Large Language Models
(LLMs) for planning, offer promising solutions to these challenges, as the
common sense reasoning capabilities of LLMs provide a strong heuristic for
efficiently searching the action space. However, prior work fails to address
the possibility of hallucinations from LLMs, which results in failures to
execute the planned actions largely due to logical fallacies at high- or
low-levels. To contend with automation failure due to such hallucinations, we
introduce ConceptAgent, a natural language-driven robotic platform designed for
task execution in unstructured environments. With a focus on scalability and
reliability of LLM-based planning in complex state and action spaces, we
present innovations designed to limit these shortcomings, including 1)
Predicate Grounding to prevent and recover from infeasible actions, and 2) an
embodied version of LLM-guided Monte Carlo Tree Search with self reflection. In
simulation experiments, ConceptAgent achieved a 19% task completion rate across
three room layouts and 30 easy level embodied tasks outperforming other
state-of-the-art LLM-driven reasoning baselines that scored 10.26% and 8.11% on
the same benchmark. Additionally, ablation studies on moderate to hard embodied
tasks revealed a 20% increase in task completion from the baseline agent to the
fully enhanced ConceptAgent, highlighting the individual and combined
contributions of Predicate Grounding and LLM-guided Tree Search to enable more
robust automation in complex state and action spaces.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.07245v1' target='_blank'>AAAI Workshop on AI Planning for Cyber-Physical Systems -- CAIPI24</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Oliver Niggemann, Gautam Biswas, Alexander Diedrich, Jonas Ehrhardt, René Heesch, Niklas Widulle</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-08 05:52:00</h6>
<p class='card-text'>The workshop 'AI-based Planning for Cyber-Physical Systems', which took place
on February 26, 2024, as part of the 38th Annual AAAI Conference on Artificial
Intelligence in Vancouver, Canada, brought together researchers to discuss
recent advances in AI planning methods for Cyber-Physical Systems (CPS). CPS
pose a major challenge due to their complexity and data-intensive nature, which
often exceeds the capabilities of traditional planning algorithms. The workshop
highlighted new approaches such as neuro-symbolic architectures, large language
models (LLMs), deep reinforcement learning and advances in symbolic planning.
These techniques are promising when it comes to managing the complexity of CPS
and have potential for real-world applications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.05669v2' target='_blank'>ACPBench: Reasoning about Action, Change, and Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Harsha Kokel, Michael Katz, Kavitha Srinivas, Shirin Sohrabi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-08 03:48:57</h6>
<p class='card-text'>There is an increasing body of work using Large Language Models (LLMs) as
agents for orchestrating workflows and making decisions in domains that require
planning and multi-step reasoning. As a result, it is imperative to evaluate
LLMs on core skills required for planning. In this work, we present ACPBench, a
benchmark for evaluating the reasoning tasks in the field of planning. The
benchmark consists of 7 reasoning tasks over 13 planning domains. The
collection is constructed from planning domains described in a formal language.
This allows us to synthesize problems with provably correct solutions across
many tasks and domains. Further, it allows us the luxury of scale without
additional human effort, i.e., many additional problems can be created
automatically. Our extensive evaluation of 22 LLMs and OpenAI o1 reasoning
models highlights the significant gap in the reasoning capability of the LLMs.
Our findings with OpenAI o1, a multi-turn reasoning model, reveal significant
gains in performance on multiple-choice questions, yet surprisingly, no notable
progress is made on boolean questions.
  The ACPBench collection is available at https://ibm.github.io/ACPBench.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.05656v1' target='_blank'>On the Modeling Capabilities of Large Language Models for Sequential
  Decision Making</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Martin Klissarov, Devon Hjelm, Alexander Toshev, Bogdan Mazoure</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-08 03:12:57</h6>
<p class='card-text'>Large pretrained models are showing increasingly better performance in
reasoning and planning tasks across different modalities, opening the
possibility to leverage them for complex sequential decision making problems.
In this paper, we investigate the capabilities of Large Language Models (LLMs)
for reinforcement learning (RL) across a diversity of interactive domains. We
evaluate their ability to produce decision-making policies, either directly, by
generating actions, or indirectly, by first generating reward models to train
an agent with RL. Our results show that, even without task-specific
fine-tuning, LLMs excel at reward modeling. In particular, crafting rewards
through artificial intelligence (AI) feedback yields the most generally
applicable approach and can enhance performance by improving credit assignment
and exploration. Finally, in environments with unfamiliar dynamics, we explore
how fine-tuning LLMs with synthetic data can significantly improve their reward
modeling capabilities while mitigating catastrophic forgetting, further
broadening their utility in sequential decision-making tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.05045v1' target='_blank'>Can LLMs plan paths with extra hints from solvers?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Erik Wu, Sayan Mitra</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-07 14:00:08</h6>
<p class='card-text'>Large Language Models (LLMs) have shown remarkable capabilities in natural
language processing, mathematical problem solving, and tasks related to program
synthesis. However, their effectiveness in long-term planning and higher-order
reasoning has been noted to be limited and fragile. This paper explores an
approach for enhancing LLM performance in solving a classical robotic planning
task by integrating solver-generated feedback. We explore four different
strategies for providing feedback, including visual feedback, we utilize
fine-tuning, and we evaluate the performance of three different LLMs across a
10 standard and 100 more randomly generated planning problems. Our results
suggest that the solver-generated feedback improves the LLM's ability to solve
the moderately difficult problems, but the harder problems still remain out of
reach. The study provides detailed analysis of the effects of the different
hinting strategies and the different planning tendencies of the evaluated LLMs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.04612v1' target='_blank'>Regressing the Relative Future: Efficient Policy Optimization for
  Multi-turn RLHF</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhaolin Gao, Wenhao Zhan, Jonathan D. Chang, Gokul Swamy, Kianté Brantley, Jason D. Lee, Wen Sun</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-06 20:20:22</h6>
<p class='card-text'>Large Language Models (LLMs) have achieved remarkable success at tasks like
summarization that involve a single turn of interaction. However, they can
still struggle with multi-turn tasks like dialogue that require long-term
planning. Previous works on multi-turn dialogue extend single-turn
reinforcement learning from human feedback (RLHF) methods to the multi-turn
setting by treating all prior dialogue turns as a long context. Such approaches
suffer from covariate shift: the conversations in the training set have
previous turns generated by some reference policy, which means that low
training error may not necessarily correspond to good performance when the
learner is actually in the conversation loop. In response, we introduce
REgressing the RELative FUture (REFUEL), an efficient policy optimization
approach designed to address multi-turn RLHF in LLMs. REFUEL employs a single
model to estimate $Q$-values and trains on self-generated data, addressing the
covariate shift issue. REFUEL frames the multi-turn RLHF problem as a sequence
of regression tasks on iteratively collected datasets, enabling ease of
implementation. Theoretically, we prove that REFUEL can match the performance
of any policy covered by the training set. Empirically, we evaluate our
algorithm by using Llama-3.1-70B-it to simulate a user in conversation with our
model. REFUEL consistently outperforms state-of-the-art methods such as DPO and
REBEL across various settings. Furthermore, despite having only 8 billion
parameters, Llama-3-8B-it fine-tuned with REFUEL outperforms Llama-3.1-70B-it
on long multi-turn dialogues. Implementation of REFUEL can be found at
https://github.com/ZhaolinGao/REFUEL/, and models trained by REFUEL can be
found at https://huggingface.co/Cornell-AGI.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.04223v1' target='_blank'>Multimodal Large Language Models for Inverse Molecular Design with
  Retrosynthetic Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Gang Liu, Michael Sun, Wojciech Matusik, Meng Jiang, Jie Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-05 16:35:32</h6>
<p class='card-text'>While large language models (LLMs) have integrated images, adapting them to
graphs remains challenging, limiting their applications in materials and drug
design. This difficulty stems from the need for coherent autoregressive
generation across texts and graphs. To address this, we introduce Llamole, the
first multimodal LLM capable of interleaved text and graph generation, enabling
molecular inverse design with retrosynthetic planning. Llamole integrates a
base LLM with the Graph Diffusion Transformer and Graph Neural Networks for
multi-conditional molecular generation and reaction inference within texts,
while the LLM, with enhanced molecular understanding, flexibly controls
activation among the different graph modules. Additionally, Llamole integrates
A* search with LLM-based cost functions for efficient retrosynthetic planning.
We create benchmarking datasets and conduct extensive experiments to evaluate
Llamole against in-context learning and supervised fine-tuning. Llamole
significantly outperforms 14 adapted LLMs across 12 metrics for controllable
molecular design and retrosynthetic planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.04155v1' target='_blank'>Toxic Subword Pruning for Dialogue Response Generation on Large Language
  Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hongyuan Lu, Wai Lam</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-05 13:30:33</h6>
<p class='card-text'>How to defend large language models (LLMs) from generating toxic content is
an important research area. Yet, most research focused on various model
training techniques to remediate LLMs by updating their weights. A typical
related research area is safety alignment. This however is often costly and
tedious and can expose the model to even more problems such as catastrophic
forgetting if the trainings are not carefully handled by experienced NLP
practitioners. We thus propose a simple yet effective and novel algorithm,
namely \textbf{Tox}ic Subword \textbf{Prun}ing (ToxPrune) to prune the subword
contained by the toxic words from BPE in trained LLMs. In contrast to the
previous work that demonstrates pruning BPE tokens as harmful to the task of
machine translation, we surprisingly found its usefulness in preventing toxic
content from being generated on LLMs. Fortunately, our findings suggest that
ToxPrune simultaneously improves the toxic language model NSFW-3B on the task
of dialogue response generation obviously. We surprisingly found that ToxPrune
can even obviously improve official Llama-3.1-6B in the metric of dialogue
diversity. Extensive automatic results and human evaluation indicate that
ToxPrune could be helpful for both remediating toxic LLMs and improving
non-toxic LLMs on the task of dialogue response generation.\footnote{We plan to
release the resources to facilitate future work.}</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.03997v1' target='_blank'>YOLO-MARL: You Only LLM Once for Multi-agent Reinforcement Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuan Zhuang, Yi Shen, Zhili Zhang, Yuxiao Chen, Fei Miao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-05 01:44:11</h6>
<p class='card-text'>Advancements in deep multi-agent reinforcement learning (MARL) have
positioned it as a promising approach for decision-making in cooperative games.
However, it still remains challenging for MARL agents to learn cooperative
strategies for some game environments. Recently, large language models (LLMs)
have demonstrated emergent reasoning capabilities, making them promising
candidates for enhancing coordination among the agents. However, due to the
model size of LLMs, it can be expensive to frequently infer LLMs for actions
that agents can take. In this work, we propose You Only LLM Once for MARL
(YOLO-MARL), a novel framework that leverages the high-level task planning
capabilities of LLMs to improve the policy learning process of multi-agents in
cooperative games. Notably, for each game environment, YOLO-MARL only requires
one time interaction with LLMs in the proposed strategy generation, state
interpretation and planning function generation modules, before the MARL policy
training process. This avoids the ongoing costs and computational time
associated with frequent LLMs API calls during training. Moreover, the trained
decentralized normal-sized neural network-based policies operate independently
of the LLM. We evaluate our method across three different environments and
demonstrate that YOLO-MARL outperforms traditional MARL algorithms.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.03907v1' target='_blank'>ActPlan-1K: Benchmarking the Procedural Planning Ability of Visual
  Language Models in Household Activities</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ying Su, Zhan Ling, Haochen Shi, Jiayang Cheng, Yauwai Yim, Yangqiu Song</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-04 20:21:40</h6>
<p class='card-text'>Large language models~(LLMs) have been adopted to process textual task
description and accomplish procedural planning in embodied AI tasks because of
their powerful reasoning ability. However, there is still lack of study on how
vision language models~(VLMs) behave when multi-modal task inputs are
considered. Counterfactual planning that evaluates the model's reasoning
ability over alternative task situations are also under exploited. In order to
evaluate the planning ability of both multi-modal and counterfactual aspects,
we propose ActPlan-1K. ActPlan-1K is a multi-modal planning benchmark
constructed based on ChatGPT and household activity simulator iGibson2. The
benchmark consists of 153 activities and 1,187 instances. Each instance
describing one activity has a natural language task description and multiple
environment images from the simulator. The gold plan of each instance is action
sequences over the objects in provided scenes. Both the correctness and
commonsense satisfaction are evaluated on typical VLMs. It turns out that
current VLMs are still struggling at generating human-level procedural plans
for both normal activities and counterfactual activities. We further provide
automatic evaluation metrics by finetuning over BLEURT model to facilitate
future research on our benchmark.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.03864v1' target='_blank'>DOTS: Learning to Reason Dynamically in LLMs via Optimal Reasoning
  Trajectories Search</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Murong Yue, Wenlin Yao, Haitao Mi, Dian Yu, Ziyu Yao, Dong Yu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-04 18:58:09</h6>
<p class='card-text'>Enhancing the capability of large language models (LLMs) in reasoning has
gained significant attention in recent years. Previous studies have
demonstrated the effectiveness of various prompting strategies in aiding LLMs
in reasoning (called "reasoning actions"), such as step-by-step thinking,
reflecting before answering, solving with programs, and their combinations.
However, these approaches often applied static, predefined reasoning actions
uniformly to all questions, without considering the specific characteristics of
each question or the capability of the task-solving LLM. In this paper, we
propose DOTS, an approach enabling LLMs to reason dynamically via optimal
reasoning trajectory search, tailored to the specific characteristics of each
question and the inherent capability of the task-solving LLM. Our approach
involves three key steps: i) defining atomic reasoning action modules that can
be composed into various reasoning action trajectories; ii) searching for the
optimal action trajectory for each training question through iterative
exploration and evaluation for the specific task-solving LLM; and iii) using
the collected optimal trajectories to train an LLM to plan for the reasoning
trajectories of unseen questions. In particular, we propose two learning
paradigms, i.e., fine-tuning an external LLM as a planner to guide the
task-solving LLM, or directly fine-tuning the task-solving LLM with an
internalized capability for reasoning actions planning. Our experiments across
eight reasoning tasks show that our method consistently outperforms static
reasoning techniques and the vanilla instruction tuning approach. Further
analysis reveals that our method enables LLMs to adjust their computation based
on problem complexity, allocating deeper thinking and reasoning to harder
problems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.03645v1' target='_blank'>GenSim2: Scaling Robot Data Generation with Multi-modal and Reasoning
  LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Pu Hua, Minghuan Liu, Annabella Macaluso, Yunfeng Lin, Weinan Zhang, Huazhe Xu, Lirui Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-04 17:51:33</h6>
<p class='card-text'>Robotic simulation today remains challenging to scale up due to the human
efforts required to create diverse simulation tasks and scenes.
Simulation-trained policies also face scalability issues as many sim-to-real
methods focus on a single task. To address these challenges, this work proposes
GenSim2, a scalable framework that leverages coding LLMs with multi-modal and
reasoning capabilities for complex and realistic simulation task creation,
including long-horizon tasks with articulated objects. To automatically
generate demonstration data for these tasks at scale, we propose planning and
RL solvers that generalize within object categories. The pipeline can generate
data for up to 100 articulated tasks with 200 objects and reduce the required
human efforts. To utilize such data, we propose an effective multi-task
language-conditioned policy architecture, dubbed proprioceptive point-cloud
transformer (PPT), that learns from the generated demonstrations and exhibits
strong sim-to-real zero-shot transfer. Combining the proposed pipeline and the
policy architecture, we show a promising usage of GenSim2 that the generated
data can be used for zero-shot transfer or co-train with real-world collected
data, which enhances the policy performance by 20% compared with training
exclusively on limited real data.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.03806v1' target='_blank'>Metadata Matters for Time Series: Informative Forecasting with
  Transformers</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiaxiang Dong, Haixu Wu, Yuxuan Wang, Li Zhang, Jianmin Wang, Mingsheng Long</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-04 11:37:55</h6>
<p class='card-text'>Time series forecasting is prevalent in extensive real-world applications,
such as financial analysis and energy planning. Previous studies primarily
focus on time series modality, endeavoring to capture the intricate variations
and dependencies inherent in time series. Beyond numerical time series data, we
notice that metadata (e.g.~dataset and variate descriptions) also carries
valuable information essential for forecasting, which can be used to identify
the application scenario and provide more interpretable knowledge than digit
sequences. Inspired by this observation, we propose a Metadata-informed Time
Series Transformer (MetaTST), which incorporates multiple levels of
context-specific metadata into Transformer forecasting models to enable
informative time series forecasting. To tackle the unstructured nature of
metadata, MetaTST formalizes them into natural languages by pre-designed
templates and leverages large language models (LLMs) to encode these texts into
metadata tokens as a supplement to classic series tokens, resulting in an
informative embedding. Further, a Transformer encoder is employed to
communicate series and metadata tokens, which can extend series representations
by metadata information for more accurate forecasting. This design also allows
the model to adaptively learn context-specific patterns across various
scenarios, which is particularly effective in handling large-scale,
diverse-scenario forecasting tasks. Experimentally, MetaTST achieves
state-of-the-art compared to advanced time series models and LLM-based methods
on widely acknowledged short- and long-term forecasting benchmarks, covering
both single-dataset individual and multi-dataset joint training settings.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.03035v1' target='_blank'>SPINE: Online Semantic Planning for Missions with Incomplete Natural
  Language Specifications in Unstructured Environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zachary Ravichandran, Varun Murali, Mariliza Tzes, George J. Pappas, Vijay Kumar</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-03 22:41:47</h6>
<p class='card-text'>As robots become increasingly capable, users will want to describe high-level
missions and have robots fill in the gaps. In many realistic settings,
pre-built maps are difficult to obtain, so execution requires exploration and
mapping that are necessary and specific to the mission. Consider an emergency
response scenario where a user commands a robot, "triage impacted regions." The
robot must infer relevant semantics (victims, etc.) and exploration targets
(damaged regions) based on priors or other context, then explore and refine its
plan online. These missions are incompletely specified, meaning they imply
subtasks and semantics. While many semantic planning methods operate online,
they are typically designed for well specified tasks such as object search or
exploration. Recently, Large Language Models (LLMs) have demonstrated powerful
contextual reasoning over a range of robotic tasks described in natural
language. However, existing LLM planners typically do not consider online
planning or complex missions; rather, relevant subtasks are provided by a
pre-built map or a user. We address these limitations via SPINE (online
Semantic Planner for missions with Incomplete Natural language specifications
in unstructured Environments). SPINE uses an LLM to reason about subtasks
implied by the mission then realizes these subtasks in a receding horizon
framework. Tasks are automatically validated for safety and refined online with
new observations. We evaluate SPINE in simulation and real-world settings.
Evaluation missions require multiple steps of semantic reasoning and
exploration in cluttered outdoor environments of over 20,000m$^2$ area. We
evaluate SPINE against competitive baselines in single-agent and air-ground
teaming applications. Please find videos and software on our project page:
https://zacravichandran.github.io/SPINE</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.02958v1' target='_blank'>AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Patara Trirat, Wonyong Jeong, Sung Ju Hwang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-03 20:01:09</h6>
<p class='card-text'>Automated machine learning (AutoML) accelerates AI development by automating
tasks in the development pipeline, such as optimal model search and
hyperparameter tuning. Existing AutoML systems often require technical
expertise to set up complex tools, which is in general time-consuming and
requires a large amount of human effort. Therefore, recent works have started
exploiting large language models (LLM) to lessen such burden and increase the
usability of AutoML frameworks via a natural language interface, allowing
non-expert users to build their data-driven solutions. These methods, however,
are usually designed only for a particular process in the AI development
pipeline and do not efficiently use the inherent capacity of the LLMs. This
paper proposes AutoML-Agent, a novel multi-agent framework tailored for
full-pipeline AutoML, i.e., from data retrieval to model deployment.
AutoML-Agent takes user's task descriptions, facilitates collaboration between
specialized LLM agents, and delivers deployment-ready models. Unlike existing
work, instead of devising a single plan, we introduce a retrieval-augmented
planning strategy to enhance exploration to search for more optimal plans. We
also decompose each plan into sub-tasks (e.g., data preprocessing and neural
network design) each of which is solved by a specialized agent we build via
prompting executing in parallel, making the search process more efficient.
Moreover, we propose a multi-stage verification to verify executed results and
guide the code generation LLM in implementing successful solutions. Extensive
experiments on seven downstream tasks using fourteen datasets show that
AutoML-Agent achieves a higher success rate in automating the full AutoML
process, yielding systems with good performance throughout the diverse domains.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.02874v2' target='_blank'>Real-World Cooking Robot System from Recipes Based on Food State
  Recognition Using Foundation Models and PDDL</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Naoaki Kanazawa, Kento Kawaharazuka, Yoshiki Obinata, Kei Okada, Masayuki Inaba</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-03 18:02:56</h6>
<p class='card-text'>Although there is a growing demand for cooking behaviours as one of the
expected tasks for robots, a series of cooking behaviours based on new recipe
descriptions by robots in the real world has not yet been realised. In this
study, we propose a robot system that integrates real-world executable robot
cooking behaviour planning using the Large Language Model (LLM) and classical
planning of PDDL descriptions, and food ingredient state recognition learning
from a small number of data using the Vision-Language model (VLM). We succeeded
in experiments in which PR2, a dual-armed wheeled robot, performed cooking from
arranged new recipes in a real-world environment, and confirmed the
effectiveness of the proposed system.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.12836v1' target='_blank'>EditRoom: LLM-parameterized Graph Diffusion for Composable 3D Room
  Layout Editing</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kaizhi Zheng, Xiaotong Chen, Xuehai He, Jing Gu, Linjie Li, Zhengyuan Yang, Kevin Lin, Jianfeng Wang, Lijuan Wang, Xin Eric Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-03 17:42:24</h6>
<p class='card-text'>Given the steep learning curve of professional 3D software and the
time-consuming process of managing large 3D assets, language-guided 3D scene
editing has significant potential in fields such as virtual reality, augmented
reality, and gaming. However, recent approaches to language-guided 3D scene
editing either require manual interventions or focus only on appearance
modifications without supporting comprehensive scene layout changes. In
response, we propose Edit-Room, a unified framework capable of executing a
variety of layout edits through natural language commands, without requiring
manual intervention. Specifically, EditRoom leverages Large Language Models
(LLMs) for command planning and generates target scenes using a diffusion-based
method, enabling six types of edits: rotate, translate, scale, replace, add,
and remove. To address the lack of data for language-guided 3D scene editing,
we have developed an automatic pipeline to augment existing 3D scene synthesis
datasets and introduced EditRoom-DB, a large-scale dataset with 83k editing
pairs, for training and evaluation. Our experiments demonstrate that our
approach consistently outperforms other baselines across all metrics,
indicating higher accuracy and coherence in language-guided scene layout
editing.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.02644v1' target='_blank'>Agent Security Bench (ASB): Formalizing and Benchmarking Attacks and
  Defenses in LLM-based Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hanrong Zhang, Jingyuan Huang, Kai Mei, Yifei Yao, Zhenting Wang, Chenlu Zhan, Hongwei Wang, Yongfeng Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-03 16:30:47</h6>
<p class='card-text'>Although LLM-based agents, powered by Large Language Models (LLMs), can use
external tools and memory mechanisms to solve complex real-world tasks, they
may also introduce critical security vulnerabilities. However, the existing
literature does not comprehensively evaluate attacks and defenses against
LLM-based agents. To address this, we introduce Agent Security Bench (ASB), a
comprehensive framework designed to formalize, benchmark, and evaluate the
attacks and defenses of LLM-based agents, including 10 scenarios (e.g.,
e-commerce, autonomous driving, finance), 10 agents targeting the scenarios,
over 400 tools, 23 different types of attack/defense methods, and 8 evaluation
metrics. Based on ASB, we benchmark 10 prompt injection attacks, a memory
poisoning attack, a novel Plan-of-Thought backdoor attack, a mixed attack, and
10 corresponding defenses across 13 LLM backbones with nearly 90,000 testing
cases in total. Our benchmark results reveal critical vulnerabilities in
different stages of agent operation, including system prompt, user prompt
handling, tool usage, and memory retrieval, with the highest average attack
success rate of 84.30\%, but limited effectiveness shown in current defenses,
unveiling important works to be done in terms of agent security for the
community. Our code can be found at https://github.com/agiresearch/ASB.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.03781v1' target='_blank'>Towards the Pedagogical Steering of Large Language Models for Tutoring:
  A Case Study with Modeling Productive Failure</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Romain Puech, Jakub Macina, Julia Chatain, Mrinmaya Sachan, Manu Kapur</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-03 16:15:41</h6>
<p class='card-text'>One-to-one tutoring is one of the most efficient methods of teaching.
Following the rise in popularity of Large Language Models (LLMs), there have
been efforts to use them to create conversational tutoring systems, which can
make the benefits of one-to-one tutoring accessible to everyone. However,
current LLMs are primarily trained to be helpful assistants and thus lack
crucial pedagogical skills. For example, they often quickly reveal the solution
to the student and fail to plan for a richer multi-turn pedagogical
interaction. To use LLMs in pedagogical scenarios, they need to be steered
towards using effective teaching strategies: a problem we introduce as
Pedagogical Steering and believe to be crucial for the efficient use of LLMs as
tutors. We address this problem by formalizing a concept of tutoring strategy,
and introducing StratL, an algorithm to model a strategy and use prompting to
steer the LLM to follow this strategy. As a case study, we create a prototype
tutor for high school math following Productive Failure (PF), an advanced and
effective learning design. To validate our approach in a real-world setting, we
run a field study with 17 high school students in Singapore. We quantitatively
show that StratL succeeds in steering the LLM to follow a Productive Failure
tutoring strategy. We also thoroughly investigate the existence of spillover
effects on desirable properties of the LLM, like its ability to generate
human-like answers. Based on these results, we highlight the challenges in
Pedagogical Steering and suggest opportunities for further improvements. We
further encourage follow-up research by releasing a dataset of Productive
Failure problems and the code of our prototype and algorithm.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.02428v1' target='_blank'>Collective Critics for Creative Story Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Minwook Bae, Hyounghun Kim</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-03 12:21:17</h6>
<p class='card-text'>Generating a long story of several thousand words with narrative coherence
using Large Language Models (LLMs) has been a challenging task. Previous
research has addressed this challenge by proposing different frameworks that
create a story plan and generate a long story based on that plan. However,
these frameworks have been mainly focusing on maintaining narrative coherence
in stories, often overlooking creativity in story planning and the
expressiveness of the stories generated from those plans, which are desirable
properties to captivate readers' interest. In this paper, we propose Collective
Critics for Creative Story Generation framework (CritiCS), which is composed of
plan refining stage (CrPlan) and story generation stage (CrText), to integrate
a collective revision mechanism that promotes those properties into long-form
story generation process. Specifically, in each stage, a group of LLM critics
and one leader collaborate to incrementally refine drafts of plan and story
throughout multiple rounds. Extensive human evaluation shows that the CritiCS
can significantly enhance story creativity and reader engagement, while also
maintaining narrative coherence. Furthermore, the design of the framework
allows active participation from human writers in any role within the critique
process, enabling interactive human-machine collaboration in story writing.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.02231v1' target='_blank'>SEAL: SEmantic-Augmented Imitation Learning via Language Model</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chengyang Gu, Yuxin Pan, Haotian Bai, Hui Xiong, Yize Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-03 05:53:10</h6>
<p class='card-text'>Hierarchical Imitation Learning (HIL) is a promising approach for tackling
long-horizon decision-making tasks. While it is a challenging task due to the
lack of detailed supervisory labels for sub-goal learning, and reliance on
hundreds to thousands of expert demonstrations. In this work, we introduce
SEAL, a novel framework that leverages Large Language Models (LLMs)'s powerful
semantic and world knowledge for both specifying sub-goal space and
pre-labeling states to semantically meaningful sub-goal representations without
prior knowledge of task hierarchies. SEAL employs a dual-encoder structure,
combining supervised LLM-guided sub-goal learning with unsupervised Vector
Quantization (VQ) for more robust sub-goal representations. Additionally, SEAL
incorporates a transition-augmented low-level planner for improved adaptation
to sub-goal transitions. Our experiments demonstrate that SEAL outperforms
state-of-the-art HIL methods and LLM-based planning approaches, particularly in
settings with small expert datasets and complex long-horizon tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.02162v1' target='_blank'>Planning in Strawberry Fields: Evaluating and Improving the Planning and
  Scheduling Capabilities of LRM o1</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Karthik Valmeekam, Kaya Stechly, Atharva Gundawar, Subbarao Kambhampati</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-03 03:04:36</h6>
<p class='card-text'>The ability to plan a course of action that achieves a desired state of
affairs has long been considered a core competence of intelligent agents and
has been an integral part of AI research since its inception. With the advent
of large language models (LLMs), there has been considerable interest in the
question of whether or not they possess such planning abilities, but -- despite
the slew of new private and open source LLMs since GPT3 -- progress has
remained slow. OpenAI claims that their recent o1 (Strawberry) model has been
specifically constructed and trained to escape the normal limitations of
autoregressive LLMs -- making it a new kind of model: a Large Reasoning Model
(LRM). In this paper, we evaluate the planning capabilities of two LRMs
(o1-preview and o1-mini) on both planning and scheduling benchmarks. We see
that while o1 does seem to offer significant improvements over autoregressive
LLMs, this comes at a steep inference cost, while still failing to provide any
guarantees over what it generates. We also show that combining o1 models with
external verifiers -- in a so-called LRM-Modulo system -- guarantees the
correctness of the combined system's output while further improving
performance.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.02141v3' target='_blank'>E2H: A Two-Stage Non-Invasive Neural Signal Driven Humanoid Robotic
  Whole-Body Control Framework</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yiqun Duan, Qiang Zhang, Jinzhao Zhou, Jingkai Sun, Xiaowei Jiang, Jiahang Cao, Jiaxu Wang, Yiqian Yang, Wen Zhao, Gang Han, Yijie Guo, Chin-Teng Lin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-03 01:58:34</h6>
<p class='card-text'>Recent advancements in humanoid robotics, including the integration of
hierarchical reinforcement learning-based control and the utilization of LLM
planning, have significantly enhanced the ability of robots to perform complex
tasks. In contrast to the highly developed humanoid robots, the human factors
involved remain relatively unexplored. Directly controlling humanoid robots
with the brain has already appeared in many science fiction novels, such as
Pacific Rim and Gundam. In this work, we present E2H (EEG-to-Humanoid), an
innovative framework that pioneers the control of humanoid robots using
high-frequency non-invasive neural signals. As the none-invasive signal quality
remains low in decoding precise spatial trajectory, we decompose the E2H
framework in an innovative two-stage formation: 1) decoding neural signals
(EEG) into semantic motion keywords, 2) utilizing LLM facilitated motion
generation with a precise motion imitation control policy to realize humanoid
robotics control. The method of directly driving robots with brainwave commands
offers a novel approach to human-machine collaboration, especially in
situations where verbal commands are impractical, such as in cases of speech
impairments, space exploration, or underwater exploration, unlocking
significant potential. E2H offers an exciting glimpse into the future, holding
immense potential for human-computer interaction.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.14682v2' target='_blank'>ET-Plan-Bench: Embodied Task-level Planning Benchmark Towards
  Spatial-Temporal Cognition with Foundation Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lingfeng Zhang, Yuening Wang, Hongjian Gu, Atia Hamidizadeh, Zhanguang Zhang, Yuecheng Liu, Yutong Wang, David Gamaliel Arcos Bravo, Junyi Dong, Shunbo Zhou, Tongtong Cao, Xingyue Quan, Yuzheng Zhuang, Yingxue Zhang, Jianye Hao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-02 19:56:38</h6>
<p class='card-text'>Recent advancements in Large Language Models (LLMs) have spurred numerous
attempts to apply these technologies to embodied tasks, particularly focusing
on high-level task planning and task decomposition. To further explore this
area, we introduce a new embodied task planning benchmark, ET-Plan-Bench, which
specifically targets embodied task planning using LLMs. It features a
controllable and diverse set of embodied tasks varying in different levels of
difficulties and complexities, and is designed to evaluate two critical
dimensions of LLMs' application in embodied task understanding: spatial
(relation constraint, occlusion for target objects) and temporal & causal
understanding of the sequence of actions in the environment. By using
multi-source simulators as the backend simulator, it can provide immediate
environment feedback to LLMs, which enables LLMs to interact dynamically with
the environment and re-plan as necessary. We evaluated the state-of-the-art
open source and closed source foundation models, including GPT-4, LLAMA and
Mistral on our proposed benchmark. While they perform adequately well on simple
navigation tasks, their performance can significantly deteriorate when faced
with tasks that require a deeper understanding of spatial, temporal, and causal
relationships. Thus, our benchmark distinguishes itself as a large-scale,
quantifiable, highly automated, and fine-grained diagnostic framework that
presents a significant challenge to the latest foundation models. We hope it
can spark and drive further research in embodied task planning using foundation
models.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.01943v1' target='_blank'>CHASE-SQL: Multi-Path Reasoning and Preference Optimized Candidate
  Selection in Text-to-SQL</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mohammadreza Pourreza, Hailong Li, Ruoxi Sun, Yeounoh Chung, Shayan Talaei, Gaurav Tarlok Kakkar, Yu Gan, Amin Saberi, Fatma Ozcan, Sercan O. Arik</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-02 18:41:35</h6>
<p class='card-text'>In tackling the challenges of large language model (LLM) performance for
Text-to-SQL tasks, we introduce CHASE-SQL, a new framework that employs
innovative strategies, using test-time compute in multi-agent modeling to
improve candidate generation and selection. CHASE-SQL leverages LLMs' intrinsic
knowledge to generate diverse and high-quality SQL candidates using different
LLM generators with: (1) a divide-and-conquer method that decomposes complex
queries into manageable sub-queries in a single LLM call; (2) chain-of-thought
reasoning based on query execution plans, reflecting the steps a database
engine takes during execution; and (3) a unique instance-aware synthetic
example generation technique, which offers specific few-shot demonstrations
tailored to test questions.To identify the best candidate, a selection agent is
employed to rank the candidates through pairwise comparisons with a fine-tuned
binary-candidates selection LLM. This selection approach has been demonstrated
to be more robust over alternatives. The proposed generators-selector framework
not only enhances the quality and diversity of SQL queries but also outperforms
previous methods. Overall, our proposed CHASE-SQL achieves the state-of-the-art
execution accuracy of 73.0% and 73.01% on the test set and development set of
the notable BIRD Text-to-SQL dataset benchmark, rendering CHASE-SQL the top
submission of the leaderboard (at the time of paper submission).</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.01791v1' target='_blank'>DreamGarden: A Designer Assistant for Growing Games from a Single Prompt</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sam Earle, Samyak Parajuli, Andrzej Banburski-Fahey</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-02 17:49:07</h6>
<p class='card-text'>Coding assistants are increasingly leveraged in game design, both generating
code and making high-level plans. To what degree can these tools align with
developer workflows, and what new modes of human-computer interaction can
emerge from their use? We present DreamGarden, an AI system capable of
assisting with the development of diverse game environments in Unreal Engine.
At the core of our method is an LLM-driven planner, capable of breaking down a
single, high-level prompt -- a dream, memory, or imagined scenario provided by
a human user -- into a hierarchical action plan, which is then distributed
across specialized submodules facilitating concrete implementation. This system
is presented to the user as a garden of plans and actions, both growing
independently and responding to user intervention via seed prompts, pruning,
and feedback. Through a user study, we explore design implications of this
system, charting courses for future work in semi-autonomous assistants and
open-ended simulation design.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.01677v3' target='_blank'>Mind Scramble: Unveiling Large Language Model Psychology Via
  Typoglycemia</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Miao Yu, Junyuan Mao, Guibin Zhang, Jingheng Ye, Junfeng Fang, Aoxiao Zhong, Yang Liu, Yuxuan Liang, Kun Wang, Qingsong Wen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-02 15:47:25</h6>
<p class='card-text'>Research into the external behaviors and internal mechanisms of large
language models (LLMs) has shown promise in addressing complex tasks in the
physical world. Studies suggest that powerful LLMs, like GPT-4, are beginning
to exhibit human-like cognitive abilities, including planning, reasoning, and
reflection. In this paper, we introduce a research line and methodology called
LLM Psychology, leveraging human psychology experiments to investigate the
cognitive behaviors and mechanisms of LLMs. We migrate the Typoglycemia
phenomenon from psychology to explore the "mind" of LLMs. Unlike human brains,
which rely on context and word patterns to comprehend scrambled text, LLMs use
distinct encoding and decoding processes. Through Typoglycemia experiments at
the character, word, and sentence levels, we observe: (I) LLMs demonstrate
human-like behaviors on a macro scale, such as lower task accuracy and higher
token/time consumption; (II) LLMs exhibit varying robustness to scrambled
input, making Typoglycemia a benchmark for model evaluation without new
datasets; (III) Different task types have varying impacts, with complex logical
tasks (e.g., math) being more challenging in scrambled form; (IV) Each LLM has
a unique and consistent "cognitive pattern" across tasks, revealing general
mechanisms in its psychology process. We provide an in-depth analysis of hidden
layers to explain these phenomena, paving the way for future research in LLM
Psychology and deeper interpretability.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.01428v1' target='_blank'>Can We Further Elicit Reasoning in LLMs? Critic-Guided Planning with
  Retrieval-Augmentation for Solving Challenging Tasks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xingxuan Li, Weiwen Xu, Ruochen Zhao, Fangkai Jiao, Shafiq Joty, Lidong Bing</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-02 11:26:02</h6>
<p class='card-text'>State-of-the-art large language models (LLMs) exhibit impressive
problem-solving capabilities but may struggle with complex reasoning and
factual correctness. Existing methods harness the strengths of chain-of-thought
and retrieval-augmented generation (RAG) to decompose a complex problem into
simpler steps and apply retrieval to improve factual correctness. These methods
work well on straightforward reasoning tasks but often falter on challenging
tasks such as competitive programming and mathematics, due to frequent
reasoning errors and irrelevant knowledge retrieval. To address this, we
introduce Critic-guided planning with Retrieval-augmentation, CR-Planner, a
novel framework that leverages fine-tuned critic models to guide both reasoning
and retrieval processes through planning. CR-Planner solves a problem by
iteratively selecting and executing sub-goals. Initially, it identifies the
most promising sub-goal from reasoning, query generation, and retrieval, guided
by rewards given by a critic model named sub-goal critic. It then executes this
sub-goal through sampling and selecting the optimal output based on evaluations
from another critic model named execution critic. This iterative process,
informed by retrieved information and critic models, enables CR-Planner to
effectively navigate the solution space towards the final answer. We employ
Monte Carlo Tree Search to collect the data for training the critic models,
allowing for a systematic exploration of action sequences and their long-term
impacts. We validate CR-Planner on challenging domain-knowledge-intensive and
reasoning-heavy tasks, including competitive programming, theorem-driven math
reasoning, and complex domain retrieval problems. Our experiments demonstrate
that CR-Planner significantly outperforms baselines, highlighting its
effectiveness in addressing challenging problems by improving both reasoning
and retrieval.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.01363v1' target='_blank'>PCQPR: Proactive Conversational Question Planning with Reflection</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shasha Guo, Lizi Liao, Jing Zhang, Cuiping Li, Hong Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-02 09:23:07</h6>
<p class='card-text'>Conversational Question Generation (CQG) enhances the interactivity of
conversational question-answering systems in fields such as education, customer
service, and entertainment. However, traditional CQG, focusing primarily on the
immediate context, lacks the conversational foresight necessary to guide
conversations toward specified conclusions. This limitation significantly
restricts their ability to achieve conclusion-oriented conversational outcomes.
In this work, we redefine the CQG task as Conclusion-driven Conversational
Question Generation (CCQG) by focusing on proactivity, not merely reacting to
the unfolding conversation but actively steering it towards a
conclusion-oriented question-answer pair. To address this, we propose a novel
approach, called Proactive Conversational Question Planning with self-Refining
(PCQPR). Concretely, by integrating a planning algorithm inspired by Monte
Carlo Tree Search (MCTS) with the analytical capabilities of large language
models (LLMs), PCQPR predicts future conversation turns and continuously
refines its questioning strategies. This iterative self-refining mechanism
ensures the generation of contextually relevant questions strategically devised
to reach a specified outcome. Our extensive evaluations demonstrate that PCQPR
significantly surpasses existing CQG methods, marking a paradigm shift towards
conclusion-oriented conversational question-answering systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.01345v1' target='_blank'>Towards Generalizable Vision-Language Robotic Manipulation: A Benchmark
  and LLM-guided 3D Policy</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ricardo Garcia, Shizhe Chen, Cordelia Schmid</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-02 09:02:34</h6>
<p class='card-text'>Generalizing language-conditioned robotic policies to new tasks remains a
significant challenge, hampered by the lack of suitable simulation benchmarks.
In this paper, we address this gap by introducing GemBench, a novel benchmark
to assess generalization capabilities of vision-language robotic manipulation
policies. GemBench incorporates seven general action primitives and four levels
of generalization, spanning novel placements, rigid and articulated objects,
and complex long-horizon tasks. We evaluate state-of-the-art approaches on
GemBench and also introduce a new method. Our approach 3D-LOTUS leverages rich
3D information for action prediction conditioned on language. While 3D-LOTUS
excels in both efficiency and performance on seen tasks, it struggles with
novel tasks. To address this, we present 3D-LOTUS++, a framework that
integrates 3D-LOTUS's motion planning capabilities with the task planning
capabilities of LLMs and the object grounding accuracy of VLMs. 3D-LOTUS++
achieves state-of-the-art performance on novel tasks of GemBench, setting a new
standard for generalization in robotic manipulation. The benchmark, codes and
trained models are available at
\url{https://www.di.ens.fr/willow/research/gembench/}.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.01098v1' target='_blank'>Generative AI Application for Building Industry</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hanlong Wan, Jian Zhang, Yan Chen, Weili Xu, Fan Feng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-01 21:59:08</h6>
<p class='card-text'>This paper investigates the transformative potential of generative AI
technologies, particularly large language models (LLMs), within the building
industry. By leveraging these advanced AI tools, the study explores their
application across key areas such as energy code compliance, building design
optimization, and workforce training. The research highlights how LLMs can
automate labor-intensive processes, significantly improving efficiency,
accuracy, and safety in building practices. The paper also addresses the
challenges associated with interpreting complex visual and textual data in
architectural plans and regulatory codes, proposing innovative solutions to
enhance AI-driven compliance checking and design processes. Additionally, the
study considers the broader implications of AI integration, including the
development of AI-powered tools for comprehensive code compliance across
various regulatory domains and the potential for AI to revolutionize workforce
training through realistic simulations. This paper provides a comprehensive
analysis of the current capabilities of generative AI in the building industry
while outlining future directions for research and development, aiming to pave
the way for smarter, more sustainable, and responsive construction practices.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.00773v1' target='_blank'>BabelBench: An Omni Benchmark for Code-Driven Analysis of Multimodal and
  Multistructured Data</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xuwu Wang, Qiwen Cui, Yunzhe Tao, Yiran Wang, Ziwei Chai, Xiaotian Han, Boyi Liu, Jianbo Yuan, Jing Su, Guoyin Wang, Tingkai Liu, Liyu Chen, Tianyi Liu, Tao Sun, Yufeng Zhang, Sirui Zheng, Quanzeng You, Yang Yang, Hongxia Yang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-01 15:11:24</h6>
<p class='card-text'>Large language models (LLMs) have become increasingly pivotal across various
domains, especially in handling complex data types. This includes structured
data processing, as exemplified by ChartQA and ChatGPT-Ada, and multimodal
unstructured data processing as seen in Visual Question Answering (VQA). These
areas have attracted significant attention from both industry and academia.
Despite this, there remains a lack of unified evaluation methodologies for
these diverse data handling scenarios. In response, we introduce BabelBench, an
innovative benchmark framework that evaluates the proficiency of LLMs in
managing multimodal multistructured data with code execution. BabelBench
incorporates a dataset comprising 247 meticulously curated problems that
challenge the models with tasks in perception, commonsense reasoning, logical
reasoning, and so on. Besides the basic capabilities of multimodal
understanding, structured data processing as well as code generation, these
tasks demand advanced capabilities in exploration, planning, reasoning and
debugging. Our experimental findings on BabelBench indicate that even
cutting-edge models like ChatGPT 4 exhibit substantial room for improvement.
The insights derived from our comprehensive analysis offer valuable guidance
for future research within the community. The benchmark data can be found at
https://github.com/FFD8FFE/babelbench.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.00467v3' target='_blank'>Dynamic Planning for LLM-based Graphical User Interface Automation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shaoqing Zhang, Zhuosheng Zhang, Kehai Chen, Xinbei Ma, Muyun Yang, Tiejun Zhao, Min Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-01 07:49:24</h6>
<p class='card-text'>The advent of large language models (LLMs) has spurred considerable interest
in advancing autonomous LLMs-based agents, particularly in intriguing
applications within smartphone graphical user interfaces (GUIs). When presented
with a task goal, these agents typically emulate human actions within a GUI
environment until the task is completed. However, a key challenge lies in
devising effective plans to guide action prediction in GUI tasks, though
planning have been widely recognized as effective for decomposing complex tasks
into a series of steps. Specifically, given the dynamic nature of environmental
GUIs following action execution, it is crucial to dynamically adapt plans based
on environmental feedback and action history.We show that the widely-used ReAct
approach fails due to the excessively long historical dialogues. To address
this challenge, we propose a novel approach called Dynamic Planning of Thoughts
(D-PoT) for LLM-based GUI agents.D-PoT involves the dynamic adjustment of
planning based on the environmental feedback and execution history.
Experimental results reveal that the proposed D-PoT significantly surpassed the
strong GPT-4V baseline by +12.7% (34.66% $\rightarrow$ 47.36%) in accuracy. The
analysis highlights the generality of dynamic planning in different backbone
LLMs, as well as the benefits in mitigating hallucinations and adapting to
unseen tasks. Code is available at https://github.com/sqzhang-lazy/D-PoT.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.03741v1' target='_blank'>Towards Democratization of Subspeciality Medical Expertise</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jack W. O'Sullivan, Anil Palepu, Khaled Saab, Wei-Hung Weng, Yong Cheng, Emily Chu, Yaanik Desai, Aly Elezaby, Daniel Seung Kim, Roy Lan, Wilson Tang, Natalie Tapaskar, Victoria Parikh, Sneha S. Jain, Kavita Kulkarni, Philip Mansfield, Dale Webster, Juraj Gottweis, Joelle Barral, Mike Schaekermann, Ryutaro Tanno, S. Sara Mahdavi, Vivek Natarajan, Alan Karthikesalingam, Euan Ashley, Tao Tu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-01 06:34:31</h6>
<p class='card-text'>The scarcity of subspecialist medical expertise, particularly in rare,
complex and life-threatening diseases, poses a significant challenge for
healthcare delivery. This issue is particularly acute in cardiology where
timely, accurate management determines outcomes. We explored the potential of
AMIE (Articulate Medical Intelligence Explorer), a large language model
(LLM)-based experimental AI system optimized for diagnostic dialogue, to
potentially augment and support clinical decision-making in this challenging
context. We curated a real-world dataset of 204 complex cases from a
subspecialist cardiology practice, including results for electrocardiograms,
echocardiograms, cardiac MRI, genetic tests, and cardiopulmonary stress tests.
We developed a ten-domain evaluation rubric used by subspecialists to evaluate
the quality of diagnosis and clinical management plans produced by general
cardiologists or AMIE, the latter enhanced with web-search and self-critique
capabilities. AMIE was rated superior to general cardiologists for 5 of the 10
domains (with preference ranging from 9% to 20%), and equivalent for the rest.
Access to AMIE's response improved cardiologists' overall response quality in
63.7% of cases while lowering quality in just 3.4%. Cardiologists' responses
with access to AMIE were superior to cardiologist responses without access to
AMIE for all 10 domains. Qualitative examinations suggest AMIE and general
cardiologist could complement each other, with AMIE thorough and sensitive,
while general cardiologist concise and specific. Overall, our results suggest
that specialized medical LLMs have the potential to augment general
cardiologists' capabilities by bridging gaps in subspecialty expertise, though
further research and validation are essential for wide clinical utility.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.00371v1' target='_blank'>AHA: A Vision-Language-Model for Detecting and Reasoning Over Failures
  in Robotic Manipulation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiafei Duan, Wilbert Pumacay, Nishanth Kumar, Yi Ru Wang, Shulin Tian, Wentao Yuan, Ranjay Krishna, Dieter Fox, Ajay Mandlekar, Yijie Guo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-10-01 03:47:00</h6>
<p class='card-text'>Robotic manipulation in open-world settings requires not only task execution
but also the ability to detect and learn from failures. While recent advances
in vision-language models (VLMs) and large language models (LLMs) have improved
robots' spatial reasoning and problem-solving abilities, they still struggle
with failure recognition, limiting their real-world applicability. We introduce
AHA, an open-source VLM designed to detect and reason about failures in robotic
manipulation using natural language. By framing failure detection as a
free-form reasoning task, AHA identifies failures and provides detailed,
adaptable explanations across different robots, tasks, and environments. We
fine-tuned AHA using FailGen, a scalable framework that generates the first
large-scale dataset of robotic failure trajectories, the AHA dataset. FailGen
achieves this by procedurally perturbing successful demonstrations from
simulation. Despite being trained solely on the AHA dataset, AHA generalizes
effectively to real-world failure datasets, robotic systems, and unseen tasks.
It surpasses the second-best model (GPT-4o in-context learning) by 10.3% and
exceeds the average performance of six compared models including five
state-of-the-art VLMs by 35.3% across multiple metrics and datasets. We
integrate AHA into three manipulation frameworks that utilize LLMs/VLMs for
reinforcement learning, task and motion planning, and zero-shot trajectory
generation. AHA's failure feedback enhances these policies' performances by
refining dense reward functions, optimizing task planning, and improving
sub-task verification, boosting task success rates by an average of 21.4%
across all three tasks compared to GPT-4 models.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.20557v1' target='_blank'>Propose, Assess, Search: Harnessing LLMs for Goal-Oriented Planning in
  Instructional Videos</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Md Mohaiminul Islam, Tushar Nagarajan, Huiyu Wang, Fu-Jen Chu, Kris Kitani, Gedas Bertasius, Xitong Yang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-30 17:57:28</h6>
<p class='card-text'>Goal-oriented planning, or anticipating a series of actions that transition
an agent from its current state to a predefined objective, is crucial for
developing intelligent assistants aiding users in daily procedural tasks. The
problem presents significant challenges due to the need for comprehensive
knowledge of temporal and hierarchical task structures, as well as strong
capabilities in reasoning and planning. To achieve this, prior work typically
relies on extensive training on the target dataset, which often results in
significant dataset bias and a lack of generalization to unseen tasks. In this
work, we introduce VidAssist, an integrated framework designed for
zero/few-shot goal-oriented planning in instructional videos. VidAssist
leverages large language models (LLMs) as both the knowledge base and the
assessment tool for generating and evaluating action plans, thus overcoming the
challenges of acquiring procedural knowledge from small-scale, low-diversity
datasets. Moreover, VidAssist employs a breadth-first search algorithm for
optimal plan generation, in which a composite of value functions designed for
goal-oriented planning is utilized to assess the predicted actions at each
step. Extensive experiments demonstrate that VidAssist offers a unified
framework for different goal-oriented planning setups, e.g., visual planning
for assistance (VPA) and procedural planning (PP), and achieves remarkable
performance in zero-shot and few-shot setups. Specifically, our few-shot model
outperforms the prior fully supervised state-of-the-art method by +7.7% in VPA
and +4.81% PP task on the COIN dataset while predicting 4 future actions. Code,
and models are publicly available at https://sites.google.com/view/vidassist.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.20548v1' target='_blank'>Robi Butler: Remote Multimodal Interactions with Household Robot
  Assistant</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Anxing Xiao, Nuwan Janaka, Tianrun Hu, Anshul Gupta, Kaixin Li, Cunjun Yu, David Hsu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-30 17:49:09</h6>
<p class='card-text'>In this paper, we introduce Robi Butler, a novel household robotic system
that enables multimodal interactions with remote users. Building on the
advanced communication interfaces, Robi Butler allows users to monitor the
robot's status, send text or voice instructions, and select target objects by
hand pointing. At the core of our system is a high-level behavior module,
powered by Large Language Models (LLMs), that interprets multimodal
instructions to generate action plans. These plans are composed of a set of
open vocabulary primitives supported by Vision Language Models (VLMs) that
handle both text and pointing queries. The integration of the above components
allows Robi Butler to ground remote multimodal instructions in the real-world
home environment in a zero-shot manner. We demonstrate the effectiveness and
efficiency of this system using a variety of daily household tasks that involve
remote users giving multimodal instructions. Additionally, we conducted a user
study to analyze how multimodal interactions affect efficiency and user
experience during remote human-robot interaction and discuss the potential
improvements.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.20502v1' target='_blank'>COLLAGE: Collaborative Human-Agent Interaction Generation using
  Hierarchical Latent Diffusion and Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Divyanshu Daiya, Damon Conover, Aniket Bera</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-30 17:02:13</h6>
<p class='card-text'>We propose a novel framework COLLAGE for generating collaborative
agent-object-agent interactions by leveraging large language models (LLMs) and
hierarchical motion-specific vector-quantized variational autoencoders
(VQ-VAEs). Our model addresses the lack of rich datasets in this domain by
incorporating the knowledge and reasoning abilities of LLMs to guide a
generative diffusion model. The hierarchical VQ-VAE architecture captures
different motion-specific characteristics at multiple levels of abstraction,
avoiding redundant concepts and enabling efficient multi-resolution
representation. We introduce a diffusion model that operates in the latent
space and incorporates LLM-generated motion planning cues to guide the
denoising process, resulting in prompt-specific motion generation with greater
control and diversity. Experimental results on the CORE-4D, and InterHuman
datasets demonstrate the effectiveness of our approach in generating realistic
and diverse collaborative human-object-human interactions, outperforming
state-of-the-art methods. Our work opens up new possibilities for modeling
complex interactions in various domains, such as robotics, graphics and
computer vision.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.00079v1' target='_blank'>Interactive Speculative Planning: Enhance Agent Efficiency through
  Co-design of System and User Interface</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wenyue Hua, Mengting Wan, Shashank Vadrevu, Ryan Nadel, Yongfeng Zhang, Chi Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-30 16:52:51</h6>
<p class='card-text'>Agents, as user-centric tools, are increasingly deployed for human task
delegation, assisting with a broad spectrum of requests by generating thoughts,
engaging with user proxies, and producing action plans. However, agents based
on large language models (LLMs) often face substantial planning latency due to
two primary factors: the efficiency limitations of the underlying LLMs due to
their large size and high demand, and the structural complexity of the agents
due to the extensive generation of intermediate thoughts to produce the final
output. Given that inefficiency in service provision can undermine the value of
automation for users, this paper presents a human-centered efficient agent
planning method -- Interactive Speculative Planning -- aiming at enhancing the
efficiency of agent planning through both system design and human-AI
interaction. Our approach advocates for the co-design of the agent system and
user interface, underscoring the importance of an agent system that can fluidly
manage user interactions and interruptions. By integrating human interruptions
as a fundamental component of the system, we not only make it more user-centric
but also expedite the entire process by leveraging human-in-the-loop
interactions to provide accurate intermediate steps. Code and data will be
released.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.19924v4' target='_blank'>On The Planning Abilities of OpenAI's o1 Models: Feasibility,
  Optimality, and Generalizability</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kevin Wang, Junbo Li, Neel P. Bhatt, Yihan Xi, Qiang Liu, Ufuk Topcu, Zhangyang Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-30 03:58:43</h6>
<p class='card-text'>Recent advancements in Large Language Models (LLMs) have showcased their
ability to perform complex reasoning tasks, but their effectiveness in planning
remains underexplored. In this study, we evaluate the planning capabilities of
OpenAI's o1 models across a variety of benchmark tasks, focusing on three key
aspects: feasibility, optimality, and generalizability. Through empirical
evaluations on constraint-heavy tasks (e.g., $\textit{Barman}$,
$\textit{Tyreworld}$) and spatially complex environments (e.g.,
$\textit{Termes}$, $\textit{Floortile}$), we highlight o1-preview's strengths
in self-evaluation and constraint-following, while also identifying bottlenecks
in decision-making and memory management, particularly in tasks requiring
robust spatial reasoning. Our results reveal that o1-preview outperforms GPT-4
in adhering to task constraints and managing state transitions in structured
environments. However, the model often generates suboptimal solutions with
redundant actions and struggles to generalize effectively in spatially complex
tasks. This pilot study provides foundational insights into the planning
limitations of LLMs, offering key directions for future research on improving
memory management, decision-making, and generalization in LLM-based planning.
Code available at https://github.com/VITA-Group/o1-planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.19527v1' target='_blank'>BuildingView: Constructing Urban Building Exteriors Databases with
  Street View Imagery and Multimodal Large Language Mode</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zongrong Li, Yunlei Su, Chenyuan Zhu, Wufan Zhao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-29 03:00:16</h6>
<p class='card-text'>Urban Building Exteriors are increasingly important in urban analytics,
driven by advancements in Street View Imagery and its integration with urban
research. Multimodal Large Language Models (LLMs) offer powerful tools for
urban annotation, enabling deeper insights into urban environments. However,
challenges remain in creating accurate and detailed urban building exterior
databases, identifying critical indicators for energy efficiency, environmental
sustainability, and human-centric design, and systematically organizing these
indicators. To address these challenges, we propose BuildingView, a novel
approach that integrates high-resolution visual data from Google Street View
with spatial information from OpenStreetMap via the Overpass API. This research
improves the accuracy of urban building exterior data, identifies key
sustainability and design indicators, and develops a framework for their
extraction and categorization. Our methodology includes a systematic literature
review, building and Street View sampling, and annotation using the ChatGPT-4O
API. The resulting database, validated with data from New York City, Amsterdam,
and Singapore, provides a comprehensive tool for urban studies, supporting
informed decision-making in urban planning, architectural design, and
environmental policy. The code for BuildingView is available at
https://github.com/Jasper0122/BuildingView.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.19479v1' target='_blank'>Spatial Reasoning and Planning for Deep Embodied Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shu Ishida</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-28 23:05:56</h6>
<p class='card-text'>Humans can perform complex tasks with long-term objectives by planning,
reasoning, and forecasting outcomes of actions. For embodied agents to achieve
similar capabilities, they must gain knowledge of the environment transferable
to novel scenarios with a limited budget of additional trial and error.
Learning-based approaches, such as deep RL, can discover and take advantage of
inherent regularities and characteristics of the application domain from data,
and continuously improve their performances, however at a cost of large amounts
of training data. This thesis explores the development of data-driven
techniques for spatial reasoning and planning tasks, focusing on enhancing
learning efficiency, interpretability, and transferability across novel
scenarios. Four key contributions are made. 1) CALVIN, a differential planner
that learns interpretable models of the world for long-term planning. It
successfully navigated partially observable 3D environments, such as mazes and
indoor rooms, by learning the rewards and state transitions from expert
demonstrations. 2) SOAP, an RL algorithm that discovers options unsupervised
for long-horizon tasks. Options segment a task into subtasks and enable
consistent execution of the subtask. SOAP showed robust performances on
history-conditional corridor tasks as well as classical benchmarks such as
Atari. 3) LangProp, a code optimisation framework using LLMs to solve embodied
agent problems that require reasoning by treating code as learnable policies.
The framework successfully generated interpretable code with comparable or
superior performance to human-written experts in the CARLA autonomous driving
benchmark. 4) Voggite, an embodied agent with a vision-to-action transformer
backend that solves complex tasks in Minecraft. It achieved third place in the
MineRL BASALT Competition by identifying action triggers to segment tasks into
multiple stages.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.19471v2' target='_blank'>SELP: Generating Safe and Efficient Task Plans for Robot Agents with
  Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yi Wu, Zikang Xiong, Yiran Hu, Shreyash S. Iyengar, Nan Jiang, Aniket Bera, Lin Tan, Suresh Jagannathan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-28 22:33:44</h6>
<p class='card-text'>Despite significant advancements in large language models (LLMs) that enhance
robot agents' understanding and execution of natural language (NL) commands,
ensuring the agents adhere to user-specified constraints remains challenging,
particularly for complex commands and long-horizon tasks. To address this
challenge, we present three key insights, equivalence voting, constrained
decoding, and domain-specific fine-tuning, which significantly enhance LLM
planners' capability in handling complex tasks. Equivalence voting ensures
consistency by generating and sampling multiple Linear Temporal Logic (LTL)
formulas from NL commands, grouping equivalent LTL formulas, and selecting the
majority group of formulas as the final LTL formula. Constrained decoding then
uses the generated LTL formula to enforce the autoregressive inference of
plans, ensuring the generated plans conform to the LTL. Domain-specific
fine-tuning customizes LLMs to produce safe and efficient plans within specific
task domains. Our approach, Safe Efficient LLM Planner (SELP), combines these
insights to create LLM planners to generate plans adhering to user commands
with high confidence. We demonstrate the effectiveness and generalizability of
SELP across different robot agents and tasks, including drone navigation and
robot manipulation. For drone navigation tasks, SELP outperforms
state-of-the-art planners by 10.8% in safety rate (i.e., finishing tasks
conforming to NL commands) and by 19.8% in plan efficiency. For robot
manipulation tasks, SELP achieves 20.4% improvement in safety rate. Our
datasets for evaluating NL-to-LTL and robot task planning will be released in
github.com/lt-asset/selp.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.19250v1' target='_blank'>Fast and Accurate Task Planning using Neuro-Symbolic Language Models and
  Multi-level Goal Decomposition</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Minseo Kwon, Yaesol Kim, Young J. Kim</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-28 05:48:51</h6>
<p class='card-text'>In robotic task planning, symbolic planners using rule-based representations
like PDDL are effective but struggle with long-sequential tasks in complicated
planning environments due to exponentially increasing search space. Recently,
Large Language Models (LLMs) based on artificial neural networks have emerged
as promising alternatives for autonomous robot task planning, offering faster
inference and leveraging commonsense knowledge. However, they typically suffer
from lower success rates. In this paper, to address the limitations of the
current symbolic (slow speed) or LLM-based approaches (low accuracy), we
propose a novel neuro-symbolic task planner that decomposes complex tasks into
subgoals using LLM and carries out task planning for each subgoal using either
symbolic or MCTS-based LLM planners, depending on the subgoal complexity.
Generating subgoals helps reduce planning time and improve success rates by
narrowing the overall search space and enabling LLMs to focus on smaller, more
manageable tasks. Our method significantly reduces planning time while
maintaining a competitive success rate, as demonstrated through experiments in
different public task planning domains, as well as real-world and simulated
robotics environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.01841v1' target='_blank'>A GEN AI Framework for Medical Note Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hui Yi Leong, Yi Fan Gao, Shuai Ji, Bora Kalaycioglu, Uktu Pamuksuz</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-27 23:05:02</h6>
<p class='card-text'>The increasing administrative burden of medical documentation, particularly
through Electronic Health Records (EHR), significantly reduces the time
available for direct patient care and contributes to physician burnout. To
address this issue, we propose MediNotes, an advanced generative AI framework
designed to automate the creation of SOAP (Subjective, Objective, Assessment,
Plan) notes from medical conversations. MediNotes integrates Large Language
Models (LLMs), Retrieval-Augmented Generation (RAG), and Automatic Speech
Recognition (ASR) to capture and process both text and voice inputs in real
time or from recorded audio, generating structured and contextually accurate
medical notes. The framework also incorporates advanced techniques like
Quantized Low-Rank Adaptation (QLoRA) and Parameter-Efficient Fine-Tuning
(PEFT) for efficient model fine-tuning in resource-constrained environments.
Additionally, MediNotes offers a query-based retrieval system, allowing
healthcare providers and patients to access relevant medical information
quickly and accurately. Evaluations using the ACI-BENCH dataset demonstrate
that MediNotes significantly improves the accuracy, efficiency, and usability
of automated medical documentation, offering a robust solution to reduce the
administrative burden on healthcare professionals while improving the quality
of clinical workflows.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.19091v2' target='_blank'>System-Level Defense against Indirect Prompt Injection Attacks: An
  Information Flow Control Perspective</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Fangzhou Wu, Ethan Cecchetti, Chaowei Xiao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-27 18:41:58</h6>
<p class='card-text'>Large Language Model-based systems (LLM systems) are information and query
processing systems that use LLMs to plan operations from natural-language
prompts and feed the output of each successive step into the LLM to plan the
next. This structure results in powerful tools that can process complex
information from diverse sources but raises critical security concerns.
Malicious information from any source may be processed by the LLM and can
compromise the query processing, resulting in nearly arbitrary misbehavior. To
tackle this problem, we present a system-level defense based on the principles
of information flow control that we call an f-secure LLM system. An f-secure
LLM system disaggregates the components of an LLM system into a context-aware
pipeline with dynamically generated structured executable plans, and a security
monitor filters out untrusted input into the planning process. This structure
prevents compromise while maximizing flexibility. We provide formal models for
both existing LLM systems and our f-secure LLM system, allowing analysis of
critical security guarantees. We further evaluate case studies and benchmarks
showing that f-secure LLM systems provide robust security while preserving
functionality and efficiency. Our code is released at
https://github.com/fzwark/Secure_LLM_System.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.02823v1' target='_blank'>DANA: Domain-Aware Neurosymbolic Agents for Consistency and Accuracy</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Vinh Luong, Sang Dinh, Shruti Raghavan, William Nguyen, Zooey Nguyen, Quynh Le, Hung Vo, Kentaro Maegaito, Loc Nguyen, Thao Nguyen, Anh Hai Ha, Christopher Nguyen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-27 18:29:23</h6>
<p class='card-text'>Large Language Models (LLMs) have shown remarkable capabilities, but their
inherent probabilistic nature often leads to inconsistency and inaccuracy in
complex problem-solving tasks. This paper introduces DANA (Domain-Aware
Neurosymbolic Agent), an architecture that addresses these issues by
integrating domain-specific knowledge with neurosymbolic approaches. We begin
by analyzing current AI architectures, including AutoGPT, LangChain ReAct and
OpenAI's ChatGPT, through a neurosymbolic lens, highlighting how their reliance
on probabilistic inference contributes to inconsistent outputs. In response,
DANA captures and applies domain expertise in both natural-language and
symbolic forms, enabling more deterministic and reliable problem-solving
behaviors. We implement a variant of DANA using Hierarchical Task Plans (HTPs)
in the open-source OpenSSA framework. This implementation achieves over 90\%
accuracy on the FinanceBench financial-analysis benchmark, significantly
outperforming current LLM-based systems in both consistency and accuracy.
Application of DANA in physical industries such as semiconductor shows that its
flexible architecture for incorporating knowledge is effective in mitigating
the probabilistic limitations of LLMs and has potential in tackling complex,
real-world problems that require reliability and precision.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.19074v3' target='_blank'>Show and Guide: Instructional-Plan Grounded Vision and Language Model</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Diogo Glória-Silva, David Semedo, João Magalhães</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-27 18:20:24</h6>
<p class='card-text'>Guiding users through complex procedural plans is an inherently multimodal
task in which having visually illustrated plan steps is crucial to deliver an
effective plan guidance. However, existing works on plan-following language
models (LMs) often are not capable of multimodal input and output. In this
work, we present MM-PlanLLM, the first multimodal LLM designed to assist users
in executing instructional tasks by leveraging both textual plans and visual
information. Specifically, we bring cross-modality through two key tasks:
Conversational Video Moment Retrieval, where the model retrieves relevant
step-video segments based on user queries, and Visually-Informed Step
Generation, where the model generates the next step in a plan, conditioned on
an image of the user's current progress. MM-PlanLLM is trained using a novel
multitask-multistage approach, designed to gradually expose the model to
multimodal instructional-plans semantic layers, achieving strong performance on
both multimodal and textual dialogue in a plan-grounded setting. Furthermore,
we show that the model delivers cross-modal temporal and plan-structure
representations aligned between textual plan steps and instructional video
moments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.18382v1' target='_blank'>CurricuLLM: Automatic Task Curricula Design for Learning Complex Robot
  Skills using Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kanghyun Ryu, Qiayuan Liao, Zhongyu Li, Koushil Sreenath, Negar Mehr</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-27 01:48:16</h6>
<p class='card-text'>Curriculum learning is a training mechanism in reinforcement learning (RL)
that facilitates the achievement of complex policies by progressively
increasing the task difficulty during training. However, designing effective
curricula for a specific task often requires extensive domain knowledge and
human intervention, which limits its applicability across various domains. Our
core idea is that large language models (LLMs), with their extensive training
on diverse language data and ability to encapsulate world knowledge, present
significant potential for efficiently breaking down tasks and decomposing
skills across various robotics environments. Additionally, the demonstrated
success of LLMs in translating natural language into executable code for RL
agents strengthens their role in generating task curricula. In this work, we
propose CurricuLLM, which leverages the high-level planning and programming
capabilities of LLMs for curriculum design, thereby enhancing the efficient
learning of complex target tasks. CurricuLLM consists of: (Step 1) Generating
sequence of subtasks that aid target task learning in natural language form,
(Step 2) Translating natural language description of subtasks in executable
task code, including the reward code and goal distribution code, and (Step 3)
Evaluating trained policies based on trajectory rollout and subtask
description. We evaluate CurricuLLM in various robotics simulation
environments, ranging from manipulation, navigation, and locomotion, to show
that CurricuLLM can aid learning complex robot control tasks. In addition, we
validate humanoid locomotion policy learned through CurricuLLM in real-world.
The code is provided in https://github.com/labicon/CurricuLLM</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.18216v1' target='_blank'>MMMT-IF: A Challenging Multimodal Multi-Turn Instruction Following
  Benchmark</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Elliot L. Epstein, Kaisheng Yao, Jing Li, Xinyi Bai, Hamid Palangi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-26 18:51:46</h6>
<p class='card-text'>Evaluating instruction following capabilities for multimodal, multi-turn
dialogue is challenging. With potentially multiple instructions in the input
model context, the task is time-consuming for human raters and we show LLM
based judges are biased towards answers from the same model. We propose
MMMT-IF, an image based multi-turn Q$\&$A evaluation set with added global
instructions between questions, constraining the answer format. This challenges
models to retrieve instructions dispersed across long dialogues and reason
under instruction constraints. All instructions are objectively verifiable
through code execution. We introduce the Programmatic Instruction Following
($\operatorname{PIF}$) metric to measure the fraction of the instructions that
are correctly followed while performing a reasoning task. The
$\operatorname{PIF-N-K}$ set of metrics further evaluates robustness by
measuring the fraction of samples in a corpus where, for each sample, at least
K out of N generated model responses achieve a $\operatorname{PIF}$ score of
one. The $\operatorname{PIF}$ metric aligns with human instruction following
ratings, showing 60 percent correlation. Experiments show Gemini 1.5 Pro,
GPT-4o, and Claude 3.5 Sonnet, have a $\operatorname{PIF}$ metric that drops
from 0.81 on average at turn 1 across the models, to 0.64 at turn 20. Across
all turns, when each response is repeated 4 times ($\operatorname{PIF-4-4}$),
GPT-4o and Gemini successfully follow all instructions only $11\%$ of the time.
When all the instructions are also appended to the end of the model input
context, the $\operatorname{PIF}$ metric improves by 22.3 points on average,
showing that the challenge with the task lies not only in following the
instructions, but also in retrieving the instructions spread out in the model
context. We plan to open source the MMMT-IF dataset and metric computation
code.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.18053v3' target='_blank'>DualAD: Dual-Layer Planning for Reasoning in Autonomous Driving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Dingrui Wang, Marc Kaufeld, Johannes Betz</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-26 16:58:04</h6>
<p class='card-text'>We present a novel autonomous driving framework, DualAD, designed to imitate
human reasoning during driving. DualAD comprises two layers: a rule-based
motion planner at the bottom layer that handles routine driving tasks requiring
minimal reasoning, and an upper layer featuring a rule-based text encoder that
converts driving scenarios from absolute states into text description. This
text is then processed by a large language model (LLM) to make driving
decisions. The upper layer intervenes in the bottom layer's decisions when
potential danger is detected, mimicking human reasoning in critical situations.
Closed-loop experiments demonstrate that DualAD, using a zero-shot pre-trained
model, significantly outperforms rule-based motion planners that lack reasoning
abilities. Our experiments also highlight the effectiveness of the text
encoder, which considerably enhances the model's scenario understanding.
Additionally, the integrated DualAD model improves with stronger LLMs,
indicating the framework's potential for further enhancement. Code and
benchmarks are available at github.com/TUM-AVS/DualAD.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.18009v1' target='_blank'>Control Industrial Automation System with Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuchen Xia, Nasser Jazdi, Jize Zhang, Chaitanya Shah, Michael Weyrich</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-26 16:19:37</h6>
<p class='card-text'>Traditional industrial automation systems require specialized expertise to
operate and complex reprogramming to adapt to new processes. Large language
models offer the intelligence to make them more flexible and easier to use.
However, LLMs' application in industrial settings is underexplored. This paper
introduces a framework for integrating LLMs to achieve end-to-end control of
industrial automation systems. At the core of the framework are an agent system
designed for industrial tasks, a structured prompting method, and an
event-driven information modeling mechanism that provides real-time data for
LLM inference. The framework supplies LLMs with real-time events on different
context semantic levels, allowing them to interpret the information, generate
production plans, and control operations on the automation system. It also
supports structured dataset creation for fine-tuning on this downstream
application of LLMs. Our contribution includes a formal system design,
proof-of-concept implementation, and a method for generating task-specific
datasets for LLM fine-tuning and testing. This approach enables a more adaptive
automation system that can respond to spontaneous events, while allowing easier
operation and configuration through natural language for more intuitive
human-machine interaction. We provide demo videos and detailed data on GitHub:
https://github.com/YuchenXia/LLM4IAS</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.16900v1' target='_blank'>A Roadmap for Embodied and Social Grounding in LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sara Incao, Carlo Mazzola, Giulia Belgiovine, Alessandra Sciutti</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-25 13:09:23</h6>
<p class='card-text'>The fusion of Large Language Models (LLMs) and robotic systems has led to a
transformative paradigm in the robotic field, offering unparalleled
capabilities not only in the communication domain but also in skills like
multimodal input handling, high-level reasoning, and plan generation. The
grounding of LLMs knowledge into the empirical world has been considered a
crucial pathway to exploit the efficiency of LLMs in robotics. Nevertheless,
connecting LLMs' representations to the external world with multimodal
approaches or with robots' bodies is not enough to let them understand the
meaning of the language they are manipulating. Taking inspiration from humans,
this work draws attention to three necessary elements for an agent to grasp and
experience the world. The roadmap for LLMs grounding is envisaged in an active
bodily system as the reference point for experiencing the environment, a
temporally structured experience for a coherent, self-related interaction with
the external world, and social skills to acquire a common-grounded shared
experience.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.16751v2' target='_blank'>E-SQL: Direct Schema Linking via Question Enrichment in Text-to-SQL</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hasan Alp Caferoğlu, Özgür Ulusoy</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-25 09:02:48</h6>
<p class='card-text'>Translating Natural Language Queries into Structured Query Language
(Text-to-SQL or NLQ-to-SQL) is a critical task extensively studied by both the
natural language processing and database communities, aimed at providing a
natural language interface to databases (NLIDB) and lowering the barrier for
non-experts. Despite recent advancements made through the use of Large Language
Models (LLMs), significant challenges remain. These include handling complex
database schemas, resolving ambiguity in user queries, and generating SQL
queries with intricate structures that accurately reflect the user's intent. In
this work, we introduce E-SQL, a novel pipeline specifically designed to
address these challenges through direct schema linking and candidate predicate
augmentation. E-SQL enhances the natural language query by incorporating
relevant database items (i.e., tables, columns, and values) and conditions
directly into the question and SQL construction plan, bridging the gap between
the query and the database structure. The pipeline leverages candidate
predicate augmentation to mitigate erroneous or incomplete predicates in
generated SQLs. Comprehensive evaluations on the BIRD benchmark illustrate that
E-SQL achieves competitive performance, particularly excelling in complex
queries with a 66.29% execution accuracy on the test set. A further observation
from our experiments reveals that incorporating schema filtering into the
translation pipeline does not have a positive impact on performance when the
most advanced proprietary LLMs are used. Additionally, our experiments with
small LLMs highlight the importance and positive impact of enriched questions
on their performance. Without fine-tuning, single-prompt SQL generation using
enriched questions with DeepSeek Coder 7B Instruct 1.5v achieves 56.45%
execution accuracy on the BIRD development set.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.16686v2' target='_blank'>MSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for
  Superior Planning and Decision-Making</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Dayuan Fu, Biqing Qi, Yihuai Gao, Che Jiang, Guanting Dong, Bowen Zhou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-25 07:21:51</h6>
<p class='card-text'>Long-term memory is significant for agents, in which insights play a crucial
role. However, the emergence of irrelevant insight and the lack of general
insight can greatly undermine the effectiveness of insight. To solve this
problem, in this paper, we introduce Multi-Scale Insight Agent (MSI-Agent), an
embodied agent designed to improve LLMs' planning and decision-making ability
by summarizing and utilizing insight effectively across different scales. MSI
achieves this through the experience selector, insight generator, and insight
selector. Leveraging a three-part pipeline, MSI can generate task-specific and
high-level insight, store it in a database, and then use relevant insight from
it to aid in decision-making. Our experiments show that MSI outperforms another
insight strategy when planning by GPT3.5. Moreover, We delve into the
strategies for selecting seed experience and insight, aiming to provide LLM
with more useful and relevant insight for better decision-making. Our
observations also indicate that MSI exhibits better robustness when facing
domain-shifting scenarios.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.16455v1' target='_blank'>MultiTalk: Introspective and Extrospective Dialogue for
  Human-Environment-LLM Alignment</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Venkata Naren Devarakonda, Ali Umut Kaypak, Shuaihang Yuan, Prashanth Krishnamurthy, Yi Fang, Farshad Khorrami</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-24 20:54:21</h6>
<p class='card-text'>LLMs have shown promising results in task planning due to their strong
natural language understanding and reasoning capabilities. However, issues such
as hallucinations, ambiguities in human instructions, environmental
constraints, and limitations in the executing agent's capabilities often lead
to flawed or incomplete plans. This paper proposes MultiTalk, an LLM-based task
planning methodology that addresses these issues through a framework of
introspective and extrospective dialogue loops. This approach helps ground
generated plans in the context of the environment and the agent's capabilities,
while also resolving uncertainties and ambiguities in the given task. These
loops are enabled by specialized systems designed to extract and predict
task-specific states, and flag mismatches or misalignments among the human
user, the LLM agent, and the environment. Effective feedback pathways between
these systems and the LLM planner foster meaningful dialogue. The efficacy of
this methodology is demonstrated through its application to robotic
manipulation tasks. Experiments and ablations highlight the robustness and
reliability of our method, and comparisons with baselines further illustrate
the superiority of MultiTalk in task planning for embodied agents.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.18807v1' target='_blank'>LLM With Tools: A Survey</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhuocheng Shen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-24 14:08:11</h6>
<p class='card-text'>The integration of tools in augmenting large language models presents a novel
approach toward enhancing the efficiency and accuracy of these models in
handling specific, complex tasks. This paper delves into the
methodology,challenges, and developments in the realm of teaching LLMs to use
external tools, thereby pushing the boundaries of their capabilities beyond
pre-existing knowledge bases. We introduce a standardized paradigm for tool
integration guided by a series of functions that map user instructions to
actionable plans and their execution, emphasizing the significance of
understanding user intent, tool selection, and dynamic plan adjustment. Our
exploration reveals the various challenges encountered, such as tool invocation
timing, selection accuracy, and the need for robust reasoning processes. In
addressing these challenges, we investigate techniques within the context of
fine-tuning and incontext learning paradigms, highlighting innovative
approaches to ensure diversity, augment datasets, and improve
generalization.Furthermore, we investigate a perspective on enabling LLMs to
not only utilize but also autonomously create tools, which may redefine their
role from mere tool users to tool creators. Finally,we reproduced Chameleon's
results on ScienceQA and analyzed the code structure.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.16030v2' target='_blank'>MHRC: Closed-loop Decentralized Multi-Heterogeneous Robot Collaboration
  with Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wenhao Yu, Jie Peng, Yueliang Ying, Sai Li, Jianmin Ji, Yanyong Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-24 12:29:44</h6>
<p class='card-text'>The integration of large language models (LLMs) with robotics has
significantly advanced robots' abilities in perception, cognition, and task
planning. The use of natural language interfaces offers a unified approach for
expressing the capability differences of heterogeneous robots, facilitating
communication between them, and enabling seamless task allocation and
collaboration. Currently, the utilization of LLMs to achieve decentralized
multi-heterogeneous robot collaborative tasks remains an under-explored area of
research. In this paper, we introduce a novel framework that utilizes LLMs to
achieve decentralized collaboration among multiple heterogeneous robots. Our
framework supports three robot categories, mobile robots, manipulation robots,
and mobile manipulation robots, working together to complete tasks such as
exploration, transportation, and organization. We developed a rich set of
textual feedback mechanisms and chain-of-thought (CoT) prompts to enhance task
planning efficiency and overall system performance. The mobile manipulation
robot can adjust its base position flexibly, ensuring optimal conditions for
grasping tasks. The manipulation robot can comprehend task requirements, seek
assistance when necessary, and handle objects appropriately. Meanwhile, the
mobile robot can explore the environment extensively, map object locations, and
communicate this information to the mobile manipulation robot, thus improving
task execution efficiency. We evaluated the framework using PyBullet, creating
scenarios with three different room layouts and three distinct operational
tasks. We tested various LLM models and conducted ablation studies to assess
the contributions of different modules. The experimental results confirm the
effectiveness and necessity of our proposed framework.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.15915v1' target='_blank'>Planning in the Dark: LLM-Symbolic Planning Pipeline without Experts</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sukai Huang, Nir Lipovetzky, Trevor Cohn</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-24 09:33:12</h6>
<p class='card-text'>Large Language Models (LLMs) have shown promise in solving natural
language-described planning tasks, but their direct use often leads to
inconsistent reasoning and hallucination. While hybrid LLM-symbolic planning
pipelines have emerged as a more robust alternative, they typically require
extensive expert intervention to refine and validate generated action schemas.
It not only limits scalability but also introduces a potential for biased
interpretation, as a single expert's interpretation of ambiguous natural
language descriptions might not align with the user's actual intent. To address
this, we propose a novel approach that constructs an action schema library to
generate multiple candidates, accounting for the diverse possible
interpretations of natural language descriptions. We further introduce a
semantic validation and ranking module that automatically filter and rank the
generated schemas and plans without expert-in-the-loop. The experiments showed
our pipeline maintains superiority in planning over the direct LLM planning
approach. These findings demonstrate the feasibility of a fully automated
end-to-end LLM-symbolic planner that requires no expert intervention, opening
up the possibility for a broader audience to engage with AI planning with less
prerequisite of domain expertise.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.15523v1' target='_blank'>SEAL: Suite for Evaluating API-use of LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Woojeong Kim, Ashish Jagmohan, Aditya Vempaty</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-23 20:16:49</h6>
<p class='card-text'>Large language models (LLMs) have limitations in handling tasks that require
real-time access to external APIs. While several benchmarks like ToolBench and
APIGen have been developed to assess LLMs' API-use capabilities, they often
suffer from issues such as lack of generalizability, limited multi-step
reasoning coverage, and instability due to real-time API fluctuations. In this
paper, we introduce SEAL, an end-to-end testbed designed to evaluate LLMs in
real-world API usage. SEAL standardizes existing benchmarks, integrates an
agent system for testing API retrieval and planning, and addresses the
instability of real-time APIs by introducing a GPT-4-powered API simulator with
caching for deterministic evaluations. Our testbed provides a comprehensive
evaluation pipeline that covers API retrieval, API calls, and final responses,
offering a reliable framework for structured performance comparison in diverse
real-world scenarios. SEAL is publicly available, with ongoing updates for new
benchmarks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.15471v1' target='_blank'>EvAlignUX: Advancing UX Research through LLM-Supported Exploration of
  Evaluation Metrics</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Qingxiao Zheng, Minrui Chen, Pranav Sharma, Yiliu Tang, Mehul Oswal, Yiren Liu, Yun Huang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-23 18:52:31</h6>
<p class='card-text'>Evaluating UX in the context of AI's complexity, unpredictability, and
generative nature presents unique challenges. HCI scholars lack sufficient tool
support to build knowledge around diverse evaluation metrics and develop
comprehensive UX evaluation plans. In this paper, we introduce EvAlignUX, an
innovative system grounded in scientific literature and powered by large
language models (LLMs), designed to help HCI scholars explore evaluation
metrics and their relationship to potential research outcomes. A user study
involving 19 HCI scholars revealed that EvAlignUX significantly improved the
perceived clarity, specificity, feasibility, and overall quality of their
evaluation proposals. The use of EvAlignUX enhanced participants' thought
processes, resulting in the creation of a Question Bank that can be used to
guide UX Evaluation Development. Additionally, the influence of researchers'
backgrounds on their perceived inspiration and concerns about over-reliance on
AI highlights future research directions for AI's role in fostering critical
thinking.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.15451v1' target='_blank'>Tag Map: A Text-Based Map for Spatial Reasoning and Navigation with
  Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mike Zhang, Kaixian Qu, Vaishakh Patil, Cesar Cadena, Marco Hutter</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-23 18:26:19</h6>
<p class='card-text'>Large Language Models (LLM) have emerged as a tool for robots to generate
task plans using common sense reasoning. For the LLM to generate actionable
plans, scene context must be provided, often through a map. Recent works have
shifted from explicit maps with fixed semantic classes to implicit open
vocabulary maps based on queryable embeddings capable of representing any
semantic class. However, embeddings cannot directly report the scene context as
they are implicit, requiring further processing for LLM integration. To address
this, we propose an explicit text-based map that can represent thousands of
semantic classes while easily integrating with LLMs due to their text-based
nature by building upon large-scale image recognition models. We study how
entities in our map can be localized and show through evaluations that our
text-based map localizations perform comparably to those from open vocabulary
maps while using two to four orders of magnitude less memory. Real-robot
experiments demonstrate the grounding of an LLM with the text-based map to
solve user tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.15441v1' target='_blank'>Steward: Natural Language Web Automation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Brian Tang, Kang G. Shin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-23 18:06:32</h6>
<p class='card-text'>Recently, large language models (LLMs) have demonstrated exceptional
capabilities in serving as the foundation for AI assistants. One emerging
application of LLMs, navigating through websites and interacting with UI
elements across various web pages, remains somewhat underexplored. We introduce
Steward, a novel LLM-powered web automation tool designed to serve as a
cost-effective, scalable, end-to-end solution for automating web interactions.
Traditional browser automation frameworks like Selenium, Puppeteer, and
Playwright are not scalable for extensive web interaction tasks, such as
studying recommendation algorithms on platforms like YouTube and Twitter. These
frameworks require manual coding of interactions, limiting their utility in
large-scale or dynamic contexts. Steward addresses these limitations by
integrating LLM capabilities with browser automation, allowing for natural
language-driven interaction with websites. Steward operates by receiving
natural language instructions and reactively planning and executing a sequence
of actions on websites, looping until completion, making it a practical tool
for developers and researchers to use. It achieves high efficiency, completing
actions in 8.52 to 10.14 seconds at a cost of $0.028 per action or an average
of $0.18 per task, which is further reduced to 4.8 seconds and $0.022 through a
caching mechanism. It runs tasks on real websites with a 40% completion success
rate. We discuss various design and implementation challenges, including state
representation, action sequence selection, system responsiveness, detecting
task completion, and caching implementation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.15146v2' target='_blank'>COHERENT: Collaboration of Heterogeneous Multi-Robot System with Large
  Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kehui Liu, Zixin Tang, Dong Wang, Zhigang Wang, Bin Zhao, Xuelong Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-23 15:53:41</h6>
<p class='card-text'>Leveraging the powerful reasoning capabilities of large language models
(LLMs), recent LLM-based robot task planning methods yield promising results.
However, they mainly focus on single or multiple homogeneous robots on simple
tasks. Practically, complex long-horizon tasks always require collaborations
among multiple heterogeneous robots especially with more complex action spaces,
which makes these tasks more challenging. To this end, we propose COHERENT, a
novel LLM-based task planning framework for collaboration of heterogeneous
multi-robot systems including quadrotors, robotic dogs, and robotic arms.
Specifically, a Proposal-Execution-Feedback-Adjustment (PEFA) mechanism is
designed to decompose and assign actions for individual robots, where a
centralized task assigner makes a task planning proposal to decompose the
complex task into subtasks, and then assigns subtasks to robot executors. Each
robot executor selects a feasible action to implement the assigned subtask and
reports self-reflection feedback to the task assigner for plan adjustment. The
PEFA loops until the task is completed. Moreover, we create a challenging
heterogeneous multi-robot task planning benchmark encompassing 100 complex
long-horizon tasks. The experimental results show that our work surpasses the
previous methods by a large margin in terms of success rate and execution
efficiency. The experimental videos, code, and benchmark are released at
https://github.com/MrKeee/COHERENT.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.14908v1' target='_blank'>KARMA: Augmenting Embodied AI Agents with Long-and-short Term Memory
  Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zixuan Wang, Bo Yu, Junzhe Zhao, Wenhao Sun, Sai Hou, Shuai Liang, Xing Hu, Yinhe Han, Yiming Gan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-23 11:02:46</h6>
<p class='card-text'>Embodied AI agents responsible for executing interconnected, long-sequence
household tasks often face difficulties with in-context memory, leading to
inefficiencies and errors in task execution. To address this issue, we
introduce KARMA, an innovative memory system that integrates long-term and
short-term memory modules, enhancing large language models (LLMs) for planning
in embodied agents through memory-augmented prompting. KARMA distinguishes
between long-term and short-term memory, with long-term memory capturing
comprehensive 3D scene graphs as representations of the environment, while
short-term memory dynamically records changes in objects' positions and states.
This dual-memory structure allows agents to retrieve relevant past scene
experiences, thereby improving the accuracy and efficiency of task planning.
Short-term memory employs strategies for effective and adaptive memory
replacement, ensuring the retention of critical information while discarding
less pertinent data. Compared to state-of-the-art embodied agents enhanced with
memory, our memory-augmented embodied AI agent improves success rates by 1.3x
and 2.3x in Composite Tasks and Complex Tasks within the AI2-THOR simulator,
respectively, and enhances task execution efficiency by 3.4x and 62.7x.
Furthermore, we demonstrate that KARMA's plug-and-play capability allows for
seamless deployment on real-world robotic systems, such as mobile manipulation
platforms.Through this plug-and-play memory system, KARMA significantly
enhances the ability of embodied agents to generate coherent and contextually
appropriate plans, making the execution of complex household tasks more
efficient. The experimental videos from the work can be found at
https://youtu.be/4BT7fnw9ehs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.14907v1' target='_blank'>Knowledge Planning in Large Language Models for Domain-Aligned
  Counseling Summarization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Aseem Srivastava, Smriti Joshi, Tanmoy Chakraborty, Md Shad Akhtar</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-23 11:01:31</h6>
<p class='card-text'>In mental health counseling, condensing dialogues into concise and relevant
summaries (aka counseling notes) holds pivotal significance. Large Language
Models (LLMs) exhibit remarkable capabilities in various generative tasks;
however, their adaptation to domain-specific intricacies remains challenging,
especially within mental health contexts. Unlike standard LLMs, mental health
experts first plan to apply domain knowledge in writing summaries. Our work
enhances LLMs' ability by introducing a novel planning engine to orchestrate
structuring knowledge alignment. To achieve high-order planning, we divide
knowledge encapsulation into two major phases: (i) holding dialogue structure
and (ii) incorporating domain-specific knowledge. We employ a planning engine
on Llama-2, resulting in a novel framework, PIECE. Our proposed system employs
knowledge filtering-cum-scaffolding to encapsulate domain knowledge.
Additionally, PIECE leverages sheaf convolution learning to enhance its
understanding of the dialogue's structural nuances. We compare PIECE with 14
baseline methods and observe a significant improvement across ROUGE and Bleurt
scores. Further, expert evaluation and analyses validate the generation quality
to be effective, sometimes even surpassing the gold standard. We further
benchmark PIECE with other LLMs and report improvement, including Llama-2
(+2.72%), Mistral (+2.04%), and Zephyr (+1.59%), to justify the
generalizability of the planning engine.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.14826v3' target='_blank'>ToolPlanner: A Tool Augmented LLM for Multi Granularity Instructions
  with Path Planning and Feedback</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Qinzhuo Wu, Wei Liu, Jian Luan, Bin Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-23 08:58:48</h6>
<p class='card-text'>Recently, tool-augmented LLMs have gained increasing attention. Given an
instruction, tool-augmented LLMs can interact with various external tools in
multiple rounds and provide a final answer. However, previous LLMs were trained
on overly detailed instructions, which included API names or parameters, while
real users would not explicitly mention these API details. This leads to a gap
between trained LLMs and real-world scenarios. In addition, most works ignore
whether the interaction process follows the instruction. To address these
issues, we constructed a training dataset called MGToolBench, which contains
statement and category-level instructions to better reflect real-world
scenarios. In addition, we propose ToolPlanner, a two-stage reinforcement
learning framework that utilizes path planning and two feedback mechanisms to
enhance the LLM's task completion and instruction-following capabilities.
Experimental results show that ToolPlanner significantly improves the Match
Rate, Pass Rate and Win Rate by 26.8%, 20.2%, and 5.6% compared to the SOTA
model. Human evaluation verifies that the multi-granularity instructions can
better align with users' usage habits. Our data and code will be released upon
acceptance.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.07139v1' target='_blank'>Advancing Global South University Education with Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kemas Muslim L, Toru Ishida, Aditya Firman Ihsan, Rikman Aherliwan Rudawan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-23 07:33:38</h6>
<p class='card-text'>In recent years, it has been observed that the center of gravity for the
volume of higher education has shifted to the Global South. However, research
indicates a widening disparity in the quality of higher education between the
Global South and the Global North. Although investments in higher education
within the Global South have increased, the rapid surge in student numbers has
resulted in a decline in public expenditure per student. For instance, the
student-to-teacher ratio in the Global South is significantly higher compared
to that in the Global North, which poses a substantial barrier to the
implementation of creative education. In response, Telkom University in
Indonesia has embarked on an experiment to enhance the quality of learning and
teaching by integrating large language models (LLMs) such as ChatGPT into five
of its courses-Mathematics, English, Computing, Computer Systems, and Creative
Media. This article elucidates the ongoing experimental plan and explores how
the integration of LLMs could contribute to addressing the challenges currently
faced by higher education in the Global South.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.14762v1' target='_blank'>Do Large Language Models have Problem-Solving Capability under
  Incomplete Information Scenarios?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuyan Chen, Tianhao Yu, Yueze Li, Songzhou Yan, Sijia Liu, Jiaqing Liang, Yanghua Xiao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-23 07:18:02</h6>
<p class='card-text'>The evaluation of the problem-solving capability under incomplete information
scenarios of Large Language Models (LLMs) is increasingly important,
encompassing capabilities such as questioning, knowledge search, error
detection, and path planning. Current research mainly focus on LLMs'
problem-solving capability such as ``Twenty Questions''. However, these kinds
of games do not require recognizing misleading cues which are necessary in the
incomplete information scenario. Moreover, the existing game such as ``Who is
undercover'' are highly subjective, making it challenging for evaluation.
Therefore, in this paper, we introduce a novel game named BrainKing based on
the ``Who is undercover'' and ``Twenty Questions'' for evaluating LLM
capabilities under incomplete information scenarios. It requires LLMs to
identify target entities with limited yes-or-no questions and potential
misleading answers. By setting up easy, medium, and hard difficulty modes, we
comprehensively assess the performance of LLMs across various aspects. Our
results reveal the capabilities and limitations of LLMs in BrainKing, providing
significant insights of LLM problem-solving levels.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.14516v1' target='_blank'>Beyond Words: Evaluating Large Language Models in Transportation
  Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shaowei Ying, Zhenlong Li, Manzhu Yu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-22 16:20:00</h6>
<p class='card-text'>The resurgence and rapid advancement of Generative Artificial Intelligence
(GenAI) in 2023 has catalyzed transformative shifts across numerous industry
sectors, including urban transportation and logistics. This study investigates
the evaluation of Large Language Models (LLMs), specifically GPT-4 and
Phi-3-mini, to enhance transportation planning. The study assesses the
performance and spatial comprehension of these models through a
transportation-informed evaluation framework that includes general geospatial
skills, general transportation domain skills, and real-world transportation
problem-solving. Utilizing a mixed-methods approach, the research encompasses
an evaluation of the LLMs' general Geographic Information System (GIS) skills,
general transportation domain knowledge as well as abilities to support human
decision-making in the real-world transportation planning scenarios of
congestion pricing. Results indicate that GPT-4 demonstrates superior accuracy
and reliability across various GIS and transportation-specific tasks compared
to Phi-3-mini, highlighting its potential as a robust tool for transportation
planners. Nonetheless, Phi-3-mini exhibits competence in specific analytical
scenarios, suggesting its utility in resource-constrained environments. The
findings underscore the transformative potential of GenAI technologies in urban
transportation planning. Future work could explore the application of newer
LLMs and the impact of Retrieval-Augmented Generation (RAG) techniques, on a
broader set of real-world transportation planning and operations challenges, to
deepen the integration of advanced AI models in transportation management
practices.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.14371v1' target='_blank'>The Ability of Large Language Models to Evaluate Constraint-satisfaction
  in Agent Responses to Open-ended Requests</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lior Madmoni, Amir Zait, Ilia Labzovsky, Danny Karmon</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-22 09:27:42</h6>
<p class='card-text'>Generative AI agents are often expected to respond to complex user requests
that have No One Right Answer (NORA), e.g., "design a vegetarian meal plan
below 1800 calories". Such requests may entail a set of constraints that the
agent should adhere to. To successfully develop agents for NORA scenarios, an
accurate automatic evaluation framework is essential, and specifically - one
capable of validating the satisfaction of constraints in the agent's response.
Recently, large language models (LLMs) have been adopted as versatile
evaluators for many NORA tasks, but their ability to evaluate
constraint-satisfaction in generated text remains unclear. To study this, we
develop and release a novel Arithmetic Constraint-Satisfaction (ACS)
benchmarking dataset. The dataset consists of complex user requests with
corresponding constraints, agent responses and human labels indicating each
constraint's satisfaction level in the response. A unique property of this
dataset is that validating many of its constraints requires reviewing the
response as a whole (in contrast to many other benchmarks that require the
validation of a single independent item). Moreover, it assesses LLMs in
performing reasoning, in-context data extraction, arithmetic calculations, and
counting. We then benchmark both open and proprietary LLMs on evaluating
constraint-satisfaction, and show that most models still have a significant
headroom for improvement, and that errors primarily stem from reasoning issues.
In addition, most models exhibit a skewed constraint-satisfaction prediction
pattern, with higher accuracy where the ground-truth label is "satisfied".
Lastly, few-shot prompting for our task proved to be rather challenging, since
many of the studied models showed a degradation in performance when it was
introduced.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.14165v3' target='_blank'>A Survey on Large Language Model-empowered Autonomous Driving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuxuan Zhu, Shiyi Wang, Wenqing Zhong, Nianchen Shen, Yunqi Li, Siqi Wang, Zhiheng Li, Cathy Wu, Zhengbing He, Li Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-21 15:07:37</h6>
<p class='card-text'>Artificial intelligence (AI) plays a crucial role in autonomous driving (AD)
research, propelling its development towards intelligence and efficiency.
Currently, the development of AD technology follows two main technical paths:
modularization and end-to-end. Modularization decompose the driving task into
modules such as perception, prediction, planning, and control, and train them
separately. Due to the inconsistency of training objectives between modules,
the integrated effect suffers from bias. End-to-end attempts to address this
issue by utilizing a single model that directly maps from sensor data to
control signals. This path has limited learning capabilities in a comprehensive
set of features and struggles to handle unpredictable long-tail events and
complex urban traffic scenarios. In the face of challenges encountered in both
paths, many researchers believe that large language models (LLMs) with powerful
reasoning capabilities and extensive knowledge understanding may be the
solution, expecting LLMs to provide AD systems with deeper levels of
understanding and decision-making capabilities. In light of the challenges
faced by both paths, many researchers believe that LLMs, with their powerful
reasoning abilities and extensive knowledge, could offer a solution. To
understand if LLMs could enhance AD, this paper conducts a thorough analysis of
the potential applications of LLMs in AD systems, including exploring their
optimization strategies in both modular and end-to-end approaches, with a
particular focus on how LLMs can tackle the problems and challenges present in
current solutions. Furthermore, we discuss an important question: Can LLM-based
artificial general intelligence (AGI) be a key to achieve high-level AD? We
further analyze the potential limitations and challenges that LLMs may
encounter in promoting the development of AD technology.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.02810v2' target='_blank'>StateAct: State Tracking and Reasoning for Acting and Planning with
  Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nikolai Rozanov, Marek Rei</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-21 05:54:35</h6>
<p class='card-text'>Planning and acting to solve `real' tasks using large language models (LLMs)
in interactive environments has become a new frontier for AI methods. While
recent advances allowed LLMs to interact with online tools, solve robotics
tasks and many more, long range reasoning tasks remain a problem for LLMs.
Existing methods to address this issue are very resource intensive and require
additional data or human crafted rules, instead, we propose a simple method
based on few-shot in-context learning alone to enhance `chain-of-thought' with
state-tracking for planning and acting with LLMs. We show that our method
establishes the new state-of-the-art on Alfworld for in-context learning
methods (+14\% over the previous best few-shot in-context learning method) and
performs on par with methods that use additional training data and additional
tools such as code-execution. We also demonstrate that our enhanced
`chain-of-states' allows the agent to both solve longer horizon problems and to
be more efficient in number of steps required to solve a task. We show that our
method works across a variety of LLMs for both API-based and open source ones.
Finally, we also conduct ablation studies and show that `chain-of-thoughts'
helps state-tracking accuracy, while a json-structure harms overall
performance. We open-source our code and annotations at
https://github.com/ai-nikolai/StateAct.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2410.03688v1' target='_blank'>LLM Agents as 6G Orchestrator: A Paradigm for Task-Oriented
  Physical-Layer Automation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhuoran Xiao, Chenhui Ye, Yunbo Hu, Honggang Yuan, Yihang Huang, Yijia Feng, Liyu Cai, Jiang Chang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-21 05:08:29</h6>
<p class='card-text'>The rapid advancement in generative pre-training models is propelling a
paradigm shift in technological progression from basic applications such as
chatbots towards more sophisticated agent-based systems. It is with huge
potential and necessity that the 6G system be combined with the copilot of
large language model (LLM) agents and digital twins (DT) to manage the highly
complicated communication system with new emerging features such as native AI
service and sensing. With the 6G-oriented agent, the base station could
understand the transmission requirements of various dynamic upper-layer tasks,
automatically orchestrate the optimal system workflow. Through continuously get
feedback from the 6G DT for reinforcement, the agents can finally raise the
performance of practical system accordingly. Differing from existing LLM agents
designed for general application, the 6G-oriented agent aims to make highly
rigorous and precise planning with a vast amount of extra expert knowledge,
which inevitably requires a specific system design from model training to
implementation. This paper proposes a novel comprehensive approach for building
task-oriented 6G LLM agents. We first propose a two-stage continual
pre-training and fine-tuning scheme to build the field basic model and
diversities of specialized expert models for meeting the requirements of
various application scenarios. Further, a novel inference framework based on
semantic retrieval for leveraging the existing communication-related functions
is proposed. Experiment results of exemplary tasks, such as physical-layer task
decomposition, show the proposed paradigm's feasibility and effectiveness.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.13588v2' target='_blank'>ChainBuddy: An AI Agent System for Generating LLM Pipelines</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jingyue Zhang, Ian Arawjo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-20 15:42:33</h6>
<p class='card-text'>As large language models (LLMs) advance, their potential applications have
grown significantly. However, it remains difficult to evaluate LLM behavior on
user-defined tasks and craft effective pipelines to do so. Many users struggle
with where to start, often referred to as the "blank page problem." ChainBuddy,
an AI workflow generation assistant built into the ChainForge platform, aims to
tackle this issue. From a single prompt or chat, ChainBuddy generates a starter
evaluative LLM pipeline in ChainForge aligned to the user's requirements.
ChainBuddy offers a straightforward and user-friendly way to plan and evaluate
LLM behavior and make the process less daunting and more accessible across a
wide range of possible tasks and use cases. We report a within-subjects user
study comparing ChainBuddy to the baseline interface. We find that when using
AI assistance, participants reported a less demanding workload, felt more
confident, and produced higher quality pipelines evaluating LLM behavior.
However, we also uncover a mismatch between subjective and objective ratings of
performance: participants rated their successfulness similarly across
conditions, while independent experts rated participant workflows significantly
higher with AI assistance. Drawing connections to the Dunning-Kruger effect, we
draw design implications for the future of workflow generation assistants to
mitigate the risk of over-reliance.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.13373v1' target='_blank'>LLMs Still Can't Plan; Can LRMs? A Preliminary Evaluation of OpenAI's o1
  on PlanBench</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Karthik Valmeekam, Kaya Stechly, Subbarao Kambhampati</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-20 10:20:46</h6>
<p class='card-text'>The ability to plan a course of action that achieves a desired state of
affairs has long been considered a core competence of intelligent agents and
has been an integral part of AI research since its inception. With the advent
of large language models (LLMs), there has been considerable interest in the
question of whether or not they possess such planning abilities. PlanBench, an
extensible benchmark we developed in 2022, soon after the release of GPT3, has
remained an important tool for evaluating the planning abilities of LLMs.
Despite the slew of new private and open source LLMs since GPT3, progress on
this benchmark has been surprisingly slow. OpenAI claims that their recent o1
(Strawberry) model has been specifically constructed and trained to escape the
normal limitations of autoregressive LLMs--making it a new kind of model: a
Large Reasoning Model (LRM). Using this development as a catalyst, this paper
takes a comprehensive look at how well current LLMs and new LRMs do on
PlanBench. As we shall see, while o1's performance is a quantum improvement on
the benchmark, outpacing the competition, it is still far from saturating it.
This improvement also brings to the fore questions about accuracy, efficiency,
and guarantees which must be considered before deploying such systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.13356v1' target='_blank'>Automatic Behavior Tree Expansion with LLMs for Robotic Manipulation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jonathan Styrud, Matteo Iovino, Mikael Norrlöf, Mårten Björkman, Christian Smith</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-20 09:41:13</h6>
<p class='card-text'>Robotic systems for manipulation tasks are increasingly expected to be easy
to configure for new tasks or unpredictable environments, while keeping a
transparent policy that is readable and verifiable by humans. We propose the
method BEhavior TRee eXPansion with Large Language Models (BETR-XP-LLM) to
dynamically and automatically expand and configure Behavior Trees as policies
for robot control. The method utilizes an LLM to resolve errors outside the
task planner's capabilities, both during planning and execution. We show that
the method is able to solve a variety of tasks and failures and permanently
update the policy to handle similar problems in the future.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.13107v2' target='_blank'>Towards Robust Automation of Surgical Systems via Digital Twin-based
  Scene Representations from Foundation Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hao Ding, Lalithkumar Seenivasan, Hongchao Shu, Grayson Byrd, Han Zhang, Pu Xiao, Juan Antonio Barragan, Russell H. Taylor, Peter Kazanzides, Mathias Unberath</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-19 22:24:46</h6>
<p class='card-text'>Large language model-based (LLM) agents are emerging as a powerful enabler of
robust embodied intelligence due to their capability of planning complex action
sequences. Sound planning ability is necessary for robust automation in many
task domains, but especially in surgical automation. These agents rely on a
highly detailed natural language representation of the scene. Thus, to leverage
the emergent capabilities of LLM agents for surgical task planning, developing
similarly powerful and robust perception algorithms is necessary to derive a
detailed scene representation of the environment from visual input. Previous
research has focused primarily on enabling LLM-based task planning while
adopting simple yet severely limited perception solutions to meet the needs for
bench-top experiments but lack the critical flexibility to scale to less
constrained settings. In this work, we propose an alternate perception approach
-- a digital twin-based machine perception approach that capitalizes on the
convincing performance and out-of-the-box generalization of recent vision
foundation models. Integrating our digital twin-based scene representation and
LLM agent for planning with the dVRK platform, we develop an embodied
intelligence system and evaluate its robustness in performing peg transfer and
gauze retrieval tasks. Our approach shows strong task performance and
generalizability to varied environment settings. Despite convincing
performance, this work is merely a first step towards the integration of
digital twin-based scene representations. Future studies are necessary for the
realization of a comprehensive digital twin framework to improve the
interpretability and generalizability of embodied intelligence in surgery.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.12889v2' target='_blank'>Can VLMs Play Action Role-Playing Games? Take Black Myth Wukong as a
  Study Case</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Peng Chen, Pi Bu, Jun Song, Yuan Gao, Bo Zheng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-19 16:30:25</h6>
<p class='card-text'>Recently, large language model (LLM)-based agents have made significant
advances across various fields. One of the most popular research areas involves
applying these agents to video games. Traditionally, these methods have relied
on game APIs to access in-game environmental and action data. However, this
approach is limited by the availability of APIs and does not reflect how humans
play games. With the advent of vision language models (VLMs), agents now have
enhanced visual understanding capabilities, enabling them to interact with
games using only visual inputs. Despite these advances, current approaches
still face challenges in action-oriented tasks, particularly in action
role-playing games (ARPGs), where reinforcement learning methods are prevalent
but suffer from poor generalization and require extensive training. To address
these limitations, we select an ARPG, ``Black Myth: Wukong'', as a research
platform to explore the capability boundaries of existing VLMs in scenarios
requiring visual-only input and complex action output. We define 12 tasks
within the game, with 75% focusing on combat, and incorporate several
state-of-the-art VLMs into this benchmark. Additionally, we will release a
human operation dataset containing recorded gameplay videos and operation logs,
including mouse and keyboard actions. Moreover, we propose a novel VARP (Vision
Action Role-Playing) agent framework, consisting of an action planning system
and a visual trajectory system. Our framework demonstrates the ability to
perform basic tasks and succeed in 90% of easy and medium-level combat
scenarios. This research aims to provide new insights and directions for
applying multimodal agents in complex action game environments. The code and
datasets will be made available at https://varp-agent.github.io/.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.12452v2' target='_blank'>Unlocking Reasoning Potential in Large Langauge Models by Scaling
  Code-form Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiaxin Wen, Jian Guan, Hongning Wang, Wei Wu, Minlie Huang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-19 04:13:58</h6>
<p class='card-text'>Despite the remarkable success of large language models (LLMs) on traditional
natural language processing tasks, their planning ability remains a critical
bottleneck in tackling complex multi-step reasoning tasks. Existing approaches
mainly rely on prompting or task-specific fine-tuning, often suffering from
poor robustness and cross-task generalization. To address the limitation, we
introduce CodePlan, a scalable framework that empowers LLMs to generate and
follow \textit{code-form plans} -- pseudocode that outlines high-level,
structured reasoning processes. By leveraging the structured and versatile
nature of code, CodePlan effectively captures the rich semantics and control
flows inherent to sophisticated reasoning tasks. Importantly, CodePlan allows
automatic extraction of code-form plans from massive, wide-ranging text corpora
without the need for curated, task-specific datasets. This enables it to scale
up efficiently and improve LLM's reasoning capabilities across diverse
scenarios. To train CodePlan, we construct a large-scale dataset of 2M examples
that integrate code-form plans with standard prompt-response pairs from
existing corpora. With minimal computation overhead during both training and
inference, CodePlan achieves a 25.1\% relative improvement compared with
directly generating responses, averaged across 13 challenging multi-step
reasoning benchmarks, spanning mathematical reasoning, symbolic reasoning,
instruction-following, multi-hop QA, and decision-making tasks. Further
analysis reveals CodePlan's increasing performance gains on more complex
reasoning tasks, as well as significant data efficiency thanks to its
generalization ability.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.12278v2' target='_blank'>Making Large Language Models into World Models with Precondition and
  Effect Knowledge</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kaige Xie, Ian Yang, John Gunerli, Mark Riedl</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-18 19:28:04</h6>
<p class='card-text'>World models, which encapsulate the dynamics of how actions affect
environments, are foundational to the functioning of intelligent agents. In
this work, we explore the potential of Large Language Models (LLMs) to operate
as world models. Although LLMs are not inherently designed to model real-world
dynamics, we show that they can be induced to perform two critical world model
functions: determining the applicability of an action based on a given world
state, and predicting the resulting world state upon action execution. This is
achieved by fine-tuning two separate LLMs-one for precondition prediction and
another for effect prediction-while leveraging synthetic data generation
techniques. Through human-participant studies, we validate that the
precondition and effect knowledge generated by our models aligns with human
understanding of world dynamics. We also analyze the extent to which the world
model trained on our synthetic data results in an inferred state space that
supports the creation of action chains, a necessary property for planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.12262v2' target='_blank'>Bootstrapping Object-level Planning with Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:David Paulius, Alejandro Agostini, Benedict Quartey, George Konidaris</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-18 18:47:58</h6>
<p class='card-text'>We introduce a new method that extracts knowledge from a large language model
(LLM) to produce object-level plans, which describe high-level changes to
object state, and uses them to bootstrap task and motion planning (TAMP) in a
hierarchical manner. Existing works use LLMs to either directly output task
plans or to generate goals in representations like PDDL. However, these methods
fall short because they either rely on the LLM to do the actual planning or
output a hard-to-satisfy goal. Our approach instead extracts knowledge from a
LLM in the form of plan schemas as an object level representation called
functional object-oriented networks (FOON), from which we automatically
generate PDDL subgoals. Our experiments demonstrate how our method's
performance markedly exceeds alternative planning strategies across several
tasks in simulation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.12183v2' target='_blank'>To CoT or not to CoT? Chain-of-thought helps mainly on math and symbolic
  reasoning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zayne Sprague, Fangcong Yin, Juan Diego Rodriguez, Dongwei Jiang, Manya Wadhwa, Prasann Singhal, Xinyu Zhao, Xi Ye, Kyle Mahowald, Greg Durrett</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-18 17:55:00</h6>
<p class='card-text'>Chain-of-thought (CoT) via prompting is the de facto method for eliciting
reasoning capabilities from large language models (LLMs). But for what kinds of
tasks is this extra ``thinking'' really helpful? To analyze this, we conducted
a quantitative meta-analysis covering over 100 papers using CoT and ran our own
evaluations of 20 datasets across 14 models. Our results show that CoT gives
strong performance benefits primarily on tasks involving math or logic, with
much smaller gains on other types of tasks. On MMLU, directly generating the
answer without CoT leads to almost identical accuracy as CoT unless the
question or model's response contains an equals sign, indicating symbolic
operations and reasoning. Following this finding, we analyze the behavior of
CoT on these problems by separating planning and execution and comparing
against tool-augmented LLMs. Much of CoT's gain comes from improving symbolic
execution, but it underperforms relative to using a symbolic solver. Our
results indicate that CoT can be applied selectively, maintaining performance
while saving inference costs. Furthermore, they suggest a need to move beyond
prompt-based CoT to new paradigms that better leverage intermediate computation
across the whole range of LLM applications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.11863v1' target='_blank'>Learning Task Planning from Multi-Modal Demonstration for Multi-Stage
  Contact-Rich Manipulation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kejia Chen, Zheng Shen, Yue Zhang, Lingyun Chen, Fan Wu, Zhenshan Bing, Sami Haddadin, Alois Knoll</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-18 10:36:47</h6>
<p class='card-text'>Large Language Models (LLMs) have gained popularity in task planning for
long-horizon manipulation tasks. To enhance the validity of LLM-generated
plans, visual demonstrations and online videos have been widely employed to
guide the planning process. However, for manipulation tasks involving subtle
movements but rich contact interactions, visual perception alone may be
insufficient for the LLM to fully interpret the demonstration. Additionally,
visual data provides limited information on force-related parameters and
conditions, which are crucial for effective execution on real robots.
  In this paper, we introduce an in-context learning framework that
incorporates tactile and force-torque information from human demonstrations to
enhance LLMs' ability to generate plans for new task scenarios. We propose a
bootstrapped reasoning pipeline that sequentially integrates each modality into
a comprehensive task plan. This task plan is then used as a reference for
planning in new task configurations. Real-world experiments on two different
sequential manipulation tasks demonstrate the effectiveness of our framework in
improving LLMs' understanding of multi-modal demonstrations and enhancing the
overall planning performance.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.11580v1' target='_blank'>PLATO: Planning with LLMs and Affordances for Tool Manipulation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Arvind Car, Sai Sravan Yarlagadda, Alison Bartsch, Abraham George, Amir Barati Farimani</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-17 22:12:07</h6>
<p class='card-text'>As robotic systems become increasingly integrated into complex real-world
environments, there is a growing need for approaches that enable robots to
understand and act upon natural language instructions without relying on
extensive pre-programmed knowledge of their surroundings. This paper presents
PLATO, an innovative system that addresses this challenge by leveraging
specialized large language model agents to process natural language inputs,
understand the environment, predict tool affordances, and generate executable
actions for robotic systems. Unlike traditional systems that depend on
hard-coded environmental information, PLATO employs a modular architecture of
specialized agents to operate without any initial knowledge of the environment.
These agents identify objects and their locations within the scene, generate a
comprehensive high-level plan, translate this plan into a series of low-level
actions, and verify the completion of each step. The system is particularly
tested on challenging tool-use tasks, which involve handling diverse objects
and require long-horizon planning. PLATO's design allows it to adapt to dynamic
and unstructured settings, significantly enhancing its flexibility and
robustness. By evaluating the system across various complex scenarios, we
demonstrate its capability to tackle a diverse range of tasks and offer a novel
solution to integrate LLMs with robotic platforms, advancing the
state-of-the-art in autonomous robotic task execution. For videos and prompt
details, please see our project website:
https://sites.google.com/andrew.cmu.edu/plato</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.11393v2' target='_blank'>LLM-Agent-UMF: LLM-based Agent Unified Modeling Framework for Seamless
  Integration of Multi Active/Passive Core-Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Amine Ben Hassouna, Hana Chaari, Ines Belhaj</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-17 17:54:17</h6>
<p class='card-text'>In an era where vast amounts of data are collected and processed from diverse
sources, there is a growing demand to develop sophisticated AI systems capable
of intelligently fusing and analyzing this information. To address these
challenges, researchers have turned towards integrating tools into LLM-powered
agents to enhance the overall information fusion process. However, the
conjunction of these technologies and the proposed enhancements in several
state-of-the-art works followed a non-unified software architecture resulting
in a lack of modularity and terminological inconsistencies among researchers.
To address these issues, we propose a novel LLM-based Agent Unified Modeling
Framework (LLM-Agent-UMF) that aims to establish a clear foundation for agent
development from both functional and software architectural perspectives. Our
framework distinguishes between the different components of an LLM-based agent,
setting LLMs, and tools apart from a new element, the core-agent, playing the
role of the central coordinator of the agent. This pivotal entity comprises
five modules: planning, memory, profile, action, and security - the latter
often neglected in previous works. By classifying core-agents into passive and
active types based on their authoritative natures, we propose various
multi-core agent architectures that combine unique characteristics of
distinctive agents to tackle complex tasks more efficiently. We evaluate our
framework by applying it to thirteen state-of-the-art agents, thereby
demonstrating its alignment with their functionalities and clarifying the
overlooked architectural aspects. Moreover, we thoroughly assess five of our
proposed architectures through the integration of existing agents into new
hybrid active/passive core-agents architectures. This analysis provides
insights into potential improvements and highlights challenges involved in
combining specific agents.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.11279v1' target='_blank'>P-RAG: Progressive Retrieval Augmented Generation For Planning on
  Embodied Everyday Task</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Weiye Xu, Min Wang, Wengang Zhou, Houqiang Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-17 15:29:34</h6>
<p class='card-text'>Embodied Everyday Task is a popular task in the embodied AI community,
requiring agents to make a sequence of actions based on natural language
instructions and visual observations. Traditional learning-based approaches
face two challenges. Firstly, natural language instructions often lack explicit
task planning. Secondly, extensive training is required to equip models with
knowledge of the task environment. Previous works based on Large Language Model
(LLM) either suffer from poor performance due to the lack of task-specific
knowledge or rely on ground truth as few-shot samples. To address the above
limitations, we propose a novel approach called Progressive Retrieval Augmented
Generation (P-RAG), which not only effectively leverages the powerful language
processing capabilities of LLMs but also progressively accumulates
task-specific knowledge without ground-truth. Compared to the conventional RAG
methods, which retrieve relevant information from the database in a one-shot
manner to assist generation, P-RAG introduces an iterative approach to
progressively update the database. In each iteration, P-RAG retrieves the
latest database and obtains historical information from the previous
interaction as experiential references for the current interaction. Moreover,
we also introduce a more granular retrieval scheme that not only retrieves
similar tasks but also incorporates retrieval of similar situations to provide
more valuable reference experiences. Extensive experiments reveal that P-RAG
achieves competitive results without utilizing ground truth and can even
further improve performance through self-iterations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.11276v1' target='_blank'>Hackphyr: A Local Fine-Tuned LLM Agent for Network Security Environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Maria Rigaki, Carlos Catania, Sebastian Garcia</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-17 15:28:25</h6>
<p class='card-text'>Large Language Models (LLMs) have shown remarkable potential across various
domains, including cybersecurity. Using commercial cloud-based LLMs may be
undesirable due to privacy concerns, costs, and network connectivity
constraints. In this paper, we present Hackphyr, a locally fine-tuned LLM to be
used as a red-team agent within network security environments. Our fine-tuned 7
billion parameter model can run on a single GPU card and achieves performance
comparable with much larger and more powerful commercial models such as GPT-4.
Hackphyr clearly outperforms other models, including GPT-3.5-turbo, and
baselines, such as Q-learning agents in complex, previously unseen scenarios.
To achieve this performance, we generated a new task-specific cybersecurity
dataset to enhance the base model's capabilities. Finally, we conducted a
comprehensive analysis of the agents' behaviors that provides insights into the
planning abilities and potential shortcomings of such agents, contributing to
the broader understanding of LLM-based agents in cybersecurity contexts</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.10444v1' target='_blank'>LLM as BT-Planner: Leveraging LLMs for Behavior Tree Generation in Robot
  Task Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jicong Ao, Fan Wu, Yansong Wu, Abdalla Swikir, Sami Haddadin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-16 16:28:34</h6>
<p class='card-text'>Robotic assembly tasks are open challenges due to the long task horizon and
complex part relations. Behavior trees (BTs) are increasingly used in robot
task planning for their modularity and flexibility, but manually designing them
can be effort-intensive. Large language models (LLMs) have recently been
applied in robotic task planning for generating action sequences, but their
ability to generate BTs has not been fully investigated. To this end, We
propose LLM as BT-planner, a novel framework to leverage LLMs for BT generation
in robotic assembly task planning and execution. Four in-context learning
methods are introduced to utilize the natural language processing and inference
capabilities of LLMs to produce task plans in BT format, reducing manual effort
and ensuring robustness and comprehensibility. We also evaluate the performance
of fine-tuned, fewer-parameter LLMs on the same tasks. Experiments in simulated
and real-world settings show that our framework enhances LLMs' performance in
BT generation, improving success rates in BT generation through in-context
learning and supervised fine-tuning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.10090v1' target='_blank'>MotionCom: Automatic and Motion-Aware Image Composition with LLM and
  Video Diffusion Prior</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Weijing Tao, Xiaofeng Yang, Miaomiao Cui, Guosheng Lin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-16 08:44:17</h6>
<p class='card-text'>This work presents MotionCom, a training-free motion-aware diffusion based
image composition, enabling automatic and seamless integration of target
objects into new scenes with dynamically coherent results without finetuning or
optimization. Traditional approaches in this area suffer from two significant
limitations: they require manual planning for object placement and often
generate static compositions lacking motion realism. MotionCom addresses these
issues by utilizing a Large Vision Language Model (LVLM) for intelligent
planning, and a Video Diffusion prior for motion-infused image synthesis,
streamlining the composition process. Our multi-modal Chain-of-Thought (CoT)
prompting with LVLM automates the strategic placement planning of foreground
objects, considering their potential motion and interaction within the scenes.
Complementing this, we propose a novel method MotionPaint to distill
motion-aware information from pretrained video diffusion models in the
generation phase, ensuring that these objects are not only seamlessly
integrated but also endowed with realistic motion. Extensive quantitative and
qualitative results highlight MotionCom's superiority, showcasing its
efficiency in streamlining the planning process and its capability to produce
compositions that authentically depict motion and interaction.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.10027v4' target='_blank'>E2Map: Experience-and-Emotion Map for Self-Reflective Robot Navigation
  with Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chan Kim, Keonwoo Kim, Mintaek Oh, Hanbi Baek, Jiyang Lee, Donghwi Jung, Soojin Woo, Younkyung Woo, John Tucker, Roya Firoozi, Seung-Woo Seo, Mac Schwager, Seong-Woo Kim</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-16 06:35:18</h6>
<p class='card-text'>Large language models (LLMs) have shown significant potential in guiding
embodied agents to execute language instructions across a range of tasks,
including robotic manipulation and navigation. However, existing methods are
primarily designed for static environments and do not leverage the agent's own
experiences to refine its initial plans. Given that real-world environments are
inherently stochastic, initial plans based solely on LLMs' general knowledge
may fail to achieve their objectives, unlike in static scenarios. To address
this limitation, this study introduces the Experience-and-Emotion Map (E2Map),
which integrates not only LLM knowledge but also the agent's real-world
experiences, drawing inspiration from human emotional responses. The proposed
methodology enables one-shot behavior adjustments by updating the E2Map based
on the agent's experiences. Our evaluation in stochastic navigation
environments, including both simulations and real-world scenarios, demonstrates
that the proposed method significantly enhances performance in stochastic
environments compared to existing LLM-based approaches. Code and supplementary
materials are available at https://e2map.github.io/.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.09575v2' target='_blank'>Traffic Scene Generation from Natural Language Description for
  Autonomous Vehicles with Large Language Model</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Bo-Kai Ruan, Hao-Tang Tsui, Yung-Hui Li, Hong-Han Shuai</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-15 01:32:57</h6>
<p class='card-text'>Text-to-scene generation typically limits environmental diversity by
generating key scenarios along predetermined paths. To address these
constraints, we propose a novel text-to-traffic scene framework that leverages
a large language model (LLM) to autonomously generate diverse traffic scenarios
for the CARLA simulator based on natural language descriptions. Our pipeline
comprises several key stages: (1) Prompt Analysis, where natural language
inputs are decomposed; (2) Road Retrieval, selecting optimal roads from a
database; (3) Agent Planning, detailing agent types and behaviors; (4) Road
Ranking, scoring roads to match scenario requirements; and (5) Scene
Generation, rendering the planned scenarios in the simulator. This framework
supports both routine and critical traffic scenarios, enhancing its
applicability. We demonstrate that our approach not only diversifies agent
planning and road selection but also significantly reduces the average
collision rate from 8% to 3.5% in SafeBench. Additionally, our framework
improves narration and reasoning for driving captioning tasks. Our
contributions and resources are publicly available at
https://basiclab.github.io/TTSG.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.09568v1' target='_blank'>Thesis proposal: Are We Losing Textual Diversity to Natural Language
  Processing?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Josef Jon</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-15 01:06:07</h6>
<p class='card-text'>This thesis argues that the currently widely used Natural Language Processing
algorithms possibly have various limitations related to the properties of the
texts they handle and produce. With the wide adoption of these tools in rapid
progress, we must ask what these limitations are and what are the possible
implications of integrating such tools even more deeply into our daily lives.
  As a testbed, we have chosen the task of Neural Machine Translation (NMT).
Nevertheless, we aim for general insights and outcomes, applicable even to
current Large Language Models (LLMs). We ask whether the algorithms used in NMT
have inherent inductive biases that are beneficial for most types of inputs but
might harm the processing of untypical texts. To explore this hypothesis, we
define a set of measures to quantify text diversity based on its statistical
properties, like uniformity or rhythmicity of word-level surprisal, on multiple
scales (sentence, discourse, language). We then conduct a series of experiments
to investigate whether NMT systems struggle with maintaining the diversity of
such texts, potentially reducing the richness of the language generated by
these systems, compared to human translators.
  We search for potential causes of these limitations rooted in training
objectives and decoding algorithms. Our ultimate goal is to develop
alternatives that do not enforce uniformity in the distribution of statistical
properties in the output and that allow for better global planning of the
translation, taking into account the intrinsic ambiguity of the translation
task.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.09435v1' target='_blank'>Behavior Tree Generation using Large Language Models for Sequential
  Manipulation Planning with Human Instructions and Feedback</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jicong Ao, Yansong Wu, Fan Wu, Sami Haddadin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-14 13:27:31</h6>
<p class='card-text'>In this work, we propose an LLM-based BT generation framework to leverage the
strengths of both for sequential manipulation planning. To enable human-robot
collaborative task planning and enhance intuitive robot programming by
nonexperts, the framework takes human instructions to initiate the generation
of action sequences and human feedback to refine BT generation in runtime. All
presented methods within the framework are tested on a real robotic assembly
example, which uses a gear set model from the Siemens Robot Assembly Challenge.
We use a single manipulator with a tool-changing mechanism, a common practice
in flexible manufacturing, to facilitate robust grasping of a large variety of
objects. Experimental results are evaluated regarding success rate, logical
coherence, executability, time consumption, and token consumption. To our
knowledge, this is the first human-guided LLM-based BT generation framework
that unifies various plausible ways of using LLMs to fully generate BTs that
are executable on the real testbed and take into account granular knowledge of
tool use.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.09191v2' target='_blank'>ProcessTBench: An LLM Plan Generation Dataset for Process Mining</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Andrei Cosmin Redis, Mohammadreza Fani Sani, Bahram Zarrin, Andrea Burattin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-13 20:56:21</h6>
<p class='card-text'>Large Language Models (LLMs) have shown significant promise in plan
generation. Yet, existing datasets often lack the complexity needed for
advanced tool use scenarios - such as handling paraphrased query statements,
supporting multiple languages, and managing actions that can be done in
parallel. These scenarios are crucial for evaluating the evolving capabilities
of LLMs in real-world applications. Moreover, current datasets don't enable the
study of LLMs from a process perspective, particularly in scenarios where
understanding typical behaviors and challenges in executing the same process
under different conditions or formulations is crucial. To address these gaps,
we present the ProcessTBench synthetic dataset, an extension of the TaskBench
dataset specifically designed to evaluate LLMs within a process mining
framework.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.08642v2' target='_blank'>CPL: Critical Plan Step Learning Boosts LLM Generalization in Reasoning
  Tasks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tianlong Wang, Junzhe Chen, Xueting Han, Jing Bai</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-13 08:59:31</h6>
<p class='card-text'>Post-training, particularly reinforcement learning (RL) using
self-play-generated data, has become a new learning paradigm for large language
models (LLMs). However, scaling RL to develop a general reasoner remains a
research challenge, as existing methods focus on task-specific reasoning
without adequately addressing generalization across a broader range of tasks.
Moreover, unlike traditional RL with limited action space, LLMs operate in an
infinite space, making it crucial to search for valuable and diverse strategies
to solve problems effectively. To address this, we propose searching within the
action space on high-level abstract plans to enhance model generalization and
introduce Critical Plan Step Learning (CPL), comprising: 1) searching on plan,
using Monte Carlo Tree Search (MCTS) to explore diverse plan steps in
multi-step reasoning tasks, and 2) learning critical plan steps through
Step-level Advantage Preference Optimization (Step-APO), which integrates
advantage estimates for step preference obtained via MCTS into Direct
Preference Optimization (DPO). This combination helps the model effectively
learn critical plan steps, enhancing both reasoning capabilities and
generalization. Experimental results demonstrate that our method, trained
exclusively on GSM8K and MATH, not only significantly improves performance on
GSM8K (+10.5%) and MATH (+6.5%), but also enhances out-of-domain reasoning
benchmarks, such as HumanEval (+12.2%), GPQA (+8.6%), ARC-C (+4.0%), MMLU-STEM
(+2.2%), and BBH (+1.8%).</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.08410v1' target='_blank'>Sequential Discrete Action Selection via Blocking Conditions and
  Resolutions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Liam Merz Hoffmeister, Brian Scassellati, Daniel Rakita</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-12 21:42:28</h6>
<p class='card-text'>In this work, we introduce a strategy that frames the sequential action
selection problem for robots in terms of resolving \textit{blocking
conditions}, i.e., situations that impede progress on an action en route to a
goal. This strategy allows a robot to make one-at-a-time decisions that take in
pertinent contextual information and swiftly adapt and react to current
situations. We present a first instantiation of this strategy that combines a
state-transition graph and a zero-shot Large Language Model (LLM). The
state-transition graph tracks which previously attempted actions are currently
blocked and which candidate actions may resolve existing blocking conditions.
This information from the state-transition graph is used to automatically
generate a prompt for the LLM, which then uses the given context and set of
possible actions to select a single action to try next. This selection process
is iterative, with each chosen and executed action further refining the
state-transition graph, continuing until the agent either fulfills the goal or
encounters a termination condition. We demonstrate the effectiveness of our
approach by comparing it to various LLM and traditional task-planning methods
in a testbed of simulation experiments. We discuss the implications of our work
based on our results.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.08264v2' target='_blank'>Windows Agent Arena: Evaluating Multi-Modal OS Agents at Scale</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Rogerio Bonatti, Dan Zhao, Francesco Bonacci, Dillon Dupont, Sara Abdali, Yinheng Li, Yadong Lu, Justin Wagle, Kazuhito Koishida, Arthur Bucker, Lawrence Jang, Zack Hui</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-12 17:56:43</h6>
<p class='card-text'>Large language models (LLMs) show remarkable potential to act as computer
agents, enhancing human productivity and software accessibility in multi-modal
tasks that require planning and reasoning. However, measuring agent performance
in realistic environments remains a challenge since: (i) most benchmarks are
limited to specific modalities or domains (e.g. text-only, web navigation, Q&A,
coding) and (ii) full benchmark evaluations are slow (on order of magnitude of
days) given the multi-step sequential nature of tasks. To address these
challenges, we introduce the Windows Agent Arena: a reproducible, general
environment focusing exclusively on the Windows operating system (OS) where
agents can operate freely within a real Windows OS and use the same wide range
of applications, tools, and web browsers available to human users when solving
tasks. We adapt the OSWorld framework (Xie et al., 2024) to create 150+ diverse
Windows tasks across representative domains that require agent abilities in
planning, screen understanding, and tool usage. Our benchmark is scalable and
can be seamlessly parallelized in Azure for a full benchmark evaluation in as
little as 20 minutes. To demonstrate Windows Agent Arena's capabilities, we
also introduce a new multi-modal agent, Navi. Our agent achieves a success rate
of 19.5% in the Windows domain, compared to 74.5% performance of an unassisted
human. Navi also demonstrates strong performance on another popular web-based
benchmark, Mind2Web. We offer extensive quantitative and qualitative analysis
of Navi's performance, and provide insights into the opportunities for future
research in agent development and data generation using Windows Agent Arena.
  Webpage: https://microsoft.github.io/WindowsAgentArena
  Code: https://github.com/microsoft/WindowsAgentArena</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.08069v1' target='_blank'>TravelAgent: An AI Assistant for Personalized Travel Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Aili Chen, Xuyang Ge, Ziquan Fu, Yanghua Xiao, Jiangjie Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-12 14:24:45</h6>
<p class='card-text'>As global tourism expands and artificial intelligence technology advances,
intelligent travel planning services have emerged as a significant research
focus. Within dynamic real-world travel scenarios with multi-dimensional
constraints, services that support users in automatically creating practical
and customized travel itineraries must address three key objectives:
Rationality, Comprehensiveness, and Personalization. However, existing systems
with rule-based combinations or LLM-based planning methods struggle to fully
satisfy these criteria. To overcome the challenges, we introduce TravelAgent, a
travel planning system powered by large language models (LLMs) designed to
provide reasonable, comprehensive, and personalized travel itineraries grounded
in dynamic scenarios. TravelAgent comprises four modules: Tool-usage,
Recommendation, Planning, and Memory Module. We evaluate TravelAgent's
performance with human and simulated users, demonstrating its overall
effectiveness in three criteria and confirming the accuracy of personalized
recommendations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.07267v4' target='_blank'>MiniDrive: More Efficient Vision-Language Models with Multi-Level 2D
  Features as Text Tokens for Autonomous Driving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Enming Zhang, Xingyuan Dai, Yisheng Lv, Qinghai Miao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-11 13:43:01</h6>
<p class='card-text'>Vision-language models (VLMs) serve as general-purpose end-to-end models in
autonomous driving, performing subtasks such as prediction, planning, and
perception through question-and-answer interactions. However, most existing
methods rely on computationally expensive visual encoders and large language
models (LLMs), making them difficult to deploy in real-world scenarios and
real-time applications. Meanwhile, most existing VLMs lack the ability to
process multiple images, making it difficult to adapt to multi-camera
perception in autonomous driving. To address these issues, we propose a novel
framework called MiniDrive, which incorporates our proposed Feature Engineering
Mixture of Experts (FE-MoE) module and Dynamic Instruction Adapter
(DI-Adapter). The FE-MoE effectively maps 2D features into visual token
embeddings before being input into the language model. The DI-Adapter enables
the visual token embeddings to dynamically change with the instruction text
embeddings, resolving the issue of static visual token embeddings for the same
image in previous approaches. Compared to previous works, MiniDrive achieves
state-of-the-art performance in terms of parameter size, floating point
operations, and response efficiency, with the smallest version containing only
83M parameters.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.06859v2' target='_blank'>NSP: A Neuro-Symbolic Natural Language Navigational Planner</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:William English, Dominic Simon, Sumit Jha, Rickard Ewetz</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-10 20:49:05</h6>
<p class='card-text'>Path planners that can interpret free-form natural language instructions hold
promise to automate a wide range of robotics applications. These planners
simplify user interactions and enable intuitive control over complex
semi-autonomous systems. While existing symbolic approaches offer guarantees on
the correctness and efficiency, they struggle to parse free-form natural
language inputs. Conversely, neural approaches based on pre-trained Large
Language Models (LLMs) can manage natural language inputs but lack performance
guarantees. In this paper, we propose a neuro-symbolic framework for path
planning from natural language inputs called NSP. The framework leverages the
neural reasoning abilities of LLMs to i) craft symbolic representations of the
environment and ii) a symbolic path planning algorithm. Next, a solution to the
path planning problem is obtained by executing the algorithm on the environment
representation. The framework uses a feedback loop from the symbolic execution
environment to the neural generation process to self-correct syntax errors and
satisfy execution time constraints. We evaluate our neuro-symbolic approach
using a benchmark suite with 1500 path-planning problems. The experimental
evaluation shows that our neuro-symbolic approach produces 90.1% valid paths
that are on average 19-77% shorter than state-of-the-art neural approaches.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.06646v1' target='_blank'>Optimal Workload Placement on Multi-Instance GPUs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Bekir Turkkan, Pavankumar Murali, Pavithra Harsha, Rohan Arora, Gerard Vanloo, Chandra Narayanaswami</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-10 17:05:11</h6>
<p class='card-text'>There is an urgent and pressing need to optimize usage of Graphical
Processing Units (GPUs), which have arguably become one of the most expensive
and sought after IT resources. To help with this goal, several of the current
generation of GPUs support a partitioning feature, called Multi-Instance GPU
(MIG) to allow multiple workloads to share a GPU, albeit with some constraints.
In this paper we investigate how to optimize the placement of Large Language
Model (LLM)-based AI Inferencing workloads on GPUs. We first identify and
present several use cases that are encountered in practice that require
workloads to be efficiently placed or migrated to other GPUs to make room for
incoming workloads. The overarching goal is to use as few GPUs as possible and
to further minimize memory and compute wastage on GPUs that are utilized. We
have developed two approaches to address this problem: an optimization method
and a heuristic method. We benchmark these with two workload scheduling
heuristics for multiple use cases. Our results show up to 2.85x improvement in
the number of GPUs used and up to 70% reduction in GPU wastage over baseline
heuristics. We plan to enable the SRE community to leverage our proposed method
in production environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.06328v1' target='_blank'>Extracting Paragraphs from LLM Token Activations</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nicholas Pochinkov, Angelo Benoit, Lovkush Agarwal, Zainab Ali Majid, Lucile Ter-Minassian</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-10 08:33:31</h6>
<p class='card-text'>Generative large language models (LLMs) excel in natural language processing
tasks, yet their inner workings remain underexplored beyond token-level
predictions. This study investigates the degree to which these models decide
the content of a paragraph at its onset, shedding light on their contextual
understanding. By examining the information encoded in single-token
activations, specifically the "\textbackslash n\textbackslash n" double newline
token, we demonstrate that patching these activations can transfer significant
information about the context of the following paragraph, providing further
insights into the model's capacity to plan ahead.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.16299v2' target='_blank'>HyperAgent: Generalist Software Engineering Agents to Solve Coding Tasks
  at Scale</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Huy Nhat Phan, Tien N. Nguyen, Phong X. Nguyen, Nghi D. Q. Bui</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-09 19:35:34</h6>
<p class='card-text'>Large Language Models (LLMs) have revolutionized software engineering (SE),
showcasing remarkable proficiency in various coding tasks. Despite recent
advancements that have enabled the creation of autonomous software agents
utilizing LLMs for end-to-end development tasks, these systems are typically
designed for specific SE functions. We introduce HyperAgent, an innovative
generalist multi-agent system designed to tackle a wide range of SE tasks
across different programming languages by mimicking the workflows of human
developers. HyperAgent features four specialized agents-Planner, Navigator,
Code Editor, and Executor-capable of handling the entire lifecycle of SE tasks,
from initial planning to final verification. HyperAgent sets new benchmarks in
diverse SE tasks, including GitHub issue resolution on the renowned SWE-Bench
benchmark, outperforming robust baselines. Furthermore, HyperAgent demonstrates
exceptional performance in repository-level code generation (RepoExec) and
fault localization and program repair (Defects4J), often surpassing
state-of-the-art baselines.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.05732v1' target='_blank'>Towards Democratizing Multilingual Large Language Models For Medicine
  Through A Two-Stage Instruction Fine-tuning Approach</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Meng Zhou, Surajsinh Parmar, Anubhav Bhatti</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-09 15:42:19</h6>
<p class='card-text'>Open-source, multilingual medical large language models (LLMs) have the
potential to serve linguistically diverse populations across different regions.
Adapting generic LLMs for healthcare often requires continual pretraining, but
this approach is computationally expensive and sometimes impractical.
Instruction fine-tuning on a specific task may not always guarantee optimal
performance due to the lack of broader domain knowledge that the model needs to
understand and reason effectively in diverse scenarios. To address these
challenges, we introduce two multilingual instruction fine-tuning datasets,
MMed-IFT and MMed-IFT-MC, containing over 200k high-quality medical samples in
six languages. We propose a two-stage training paradigm: the first stage
injects general medical knowledge using MMed-IFT, while the second stage
fine-tunes task-specific multiple-choice questions with MMed-IFT-MC. Our method
achieves competitive results on both English and multilingual benchmarks,
striking a balance between computational efficiency and performance. We plan to
make our dataset and model weights public at
\url{https://github.com/SpassMed/Med-Llama3} in the future.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.05001v1' target='_blank'>A Pair Programming Framework for Code Generation via Multi-Plan
  Exploration and Feedback-Driven Refinement</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Huan Zhang, Wei Cheng, Yuhan Wu, Wei Hu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-08 07:22:19</h6>
<p class='card-text'>Large language models (LLMs) have achieved impressive performance on code
generation. Although prior studies enhanced LLMs with prompting techniques and
code refinement, they still struggle with complex programming problems due to
rigid solution plans. In this paper, we draw on pair programming practices to
propose PairCoder, a novel LLM-based framework for code generation. PairCoder
incorporates two collaborative LLM agents, namely a Navigator agent for
high-level planning and a Driver agent for specific implementation. The
Navigator is responsible for proposing promising solution plans, selecting the
current optimal plan, and directing the next iteration round based on execution
feedback. The Driver follows the guidance of Navigator to undertake initial
code generation, code testing, and refinement. This interleaved and iterative
workflow involves multi-plan exploration and feedback-based refinement, which
mimics the collaboration of pair programmers. We evaluate PairCoder with both
open-source and closed-source LLMs on various code generation benchmarks.
Extensive experimental results demonstrate the superior accuracy of PairCoder,
achieving relative pass@1 improvements of 12.00%-162.43% compared to prompting
LLMs directly.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.04827v1' target='_blank'>Incorporate LLMs with Influential Recommender System</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mingze Wang, Shuxian Bi, Wenjie Wang, Chongming Gao, Yangyang Li, Fuli Feng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-07 13:41:37</h6>
<p class='card-text'>Recommender systems have achieved increasing accuracy over the years.
However, this precision often leads users to narrow their interests, resulting
in issues such as limited diversity and the creation of echo chambers. Current
research addresses these challenges through proactive recommender systems by
recommending a sequence of items (called influence path) to guide user interest
in the target item. However, existing methods struggle to construct a coherent
influence path that builds up with items the user is likely to enjoy. In this
paper, we leverage the Large Language Model's (LLMs) exceptional ability for
path planning and instruction following, introducing a novel approach named
LLM-based Influence Path Planning (LLM-IPP). Our approach maintains coherence
between consecutive recommendations and enhances user acceptability of the
recommended items. To evaluate LLM-IPP, we implement various user simulators
and metrics to measure user acceptability and path coherence. Experimental
results demonstrate that LLM-IPP significantly outperforms traditional
proactive recommender systems. This study pioneers the integration of LLMs into
proactive recommender systems, offering a reliable and user-engaging
methodology for future recommendation technologies.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.04775v3' target='_blank'>Scalable Task Planning via Large Language Models and Structured World
  Representations</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Rodrigo Pérez-Dattari, Zhaoting Li, Robert Babuška, Jens Kober, Cosimo Della Santina</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-07 09:30:26</h6>
<p class='card-text'>Planning methods struggle with computational intractability in solving
task-level problems in large-scale environments. This work explores leveraging
the commonsense knowledge encoded in LLMs to empower planning techniques to
deal with these complex scenarios. We achieve this by efficiently using LLMs to
prune irrelevant components from the planning problem's state space,
substantially simplifying its complexity. We demonstrate the efficacy of this
system through extensive experiments within a household simulation environment,
alongside real-world validation using a 7-DoF manipulator (video
https://youtu.be/6ro2UOtOQS4).</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.03937v1' target='_blank'>Harnessing LLMs for Cross-City OD Flow Prediction</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chenyang Yu, Xinpeng Xie, Yan Huang, Chenxi Qiu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-05 23:04:28</h6>
<p class='card-text'>Understanding and predicting Origin-Destination (OD) flows is crucial for
urban planning and transportation management. Traditional OD prediction models,
while effective within single cities, often face limitations when applied
across different cities due to varied traffic conditions, urban layouts, and
socio-economic factors. In this paper, by employing Large Language Models
(LLMs), we introduce a new method for cross-city OD flow prediction. Our
approach leverages the advanced semantic understanding and contextual learning
capabilities of LLMs to bridge the gap between cities with different
characteristics, providing a robust and adaptable solution for accurate OD flow
prediction that can be transferred from one city to another. Our novel
framework involves four major components: collecting OD training datasets from
a source city, instruction-tuning the LLMs, predicting destination POIs in a
target city, and identifying the locations that best match the predicted
destination POIs. We introduce a new loss function that integrates POI
semantics and trip distance during training. By extracting high-quality
semantic features from human mobility and POI data, the model understands
spatial and functional relationships within urban spaces and captures
interactions between individuals and various POIs. Extensive experimental
results demonstrate the superiority of our approach over the state-of-the-art
learning-based methods in cross-city OD flow prediction.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.03733v2' target='_blank'>Planning In Natural Language Improves LLM Search For Code Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Evan Wang, Federico Cassano, Catherine Wu, Yunfeng Bai, Will Song, Vaskar Nath, Ziwen Han, Sean Hendryx, Summer Yue, Hugh Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-05 17:44:49</h6>
<p class='card-text'>While scaling training compute has led to remarkable improvements in large
language models (LLMs), scaling inference compute has not yet yielded analogous
gains. We hypothesize that a core missing component is a lack of diverse LLM
outputs, leading to inefficient search due to models repeatedly sampling highly
similar, yet incorrect generations. We empirically demonstrate that this lack
of diversity can be mitigated by searching over candidate plans for solving a
problem in natural language. Based on this insight, we propose PlanSearch, a
novel search algorithm which shows strong results across HumanEval+, MBPP+, and
LiveCodeBench (a contamination-free benchmark for competitive coding).
PlanSearch generates a diverse set of observations about the problem and then
uses these observations to construct plans for solving the problem. By
searching over plans in natural language rather than directly over code
solutions, PlanSearch explores a significantly more diverse range of potential
solutions compared to baseline search methods. Using PlanSearch on top of
Claude 3.5 Sonnet achieves a state-of-the-art pass@200 of 77.0% on
LiveCodeBench, outperforming both the best score achieved without search
(pass@1 = 41.4%) and using standard repeated sampling (pass@200 = 60.6%).
Finally, we show that, across all models, search algorithms, and benchmarks
analyzed, we can accurately predict performance gains due to search as a direct
function of the diversity over generated ideas. Code can be found at
https://github.com/scaleapi/plansearch.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.03272v1' target='_blank'>OccLLaMA: An Occupancy-Language-Action Generative World Model for
  Autonomous Driving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Julong Wei, Shanshuai Yuan, Pengfei Li, Qingda Hu, Zhongxue Gan, Wenchao Ding</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-05 06:30:01</h6>
<p class='card-text'>The rise of multi-modal large language models(MLLMs) has spurred their
applications in autonomous driving. Recent MLLM-based methods perform action by
learning a direct mapping from perception to action, neglecting the dynamics of
the world and the relations between action and world dynamics. In contrast,
human beings possess world model that enables them to simulate the future
states based on 3D internal visual representation and plan actions accordingly.
To this end, we propose OccLLaMA, an occupancy-language-action generative world
model, which uses semantic occupancy as a general visual representation and
unifies vision-language-action(VLA) modalities through an autoregressive model.
Specifically, we introduce a novel VQVAE-like scene tokenizer to efficiently
discretize and reconstruct semantic occupancy scenes, considering its sparsity
and classes imbalance. Then, we build a unified multi-modal vocabulary for
vision, language and action. Furthermore, we enhance LLM, specifically LLaMA,
to perform the next token/scene prediction on the unified vocabulary to
complete multiple tasks in autonomous driving. Extensive experiments
demonstrate that OccLLaMA achieves competitive performance across multiple
tasks, including 4D occupancy forecasting, motion planning, and visual question
answering, showcasing its potential as a foundation model in autonomous
driving.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.03797v2' target='_blank'>NESTFUL: A Benchmark for Evaluating LLMs on Nested Sequences of API
  Calls</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kinjal Basu, Ibrahim Abdelaziz, Kiran Kate, Mayank Agarwal, Maxwell Crouse, Yara Rizk, Kelsey Bradford, Asim Munawar, Sadhana Kumaravel, Saurabh Goyal, Xin Wang, Luis A. Lastras, Pavan Kapanipathi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-04 17:53:24</h6>
<p class='card-text'>The resurgence of autonomous agents built using large language models (LLMs)
to solve complex real-world tasks has brought increased focus on LLMs'
fundamental ability of tool or function calling. At the core of these agents,
an LLM must plan, execute, and respond using external tools, APIs, and custom
functions. Research on tool calling has gathered momentum, but evaluation
benchmarks and datasets representing the complexity of the tasks have lagged
behind. In this work, we focus on one such complexity, nested sequencing, with
the goal of extending existing benchmarks and evaluation. Specifically, we
present NESTFUL, a benchmark to evaluate LLMs on nested sequences of API calls,
i.e., sequences where the output of one API call is passed as input to a
subsequent call. NESTFUL contains 1800+ nested sequences where all the function
calls are executable. Experimental results on multiple models and settings show
that the best-performing model on the dataset has a full sequence match
accuracy of 25% and win-rate of 34% necessitating a large scope for improvement
in the nested sequencing aspect of function calling. Our analysis of these
results provides possible future research directions for the community, in
addition to a benchmark to track progress. We have released the NESTFUL dataset
under the Apache 2.0 license at https://github.com/IBM/NESTFUL.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.01893v1' target='_blank'>What are the Essential Factors in Crafting Effective Long Context
  Multi-Hop Instruction Datasets? Insights and Best Practices</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhi Chen, Qiguang Chen, Libo Qin, Qipeng Guo, Haijun Lv, Yicheng Zou, Wanxiang Che, Hang Yan, Kai Chen, Dahua Lin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-03 13:30:00</h6>
<p class='card-text'>Recent advancements in large language models (LLMs) with extended context
windows have significantly improved tasks such as information extraction,
question answering, and complex planning scenarios. In order to achieve success
in long context tasks, a large amount of work has been done to enhance the long
context capabilities of the model through synthetic data. Existing methods
typically utilize the Self-Instruct framework to generate instruction tuning
data for better long context capability improvement. However, our preliminary
experiments indicate that less than 35% of generated samples are multi-hop, and
more than 40% exhibit poor quality, limiting comprehensive understanding and
further research. To improve the quality of synthetic data, we propose the
Multi-agent Interactive Multi-hop Generation (MIMG) framework, incorporating a
Quality Verification Agent, a Single-hop Question Generation Agent, a Multiple
Question Sampling Strategy, and a Multi-hop Question Merger Agent. This
framework improves the data quality, with the proportion of high-quality,
multi-hop, and diverse data exceeding 85%. Furthermore, we systematically
investigate strategies for document selection, question merging, and validation
techniques through extensive experiments across various models. Our findings
show that our synthetic high-quality long-context instruction data
significantly enhances model performance, even surpassing models trained on
larger amounts of human-annotated data. Our code is available at:
https://github.com/WowCZ/LongMIT.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.01806v1' target='_blank'>LASP: Surveying the State-of-the-Art in Large Language Model-Assisted AI
  Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Haoming Li, Zhaoliang Chen, Jonathan Zhang, Fei Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-03 11:39:52</h6>
<p class='card-text'>Effective planning is essential for the success of any task, from organizing
a vacation to routing autonomous vehicles and developing corporate strategies.
It involves setting goals, formulating plans, and allocating resources to
achieve them. LLMs are particularly well-suited for automated planning due to
their strong capabilities in commonsense reasoning. They can deduce a sequence
of actions needed to achieve a goal from a given state and identify an
effective course of action. However, it is frequently observed that plans
generated through direct prompting often fail upon execution. Our survey aims
to highlight the existing challenges in planning with language models, focusing
on key areas such as embodied environments, optimal scheduling, competitive and
cooperative games, task decomposition, reasoning, and planning. Through this
study, we explore how LLMs transform AI planning and provide unique insights
into the future of LM-assisted planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.01344v2' target='_blank'>Pairing Analogy-Augmented Generation with Procedural Memory for
  Procedural Q&A</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:K Roth, Rushil Gupta, Simon Halle, Bang Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-02 15:58:24</h6>
<p class='card-text'>Large language models struggle to synthesize disparate pieces of information
into a coherent plan when approaching a complex procedural task. In this work,
we introduce a novel formalism and structure for such procedural knowledge.
Based on this formalism, we present a novel procedural knowledge dataset called
LCStep, which we created from LangChain tutorials. To leverage this procedural
knowledge to solve new tasks, we propose analogy-augmented generation (AAG),
which draws inspiration from the human ability to assimilate past experiences
to solve unfamiliar problems. AAG uses a custom procedure memory store to
retrieve and adapt specialized domain knowledge to answer new procedural tasks.
We demonstrate that AAG outperforms few-shot and RAG baselines on LCStep,
RecipeNLG, and CHAMP datasets under a pairwise LLM-based evaluation,
corroborated by human evaluation in the case of RecipeNLG.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.01326v1' target='_blank'>Grounding Language Models in Autonomous Loco-manipulation Tasks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jin Wang, Nikos Tsagarakis</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-02 15:27:48</h6>
<p class='card-text'>Humanoid robots with behavioral autonomy have consistently been regarded as
ideal collaborators in our daily lives and promising representations of
embodied intelligence. Compared to fixed-based robotic arms, humanoid robots
offer a larger operational space while significantly increasing the difficulty
of control and planning. Despite the rapid progress towards general-purpose
humanoid robots, most studies remain focused on locomotion ability with few
investigations into whole-body coordination and tasks planning, thus limiting
the potential to demonstrate long-horizon tasks involving both mobility and
manipulation under open-ended verbal instructions. In this work, we propose a
novel framework that learns, selects, and plans behaviors based on tasks in
different scenarios. We combine reinforcement learning (RL) with whole-body
optimization to generate robot motions and store them into a motion library. We
further leverage the planning and reasoning features of the large language
model (LLM), constructing a hierarchical task graph that comprises a series of
motion primitives to bridge lower-level execution with higher-level planning.
Experiments in simulation and real-world using the CENTAURO robot show that the
language model based planner can efficiently adapt to new loco-manipulation
tasks, demonstrating high autonomy from free-text commands in unstructured
scenes.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.01071v1' target='_blank'>VideoLLaMB: Long-context Video Understanding with Recurrent Memory
  Bridges</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuxuan Wang, Cihang Xie, Yang Liu, Zilong Zheng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-02 08:52:58</h6>
<p class='card-text'>Recent advancements in large-scale video-language models have shown
significant potential for real-time planning and detailed interactions.
However, their high computational demands and the scarcity of annotated
datasets limit their practicality for academic researchers. In this work, we
introduce VideoLLaMB, a novel framework that utilizes temporal memory tokens
within bridge layers to allow for the encoding of entire video sequences
alongside historical visual data, effectively preserving semantic continuity
and enhancing model performance across various tasks. This approach includes
recurrent memory tokens and a SceneTilling algorithm, which segments videos
into independent semantic units to preserve semantic integrity. Empirically,
VideoLLaMB significantly outstrips existing video-language models,
demonstrating a 5.5 points improvement over its competitors across three
VideoQA benchmarks, and 2.06 points on egocentric planning. Comprehensive
results on the MVBench show that VideoLLaMB-7B achieves markedly better results
than previous 7B models of same LLM. Remarkably, it maintains robust
performance as PLLaVA even as video length increases up to 8 times. Besides,
the frame retrieval results on our specialized Needle in a Video Haystack
(NIAVH) benchmark, further validate VideoLLaMB's prowess in accurately
identifying specific frames within lengthy videos. Our SceneTilling algorithm
also enables the generation of streaming video captions directly, without
necessitating additional training. In terms of efficiency, VideoLLaMB, trained
on 16 frames, supports up to 320 frames on a single Nvidia A100 GPU with linear
GPU memory scaling, ensuring both high performance and cost-effectiveness,
thereby setting a new foundation for long-form video-language models in both
academic and practical applications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.01007v2' target='_blank'>Unlocking the Wisdom of Large Language Models: An Introduction to The
  Path to Artificial General Intelligence</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Edward Y. Chang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-02 07:29:37</h6>
<p class='card-text'>This booklet, "Unlocking the Wisdom of LLM Collaborative Intelligence,"
introduces the comprehensive work "The Path to Artificial General
Intelligence." Through ten aphorisms, it distills the core principles of LLM
Collaborative Intelligence (LCI) as a promising framework toward achieving AGI.
The booklet also offers titles, abstracts, and introductions from the main
chapters, along with the first two chapters in full. The second edition,
released this week, includes significant enhancements to Chapters 6 to 9 and a
revised preface addressing Yann LeCun's skepticism about AGI. LeCun argues that
LLMs lack memory, planning, and grounding, but we propose that LCI's
collaborative architecture, involving multimodal LLMs with executive,
legislative, and judicial roles, overcomes these limitations. Chapters on
SocraSynth, EVINCE, consciousness modeling, and behavior modeling demonstrate
that collaborative LLMs with checks and balances can achieve intelligence
beyond any single model's capability. By combining complementary strengths,
such as world modeling and advanced sensory capabilities, LCI enables models to
work together and perceive reality beyond human limitations. As with human
institutions, progress depends on cooperation, not isolation. Collaborative
LLMs may unlock new levels of intelligence, paving the way toward AGI.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.00899v2' target='_blank'>MarsCode Agent: AI-native Automated Bug Fixing</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yizhou Liu, Pengfei Gao, Xinchen Wang, Jie Liu, Yexuan Shi, Zhao Zhang, Chao Peng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-02 02:24:38</h6>
<p class='card-text'>Recent advances in large language models (LLMs) have shown significant
potential to automate various software development tasks, including code
completion, test generation, and bug fixing. However, the application of LLMs
for automated bug fixing remains challenging due to the complexity and
diversity of real-world software systems. In this paper, we introduce MarsCode
Agent, a novel framework that leverages LLMs to automatically identify and
repair bugs in software code. MarsCode Agent combines the power of LLMs with
advanced code analysis techniques to accurately localize faults and generate
patches. Our approach follows a systematic process of planning, bug
reproduction, fault localization, candidate patch generation, and validation to
ensure high-quality bug fixes. We evaluated MarsCode Agent on SWE-bench, a
comprehensive benchmark of real-world software projects, and our results show
that MarsCode Agent achieves a high success rate in bug fixing compared to most
of the existing automated approaches.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.00847v3' target='_blank'>The Design of an LLM-powered Unstructured Analytics System</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Eric Anderson, Jonathan Fritz, Austin Lee, Bohou Li, Mark Lindblad, Henry Lindeman, Alex Meyer, Parth Parmar, Tanvi Ranade, Mehul A. Shah, Benjamin Sowell, Dan Tecuci, Vinayak Thapliyal, Matt Welsh</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-09-01 21:30:14</h6>
<p class='card-text'>LLMs demonstrate an uncanny ability to process unstructured data, and as
such, have the potential to go beyond search and run complex, semantic analyses
at scale. We describe the design of an unstructured analytics system, Aryn, and
the tenets and use cases that motivate its design. With Aryn, users specify
queries in natural language and the system automatically determines a semantic
plan and executes it to compute an answer from a large collection of
unstructured documents. At the core of Aryn is Sycamore, a declarative document
processing engine, that provides a reliable distributed abstraction called
DocSets. Sycamore allows users to analyze, enrich, and transform complex
documents at scale. Aryn includes Luna, a query planner that translates natural
language queries to Sycamore scripts, and DocParse, which takes raw PDFs and
document images, and converts them to DocSets for downstream processing. We
show how these pieces come together to achieve better accuracy than RAG on
analytics queries over real world reports from the National Transportation
Safety Board (NTSB). Also, given current limitations of LLMs, we argue that an
analytics system must provide explainability to be practical, and show how
Aryn's user interface does this to help build trust.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2409.00544v1' target='_blank'>Large Language Models-Enabled Digital Twins for Precision Medicine in
  Rare Gynecological Tumors</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jacqueline Lammert, Nicole Pfarr, Leonid Kuligin, Sonja Mathes, Tobias Dreyer, Luise Modersohn, Patrick Metzger, Dyke Ferber, Jakob Nikolas Kather, Daniel Truhn, Lisa Christine Adams, Keno Kyrill Bressem, Sebastian Lange, Kristina Schwamborn, Martin Boeker, Marion Kiechle, Ulrich A. Schatz, Holger Bronger, Maximilian Tschochohei</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-31 21:14:09</h6>
<p class='card-text'>Rare gynecological tumors (RGTs) present major clinical challenges due to
their low incidence and heterogeneity. The lack of clear guidelines leads to
suboptimal management and poor prognosis. Molecular tumor boards accelerate
access to effective therapies by tailoring treatment based on biomarkers,
beyond cancer type. Unstructured data that requires manual curation hinders
efficient use of biomarker profiling for therapy matching. This study explores
the use of large language models (LLMs) to construct digital twins for
precision medicine in RGTs.
  Our proof-of-concept digital twin system integrates clinical and biomarker
data from institutional and published cases (n=21) and literature-derived data
(n=655 publications with n=404,265 patients) to create tailored treatment plans
for metastatic uterine carcinosarcoma, identifying options potentially missed
by traditional, single-source analysis. LLM-enabled digital twins efficiently
model individual patient trajectories. Shifting to a biology-based rather than
organ-based tumor definition enables personalized care that could advance RGT
management and thus enhance patient outcomes.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.17377v1' target='_blank'>NDP: Next Distribution Prediction as a More Broad Target</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Junhao Ruan, Abudukeyumu Abudula, Xinyu Liu, Bei Li, Yinqiao Li, Chenglong Wang, Yuchun Fan, Yuan Ge, Tong Xiao, Jingbo Zhu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-30 16:13:49</h6>
<p class='card-text'>Large language models (LLMs) trained on next-token prediction (NTP) paradigm
have demonstrated powerful capabilities. However, the existing NTP paradigm
contains several limitations, particularly related to planned task
complications and error propagation during inference. In our work, we extend
the critique of NTP, highlighting its limitation also due to training with a
narrow objective: the prediction of a sub-optimal one-hot distribution. To
support this critique, we conducted a pre-experiment treating the output
distribution from powerful LLMs as efficient world data compression. By
evaluating the similarity between the $n$-gram distribution and the one-hot
distribution with LLMs, we observed that the $n$-gram distributions align more
closely with the output distribution of LLMs. Based on this insight, we
introduce Next Distribution Prediction (NDP), which uses $n$-gram distributions
to replace the one-hot targets, enhancing learning without extra online
training time. We conducted experiments across translation, general task,
language transfer, and medical domain adaptation. Compared to NTP, NDP can
achieve up to +2.97 COMET improvement in translation tasks, +0.61 average
improvement in general tasks, and incredible +10.75 average improvement in the
medical domain. This demonstrates the concrete benefits of addressing the
target narrowing problem, pointing to a new direction for future work on
improving NTP.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.16098v1' target='_blank'>Structured Event Reasoning with Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Li Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-28 19:03:41</h6>
<p class='card-text'>Reasoning about real-life events is a unifying challenge in AI and NLP that
has profound utility in a variety of domains, while fallacy in high-stake
applications could be catastrophic. Able to work with diverse text in these
domains, large language models (LLMs) have proven capable of answering
questions and solving problems. However, I show that end-to-end LLMs still
systematically fail to reason about complex events, and they lack
interpretability due to their black-box nature. To address these issues, I
propose three general approaches to use LLMs in conjunction with a structured
representation of events. The first is a language-based representation
involving relations of sub-events that can be learned by LLMs via fine-tuning.
The second is a semi-symbolic representation involving states of entities that
can be predicted and leveraged by LLMs via few-shot prompting. The third is a
fully symbolic representation that can be predicted by LLMs trained with
structured data and be executed by symbolic solvers. On a suite of event
reasoning tasks spanning common-sense inference and planning, I show that each
approach greatly outperforms end-to-end LLMs with more interpretability. These
results suggest manners of synergy between LLMs and structured representations
for event reasoning and beyond.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.16090v2' target='_blank'>EPO: Hierarchical LLM Agents with Environment Preference Optimization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Qi Zhao, Haotian Fu, Chen Sun, George Konidaris</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-28 18:44:02</h6>
<p class='card-text'>Long-horizon decision-making tasks present significant challenges for
LLM-based agents due to the need for extensive planning over multiple steps. In
this paper, we propose a hierarchical framework that decomposes complex tasks
into manageable subgoals, utilizing separate LLMs for subgoal prediction and
low-level action generation. To address the challenge of creating training
signals for unannotated datasets, we develop a reward model that leverages
multimodal environment feedback to automatically generate reward signals. We
introduce Environment Preference Optimization (EPO), a novel method that
generates preference signals from the environment's feedback and uses them to
train LLM-based agents. Extensive experiments on ALFRED demonstrate the
state-of-the-art performance of our framework, achieving first place on the
ALFRED public leaderboard and showcasing its potential to improve long-horizon
decision-making in diverse environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.15978v1' target='_blank'>WebPilot: A Versatile and Autonomous Multi-Agent System for Web Task
  Execution with Strategic Exploration</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yao Zhang, Zijian Ma, Yunpu Ma, Zhen Han, Yu Wu, Volker Tresp</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-28 17:49:29</h6>
<p class='card-text'>LLM-based autonomous agents often fail to execute complex web tasks that
require dynamic interaction due to the inherent uncertainty and complexity of
these environments. Existing LLM-based web agents typically rely on rigid,
expert-designed policies specific to certain states and actions, which lack the
flexibility and generalizability needed to adapt to unseen tasks. In contrast,
humans excel by exploring unknowns, continuously adapting strategies, and
resolving ambiguities through exploration. To emulate human-like adaptability,
web agents need strategic exploration and complex decision-making. Monte Carlo
Tree Search (MCTS) is well-suited for this, but classical MCTS struggles with
vast action spaces, unpredictable state transitions, and incomplete information
in web tasks. In light of this, we develop WebPilot, a multi-agent system with
a dual optimization strategy that improves MCTS to better handle complex web
environments. Specifically, the Global Optimization phase involves generating a
high-level plan by breaking down tasks into manageable subtasks and
continuously refining this plan, thereby focusing the search process and
mitigating the challenges posed by vast action spaces in classical MCTS.
Subsequently, the Local Optimization phase executes each subtask using a
tailored MCTS designed for complex environments, effectively addressing
uncertainties and managing incomplete information. Experimental results on
WebArena and MiniWoB++ demonstrate the effectiveness of WebPilot. Notably, on
WebArena, WebPilot achieves SOTA performance with GPT-4, achieving a 93%
relative increase in success rate over the concurrent tree search-based method.
WebPilot marks a significant advancement in general autonomous agent
capabilities, paving the way for more advanced and reliable decision-making in
practical environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.15950v2' target='_blank'>Atari-GPT: Benchmarking Multimodal Large Language Models as Low-Level
  Policies in Atari Games</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nicholas R. Waytowich, Devin White, MD Sunbeam, Vinicius G. Goecks</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-28 17:08:56</h6>
<p class='card-text'>Recent advancements in large language models (LLMs) have expanded their
capabilities beyond traditional text-based tasks to multimodal domains,
integrating visual, auditory, and textual data. While multimodal LLMs have been
extensively explored for high-level planning in domains like robotics and
games, their potential as low-level controllers remains largely untapped. In
this paper, we introduce a novel benchmark aimed at testing the emergent
capabilities of multimodal LLMs as low-level policies in Atari games. Unlike
traditional reinforcement learning (RL) methods that require training for each
new environment and reward function specification, these LLMs utilize
pre-existing multimodal knowledge to directly engage with game environments.
Our study assesses the performances of multiple multimodal LLMs against
traditional RL agents, human players, and random agents, focusing on their
ability to understand and interact with complex visual scenes and formulate
strategic responses. Our results show that these multimodal LLMs are not yet
capable of being zero-shot low-level policies. Furthermore, we see that this
is, in part, due to their visual and spatial reasoning. Additional results and
videos are available on our project webpage:
https://dev1nw.github.io/atari-gpt/.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.15879v2' target='_blank'>Persuasion Games using Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ganesh Prasath Ramani, Shirish Karande, Santhosh V, Yash Bhatia</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-28 15:50:41</h6>
<p class='card-text'>Large Language Models (LLMs) have emerged as formidable instruments capable
of comprehending and producing human-like text. This paper explores the
potential of LLMs, to shape user perspectives and subsequently influence their
decisions on particular tasks. This capability finds applications in diverse
domains such as Investment, Credit cards and Insurance, wherein they assist
users in selecting appropriate insurance policies, investment plans, Credit
cards, Retail, as well as in Behavioral Change Support Systems (BCSS).
  We present a sophisticated multi-agent framework wherein a consortium of
agents operate in collaborative manner. The primary agent engages directly with
user agents through persuasive dialogue, while the auxiliary agents perform
tasks such as information retrieval, response analysis, development of
persuasion strategies, and validation of facts. Empirical evidence from our
experiments demonstrates that this collaborative methodology significantly
enhances the persuasive efficacy of the LLM. We continuously analyze the
resistance of the user agent to persuasive efforts and counteract it by
employing a combination of rule-based and LLM-based resistance-persuasion
mapping techniques.
  We employ simulated personas and generate conversations in insurance,
banking, and retail domains to evaluate the proficiency of large language
models (LLMs) in recognizing, adjusting to, and influencing various personality
types. Concurrently, we examine the resistance mechanisms employed by LLM
simulated personas. Persuasion is quantified via measurable surveys before and
after interaction, LLM-generated scores on conversation, and user decisions
(purchase or non-purchase).</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.15778v4' target='_blank'>LogicGame: Benchmarking Rule-Based Reasoning Abilities of Large Language
  Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiayi Gui, Yiming Liu, Jiale Cheng, Xiaotao Gu, Xiao Liu, Hongning Wang, Yuxiao Dong, Jie Tang, Minlie Huang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-28 13:16:41</h6>
<p class='card-text'>Large Language Models (LLMs) have demonstrated notable capabilities across
various tasks, showcasing complex problem-solving abilities. Understanding and
executing complex rules, along with multi-step planning, are fundamental to
logical reasoning and critical for practical LLM agents and decision-making
systems. However, evaluating LLMs as effective rule-based executors and
planners remains underexplored. In this paper, we introduce LogicGame, a novel
benchmark designed to evaluate the comprehensive rule understanding, execution,
and planning capabilities of LLMs. Unlike traditional benchmarks, LogicGame
provides diverse games that contain a series of rules with an initial state,
requiring models to comprehend and apply predefined regulations to solve
problems. We create simulated scenarios in which models execute or plan
operations to achieve specific outcomes. These game scenarios are specifically
designed to distinguish logical reasoning from mere knowledge by relying
exclusively on predefined rules. This separation allows for a pure assessment
of rule-based reasoning capabilities. The evaluation considers not only final
outcomes but also intermediate steps, providing a comprehensive assessment of
model performance. Moreover, these intermediate steps are deterministic and can
be automatically verified. LogicGame defines game scenarios with varying
difficulty levels, from simple rule applications to complex reasoning chains,
in order to offer a precise evaluation of model performance on rule
understanding and multi-step execution. Utilizing LogicGame, we test various
LLMs and identify notable shortcomings in their rule-based logical reasoning
abilities.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.15512v3' target='_blank'>Toward Automated Simulation Research Workflow through LLM Prompt
  Engineering Design</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhihan Liu, Yubo Chai, Jianfeng Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-28 03:48:05</h6>
<p class='card-text'>The advent of Large Language Models (LLMs) has created new opportunities for
the automation of scientific research spanning both experimental processes and
computational simulations. This study explores the feasibility of constructing
an autonomous simulation agent (ASA) powered by LLMs through prompt engineering
and automated program design to automate the entire simulation research process
according to a human-provided research plan. This process includes experimental
design, remote upload and simulation execution, data analysis, and report
compilation. Using a well-studied simulation problem of polymer chain
conformations as a test case, we assessed the long-task completion and
reliability of ASAs powered by different LLMs, including GPT-4o, Claude-3.5,
etc. Our findings revealed that ASA-GPT-4o achieved near-flawless execution on
designated research missions, underscoring the potential of methods like ASA to
achieve automation in simulation research processes to enhance research
efficiency. The outlined automation can be iteratively performed for up to 20
cycles without human intervention, illustrating the potential of ASA for
long-task workflow automation. Additionally, we discussed the intrinsic traits
of ASA in managing extensive tasks, focusing on self-validation mechanisms, and
the balance between local attention and global oversight.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.14568v1' target='_blank'>Improving Clinical Note Generation from Complex Doctor-Patient
  Conversation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yizhan Li, Sifan Wu, Christopher Smith, Thomas Lo, Bang Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-26 18:39:31</h6>
<p class='card-text'>Writing clinical notes and documenting medical exams is a critical task for
healthcare professionals, serving as a vital component of patient care
documentation. However, manually writing these notes is time-consuming and can
impact the amount of time clinicians can spend on direct patient interaction
and other tasks. Consequently, the development of automated clinical note
generation systems has emerged as a clinically meaningful area of research
within AI for health. In this paper, we present three key contributions to the
field of clinical note generation using large language models (LLMs). First, we
introduce CliniKnote, a comprehensive dataset consisting of 1,200 complex
doctor-patient conversations paired with their full clinical notes. This
dataset, created and curated by medical experts with the help of modern neural
networks, provides a valuable resource for training and evaluating models in
clinical note generation tasks. Second, we propose the K-SOAP (Keyword,
Subjective, Objective, Assessment, and Plan) note format, which enhances
traditional SOAP~\cite{podder2023soap} (Subjective, Objective, Assessment, and
Plan) notes by adding a keyword section at the top, allowing for quick
identification of essential information. Third, we develop an automatic
pipeline to generate K-SOAP notes from doctor-patient conversations and
benchmark various modern LLMs using various metrics. Our results demonstrate
significant improvements in efficiency and performance compared to standard LLM
finetuning methods.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.14307v1' target='_blank'>LLM-3D Print: Large Language Models To Monitor and Control 3D Printing</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yayati Jadhav, Peter Pak, Amir Barati Farimani</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-26 14:38:19</h6>
<p class='card-text'>Industry 4.0 has revolutionized manufacturing by driving digitalization and
shifting the paradigm toward additive manufacturing (AM). Fused Deposition
Modeling (FDM), a key AM technology, enables the creation of highly customized,
cost-effective products with minimal material waste through layer-by-layer
extrusion, posing a significant challenge to traditional subtractive methods.
However, the susceptibility of material extrusion techniques to errors often
requires expert intervention to detect and mitigate defects that can severely
compromise product quality. While automated error detection and machine
learning models exist, their generalizability across diverse 3D printer setups,
firmware, and sensors is limited, and deep learning methods require extensive
labeled datasets, hindering scalability and adaptability. To address these
challenges, we present a process monitoring and control framework that
leverages pre-trained Large Language Models (LLMs) alongside 3D printers to
detect and address printing defects. The LLM evaluates print quality by
analyzing images captured after each layer or print segment, identifying
failure modes and querying the printer for relevant parameters. It then
generates and executes a corrective action plan. We validated the effectiveness
of the proposed framework in identifying defects by comparing it against a
control group of engineers with diverse AM expertise. Our evaluation
demonstrated that LLM-based agents not only accurately identify common 3D
printing errors, such as inconsistent extrusion, stringing, warping, and layer
adhesion, but also effectively determine the parameters causing these failures
and autonomously correct them without any need for human intervention.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.14033v2' target='_blank'>MLR-Copilot: Autonomous Machine Learning Research based on Large
  Language Models Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ruochen Li, Teerth Patel, Qingyun Wang, Xinya Du</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-26 05:55:48</h6>
<p class='card-text'>Machine learning research, crucial for technological advancements and
innovation, often faces significant challenges due to its inherent complexity,
slow pace of experimentation, and the necessity for specialized expertise.
Motivated by this, we present a new systematic framework, autonomous Machine
Learning Research with large language models (MLR-Copilot), designed to enhance
machine learning research productivity through the automatic generation and
implementation of research ideas using Large Language Model (LLM) agents. The
framework consists of three phases: research idea generation, experiment
implementation, and implementation execution. First, existing research papers
are used to generate hypotheses and experimental plans vis IdeaAgent powered by
LLMs. Next, the implementation generation phase translates these plans into
executables with ExperimentAgent. This phase leverages retrieved prototype code
and optionally retrieves candidate models and data. Finally, the execution
phase, also managed by ExperimentAgent, involves running experiments with
mechanisms for human feedback and iterative debugging to enhance the likelihood
of achieving executable research outcomes. We evaluate our framework on five
machine learning research tasks and the experimental results show the
framework's potential to facilitate the research progress and innovations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.13918v3' target='_blank'>Geo-Llama: Leveraging LLMs for Human Mobility Trajectory Generation with
  Spatiotemporal Constraints</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Siyu Li, Toan Tran, Haowen Lin, John Krumm, Cyrus Shahabi, Li Xiong</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-25 19:03:46</h6>
<p class='card-text'>Simulating human mobility data is essential for various application domains,
including transportation, urban planning, and epidemic control, since real data
are often inaccessible to researchers due to expensive costs and privacy
issues. Several existing deep generative solutions propose learning from real
trajectories to generate synthetic ones. Despite the progress, most of them
suffer from training stability issues and scale poorly with growing data size.
More importantly, they generally lack control mechanisms to steer the generated
trajectories based on spatiotemporal constraints such as fixing specific
visits. To address such limitations, we formally define the controlled
trajectory generation problem with spatiotemporal constraints and propose
Geo-Llama. This novel LLM-inspired framework enforces explicit visit
constraints in a contextually coherent way. It fine-tunes pre-trained LLMs on
trajectories with a visit-wise permutation strategy where each visit
corresponds to a time and location. This enables the model to capture the
spatiotemporal patterns regardless of visit orders and allows flexible and
in-context constraint integration through prompts during generation. Extensive
experiments on real-world and synthetic datasets validate the effectiveness of
Geo-Llama, demonstrating its versatility and robustness in handling a broad
range of constraints to generate more realistic trajectories compared to
existing methods.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.13890v1' target='_blank'>Making Large Language Models Better Planners with Reasoning-Decision
  Alignment</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhijian Huang, Tao Tang, Shaoxiang Chen, Sihao Lin, Zequn Jie, Lin Ma, Guangrun Wang, Xiaodan Liang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-25 16:43:47</h6>
<p class='card-text'>Data-driven approaches for autonomous driving (AD) have been widely adopted
in the past decade but are confronted with dataset bias and uninterpretability.
Inspired by the knowledge-driven nature of human driving, recent approaches
explore the potential of large language models (LLMs) to improve understanding
and decision-making in traffic scenarios. They find that the pretrain-finetune
paradigm of LLMs on downstream data with the Chain-of-Thought (CoT) reasoning
process can enhance explainability and scene understanding. However, such a
popular strategy proves to suffer from the notorious problems of misalignment
between the crafted CoTs against the consequent decision-making, which remains
untouched by previous LLM-based AD methods. To address this problem, we
motivate an end-to-end decision-making model based on multimodality-augmented
LLM, which simultaneously executes CoT reasoning and carries out planning
results. Furthermore, we propose a reasoning-decision alignment constraint
between the paired CoTs and planning results, imposing the correspondence
between reasoning and decision-making. Moreover, we redesign the CoTs to enable
the model to comprehend complex scenarios and enhance decision-making
performance. We dub our proposed large language planners with
reasoning-decision alignment as RDA-Driver. Experimental evaluations on the
nuScenes and DriveLM-nuScenes benchmarks demonstrate the effectiveness of our
RDA-Driver in enhancing the performance of end-to-end AD systems. Specifically,
our RDA-Driver achieves state-of-the-art planning performance on the nuScenes
dataset with 0.80 L2 error and 0.32 collision rate, and also achieves leading
results on challenging DriveLM-nuScenes benchmarks with 0.82 L2 error and 0.38
collision rate.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.13184v2' target='_blank'>Can LLM be a Good Path Planner based on Prompt Engineering? Mitigating
  the Hallucination for Path Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hourui Deng, Hongjie Zhang, Jie Ou, Chaosheng Feng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-23 16:02:54</h6>
<p class='card-text'>Spatial reasoning in Large Language Models (LLMs) is the foundation for
embodied intelligence. However, even in simple maze environments, LLMs still
encounter challenges in long-term path-planning, primarily influenced by their
spatial hallucination and context inconsistency hallucination by long-term
reasoning. To address this challenge, this study proposes an innovative model,
Spatial-to-Relational Transformation and Curriculum Q-Learning (S2RCQL). To
address the spatial hallucination of LLMs, we propose the Spatial-to-Relational
approach, which transforms spatial prompts into entity relations and paths
representing entity relation chains. This approach fully taps the potential of
LLMs in terms of sequential thinking. As a result, we design a path-planning
algorithm based on Q-learning to mitigate the context inconsistency
hallucination, which enhances the reasoning ability of LLMs. Using the Q-value
of state-action as auxiliary information for prompts, we correct the
hallucinations of LLMs, thereby guiding LLMs to learn the optimal path.
Finally, we propose a reverse curriculum learning technique based on LLMs to
further mitigate the context inconsistency hallucination. LLMs can rapidly
accumulate successful experiences by reducing task difficulty and leveraging
them to tackle more complex tasks. We performed comprehensive experiments based
on Baidu's self-developed LLM: ERNIE-Bot 4.0. The results showed that our
S2RCQL achieved a 23%--40% improvement in both success and optimality rates
compared with advanced prompt engineering.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.12832v1' target='_blank'>LIMP: Large Language Model Enhanced Intent-aware Mobility Prediction</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Songwei Li, Jie Feng, Jiawei Chi, Xinyuan Hu, Xiaomeng Zhao, Fengli Xu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-23 04:28:56</h6>
<p class='card-text'>Human mobility prediction is essential for applications like urban planning
and transportation management, yet it remains challenging due to the complex,
often implicit, intentions behind human behavior. Existing models predominantly
focus on spatiotemporal patterns, paying less attention to the underlying
intentions that govern movements. Recent advancements in large language models
(LLMs) offer a promising alternative research angle for integrating commonsense
reasoning into mobility prediction. However, it is a non-trivial problem
because LLMs are not natively built for mobility intention inference, and they
also face scalability issues and integration difficulties with spatiotemporal
models. To address these challenges, we propose a novel LIMP (LLMs for
Intent-ware Mobility Prediction) framework. Specifically, LIMP introduces an
"Analyze-Abstract-Infer" (A2I) agentic workflow to unleash LLM's commonsense
reasoning power for mobility intention inference. Besides, we design an
efficient fine-tuning scheme to transfer reasoning power from commercial LLM to
smaller-scale, open-source language model, ensuring LIMP's scalability to
millions of mobility records. Moreover, we propose a transformer-based
intention-aware mobility prediction model to effectively harness the intention
inference ability of LLM. Evaluated on two real-world datasets, LIMP
significantly outperforms baseline models, demonstrating improved accuracy in
next-location prediction and effective intention inference. The
interpretability of intention-aware mobility prediction highlights our LIMP
framework's potential for real-world applications. Codes and data can be found
in https://github.com/tsinghua-fib-lab/LIMP .</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.12775v2' target='_blank'>Intelligent OPC Engineer Assistant for Semiconductor Manufacturing</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Guojin Chen, Haoyu Yang, Bei Yu, Haoxing Ren</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-23 00:49:36</h6>
<p class='card-text'>Advancements in chip design and manufacturing have enabled the processing of
complex tasks such as deep learning and natural language processing, paving the
way for the development of artificial general intelligence (AGI). AI, on the
other hand, can be leveraged to innovate and streamline semiconductor
technology from planning and implementation to manufacturing. In this paper, we
present \textit{Intelligent OPC Engineer Assistant}, an AI/LLM-powered
methodology designed to solve the core manufacturing-aware optimization problem
known as optical proximity correction (OPC). The methodology involves a
reinforcement learning-based OPC recipe search and a customized multi-modal
agent system for recipe summarization. Experiments demonstrate that our
methodology can efficiently build OPC recipes on various chip designs with
specially handled design topologies, a task that typically requires the
full-time effort of OPC engineers with years of experience.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.12547v2' target='_blank'>Towards Evaluating and Building Versatile Large Language Models for
  Medicine</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chaoyi Wu, Pengcheng Qiu, Jinxin Liu, Hongfei Gu, Na Li, Ya Zhang, Yanfeng Wang, Weidi Xie</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-22 17:01:34</h6>
<p class='card-text'>In this study, we present MedS-Bench, a comprehensive benchmark designed to
evaluate the performance of large language models (LLMs) in clinical contexts.
Unlike existing benchmarks that focus on multiple-choice question answering,
MedS-Bench spans 11 high-level clinical tasks, including clinical report
summarization, treatment recommendations, diagnosis, named entity recognition,
and medical concept explanation, among others. We evaluated six leading LLMs,
e.g., MEDITRON, Mistral, InternLM 2, Llama 3, GPT-4, and Claude-3.5 using
few-shot prompting, and found that even the most sophisticated models struggle
with these complex tasks. To address these limitations, we developed MedS-Ins,
a large-scale instruction tuning dataset for medicine. MedS-Ins comprises 58
medically oriented language corpora, totaling 13.5 million samples across 122
tasks. To demonstrate the dataset's utility, we conducted a proof-of-concept
experiment by performing instruction tuning on a lightweight, open-source
medical language model. The resulting model, MMedIns-Llama 3, significantly
outperformed existing models across nearly all clinical tasks. To promote
further advancements in the application of LLMs to clinical challenges, we have
made the MedS-Ins dataset fully accessible and invite the research community to
contribute to its expansion.Additionally, we have launched a dynamic
leaderboard for MedS-Bench, which we plan to regularly update the test set to
track progress and enhance the adaptation of general LLMs to the medical
domain. Leaderboard: https://henrychur.github.io/MedS-Bench/. Github:
https://github.com/MAGIC-AI4Med/MedS-Ins.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.12315v1' target='_blank'>Large Language Models Are Self-Taught Reasoners: Enhancing LLM
  Applications via Tailored Problem-Solving Demonstrations</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kai Tzu-iunn Ong, Taeyoon Kwon, Jinyoung Yeo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-22 11:41:35</h6>
<p class='card-text'>Guiding large language models with a selected set of human-authored
demonstrations is a common practice for improving LLM applications. However,
human effort can be costly, especially in specialized domains (e.g., clinical
diagnosis), and does not guarantee optimal performance due to the potential
discrepancy of target skills between selected demonstrations and real test
instances. Motivated by these, this paper explores the automatic creation of
customized demonstrations, whose target skills align with the given target
instance. We present SELF-TAUGHT, a problem-solving framework, which
facilitates demonstrations that are "tailored" to the target problem and
"filtered" for better quality (i.e., correctness) in a zero-shot manner. In 15
tasks of multiple-choice questions of diverse domains and the diagnosis of
Alzheimer's disease (AD) with real-world patients, SELF-TAUGHT achieves
superior performance to strong baselines (e.g., Few-shot CoT, Plan-and-Solve,
Auto-CoT). We conduct comprehensive analyses on SELF-TAUGHT, including its
generalizability to existing prompting methods and different LLMs, the quality
of its intermediate generation, and more.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.12093v2' target='_blank'>LLM-enhanced Scene Graph Learning for Household Rearrangement</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wenhao Li, Zhiyuan Yu, Qijin She, Zhinan Yu, Yuqing Lan, Chenyang Zhu, Ruizhen Hu, Kai Xu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-22 03:03:04</h6>
<p class='card-text'>The household rearrangement task involves spotting misplaced objects in a
scene and accommodate them with proper places. It depends both on common-sense
knowledge on the objective side and human user preference on the subjective
side. In achieving such task, we propose to mine object functionality with user
preference alignment directly from the scene itself, without relying on human
intervention. To do so, we work with scene graph representation and propose
LLM-enhanced scene graph learning which transforms the input scene graph into
an affordance-enhanced graph (AEG) with information-enhanced nodes and newly
discovered edges (relations). In AEG, the nodes corresponding to the receptacle
objects are augmented with context-induced affordance which encodes what kind
of carriable objects can be placed on it. New edges are discovered with newly
discovered non-local relations. With AEG, we perform task planning for scene
rearrangement by detecting misplaced carriables and determining a proper
placement for each of them. We test our method by implementing a tiding robot
in simulator and perform evaluation on a new benchmark we build. Extensive
evaluations demonstrate that our method achieves state-of-the-art performance
on misplacement detection and the following rearrangement planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.11326v1' target='_blank'>Automating Thought of Search: A Journey Towards Soundness and
  Completeness</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Daniel Cao, Michael Katz, Harsha Kokel, Kavitha Srinivas, Shirin Sohrabi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-21 04:19:52</h6>
<p class='card-text'>Planning remains one of the last standing bastions for large language models
(LLMs), which now turn their attention to search. Most of the literature uses
the language models as world models to define the search space, forgoing
soundness for the sake of flexibility. A recent work, Thought of Search (ToS),
proposed defining the search space with code, having the language models
produce that code. ToS requires a human in the loop, collaboratively producing
a sound successor function and goal test. The result, however, is worth the
effort: all the tested datasets were solved with 100% accuracy. At the same
time LLMs have demonstrated significant progress in code generation and
refinement for complex reasoning tasks. In this work, we automate ToS
(AutoToS), completely taking the human out of the loop of solving planning
problems. AutoToS guides the language model step by step towards the generation
of sound and complete search components, through feedback from both generic and
domain specific unit tests. We achieve 100% accuracy, with minimal feedback
iterations, using LLMs of various sizes on all evaluated domains.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.10715v1' target='_blank'>Fine-Tuning a Local LLaMA-3 Large Language Model for Automated
  Privacy-Preserving Physician Letter Generation in Radiation Oncology</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yihao Hou, Christoph Bert, Ahmed Gomaa, Godehard Lahmer, Daniel Hoefler, Thomas Weissmann, Raphaela Voigt, Philipp Schubert, Charlotte Schmitter, Alina Depardon, Sabine Semrau, Andreas Maier, Rainer Fietkau, Yixing Huang, Florian Putz</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-20 10:31:36</h6>
<p class='card-text'>Generating physician letters is a time-consuming task in daily clinical
practice. This study investigates local fine-tuning of large language models
(LLMs), specifically LLaMA models, for physician letter generation in a
privacy-preserving manner within the field of radiation oncology. Our findings
demonstrate that base LLaMA models, without fine-tuning, are inadequate for
effectively generating physician letters. The QLoRA algorithm provides an
efficient method for local intra-institutional fine-tuning of LLMs with limited
computational resources (i.e., a single 48 GB GPU workstation within the
hospital). The fine-tuned LLM successfully learns radiation oncology-specific
information and generates physician letters in an institution-specific style.
ROUGE scores of the generated summary reports highlight the superiority of the
8B LLaMA-3 model over the 13B LLaMA-2 model. Further multidimensional physician
evaluations of 10 cases reveal that, although the fine-tuned LLaMA-3 model has
limited capacity to generate content beyond the provided input data, it
successfully generates salutations, diagnoses and treatment histories,
recommendations for further treatment, and planned schedules. Overall, clinical
benefit was rated highly by the clinical experts (average score of 3.44 on a
4-point scale). With careful physician review and correction, automated
LLM-based physician letter generation has significant practical value.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.10635v2' target='_blank'>Strategist: Learning Strategic Skills by LLMs via Bi-Level Tree Search</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jonathan Light, Min Cai, Weiqin Chen, Guanzhi Wang, Xiusi Chen, Wei Cheng, Yisong Yue, Ziniu Hu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-20 08:22:04</h6>
<p class='card-text'>In this paper, we propose a new method STRATEGIST that utilizes LLMs to
acquire new skills for playing multi-agent games through a self-improvement
process. Our method gathers quality feedback through self-play simulations with
Monte Carlo tree search and LLM-based reflection, which can then be used to
learn high-level strategic skills such as how to evaluate states that guide the
low-level execution. We showcase how our method can be used in both action
planning and dialogue generation in the context of games, achieving good
performance on both tasks. Specifically, we demonstrate that our method can
help train agents with better performance than both traditional reinforcement
learning-based approaches and other LLM-based skill learning approaches in
games including the Game of Pure Strategy (GOPS) and The Resistance: Avalon.
STRATEGIST helps bridge the gap between foundation models and symbolic
decision-making methods through its bi-level approach, leading to more robust
decision-making.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.10490v1' target='_blank'>Analysis of Plan-based Retrieval for Grounded Text Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ameya Godbole, Nicholas Monath, Seungyeon Kim, Ankit Singh Rawat, Andrew McCallum, Manzil Zaheer</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-20 02:19:35</h6>
<p class='card-text'>In text generation, hallucinations refer to the generation of seemingly
coherent text that contradicts established knowledge. One compelling hypothesis
is that hallucinations occur when a language model is given a generation task
outside its parametric knowledge (due to rarity, recency, domain, etc.). A
common strategy to address this limitation is to infuse the language models
with retrieval mechanisms, providing the model with relevant knowledge for the
task. In this paper, we leverage the planning capabilities of instruction-tuned
LLMs and analyze how planning can be used to guide retrieval to further reduce
the frequency of hallucinations. We empirically evaluate several variations of
our proposed approach on long-form text generation tasks. By improving the
coverage of relevant facts, plan-guided retrieval and generation can produce
more informative responses while providing a higher rate of attribution to
source documents.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.10455v5' target='_blank'>IDEA: Enhancing the Rule Learning Ability of Large Language Model Agent
  through Induction, Deduction, and Abduction</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kaiyu He, Mian Zhang, Shuo Yan, Peilin Wu, Zhiyu Zoey Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-19 23:37:07</h6>
<p class='card-text'>While large language models (LLMs) have been thoroughly evaluated for
deductive and inductive reasoning, their proficiency in holistic rule learning
in interactive environments remains less explored. We introduce RULEARN, a
novel benchmark to assess the rule-learning abilities of LLM agents in
interactive settings. In RULEARN, agents strategically interact with simulated
environments to gather observations, discern patterns, and solve complex
problems. To enhance the rule-learning capabilities for LLM agents, we propose
IDEA, a novel reasoning framework that integrates the process of Induction,
Deduction, and Abduction. The IDEA agent generates initial hypotheses from
limited observations through abduction, devises plans to validate these
hypotheses or leverages them to solve problems via deduction, and refines
previous hypotheses through induction, dynamically establishing and applying
rules that mimic human rule-learning behaviors. Our evaluation of the IDEA
framework, which involves five representative LLMs, demonstrates significant
improvements over the baseline. Furthermore, our study with human participants
reveals notable discrepancies in rule-learning behaviors between humans and
LLMs. We believe our benchmark will serve as a valuable and challenging
resource, and IDEA will provide crucial insights for the development of LLM
agents capable of human-like rule learning in real-world scenarios. Our code
and data is publicly available.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.09972v1' target='_blank'>Edge-Cloud Collaborative Motion Planning for Autonomous Driving with
  Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiao Chen, Suyan Dai, Fangfang Chen, Zuohong Lv, Jianhua Tang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-19 13:19:15</h6>
<p class='card-text'>Integrating large language models (LLMs) into autonomous driving enhances
personalization and adaptability in open-world scenarios. However, traditional
edge computing models still face significant challenges in processing complex
driving data, particularly regarding real-time performance and system
efficiency. To address these challenges, this study introduces EC-Drive, a
novel edge-cloud collaborative autonomous driving system with data drift
detection capabilities. EC-Drive utilizes drift detection algorithms to
selectively upload critical data, including new obstacles and traffic pattern
changes, to the cloud for processing by GPT-4, while routine data is
efficiently managed by smaller LLMs on edge devices. This approach not only
reduces inference latency but also improves system efficiency by optimizing
communication resource use. Experimental validation confirms the system's
robust processing capabilities and practical applicability in real-world
driving conditions, demonstrating the effectiveness of this edge-cloud
collaboration framework. Our data and system demonstration will be released at
https://sites.google.com/view/ec-drive.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.09955v2' target='_blank'>MegaAgent: A Practical Framework for Autonomous Cooperation in
  Large-Scale LLM Agent Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Qian Wang, Tianyu Wang, Qinbin Li, Jingsheng Liang, Bingsheng He</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-19 12:55:16</h6>
<p class='card-text'>With the emergence of large language models (LLMs), LLM-powered multi-agent
systems (LLM-MA systems) have been proposed to tackle real-world tasks.
However, their agents mostly follow predefined Standard Operating Procedures
(SOPs) that remain unchanged across the whole interaction, lacking autonomy and
scalability. Additionally, current solutions often overlook the necessity for
effective agent cooperation. To address the above limitations, we propose
MegaAgent, a practical framework designed for autonomous cooperation in
large-scale LLM Agent systems. MegaAgent leverages the autonomy of agents to
dynamically generate agents based on task requirements, incorporating features
such as automatically dividing tasks, systematic planning and monitoring of
agent activities, and managing concurrent operations. In addition, MegaAgent is
designed with a hierarchical structure and employs system-level parallelism to
enhance performance and boost communication. We demonstrate the effectiveness
of MegaAgent through Gobang game development, showing that it outperforms
popular LLM-MA systems; and national policy simulation, demonstrating its high
autonomy and potential to rapidly scale up to 590 agents while ensuring
effective cooperation among them. Our results indicate that MegaAgent is the
first autonomous large-scale LLM-MA system with no pre-defined SOPs, high
effectiveness and scalability, paving the way for further research in this
field. Our code is at https://anonymous.4open.science/r/MegaAgent-81F3.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.09568v2' target='_blank'>MergeRepair: An Exploratory Study on Merging Task-Specific Adapters in
  Code LLMs for Automated Program Repair</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Meghdad Dehghan, Jie JW Wu, Fatemeh H. Fard, Ali Ouni</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-18 18:45:48</h6>
<p class='card-text'>[Context] Large Language Models (LLMs) have shown good performance in several
software development-related tasks such as program repair, documentation, code
refactoring, debugging, and testing. Adapters are specialized, small modules
designed for parameter efficient fine-tuning of LLMs for specific tasks,
domains, or applications without requiring extensive retraining of the entire
model. These adapters offer a more efficient way to customize LLMs for
particular needs, leveraging the pre-existing capabilities of the large model.
Merging LLMs and adapters has shown promising results for various natural
language domains and tasks, enabling the use of the learned models and adapters
without additional training for a new task. [Objective] This research proposes
continual merging and empirically studies the capabilities of merged adapters
in Code LLMs, specially for the Automated Program Repair (APR) task. The goal
is to gain insights into whether and how merging task-specific adapters can
affect the performance of APR. [Method] In our framework, MergeRepair, we plan
to merge multiple task-specific adapters using three different merging methods
and evaluate the performance of the merged adapter for the APR task.
Particularly, we will employ two main merging scenarios for all three
techniques, (i) merging using equal-weight averaging applied on parameters of
different adapters, where all adapters are of equal importance; and (ii) our
proposed approach, continual merging, in which we sequentially merge the
task-specific adapters and the order and weight of merged adapters matter. By
exploratory study of merging techniques, we will investigate the improvement
and generalizability of merged adapters for APR. Through continual merging, we
will explore the capability of merged adapters and the effect of task order, as
it occurs in real-world software projects.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.09199v1' target='_blank'>TC-RAG:Turing-Complete RAG's Case study on Medical LLM Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xinke Jiang, Yue Fang, Rihong Qiu, Haoyu Zhang, Yongxin Xu, Hao Chen, Wentao Zhang, Ruizhe Zhang, Yuchen Fang, Xu Chu, Junfeng Zhao, Yasha Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-17 13:32:32</h6>
<p class='card-text'>In the pursuit of enhancing domain-specific Large Language Models (LLMs),
Retrieval-Augmented Generation (RAG) emerges as a promising solution to
mitigate issues such as hallucinations, outdated knowledge, and limited
expertise in highly specialized queries. However, existing approaches to RAG
fall short by neglecting system state variables, which are crucial for ensuring
adaptive control, retrieval halting, and system convergence. In this paper, we
introduce the TC-RAG through rigorous proof, a novel framework that addresses
these challenges by incorporating a Turing Complete System to manage state
variables, thereby enabling more efficient and accurate knowledge retrieval. By
leveraging a memory stack system with adaptive retrieval, reasoning, and
planning capabilities, TC-RAG not only ensures the controlled halting of
retrieval processes but also mitigates the accumulation of erroneous knowledge
via Push and Pop actions. In the case study of the medical domain, our
extensive experiments on real-world healthcare datasets demonstrate the
superiority of TC-RAG over existing methods in accuracy by over 7.20\%. Our
dataset and code have been available at
https://https://github.com/Artessay/SAMA.git.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.08782v4' target='_blank'>EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling
  MiXed Emotions and Discourse Dynamics</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chenwei Wan, Matthieu Labeau, Chloé Clavel</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-16 14:54:41</h6>
<p class='card-text'>Designing emotionally intelligent conversational systems to provide comfort
and advice to people experiencing distress is a compelling area of research.
Recently, with advancements in large language models (LLMs), end-to-end
dialogue agents without explicit strategy prediction steps have become
prevalent. However, implicit strategy planning lacks transparency, and recent
studies show that LLMs' inherent preference bias towards certain
socio-emotional strategies hinders the delivery of high-quality emotional
support. To address this challenge, we propose decoupling strategy prediction
from language generation, and introduce a novel dialogue strategy prediction
framework, EmoDynamiX, which models the discourse dynamics between user
fine-grained emotions and system strategies using a heterogeneous graph for
better performance and transparency. Experimental results on two ESC datasets
show EmoDynamiX outperforms previous state-of-the-art methods with a
significant margin (better proficiency and lower preference bias). Our approach
also exhibits better transparency by allowing backtracing of decision making.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.08506v2' target='_blank'>Ex3: Automatic Novel Writing by Extracting, Excelsior and Expanding</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lei Huang, Jiaming Guo, Guanhua He, Xishan Zhang, Rui Zhang, Shaohui Peng, Shaoli Liu, Tianshi Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-16 03:06:57</h6>
<p class='card-text'>Generating long-term texts such as novels using artificial intelligence has
always been a challenge. A common approach is to use large language models
(LLMs) to construct a hierarchical framework that first plans and then writes.
Despite the fact that the generated novels reach a sufficient length, they
exhibit poor logical coherence and appeal in their plots and deficiencies in
character and event depiction, ultimately compromising the overall narrative
quality. In this paper, we propose a method named Extracting Excelsior and
Expanding. Ex3 initially extracts structure information from raw novel data. By
combining this structure information with the novel data, an
instruction-following dataset is meticulously crafted. This dataset is then
utilized to fine-tune the LLM, aiming for excelsior generation performance. In
the final stage, a tree-like expansion method is deployed to facilitate the
generation of arbitrarily long novels. Evaluation against previous methods
showcases Ex3's ability to produce higher-quality long-form novels.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.08302v1' target='_blank'>Benchmarking the Capabilities of Large Language Models in Transportation
  System Engineering: Accuracy, Consistency, and Reasoning Behaviors</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Usman Syed, Ethan Light, Xingang Guo, Huan Zhang, Lianhui Qin, Yanfeng Ouyang, Bin Hu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-15 17:55:45</h6>
<p class='card-text'>In this paper, we explore the capabilities of state-of-the-art large language
models (LLMs) such as GPT-4, GPT-4o, Claude 3.5 Sonnet, Claude 3 Opus, Gemini
1.5 Pro, Llama 3, and Llama 3.1 in solving some selected undergraduate-level
transportation engineering problems. We introduce TransportBench, a benchmark
dataset that includes a sample of transportation engineering problems on a wide
range of subjects in the context of planning, design, management, and control
of transportation systems. This dataset is used by human experts to evaluate
the capabilities of various commercial and open-sourced LLMs, especially their
accuracy, consistency, and reasoning behaviors, in solving transportation
engineering problems. Our comprehensive analysis uncovers the unique strengths
and limitations of each LLM, e.g. our analysis shows the impressive accuracy
and some unexpected inconsistent behaviors of Claude 3.5 Sonnet in solving
TransportBench problems. Our study marks a thrilling first step toward
harnessing artificial general intelligence for complex transportation
challenges.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.08282v1' target='_blank'>Autonomous Behavior Planning For Humanoid Loco-manipulation Through
  Grounded Language Model</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jin Wang, Arturo Laurenzi, Nikos Tsagarakis</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-15 17:33:32</h6>
<p class='card-text'>Enabling humanoid robots to perform autonomously loco-manipulation in
unstructured environments is crucial and highly challenging for achieving
embodied intelligence. This involves robots being able to plan their actions
and behaviors in long-horizon tasks while using multi-modality to perceive
deviations between task execution and high-level planning. Recently, large
language models (LLMs) have demonstrated powerful planning and reasoning
capabilities for comprehension and processing of semantic information through
robot control tasks, as well as the usability of analytical judgment and
decision-making for multi-modal inputs. To leverage the power of LLMs towards
humanoid loco-manipulation, we propose a novel language-model based framework
that enables robots to autonomously plan behaviors and low-level execution
under given textual instructions, while observing and correcting failures that
may occur during task execution. To systematically evaluate this framework in
grounding LLMs, we created the robot 'action' and 'sensing' behavior library
for task planning, and conducted mobile manipulation tasks and experiments in
both simulated and real environments using the CENTAURO robot, and verified the
effectiveness and application of this approach in robotic tasks with autonomous
behavioral planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.08188v4' target='_blank'>Nl2Hltl2Plan: Scaling Up Natural Language Understanding for Multi-Robots
  Through Hierarchical Temporal Logic Task Representation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shaojun Xu, Xusheng Luo, Yutong Huang, Letian Leng, Ruixuan Liu, Changliu Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-15 14:46:13</h6>
<p class='card-text'>To enable non-experts to specify long-horizon, multi-robot collaborative
tasks, language models are increasingly used to translate natural language
commands into formal specifications. However, because translation can occur in
multiple ways, such translations may lack accuracy or lead to inefficient
multi-robot planning. Our key insight is that concise hierarchical
specifications can simplify planning while remaining straightforward to derive
from human instructions. We propose Nl2Hltl2Plan, a framework that translates
natural language commands into hierarchical Linear Temporal Logic (LTL) and
solves the corresponding planning problem. The translation involves two steps
leveraging Large Language Models (LLMs). First, an LLM transforms instructions
into a Hierarchical Task Tree, capturing logical and temporal relations. Next,
a fine-tuned LLM converts sub-tasks into flat LTL formulas, which are
aggregated into hierarchical specifications, with the lowest level
corresponding to ordered robot actions. These specifications are then used with
off-the-shelf planners. Our Nl2Hltl2Plan demonstrates the potential of LLMs in
hierarchical reasoning for multi-robot task planning. Evaluations in simulation
and real-world experiments with human participants show that Nl2Hltl2Plan
outperforms existing methods, handling more complex instructions while
achieving higher success rates and lower costs in task allocation and planning.
Additional details are available at https://nl2hltl2plan.github.io .</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.08160v2' target='_blank'>General-purpose Clothes Manipulation with Semantic Keypoints</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuhong Deng, David Hsu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-15 13:49:14</h6>
<p class='card-text'>Clothes manipulation is a critical skill for household robots. Recent
advancements have been made in task-specific clothes manipulation, such as
folding, flattening, and hanging. However, due to clothes' complex geometries
and deformability, creating a general-purpose robot system that can manipulate
a diverse range of clothes in many ways remains challenging. Since clothes are
typically designed with specific structures, we propose identifying these
specific features like ``left sleeve'' as semantic keypoints. Semantic
keypoints can provide semantic cues for task planning and geometric cues for
low-level action generation. With this insight, we develop a hierarchical
learning framework using the large language model (LLM) for general-purpose
CLothes mAnipulation with Semantic keyPoints (CLASP). Extensive simulation
experiments show that CLASP outperforms baseline methods on both seen and
unseen tasks across various clothes manipulation tasks. Real-world experiments
show that CLASP can be directly deployed in the real world and applied to a
wide variety of clothes.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.07971v1' target='_blank'>Predicting Lung Cancer Patient Prognosis with Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Danqing Hu, Bing Liu, Xiang Li, Xiaofeng Zhu, Nan Wu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-15 06:36:27</h6>
<p class='card-text'>Prognosis prediction is crucial for determining optimal treatment plans for
lung cancer patients. Traditionally, such predictions relied on models
developed from retrospective patient data. Recently, large language models
(LLMs) have gained attention for their ability to process and generate text
based on extensive learned knowledge. In this study, we evaluate the potential
of GPT-4o mini and GPT-3.5 in predicting the prognosis of lung cancer patients.
We collected two prognosis datasets, i.e., survival and post-operative
complication datasets, and designed multiple tasks to assess the models'
performance comprehensively. Logistic regression models were also developed as
baselines for comparison. The experimental results demonstrate that LLMs can
achieve competitive, and in some tasks superior, performance in lung cancer
prognosis prediction compared to data-driven logistic regression models despite
not using additional patient data. These findings suggest that LLMs can be
effective tools for prognosis prediction in lung cancer, particularly when
patient data is limited or unavailable.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.08335v1' target='_blank'>Plan with Code: Comparing approaches for robust NL to DSL generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nastaran Bassamzadeh, Chhaya Methani</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-15 04:29:33</h6>
<p class='card-text'>Planning in code is considered a more reliable approach for many
orchestration tasks. This is because code is more tractable than steps
generated via Natural Language and make it easy to support more complex
sequences by abstracting deterministic logic into functions. It also allows
spotting issues with incorrect function names with the help of parsing checks
that can be run on code. Progress in Code Generation methodologies, however,
remains limited to general-purpose languages like C, C++, and Python. LLMs
continue to face challenges with custom function names in Domain Specific
Languages or DSLs, leading to higher hallucination rates and syntax errors.
This is more common for custom function names, that are typically part of the
plan. Moreover, keeping LLMs up-to-date with newer function names is an issue.
This poses a challenge for scenarios like task planning over a large number of
APIs, since the plan is represented as a DSL having custom API names. In this
paper, we focus on workflow automation in RPA (Robotic Process Automation)
domain as a special case of task planning. We present optimizations for using
Retrieval Augmented Generation (or RAG) with LLMs for DSL generation along with
an ablation study comparing these strategies with a fine-tuned model. Our
results showed that the fine-tuned model scored the best on code similarity
metric. However, with our optimizations, RAG approach is able to match the
quality for in-domain API names in the test set. Additionally, it offers
significant advantage for out-of-domain or unseen API names, outperforming
Fine-Tuned model on similarity metric by 7 pts.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.07806v2' target='_blank'>From Decision to Action in Surgical Autonomy: Multi-Modal Large Language
  Models for Robot-Assisted Blood Suction</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sadra Zargarzadeh, Maryam Mirzaei, Yafei Ou, Mahdi Tavakoli</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-14 20:30:34</h6>
<p class='card-text'>The rise of Large Language Models (LLMs) has impacted research in robotics
and automation. While progress has been made in integrating LLMs into general
robotics tasks, a noticeable void persists in their adoption in more specific
domains such as surgery, where critical factors such as reasoning,
explainability, and safety are paramount. Achieving autonomy in robotic
surgery, which entails the ability to reason and adapt to changes in the
environment, remains a significant challenge. In this work, we propose a
multi-modal LLM integration in robot-assisted surgery for autonomous blood
suction. The reasoning and prioritization are delegated to the higher-level
task-planning LLM, and the motion planning and execution are handled by the
lower-level deep reinforcement learning model, creating a distributed agency
between the two components. As surgical operations are highly dynamic and may
encounter unforeseen circumstances, blood clots and active bleeding were
introduced to influence decision-making. Results showed that using a
multi-modal LLM as a higher-level reasoning unit can account for these surgical
complexities to achieve a level of reasoning previously unattainable in
robot-assisted surgeries. These findings demonstrate the potential of
multi-modal LLMs to significantly enhance contextual understanding and
decision-making in robotic-assisted surgeries, marking a step toward autonomous
surgical systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.07542v1' target='_blank'>New Curriculum, New Chance -- Retrieval Augmented Generation for Lesson
  Planning in Ugandan Secondary Schools. Prototype Quality Evaluation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Simon Kloker, Herbertson Bukoli, Twaha Kateete</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-14 13:22:14</h6>
<p class='card-text'>Introduction: Poor educational quality in Secondary Schools is still regarded
as one of the major struggles in 21st century Uganda - especially in rural
areas. Research identifies several problems, including low quality or absent
teacher lesson planning. As the government pushes towards the implementation of
a new curriculum, exiting lesson plans become obsolete and the problem is
worsened. Using a Retrieval Augmented Generation approach, we developed a
prototype that generates customized lesson plans based on the
government-accredited textbooks. This helps teachers create lesson plans more
efficiently and with better quality, ensuring they are fully aligned the new
curriculum and the competence-based learning approach.
  Methods: The prototype was created using Cohere LLM and Sentence Embeddings,
and LangChain Framework - and thereafter made available on a public website.
Vector stores were trained for three new curriculum textbooks (ICT,
Mathematics, History), all at Secondary 1 Level. Twenty-four lessons plans were
generated following a pseudo-random generation protocol, based on the suggested
periods in the textbooks. The lesson plans were analyzed regarding their
technical quality by three independent raters following the Lesson Plan
Analysis Protocol (LPAP) by Ndihokubwayo et al. (2022) that is specifically
designed for East Africa and competence-based curriculums.
  Results: Evaluation of 24 lesson plans using the LPAP resulted in an average
quality of between 75 and 80%, corresponding to "very good lesson plan". None
of the lesson plans scored below 65%, although one lesson plan could be argued
to have been missing the topic. In conclusion, the quality of the generated
lesson plans is at least comparable, if not better, than those created by
humans, as demonstrated in a study in Rwanda, whereby no lesson plan even
reached the benchmark of 50%.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.07537v2' target='_blank'>Usefulness of data flow diagrams and large language models for security
  threat validation: a registered report</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Winnie Bahati Mbaka, Katja Tuma</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-14 13:14:27</h6>
<p class='card-text'>The arrival of recent cybersecurity standards has raised the bar for security
assessments in organizations, but existing techniques don't always scale well.
Threat analysis and risk assessment are used to identify security threats for
new or refactored systems. Still, there is a lack of definition-of-done, so
identified threats have to be validated which slows down the analysis. Existing
literature has focused on the overall performance of threat analysis, but no
previous work has investigated how deep must the analysts dig into the material
before they can effectively validate the identified security threats. We
propose a controlled experiment with practitioners to investigate whether some
analysis material (like LLM-generated advice) is better than none and whether
more material (the system's data flow diagram and LLM-generated advice) is
better than some material. In addition, we present key findings from running a
pilot with 41 MSc students, which are used to improve the study design.
Finally, we also provide an initial replication package, including experimental
material and data analysis scripts and a plan to extend it to include new
materials based on the final data collection campaign with practitioners (e.g.,
pre-screening questions).</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.07531v2' target='_blank'>Development of a Large Language Model-based Multi-Agent Clinical
  Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based
  Triage and Treatment Planning in Emergency Departments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Seungjun Han, Wongyung Choi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-14 13:03:41</h6>
<p class='card-text'>Emergency department (ED) overcrowding and the complexity of rapid
decision-making in critical care settings pose significant challenges to
healthcare systems worldwide. While clinical decision support systems (CDSS)
have shown promise, the integration of large language models (LLMs) offers new
possibilities for enhancing triage accuracy and clinical decision-making. This
study presents an LLM-driven CDSS designed to assist ED physicians and nurses
in patient triage, treatment planning, and overall emergency care management.
  We developed a multi-agent CDSS utilizing Llama-3-70b as the base LLM,
orchestrated by CrewAI and Langchain. The system comprises four AI agents
emulating key ED roles: Triage Nurse, Emergency Physician, Pharmacist, and ED
Coordinator. It incorporates the Korean Triage and Acuity Scale (KTAS) for
triage assessment and integrates with the RxNorm API for medication management.
  The model was evaluated using the Asclepius dataset, with performance
assessed by a clinical emergency medicine specialist. The CDSS demonstrated
high accuracy in triage decision-making compared to the baseline of a
single-agent system. Furthermore, the system exhibited strong performance in
critical areas, including primary diagnosis, critical findings identification,
disposition decision-making, treatment planning, and resource allocation.
  Our multi-agent CDSS demonstrates significant potential for supporting
comprehensive emergency care management. By leveraging state-of-the-art AI
technologies, this system offers a scalable and adaptable tool that could
enhance emergency medical care delivery, potentially alleviating ED
overcrowding and improving patient outcomes. This work contributes to the
growing field of AI applications in emergency medicine and offers a promising
direction for future research and clinical implementation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.06578v2' target='_blank'>OpenEP: Open-Ended Future Event Prediction</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yong Guan, Hao Peng, Xiaozhi Wang, Lei Hou, Juanzi Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-13 02:35:54</h6>
<p class='card-text'>Future event prediction (FEP) is a long-standing and crucial task in the
world, as understanding the evolution of events enables early risk
identification, informed decision-making, and strategic planning. Existing work
typically treats event prediction as classification tasks and confines the
outcomes of future events to a fixed scope, such as yes/no questions, candidate
set, and taxonomy, which is difficult to include all possible outcomes of
future events. In this paper, we introduce OpenEP (an Open-Ended Future Event
Prediction task), which generates flexible and diverse predictions aligned with
real-world scenarios. This is mainly reflected in two aspects: firstly, the
predictive questions are diverse, covering different stages of event
development and perspectives; secondly, the outcomes are flexible, without
constraints on scope or format. To facilitate the study of this task, we
construct OpenEPBench, an open-ended future event prediction dataset. For
question construction, we pose questions from seven perspectives, including
location, time, event development, event outcome, event impact, event response,
and other, to facilitate an in-depth analysis and understanding of the
comprehensive evolution of events. For outcome construction, we collect
free-form text containing the outcomes as ground truth to provide semantically
complete and detail-enriched outcomes. Furthermore, we propose StkFEP, a
stakeholder-enhanced future event prediction framework, that incorporates event
characteristics for open-ended settings. Our method extracts stakeholders
involved in events to extend questions to gather diverse information. We also
collect historically events that are relevant and similar to the question to
reveal potential evolutionary patterns. Experiment results indicate that
accurately predicting future events in open-ended settings is challenging for
existing LLMs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.06520v2' target='_blank'>Retrieval-Augmented Hierarchical in-Context Reinforcement Learning and
  Hindsight Modular Reflections for Task Planning with LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chuanneng Sun, Songjun Huang, Dario Pompili</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-12 22:40:01</h6>
<p class='card-text'>Large Language Models (LLMs) have demonstrated remarkable abilities in
various language tasks, making them promising candidates for decision-making in
robotics. Inspired by Hierarchical Reinforcement Learning (HRL), we propose
Retrieval-Augmented in-context reinforcement Learning (RAHL), a novel framework
that decomposes complex tasks into sub-tasks using an LLM-based high-level
policy, in which a complex task is decomposed into sub-tasks by a high-level
policy on-the-fly. The sub-tasks, defined by goals, are assigned to the
low-level policy to complete. To improve the agent's performance in
multi-episode execution, we propose Hindsight Modular Reflection (HMR), where,
instead of reflecting on the full trajectory, we let the agent reflect on
shorter sub-trajectories to improve reflection efficiency. We evaluated the
decision-making ability of the proposed RAHL in three benchmark
environments--ALFWorld, Webshop, and HotpotQA. The results show that RAHL can
achieve an improvement in performance in 9%, 42%, and 10% in 5 episodes of
execution in strong baselines. Furthermore, we also implemented RAHL on the
Boston Dynamics SPOT robot. The experiment shows that the robot can scan the
environment, find entrances, and navigate to new rooms controlled by the LLM
policy.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.06318v1' target='_blank'>Can We Rely on LLM Agents to Draft Long-Horizon Plans? Let's Take
  TravelPlanner as an Example</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yanan Chen, Ali Pesaranghader, Tanmana Sadhu, Dong Hoon Yi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-12 17:39:01</h6>
<p class='card-text'>Large language models (LLMs) have brought autonomous agents closer to
artificial general intelligence (AGI) due to their promising generalization and
emergent capabilities. There is, however, a lack of studies on how LLM-based
agents behave, why they could potentially fail, and how to improve them,
particularly in demanding real-world planning tasks. In this paper, as an
effort to fill the gap, we present our study using a realistic benchmark,
TravelPlanner, where an agent must meet multiple constraints to generate
accurate plans. We leverage this benchmark to address four key research
questions: (1) are LLM agents robust enough to lengthy and noisy contexts when
it comes to reasoning and planning? (2) can few-shot prompting adversely impact
the performance of LLM agents in scenarios with long context? (3) can we rely
on refinement to improve plans, and (4) can fine-tuning LLMs with both positive
and negative feedback lead to further improvement? Our comprehensive
experiments indicate that, firstly, LLMs often fail to attend to crucial parts
of a long context, despite their ability to handle extensive reference
information and few-shot examples; secondly, they still struggle with analyzing
the long plans and cannot provide accurate feedback for refinement; thirdly, we
propose Feedback-Aware Fine-Tuning (FAFT), which leverages both positive and
negative feedback, resulting in substantial gains over Supervised Fine-Tuning
(SFT). Our findings offer in-depth insights to the community on various aspects
related to real-world planning applications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.06087v1' target='_blank'>Building Decision Making Models Through Language Model Regime</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yu Zhang, Haoxiang Liu, Feijun Jiang, Weihua Luo, Kaifu Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-12 12:04:14</h6>
<p class='card-text'>We propose a novel approach for decision making problems leveraging the
generalization capabilities of large language models (LLMs). Traditional
methods such as expert systems, planning algorithms, and reinforcement learning
often exhibit limited generalization, typically requiring the training of new
models for each unique task. In contrast, LLMs demonstrate remarkable success
in generalizing across varied language tasks, inspiring a new strategy for
training decision making models. Our approach, referred to as "Learning then
Using" (LTU), entails a two-stage process. Initially, the \textit{learning}
phase develops a robust foundational decision making model by integrating
diverse knowledge from various domains and decision making contexts. The
subsequent \textit{using} phase refines this foundation model for specific
decision making scenarios. Distinct from other studies that employ LLMs for
decision making through supervised learning, our LTU method embraces a
versatile training methodology that combines broad pre-training with targeted
fine-tuning. Experiments in e-commerce domains such as advertising and search
optimization have shown that LTU approach outperforms traditional supervised
learning regimes in decision making capabilities and generalization. The LTU
approach is the first practical training architecture for both single-step and
multi-step decision making tasks combined with LLMs, which can be applied
beyond game and robot domains. It provides a robust and adaptable framework for
decision making, enhances the effectiveness and flexibility of various systems
in tackling various challenges.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.05478v2' target='_blank'>Multi-Agent Planning Using Visual Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Michele Brienza, Francesco Argenziano, Vincenzo Suriani, Domenico D. Bloisi, Daniele Nardi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-10 08:10:17</h6>
<p class='card-text'>Large Language Models (LLMs) and Visual Language Models (VLMs) are attracting
increasing interest due to their improving performance and applications across
various domains and tasks. However, LLMs and VLMs can produce erroneous
results, especially when a deep understanding of the problem domain is
required. For instance, when planning and perception are needed simultaneously,
these models often struggle because of difficulties in merging multi-modal
information. To address this issue, fine-tuned models are typically employed
and trained on specialized data structures representing the environment. This
approach has limited effectiveness, as it can overly complicate the context for
processing. In this paper, we propose a multi-agent architecture for embodied
task planning that operates without the need for specific data structures as
input. Instead, it uses a single image of the environment, handling free-form
domains by leveraging commonsense knowledge. We also introduce a novel, fully
automatic evaluation procedure, PG2S, designed to better assess the quality of
a plan. We validated our approach using the widely recognized ALFRED dataset,
comparing PG2S to the existing KAS metric to further evaluate the quality of
the generated plans.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.05456v1' target='_blank'>Path-LLM: A Shortest-Path-based LLM Learning for Unified Graph
  Representation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wenbo Shang, Xuliang Zhu, Xin Huang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-10 06:35:11</h6>
<p class='card-text'>Unified graph representation learning aims to produce node embeddings, which
can be applied to multiple downstream applications. However, existing studies
based on graph neural networks and language models either suffer from the
limitations of numerous training needed toward specific downstream predictions
or have shallow semantic features. In this work, we propose a novel Path-LLM
model to learn unified graph representation, which leverages a powerful large
language model (LLM) to incorporate our proposed path features. Our Path-LLM
framework consists of several well-designed techniques. First, we develop a new
mechanism of long-to-short shortest path (L2SP) selection, which covers
essential connections between different dense groups. An in-depth comparison of
different path selection plans is offered to illustrate the strength of our
designed L2SP. Then, we design path textualization to obtain L2SP-based
training texts. Next, we feed the texts into a self-supervised LLM training
process to learn embeddings. Extensive experiments on benchmarks validate the
superiority of Path-LLM against the state-of-the-art WalkLM method on two
classical graph learning tasks (node classification and link prediction) and
one NP-hard graph query processing task (keyword search), meanwhile saving more
than 90% of training paths.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.05346v3' target='_blank'>DataNarrative: Automated Data-Driven Storytelling with Visualizations
  and Texts</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mohammed Saidul Islam, Md Tahmid Rahman Laskar, Md Rizwan Parvez, Enamul Hoque, Shafiq Joty</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-09 21:31:33</h6>
<p class='card-text'>Data-driven storytelling is a powerful method for conveying insights by
combining narrative techniques with visualizations and text. These stories
integrate visual aids, such as highlighted bars and lines in charts, along with
textual annotations explaining insights. However, creating such stories
requires a deep understanding of the data and meticulous narrative planning,
often necessitating human intervention, which can be time-consuming and
mentally taxing. While Large Language Models (LLMs) excel in various NLP tasks,
their ability to generate coherent and comprehensive data stories remains
underexplored. In this work, we introduce a novel task for data story
generation and a benchmark containing 1,449 stories from diverse sources. To
address the challenges of crafting coherent data stories, we propose a
multiagent framework employing two LLM agents designed to replicate the human
storytelling process: one for understanding and describing the data
(Reflection), generating the outline, and narration, and another for
verification at each intermediary step. While our agentic framework generally
outperforms non-agentic counterparts in both model-based and human evaluations,
the results also reveal unique challenges in data story generation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.05101v1' target='_blank'>MooER: LLM-based Speech Recognition and Translation Models from Moore
  Threads</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Junhao Xu, Zhenlin Liang, Yi Liu, Yichao Hu, Jian Li, Yajun Zheng, Meng Cai, Hua Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-09 14:43:56</h6>
<p class='card-text'>In this paper, we present MooER, a LLM-based large-scale automatic speech
recognition (ASR) / automatic speech translation (AST) model of Moore Threads.
A 5000h pseudo labeled dataset containing open source and self collected speech
data is used for training. We achieve performance comparable to other open
source models trained with up to hundreds of thousands of hours of labeled
speech data. Meanwhile, experiments conducted on Covost2 Zh2en testset suggest
that our model outperforms other open source Speech LLMs. A BLEU score of 25.2
can be obtained. The main contributions of this paper are summarized as
follows. First, this paper presents a training strategy for encoders and LLMs
on speech related tasks (including ASR and AST) using a small size of pseudo
labeled data without any extra manual annotation and selection. Second, we
release our ASR and AST models and plan to open-source our training code and
strategy in the near future. Moreover, a model trained on 8wh scale training
data is planned to be released later on.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.04168v3' target='_blank'>Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City
  Navigation without Instructions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Qingbin Zeng, Qinglong Yang, Shunan Dong, Heming Du, Liang Zheng, Fengli Xu, Yong Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-08 02:28:43</h6>
<p class='card-text'>This paper considers a scenario in city navigation: an AI agent is provided
with language descriptions of the goal location with respect to some well-known
landmarks; By only observing the scene around, including recognizing landmarks
and road network connections, the agent has to make decisions to navigate to
the goal location without instructions. This problem is very challenging,
because it requires agent to establish self-position and acquire spatial
representation of complex urban environment, where landmarks are often
invisible. In the absence of navigation instructions, such abilities are vital
for the agent to make high-quality decisions in long-range city navigation.
With the emergent reasoning ability of large language models (LLMs), a tempting
baseline is to prompt LLMs to "react" on each observation and make decisions
accordingly. However, this baseline has very poor performance that the agent
often repeatedly visits same locations and make short-sighted, inconsistent
decisions. To address these issues, this paper introduces a novel agentic
workflow featured by its abilities to perceive, reflect and plan. Specifically,
we find LLaVA-7B can be fine-tuned to perceive the direction and distance of
landmarks with sufficient accuracy for city navigation. Moreover, reflection is
achieved through a memory mechanism, where past experiences are stored and can
be retrieved with current perception for effective decision argumentation.
Planning uses reflection results to produce long-term plans, which can avoid
short-sighted decisions in long-range navigation. We show the designed workflow
significantly improves navigation ability of the LLM agent compared with the
state-of-the-art baselines.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.03624v1' target='_blank'>AgentsCoMerge: Large Language Model Empowered Collaborative Decision
  Making for Ramp Merging</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Senkang Hu, Zhengru Fang, Zihan Fang, Yiqin Deng, Xianhao Chen, Yuguang Fang, Sam Kwong</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-07 08:34:48</h6>
<p class='card-text'>Ramp merging is one of the bottlenecks in traffic systems, which commonly
cause traffic congestion, accidents, and severe carbon emissions. In order to
address this essential issue and enhance the safety and efficiency of connected
and autonomous vehicles (CAVs) at multi-lane merging zones, we propose a novel
collaborative decision-making framework, named AgentsCoMerge, to leverage large
language models (LLMs). Specifically, we first design a scene observation and
understanding module to allow an agent to capture the traffic environment. Then
we propose a hierarchical planning module to enable the agent to make decisions
and plan trajectories based on the observation and the agent's own state. In
addition, in order to facilitate collaboration among multiple agents, we
introduce a communication module to enable the surrounding agents to exchange
necessary information and coordinate their actions. Finally, we develop a
reinforcement reflection guided training paradigm to further enhance the
decision-making capability of the framework. Extensive experiments are
conducted to evaluate the performance of our proposed method, demonstrating its
superior efficiency and effectiveness for multi-agent collaborative
decision-making under various ramp merging scenarios.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.03505v1' target='_blank'>Optimus: Accelerating Large-Scale Multi-Modal LLM Training by Bubble
  Exploitation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Weiqi Feng, Yangrui Chen, Shaoyu Wang, Yanghua Peng, Haibin Lin, Minlan Yu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-07 02:08:29</h6>
<p class='card-text'>Multimodal large language models (MLLMs) have extended the success of large
language models (LLMs) to multiple data types, such as image, text and audio,
achieving significant performance in various domains, including multimodal
translation, visual question answering and content generation. Nonetheless,
existing systems are inefficient to train MLLMs due to substantial GPU bubbles
caused by the heterogeneous modality models and complex data dependencies in 3D
parallelism. This paper proposes Optimus, a distributed MLLM training system
that reduces end-to-end MLLM training time. Optimus is based on our principled
analysis that scheduling the encoder computation within the LLM bubbles can
reduce bubbles in MLLM training. To make scheduling encoder computation
possible for all GPUs, Optimus searches the separate parallel plans for encoder
and LLM, and adopts a bubble scheduling algorithm to enable exploiting LLM
bubbles without breaking the original data dependencies in the MLLM model
architecture. We further decompose encoder layer computation into a series of
kernels, and analyze the common bubble pattern of 3D parallelism to carefully
optimize the sub-millisecond bubble scheduling, minimizing the overall training
time. Our experiments in a production cluster show that Optimus accelerates
MLLM training by 20.5%-21.3% with ViT-22B and GPT-175B model over 3072 GPUs
compared to baselines.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.03033v1' target='_blank'>L3iTC at the FinLLM Challenge Task: Quantization for Financial Text
  Classification & Summarization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Elvys Linhares Pontes, Carlos-Emiliano González-Gallardo, Mohamed Benjannet, Caryn Qu, Antoine Doucet</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-06 08:25:49</h6>
<p class='card-text'>This article details our participation (L3iTC) in the FinLLM Challenge Task
2024, focusing on two key areas: Task 1, financial text classification, and
Task 2, financial text summarization. To address these challenges, we
fine-tuned several large language models (LLMs) to optimize performance for
each task. Specifically, we used 4-bit quantization and LoRA to determine which
layers of the LLMs should be trained at a lower precision. This approach not
only accelerated the fine-tuning process on the training data provided by the
organizers but also enabled us to run the models on low GPU memory. Our
fine-tuned models achieved third place for the financial classification task
with an F1-score of 0.7543 and secured sixth place in the financial
summarization task on the official test datasets.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.02882v1' target='_blank'>Compromising Embodied Agents with Contextual Backdoor Attacks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Aishan Liu, Yuguang Zhou, Xianglong Liu, Tianyuan Zhang, Siyuan Liang, Jiakai Wang, Yanjun Pu, Tianlin Li, Junqi Zhang, Wenbo Zhou, Qing Guo, Dacheng Tao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-06 01:20:12</h6>
<p class='card-text'>Large language models (LLMs) have transformed the development of embodied
intelligence. By providing a few contextual demonstrations, developers can
utilize the extensive internal knowledge of LLMs to effortlessly translate
complex tasks described in abstract language into sequences of code snippets,
which will serve as the execution logic for embodied agents. However, this
paper uncovers a significant backdoor security threat within this process and
introduces a novel method called \method{}. By poisoning just a few contextual
demonstrations, attackers can covertly compromise the contextual environment of
a black-box LLM, prompting it to generate programs with context-dependent
defects. These programs appear logically sound but contain defects that can
activate and induce unintended behaviors when the operational agent encounters
specific triggers in its interactive environment. To compromise the LLM's
contextual environment, we employ adversarial in-context generation to optimize
poisoned demonstrations, where an LLM judge evaluates these poisoned prompts,
reporting to an additional LLM that iteratively optimizes the demonstration in
a two-player adversarial game using chain-of-thought reasoning. To enable
context-dependent behaviors in downstream agents, we implement a dual-modality
activation strategy that controls both the generation and execution of program
defects through textual and visual triggers. We expand the scope of our attack
by developing five program defect modes that compromise key aspects of
confidentiality, integrity, and availability in embodied agents. To validate
the effectiveness of our approach, we conducted extensive experiments across
various tasks, including robot planning, robot manipulation, and compositional
visual reasoning. Additionally, we demonstrate the potential impact of our
approach by successfully attacking real-world autonomous driving systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.07705v1' target='_blank'>Enhancing Supply Chain Visibility with Knowledge Graphs and Large
  Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sara AlMahri, Liming Xu, Alexandra Brintrup</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-05 17:11:29</h6>
<p class='card-text'>In today's globalized economy, comprehensive supply chain visibility is
crucial for effective risk management. Achieving visibility remains a
significant challenge due to limited information sharing among supply chain
partners. This paper presents a novel framework leveraging Knowledge Graphs
(KGs) and Large Language Models (LLMs) to enhance supply chain visibility
without relying on direct stakeholder information sharing. Our zero-shot,
LLM-driven approach automates the extraction of supply chain information from
diverse public sources and constructs KGs to capture complex interdependencies
between supply chain entities. We employ zero-shot prompting for Named Entity
Recognition (NER) and Relation Extraction (RE) tasks, eliminating the need for
extensive domain-specific training. We validate the framework with a case study
on electric vehicle supply chains, focusing on tracking critical minerals for
battery manufacturing. Results show significant improvements in supply chain
mapping, extending visibility beyond tier-2 suppliers. The framework reveals
critical dependencies and alternative sourcing options, enhancing risk
management and strategic planning. With high accuracy in NER and RE tasks, it
provides an effective tool for understanding complex, multi-tiered supply
networks. This research offers a scalable, flexible method for constructing
domain-specific supply chain KGs, addressing longstanding challenges in
visibility and paving the way for advancements in digital supply chain
surveillance.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.02559v1' target='_blank'>Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan:
  A Multi-Player Cooperative Game under Imperfect Information</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yauwai Yim, Chunkit Chan, Tianyu Shi, Zheye Deng, Wei Fan, Tianshi Zheng, Yangqiu Song</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-05 15:36:46</h6>
<p class='card-text'>Large language models (LLMs) have shown success in handling simple games with
imperfect information and enabling multi-agent coordination, but their ability
to facilitate practical collaboration against other agents in complex,
imperfect information environments, especially in a non-English environment,
still needs to be explored. This study investigates the applicability of
knowledge acquired by open-source and API-based LLMs to sophisticated
text-based games requiring agent collaboration under imperfect information,
comparing their performance to established baselines using other types of
agents. We propose a Theory of Mind (ToM) planning technique that allows LLM
agents to adapt their strategy against various adversaries using only game
rules, current state, and historical context as input. An external tool was
incorporated to mitigate the challenge of dynamic and extensive action spaces
in this card game. Our results show that although a performance gap exists
between current LLMs and state-of-the-art reinforcement learning (RL) models,
LLMs demonstrate ToM capabilities in this game setting. It consistently
improves their performance against opposing agents, suggesting their ability to
understand the actions of allies and adversaries and establish collaboration
with allies. To encourage further research and understanding, we have made our
codebase openly accessible.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.02520v1' target='_blank'>OneLove beyond the field -- A few-shot pipeline for topic and sentiment
  analysis during the FIFA World Cup in Qatar</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Christoph Rauchegger, Sonja Mei Wang, Pieter Delobelle</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-05 14:40:40</h6>
<p class='card-text'>The FIFA World Cup in Qatar was discussed extensively in the news and on
social media. Due to news reports with allegations of human rights violations,
there were calls to boycott it. Wearing a OneLove armband was part of a planned
protest activity. Controversy around the armband arose when FIFA threatened to
sanction captains who wear it. To understand what topics Twitter users Tweeted
about and what the opinion of German Twitter users was towards the OneLove
armband, we performed an analysis of German Tweets published during the World
Cup using in-context learning with LLMs. We validated the labels on human
annotations. We found that Twitter users initially discussed the armband's
impact, LGBT rights, and politics; after the ban, the conversation shifted
towards politics in sports in general, accompanied by a subtle shift in
sentiment towards neutrality. Our evaluation serves as a framework for future
research to explore the impact of sports activism and evolving public
sentiment. This is especially useful in settings where labeling datasets for
specific opinions is unfeasible, such as when events are unfolding.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.02248v2' target='_blank'>ReDel: A Toolkit for LLM-Powered Recursive Multi-Agent Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Andrew Zhu, Liam Dugan, Chris Callison-Burch</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-05 05:43:23</h6>
<p class='card-text'>Recently, there has been increasing interest in using Large Language Models
(LLMs) to construct complex multi-agent systems to perform tasks such as
compiling literature reviews, drafting consumer reports, and planning
vacations. Many tools and libraries exist for helping create such systems,
however none support recursive multi-agent systems -- where the models
themselves flexibly decide when to delegate tasks and how to organize their
delegation structure. In this work, we introduce ReDel: a toolkit for recursive
multi-agent systems that supports custom tool-use, delegation schemes,
event-based logging, and interactive replay in an easy-to-use web interface. We
show that, using ReDel, we are able to easily identify potential areas of
improvements through the visualization and debugging tools. Our code,
documentation, and PyPI package are open-source and free to use under the MIT
license at https://github.com/zhudotexe/redel.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.02210v1' target='_blank'>ExoViP: Step-by-step Verification and Exploration with Exoskeleton
  Modules for Compositional Visual Reasoning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuxuan Wang, Alan Yuille, Zhuowan Li, Zilong Zheng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-05 03:22:10</h6>
<p class='card-text'>Compositional visual reasoning methods, which translate a complex query into
a structured composition of feasible visual tasks, have exhibited a strong
potential in complicated multi-modal tasks. Empowered by recent advances in
large language models (LLMs), this multi-modal challenge has been brought to a
new stage by treating LLMs as few-shot/zero-shot planners, i.e.,
vision-language (VL) programming. Such methods, despite their numerous merits,
suffer from challenges due to LLM planning mistakes or inaccuracy of visual
execution modules, lagging behind the non-compositional models. In this work,
we devise a "plug-and-play" method, ExoViP, to correct errors in both the
planning and execution stages through introspective verification. We employ
verification modules as "exoskeletons" to enhance current VL programming
schemes. Specifically, our proposed verification module utilizes a mixture of
three sub-verifiers to validate predictions after each reasoning step,
subsequently calibrating the visual module predictions and refining the
reasoning trace planned by LLMs. Experimental results on two representative VL
programming methods showcase consistent improvements on five compositional
reasoning tasks on standard benchmarks. In light of this, we believe that
ExoViP can foster better performance and generalization on open-domain
multi-modal challenges.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.01423v1' target='_blank'>Prompt Recursive Search: A Living Framework with Adaptive Growth in LLM
  Auto-Prompting</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xiangyu Zhao, Chengqian Ma</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-02 17:59:42</h6>
<p class='card-text'>Large Language Models (LLMs) exhibit remarkable proficiency in addressing a
diverse array of tasks within the Natural Language Processing (NLP) domain,
with various prompt design strategies significantly augmenting their
capabilities. However, these prompts, while beneficial, each possess inherent
limitations. The primary prompt design methodologies are twofold: The first,
exemplified by the Chain of Thought (CoT), involves manually crafting prompts
specific to individual datasets, hence termed Expert-Designed Prompts (EDPs).
Once these prompts are established, they are unalterable, and their
effectiveness is capped by the expertise of the human designers. When applied
to LLMs, the static nature of EDPs results in a uniform approach to both simple
and complex problems within the same dataset, leading to the inefficient use of
tokens for straightforward issues. The second method involves prompts
autonomously generated by the LLM, known as LLM-Derived Prompts (LDPs), which
provide tailored solutions to specific problems, mitigating the limitations of
EDPs. However, LDPs may encounter a decline in performance when tackling
complex problems due to the potential for error accumulation during the
solution planning process. To address these challenges, we have conceived a
novel Prompt Recursive Search (PRS) framework that leverages the LLM to
generate solutions specific to the problem, thereby conserving tokens. The
framework incorporates an assessment of problem complexity and an adjustable
structure, ensuring a reduction in the likelihood of errors. We have
substantiated the efficacy of PRS framework through extensive experiments using
LLMs with different numbers of parameters across a spectrum of datasets in
various domains. Compared to the CoT method, the PRS method has increased the
accuracy on the BBH dataset by 8% using Llama3-7B model, achieving a 22%
improvement.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.01380v1' target='_blank'>Coalitions of Large Language Models Increase the Robustness of AI Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Prattyush Mangal, Carol Mak, Theo Kanakis, Timothy Donovan, Dave Braines, Edward Pyzer-Knapp</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-02 16:37:44</h6>
<p class='card-text'>The emergence of Large Language Models (LLMs) have fundamentally altered the
way we interact with digital systems and have led to the pursuit of LLM powered
AI agents to assist in daily workflows. LLMs, whilst powerful and capable of
demonstrating some emergent properties, are not logical reasoners and often
struggle to perform well at all sub-tasks carried out by an AI agent to plan
and execute a workflow. While existing studies tackle this lack of proficiency
by generalised pretraining at a huge scale or by specialised fine-tuning for
tool use, we assess if a system comprising of a coalition of pretrained LLMs,
each exhibiting specialised performance at individual sub-tasks, can match the
performance of single model agents. The coalition of models approach showcases
its potential for building robustness and reducing the operational costs of
these AI agents by leveraging traits exhibited by specific models. Our findings
demonstrate that fine-tuning can be mitigated by considering a coalition of
pretrained models and believe that this approach can be applied to other
non-agentic systems which utilise LLMs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.01102v1' target='_blank'>LessonPlanner: Assisting Novice Teachers to Prepare Pedagogy-Driven
  Lesson Plans with Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Haoxiang Fan, Guanzheng Chen, Xingbo Wang, Zhenhui Peng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-02 08:26:28</h6>
<p class='card-text'>Preparing a lesson plan, e.g., a detailed road map with strategies and
materials for instructing a 90-minute class, is beneficial yet challenging for
novice teachers. Large language models (LLMs) can ease this process by
generating adaptive content for lesson plans, which would otherwise require
teachers to create from scratch or search existing resources. In this work, we
first conduct a formative study with six novice teachers to understand their
needs for support of preparing lesson plans with LLMs. Then, we develop
LessonPlanner that assists users to interactively construct lesson plans with
adaptive LLM-generated content based on Gagne's nine events. Our
within-subjects study (N=12) shows that compared to the baseline ChatGPT
interface, LessonPlanner can significantly improve the quality of outcome
lesson plans and ease users' workload in the preparation process. Our expert
interviews (N=6) further demonstrate LessonPlanner's usefulness in suggesting
effective teaching strategies and meaningful educational resources. We discuss
concerns on and design considerations for supporting teaching activities with
LLMs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.00764v3' target='_blank'>AgentGen: Enhancing Planning Abilities for Large Language Model based
  Agent via Environment and Task Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mengkang Hu, Pu Zhao, Can Xu, Qingfeng Sun, Jianguang Lou, Qingwei Lin, Ping Luo, Saravan Rajmohan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-01 17:59:46</h6>
<p class='card-text'>Large Language Model-based agents have garnered significant attention and are
becoming increasingly popular. Furthermore, planning ability is a crucial
component of an LLM-based agent, which generally entails achieving a desired
goal from an initial state. This paper investigates enhancing the planning
abilities of LLMs through instruction tuning, referred to as agent training.
Recent studies have demonstrated that utilizing expert-level trajectory for
instruction-tuning LLMs effectively enhances their planning capabilities.
However, existing work primarily focuses on synthesizing trajectories from
manually designed planning tasks and environments. The labor-intensive nature
of creating these environments and tasks impedes the generation of sufficiently
varied and extensive trajectories. To address this limitation, this paper
explores the automated synthesis of diverse environments and a gradual range of
planning tasks, from easy to difficult. We introduce a framework, AgentGen,
that leverages LLMs first to generate environments and subsequently generate
planning tasks conditioned on these environments. Specifically, to improve
environmental diversity, we propose using an inspiration corpus composed of
various domain-specific text segments as the context for synthesizing
environments. Moreover, to increase the difficulty diversity of generated
planning tasks, we propose a bidirectional evolution method, Bi-Evol, that
evolves planning tasks from easier and harder directions to synthesize a task
set with a smoother difficulty curve. The evaluation results derived from
AgentBoard show that AgentGen greatly improves LLMs' planning ability, e.g.,
the AgentGen instruction-tuned Llama-3.1-8B surpasses GPT-3.5 in overall
performance. Moreover, the AgentGen-tuned Llama-3.1-70B model achieves
state-of-the-art results in planning tasks. Project page:
https://agent-gen.github.io/.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.00523v2' target='_blank'>Jailbreaking Text-to-Image Models with LLM-Based Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yingkai Dong, Zheng Li, Xiangtao Meng, Ning Yu, Shanqing Guo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-08-01 12:54:46</h6>
<p class='card-text'>Recent advancements have significantly improved automated task-solving
capabilities using autonomous agents powered by large language models (LLMs).
However, most LLM-based agents focus on dialogue, programming, or specialized
domains, leaving their potential for addressing generative AI safety tasks
largely unexplored. In this paper, we propose Atlas, an advanced LLM-based
multi-agent framework targeting generative AI models, specifically focusing on
jailbreak attacks against text-to-image (T2I) models with built-in safety
filters. Atlas consists of two agents, namely the mutation agent and the
selection agent, each comprising four key modules: a vision-language model
(VLM) or LLM brain, planning, memory, and tool usage. The mutation agent uses
its VLM brain to determine whether a prompt triggers the T2I model's safety
filter. It then collaborates iteratively with the LLM brain of the selection
agent to generate new candidate jailbreak prompts with the highest potential to
bypass the filter. In addition to multi-agent communication, we leverage
in-context learning (ICL) memory mechanisms and the chain-of-thought (COT)
approach to learn from past successes and failures, thereby enhancing Atlas's
performance. Our evaluation demonstrates that Atlas successfully jailbreaks
several state-of-the-art T2I models equipped with multi-modal safety filters in
a black-box setting. Additionally, Atlas outperforms existing methods in both
query efficiency and the quality of generated images. This work convincingly
demonstrates the successful application of LLM-based agents in studying the
safety vulnerabilities of popular text-to-image generation models. We urge the
community to consider advanced techniques like ours in response to the rapidly
evolving text-to-image generation field.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.21762v1' target='_blank'>ReplanVLM: Replanning Robotic Tasks with Visual Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Aoran Mei, Guo-Niu Zhu, Huaxiang Zhang, Zhongxue Gan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-31 17:31:01</h6>
<p class='card-text'>Large language models (LLMs) have gained increasing popularity in robotic
task planning due to their exceptional abilities in text analytics and
generation, as well as their broad knowledge of the world. However, they fall
short in decoding visual cues. LLMs have limited direct perception of the
world, which leads to a deficient grasp of the current state of the world. By
contrast, the emergence of visual language models (VLMs) fills this gap by
integrating visual perception modules, which can enhance the autonomy of
robotic task planning. Despite these advancements, VLMs still face challenges,
such as the potential for task execution errors, even when provided with
accurate instructions. To address such issues, this paper proposes a ReplanVLM
framework for robotic task planning. In this study, we focus on error
correction interventions. An internal error correction mechanism and an
external error correction mechanism are presented to correct errors under
corresponding phases. A replan strategy is developed to replan tasks or correct
error codes when task execution fails. Experimental results on real robots and
in simulation environments have demonstrated the superiority of the proposed
framework, with higher success rates and robust error correction capabilities
in open-world tasks. Videos of our experiments are available at
https://youtu.be/NPk2pWKazJc.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.21333v1' target='_blank'>Chat2Layout: Interactive 3D Furniture Layout with a Multimodal LLM</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Can Wang, Hongliang Zhong, Menglei Chai, Mingming He, Dongdong Chen, Jing Liao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-31 04:49:46</h6>
<p class='card-text'>Automatic furniture layout is long desired for convenient interior design.
Leveraging the remarkable visual reasoning capabilities of multimodal large
language models (MLLMs), recent methods address layout generation in a static
manner, lacking the feedback-driven refinement essential for interactive user
engagement. We introduce Chat2Layout, a novel interactive furniture layout
generation system that extends the functionality of MLLMs into the realm of
interactive layout design. To achieve this, we establish a unified
vision-question paradigm for in-context learning, enabling seamless
communication with MLLMs to steer their behavior without altering model
weights. Within this framework, we present a novel training-free visual
prompting mechanism. This involves a visual-text prompting technique that
assist MLLMs in reasoning about plausible layout plans, followed by an
Offline-to-Online search (O2O-Search) method, which automatically identifies
the minimal set of informative references to provide exemplars for visual-text
prompting. By employing an agent system with MLLMs as the core controller, we
enable bidirectional interaction. The agent not only comprehends the 3D
environment and user requirements through linguistic and visual perception but
also plans tasks and reasons about actions to generate and arrange furniture
within the virtual space. Furthermore, the agent iteratively updates based on
visual feedback from execution results. Experimental results demonstrate that
our approach facilitates language-interactive generation and arrangement for
diverse and complex 3D furniture.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.21293v1' target='_blank'>SimpleLLM4AD: An End-to-End Vision-Language Model with Graph Visual
  Question Answering for Autonomous Driving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Peiru Zheng, Yun Zhao, Zhan Gong, Hong Zhu, Shaohua Wu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-31 02:35:33</h6>
<p class='card-text'>Many fields could benefit from the rapid development of the large language
models (LLMs). The end-to-end autonomous driving (e2eAD) is one of the
typically fields facing new opportunities as the LLMs have supported more and
more modalities. Here, by utilizing vision-language model (VLM), we proposed an
e2eAD method called SimpleLLM4AD. In our method, the e2eAD task are divided
into four stages, which are perception, prediction, planning, and behavior.
Each stage consists of several visual question answering (VQA) pairs and VQA
pairs interconnect with each other constructing a graph called Graph VQA
(GVQA). By reasoning each VQA pair in the GVQA through VLM stage by stage, our
method could achieve e2e driving with language. In our method, vision
transformers (ViT) models are employed to process nuScenes visual data, while
VLM are utilized to interpret and reason about the information extracted from
the visual inputs. In the perception stage, the system identifies and
classifies objects from the driving environment. The prediction stage involves
forecasting the potential movements of these objects. The planning stage
utilizes the gathered information to develop a driving strategy, ensuring the
safety and efficiency of the autonomous vehicle. Finally, the behavior stage
translates the planned actions into executable commands for the vehicle. Our
experiments demonstrate that SimpleLLM4AD achieves competitive performance in
complex driving scenarios.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2408.07302v1' target='_blank'>Effects of a Prompt Engineering Intervention on Undergraduate Students'
  AI Self-Efficacy, AI Knowledge and Prompt Engineering Ability: A Mixed
  Methods Study</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:David James Woo, Deliang Wang, Tim Yung, Kai Guo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-30 15:05:24</h6>
<p class='card-text'>Prompt engineering is critical for effective interaction with large language
models (LLMs) such as ChatGPT. However, efforts to teach this skill to students
have been limited. This study designed and implemented a prompt engineering
intervention, examining its influence on undergraduate students' AI
self-efficacy, AI knowledge, and proficiency in creating effective prompts. The
intervention involved 27 students who participated in a 100-minute workshop
conducted during their history course at a university in Hong Kong. During the
workshop, students were introduced to prompt engineering strategies, which they
applied to plan the course's final essay task. Multiple data sources were
collected, including students' responses to pre- and post-workshop
questionnaires, pre- and post-workshop prompt libraries, and written
reflections. The study's findings revealed that students demonstrated a higher
level of AI self-efficacy, an enhanced understanding of AI concepts, and
improved prompt engineering skills because of the intervention. These findings
have implications for AI literacy education, as they highlight the importance
of prompt engineering training for specific higher education use cases. This is
a significant shift from students haphazardly and intuitively learning to
engineer prompts. Through prompt engineering education, educators can faciitate
students' effective navigation and leverage of LLMs to support their
coursework.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.19667v1' target='_blank'>Smart Language Agents in Real-World Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Annabelle Miin, Timothy Wei</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-29 03:00:30</h6>
<p class='card-text'>Comprehensive planning agents have been a long term goal in the field of
artificial intelligence. Recent innovations in Natural Language Processing have
yielded success through the advent of Large Language Models (LLMs). We seek to
improve the travel-planning capability of such LLMs by extending upon the work
of the previous paper TravelPlanner. Our objective is to explore a new method
of using LLMs to improve the travel planning experience. We focus specifically
on the "sole-planning" mode of travel planning; that is, the agent is given
necessary reference information, and its goal is to create a comprehensive plan
from the reference information. While this does not simulate the real-world we
feel that an optimization of the sole-planning capability of a travel planning
agent will still be able to enhance the overall user experience. We propose a
semi-automated prompt generation framework which combines the LLM-automated
prompt and "human-in-the-loop" to iteratively refine the prompt to improve the
LLM performance. Our result shows that LLM automated prompt has its limitations
and "human-in-the-loop" greatly improves the performance by $139\%$ with one
single iteration.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.19630v2' target='_blank'>LLMs' Understanding of Natural Language Revealed</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Walid S. Saba</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-29 01:21:11</h6>
<p class='card-text'>Large language models (LLMs) are the result of a massive experiment in
bottom-up, data-driven reverse engineering of language at scale. Despite their
utility in a number of downstream NLP tasks, ample research has shown that LLMs
are incapable of performing reasoning in tasks that require quantification over
and the manipulation of symbolic variables (e.g., planning and problem
solving); see for example [25][26]. In this document, however, we will focus on
testing LLMs for their language understanding capabilities, their supposed
forte. As we will show here, the language understanding capabilities of LLMs
have been widely exaggerated. While LLMs have proven to generate human-like
coherent language (since that's how they were designed), their language
understanding capabilities have not been properly tested. In particular, we
believe that the language understanding capabilities of LLMs should be tested
by performing an operation that is the opposite of 'text generation' and
specifically by giving the LLM snippets of text as input and then querying what
the LLM "understood". As we show here, when doing so it will become apparent
that LLMs do not truly understand language, beyond very superficial inferences
that are essentially the byproduct of the memorization of massive amounts of
ingested text.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.19405v1' target='_blank'>Logic Distillation: Learning from Code Function by Function for Planning
  and Decision-making</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Dong Chen, Shilin Zhang, Fei Gao, Yueting Zhuang, Siliang Tang, Qidong Liu, Mingliang Xu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-28 05:34:42</h6>
<p class='card-text'>Large language models (LLMs) have garnered increasing attention owing to
their powerful logical reasoning capabilities. Generally, larger LLMs (L-LLMs)
that require paid interfaces exhibit significantly superior performance
compared to smaller LLMs (S-LLMs) that can be deployed on a variety of devices.
Knowledge distillation (KD) aims to empower S-LLMs with the capabilities of
L-LLMs, while S-LLMs merely mimic the outputs of L-LLMs, failing to get the
powerful logical reasoning capabilities. Consequently, S-LLMs are helpless when
it comes to planning and decision-making tasks that require logical reasoning
capabilities. To tackle the identified challenges, we propose a novel framework
called Logic Distillation (LD). Initially, LD employs L-LLMs to instantiate
complex instructions into discrete functions and illustrates their usage to
establish a function base. Subsequently, based on the function base, LD
fine-tunes S-LLMs to learn the logic employed by L-LLMs in planning and
decision-making. During testing, LD utilizes a retriever to identify the
top-$K$ relevant functions based on instructions and current states, which will
be selected and invoked by S-LLMs. Ultimately, S-LLMs yield planning and
decision-making outcomes, function by function. Relevant experiments
demonstrate that with the assistance of LD, S-LLMs can achieve outstanding
results in planning and decision-making tasks, comparable to, or even
surpassing, those of L-LLMs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.19094v6' target='_blank'>Wonderful Team: Zero-Shot Physical Task Planning with Visual LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zidan Wang, Rui Shen, Bradly Stadie</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-26 21:18:57</h6>
<p class='card-text'>We introduce Wonderful Team, a multi-agent Vision Large Language Model (VLLM)
framework for executing high-level robotic planning in a zero-shot regime. In
our context, zero-shot high-level planning means that for a novel environment,
we provide a VLLM with an image of the robot's surroundings and a task
description, and the VLLM outputs the sequence of actions necessary for the
robot to complete the task. Unlike previous methods for high-level visual
planning for robotic manipulation, our method uses VLLMs for the entire
planning process, enabling a more tightly integrated loop between perception,
control, and planning. As a result, Wonderful Team's performance on real-world
semantic and physical planning tasks often exceeds methods that rely on
separate vision systems. For example, we see an average 40% success rate
improvement on VimaBench over prior methods such as NLaP, an average 30%
improvement over Trajectory Generators on tasks from the Trajectory Generator
paper, including drawing and wiping a plate, and an average 70% improvement
over Trajectory Generators on a new set of semantic reasoning tasks including
environment rearrangement with implicit linguistic constraints. We hope these
results highlight the rapid improvements of VLLMs in the past year, and
motivate the community to consider VLLMs as an option for some high-level
robotic planning problems in the future.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.19056v1' target='_blank'>OfficeBench: Benchmarking Language Agents across Multiple Applications
  for Office Automation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zilong Wang, Yuedong Cui, Li Zhong, Zimin Zhang, Da Yin, Bill Yuchen Lin, Jingbo Shang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-26 19:27:17</h6>
<p class='card-text'>Office automation significantly enhances human productivity by automatically
finishing routine tasks in the workflow. Beyond the basic information
extraction studied in much of the prior document AI literature, the office
automation research should be extended to more realistic office tasks which
require to integrate various information sources in the office system and
produce outputs through a series of decision-making processes. We introduce
OfficeBench, one of the first office automation benchmarks for evaluating
current LLM agents' capability to address office tasks in realistic office
workflows. OfficeBench requires LLM agents to perform feasible long-horizon
planning, proficiently switch between applications in a timely manner, and
accurately ground their actions within a large combined action space, based on
the contextual demands of the workflow. Applying our customized evaluation
methods on each task, we find that GPT-4 Omni achieves the highest pass rate of
47.00%, demonstrating a decent performance in handling office tasks. However,
this is still far below the human performance and accuracy standards required
by real-world office workflows. We further observe that most issues are related
to operation redundancy and hallucinations, as well as limitations in switching
between multiple applications, which may provide valuable insights for
developing effective agent frameworks for office automation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.18553v2' target='_blank'>REAPER: Reasoning based Retrieval Planning for Complex RAG Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ashutosh Joshi, Sheikh Muhammad Sarwar, Samarth Varshney, Sreyashi Nag, Shrivats Agrawal, Juhi Naik</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-26 07:05:54</h6>
<p class='card-text'>Complex dialog systems often use retrieved evidence to facilitate factual
responses. Such RAG (Retrieval Augmented Generation) systems retrieve from
massive heterogeneous data stores that are usually architected as multiple
indexes or APIs instead of a single monolithic source. For a given query,
relevant evidence needs to be retrieved from one or a small subset of possible
retrieval sources. Complex queries can even require multi-step retrieval. For
example, a conversational agent on a retail site answering customer questions
about past orders will need to retrieve the appropriate customer order first
and then the evidence relevant to the customer's question in the context of the
ordered product. Most RAG Agents handle such Chain-of-Thought (CoT) tasks by
interleaving reasoning and retrieval steps. However, each reasoning step
directly adds to the latency of the system. For large models this latency cost
is significant -- in the order of multiple seconds. Multi-agent systems may
classify the query to a single Agent associated with a retrieval source, though
this means that a (small) classification model dictates the performance of a
large language model. In this work we present REAPER (REAsoning-based PlannER)
- an LLM based planner to generate retrieval plans in conversational systems.
We show significant gains in latency over Agent-based systems and are able to
scale easily to new and unseen use cases as compared to classification-based
planning. Though our method can be applied to any RAG system, we show our
results in the context of a conversational shopping assistant.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.17544v1' target='_blank'>MathViz-E: A Case-study in Domain-Specialized Tool-Using Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Arya Bulusu, Brandon Man, Ashish Jagmohan, Aditya Vempaty, Jennifer Mari-Wyka, Deepak Akkil</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-24 15:45:07</h6>
<p class='card-text'>There has been significant recent interest in harnessing LLMs to control
software systems through multi-step reasoning, planning and tool-usage. While
some promising results have been obtained, application to specific domains
raises several general issues including the control of specialized domain
tools, the lack of existing datasets for training and evaluation, and the
non-triviality of automated system evaluation and improvement. In this paper,
we present a case-study where we examine these issues in the context of a
specific domain. Specifically, we present an automated math visualizer and
solver system for mathematical pedagogy. The system orchestrates mathematical
solvers and math graphing tools to produce accurate visualizations from simple
natural language commands. We describe the creation of specialized data-sets,
and also develop an auto-evaluator to easily evaluate the outputs of our system
by comparing them to ground-truth expressions. We have open sourced the
data-sets and code for the proposed system.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.17086v1' target='_blank'>AI-Gadget Kit: Integrating Swarm User Interfaces with LLM-driven Agents
  for Rich Tabletop Game Applications</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yijie Guo, Zhenhan Huang, Ruhan Wang, Zhihao Yao, Tianyu Yu, Zhiling Xu, Xinyu Zhao, Xueqing Li, Haipeng Mi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-24 08:27:18</h6>
<p class='card-text'>While Swarm User Interfaces (SUIs) have succeeded in enriching tangible
interaction experiences, their limitations in autonomous action planning have
hindered the potential for personalized and dynamic interaction generation in
tabletop games. Based on the AI-Gadget Kit we developed, this paper explores
how to integrate LLM-driven agents within tabletop games to enable SUIs to
execute complex interaction tasks. After defining the design space of this kit,
we elucidate the method for designing agents that can extend the meta-actions
of SUIs to complex motion planning. Furthermore, we introduce an add-on prompt
method that simplifies the design process for four interaction behaviors and
four interaction relationships in tabletop games. Lastly, we present several
application scenarios that illustrate the potential of AI-Gadget Kit to
construct personalized interaction in SUI tabletop games. We expect to use our
work as a case study to inspire research on multi-agent-driven SUI for other
scenarios with complex interaction tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.16928v2' target='_blank'>From Sands to Mansions: Simulating Full Attack Chain with LLM-Organized
  Knowledge</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lingzhi Wang, Zhenyuan Li, Zonghan Guo, Yi Jiang, Kyle Jung, Kedar Thiagarajan, Jiahui Wang, Zhengkai Wang, Emily Wei, Xiangmin Shen, Yan Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-24 01:33:57</h6>
<p class='card-text'>Adversarial dynamics are intrinsic to the nature of offense and defense in
cyberspace, with both attackers and defenders continuously evolving their
technologies. Given the wide array of security products available, users often
face challenges in selecting the most effective solutions. Furthermore,
traditional benchmarks based on single-point attacks are increasingly
inadequate, failing to accurately reflect the full range of attacker
capabilities and falling short in properly evaluating the effectiveness of
defense products. Automated multi-stage attack simulations offer a promising
approach to enhance system evaluation efficiency and aid in analyzing the
effectiveness of detection systems. However, simulating a full attack chain is
complex and requires significant time and expertise from security
professionals, facing several challenges, including limited coverage of attack
techniques, a high level of required expertise, and a lack of execution detail.
In this paper, we model automatic attack simulation as a planning problem. By
using the Planning Domain Definition Language (PDDL) to formally describe the
attack simulation problem, and combining domain knowledge of both the problem
and the domain space, we enable the planning of attack paths through
standardized, domain-independent planning algorithms. We explore the potential
of Large Language Models (LLMs) to summarize and analyze knowledge from
existing attack documentation and reports, facilitating automated attack
planning. We introduce Aurora, a system that autonomously simulates full attack
chains based on external attack tools and threat intelligence reports.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.15723v1' target='_blank'>DStruct2Design: Data and Benchmarks for Data Structure Driven Generative
  Floor Plan Design</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhi Hao Luo, Luis Lara, Ge Ya Luo, Florian Golemo, Christopher Beckham, Christopher Pal</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-22 15:27:55</h6>
<p class='card-text'>Text conditioned generative models for images have yielded impressive
results. Text conditioned floorplan generation as a special type of raster
image generation task also received particular attention. However there are
many use cases in floorpla generation where numerical properties of the
generated result are more important than the aesthetics. For instance, one
might want to specify sizes for certain rooms in a floorplan and compare the
generated floorplan with given specifications Current approaches, datasets and
commonly used evaluations do not support these kinds of constraints. As such,
an attractive strategy is to generate an intermediate data structure that
contains numerical properties of a floorplan which can be used to generate the
final floorplan image. To explore this setting we (1) construct a new dataset
for this data-structure to data-structure formulation of floorplan generation
using two popular image based floorplan datasets RPLAN and ProcTHOR-10k, and
provide the tools to convert further procedurally generated ProcTHOR floorplan
data into our format. (2) We explore the task of floorplan generation given a
partial or complete set of constraints and we design a series of metrics and
benchmarks to enable evaluating how well samples generated from models respect
the constraints. (3) We create multiple baselines by finetuning a large
language model (LLM), Llama3, and demonstrate the feasibility of using
floorplan data structure conditioned LLMs for the problem of floorplan
generation respecting numerical constraints. We hope that our new datasets and
benchmarks will encourage further research on different ways to improve the
performance of LLMs and other generative modelling techniques for generating
designs where quantitative constraints are only partially specified, but must
be respected.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.15677v1' target='_blank'>Language models are robotic planners: reframing plans as goal refinement
  graphs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ateeq Sharfuddin, Travis Breaux</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-22 14:43:25</h6>
<p class='card-text'>Successful application of large language models (LLMs) to robotic planning
and execution may pave the way to automate numerous real-world tasks. Promising
recent research has been conducted showing that the knowledge contained in LLMs
can be utilized in making goal-driven decisions that are enactable in
interactive, embodied environments. Nonetheless, there is a considerable drop
in correctness of programs generated by LLMs. We apply goal modeling techniques
from software engineering to large language models generating robotic plans.
Specifically, the LLM is prompted to generate a step refinement graph for a
task. The executability and correctness of the program converted from this
refinement graph is then evaluated. The approach results in programs that are
more correct as judged by humans in comparison to previous work.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.15325v2' target='_blank'>Odyssey: Empowering Minecraft Agents with Open-World Skills</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shunyu Liu, Yaoru Li, Kongcheng Zhang, Zhenyu Cui, Wenkai Fang, Yuxuan Zheng, Tongya Zheng, Mingli Song</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-22 02:06:59</h6>
<p class='card-text'>Recent studies have delved into constructing generalist agents for open-world
environments like Minecraft. Despite the encouraging results, existing efforts
mainly focus on solving basic programmatic tasks, e.g., material collection and
tool-crafting following the Minecraft tech-tree, treating the ObtainDiamond
task as the ultimate goal. This limitation stems from the narrowly defined set
of actions available to agents, requiring them to learn effective long-horizon
strategies from scratch. Consequently, discovering diverse gameplay
opportunities in the open world becomes challenging. In this work, we introduce
Odyssey, a new framework that empowers Large Language Model (LLM)-based agents
with open-world skills to explore the vast Minecraft world. Odyssey comprises
three key parts: (1) An interactive agent with an open-world skill library that
consists of 40 primitive skills and 183 compositional skills. (2) A fine-tuned
LLaMA-3 model trained on a large question-answering dataset with 390k+
instruction entries derived from the Minecraft Wiki. (3) A new agent capability
benchmark includes the long-term planning task, the dynamic-immediate planning
task, and the autonomous exploration task. Extensive experiments demonstrate
that the proposed Odyssey framework can effectively evaluate different
capabilities of LLM-based agents. All datasets, model weights, and code are
publicly available to motivate future research on more advanced autonomous
agent solutions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.15141v1' target='_blank'>Text-Augmented Multimodal LLMs for Chemical Reaction Condition
  Recommendation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yu Zhang, Ruijie Yu, Kaipeng Zeng, Ding Li, Feng Zhu, Xiaokang Yang, Yaohui Jin, Yanyan Xu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-21 12:27:26</h6>
<p class='card-text'>High-throughput reaction condition (RC) screening is fundamental to chemical
synthesis. However, current RC screening suffers from laborious and costly
trial-and-error workflows. Traditional computer-aided synthesis planning (CASP)
tools fail to find suitable RCs due to data sparsity and inadequate reaction
representations. Nowadays, large language models (LLMs) are capable of tackling
chemistry-related problems, such as molecule design, and chemical logic Q\&A
tasks. However, LLMs have not yet achieved accurate predictions of chemical
reaction conditions. Here, we present MM-RCR, a text-augmented multimodal LLM
that learns a unified reaction representation from SMILES, reaction graphs, and
textual corpus for chemical reaction recommendation (RCR). To train MM-RCR, we
construct 1.2 million pair-wised Q\&A instruction datasets. Our experimental
results demonstrate that MM-RCR achieves state-of-the-art performance on two
open benchmark datasets and exhibits strong generalization capabilities on
out-of-domain (OOD) and High-Throughput Experimentation (HTE) datasets. MM-RCR
has the potential to accelerate high-throughput condition screening in chemical
synthesis.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.14926v1' target='_blank'>TraveLLM: Could you plan my new public transit route in face of a
  network disruption?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Bowen Fang, Zixiao Yang, Shukai Wang, Xuan Di</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-20 16:25:34</h6>
<p class='card-text'>Imagine there is a disruption in train 1 near Times Square metro station. You
try to find an alternative subway route to the JFK airport on Google Maps, but
the app fails to provide a suitable recommendation that takes into account the
disruption and your preferences to avoid crowded stations. We find that in many
such situations, current navigation apps may fall short and fail to give a
reasonable recommendation. To fill this gap, in this paper, we develop a
prototype, TraveLLM, to plan routing of public transit in face of disruption
that relies on Large Language Models (LLMs). LLMs have shown remarkable
capabilities in reasoning and planning across various domains. Here we hope to
investigate the potential of LLMs that lies in incorporating multi-modal
user-specific queries and constraints into public transit route
recommendations. Various test cases are designed under different scenarios,
including varying weather conditions, emergency events, and the introduction of
new transportation services. We then compare the performance of
state-of-the-art LLMs, including GPT-4, Claude 3 and Gemini, in generating
accurate routes. Our comparative analysis demonstrates the effectiveness of
LLMs, particularly GPT-4 in providing navigation plans. Our findings hold the
potential for LLMs to enhance existing navigation systems and provide a more
flexible and intelligent method for addressing diverse user needs in face of
disruptions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.14414v1' target='_blank'>System-1.x: Learning to Balance Fast and Slow Planning with Language
  Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Swarnadeep Saha, Archiki Prasad, Justin Chih-Yao Chen, Peter Hase, Elias Stengel-Eskin, Mohit Bansal</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-19 15:40:59</h6>
<p class='card-text'>Language models can be used to solve long-horizon planning problems in two
distinct modes: a fast 'System-1' mode, directly generating plans without any
explicit search or backtracking, and a slow 'System-2' mode, planning
step-by-step by explicitly searching over possible actions. While System-2 is
typically more effective, it is also more computationally expensive, making it
infeasible for long plans or large action spaces. Moreover, isolated System-1
or 2 ignores the user's end goals, failing to provide ways to control the
model's behavior. To this end, we propose the System-1.x Planner, a
controllable planning framework with LLMs that is capable of generating hybrid
plans and balancing between the two planning modes based on the difficulty of
the problem at hand. System-1.x consists of (i) a controller, (ii) a System-1
Planner, and (iii) a System-2 Planner. Based on a user-specified hybridization
factor (x) governing the mixture between System-1 and 2, the controller
decomposes a problem into sub-goals, and classifies them as easy or hard to be
solved by either System-1 or 2, respectively. We fine-tune all three components
on top of a single base LLM, requiring only search traces as supervision.
Experiments with two diverse planning tasks -- Maze Navigation and Blocksworld
-- show that our System-1.x Planner outperforms a System-1 Planner, a System-2
Planner trained to approximate A* search, and also a symbolic planner (A*). We
demonstrate the following key properties of our planner: (1) controllability:
increasing the hybridization factor (e.g., System-1.75 vs 1.5) performs more
search, improving performance, (2) flexibility: by building a neuro-symbolic
variant with a neural System-1 and a symbolic System-2, we can use existing
symbolic methods, and (3) generalizability: by being able to learn from
different search algorithms, our method is robust to the choice of search
algorithm.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.14239v1' target='_blank'>KoMA: Knowledge-driven Multi-agent Framework for Autonomous Driving with
  Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kemou Jiang, Xuan Cai, Zhiyong Cui, Aoyong Li, Yilong Ren, Haiyang Yu, Hao Yang, Daocheng Fu, Licheng Wen, Pinlong Cai</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-19 12:13:08</h6>
<p class='card-text'>Large language models (LLMs) as autonomous agents offer a novel avenue for
tackling real-world challenges through a knowledge-driven manner. These
LLM-enhanced methodologies excel in generalization and interpretability.
However, the complexity of driving tasks often necessitates the collaboration
of multiple, heterogeneous agents, underscoring the need for such LLM-driven
agents to engage in cooperative knowledge sharing and cognitive synergy.
Despite the promise of LLMs, current applications predominantly center around
single agent scenarios. To broaden the horizons of knowledge-driven strategies
and bolster the generalization capabilities of autonomous agents, we propose
the KoMA framework consisting of multi-agent interaction, multi-step planning,
shared-memory, and ranking-based reflection modules to enhance multi-agents'
decision-making in complex driving scenarios. Based on the framework's
generated text descriptions of driving scenarios, the multi-agent interaction
module enables LLM agents to analyze and infer the intentions of surrounding
vehicles, akin to human cognition. The multi-step planning module enables LLM
agents to analyze and obtain final action decisions layer by layer to ensure
consistent goals for short-term action decisions. The shared memory module can
accumulate collective experience to make superior decisions, and the
ranking-based reflection module can evaluate and improve agent behavior with
the aim of enhancing driving safety and efficiency. The KoMA framework not only
enhances the robustness and adaptability of autonomous driving agents but also
significantly elevates their generalization capabilities across diverse
scenarios. Empirical results demonstrate the superiority of our approach over
traditional methods, particularly in its ability to handle complex,
unpredictable driving environments without extensive retraining.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.13717v2' target='_blank'>CoDefeater: Using LLMs To Find Defeaters in Assurance Cases</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Usman Gohar, Michael C. Hunter, Robyn R. Lutz, Myra B. Cohen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-18 17:16:35</h6>
<p class='card-text'>Constructing assurance cases is a widely used, and sometimes required,
process toward demonstrating that safety-critical systems will operate safely
in their planned environment. To mitigate the risk of errors and missing edge
cases, the concept of defeaters - arguments or evidence that challenge claims
in an assurance case - has been introduced. Defeaters can provide timely
detection of weaknesses in the arguments, prompting further investigation and
timely mitigations. However, capturing defeaters relies on expert judgment,
experience, and creativity and must be done iteratively due to evolving
requirements and regulations. This paper proposes CoDefeater, an automated
process to leverage large language models (LLMs) for finding defeaters. Initial
results on two systems show that LLMs can efficiently find known and unforeseen
feasible defeaters to support safety analysts in enhancing the completeness and
confidence of assurance cases.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.13117v2' target='_blank'>SOMONITOR: Combining Explainable AI & Large Language Models for
  Marketing Analytics</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Aleksandr Farseev, Qi Yang, Marlo Ongpin, Ilia Gossoudarev, Yu-Yi Chu-Farseeva, Sergey Nikolenko</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-18 02:55:52</h6>
<p class='card-text'>Online marketing faces formidable challenges in managing and interpreting
immense volumes of data necessary for competitor analysis, content research,
and strategic branding. It is impossible to review hundreds to thousands of
transient online content items by hand, and partial analysis often leads to
suboptimal outcomes and poorly performing campaigns. We introduce an
explainable AI framework SOMONITOR that aims to synergize human intuition with
AI-based efficiency, helping marketers across all stages of the marketing
funnel, from strategic planning to content creation and campaign execution.
SOMONITOR incorporates a CTR prediction and ranking model for advertising
content and uses large language models (LLMs) to process high-performing
competitor content, identifying core content pillars such as target audiences,
customer needs, and product features. These pillars are then organized into
broader categories, including communication themes and targeted customer
personas. By integrating these insights with data from the brand's own
advertising campaigns, SOMONITOR constructs a narrative for addressing new
customer personas and simultaneously generates detailed content briefs in the
form of user stories that, as shown in the conducted case study, can be
directly applied by marketing teams to streamline content production and
campaign execution. The adoption of SOMONITOR in daily operations allows
digital marketers to quickly parse through extensive datasets, offering
actionable insights that significantly enhance campaign effectiveness and
overall job satisfaction.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.13101v2' target='_blank'>Retrieve, Summarize, Plan: Advancing Multi-hop Question Answering with
  an Iterative Approach</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhouyu Jiang, Mengshu Sun, Lei Liang, Zhiqiang Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-18 02:19:00</h6>
<p class='card-text'>Multi-hop question answering is a challenging task with distinct industrial
relevance, and Retrieval-Augmented Generation (RAG) methods based on large
language models (LLMs) have become a popular approach to tackle this task.
Owing to the potential inability to retrieve all necessary information in a
single iteration, a series of iterative RAG methods has been recently
developed, showing significant performance improvements. However, existing
methods still face two critical challenges: context overload resulting from
multiple rounds of retrieval, and over-planning and repetitive planning due to
the lack of a recorded retrieval trajectory. In this paper, we propose a novel
iterative RAG method called ReSP, equipped with a dual-function summarizer.
This summarizer compresses information from retrieved documents, targeting both
the overarching question and the current sub-question concurrently.
Experimental results on the multi-hop question-answering datasets HotpotQA and
2WikiMultihopQA demonstrate that our method significantly outperforms the
state-of-the-art, and exhibits excellent robustness concerning context length.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.18961v3' target='_blank'>MMAU: A Holistic Benchmark of Agent Capabilities Across Diverse Domains</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Guoli Yin, Haoping Bai, Shuang Ma, Feng Nan, Yanchao Sun, Zhaoyang Xu, Shen Ma, Jiarui Lu, Xiang Kong, Aonan Zhang, Dian Ang Yap, Yizhe zhang, Karsten Ahnert, Vik Kamath, Mathias Berglund, Dominic Walsh, Tobias Gindele, Juergen Wiest, Zhengfeng Lai, Xiaoming Wang, Jiulong Shan, Meng Cao, Ruoming Pang, Zirui Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-18 00:58:41</h6>
<p class='card-text'>Recent advances in large language models (LLMs) have increased the demand for
comprehensive benchmarks to evaluate their capabilities as human-like agents.
Existing benchmarks, while useful, often focus on specific application
scenarios, emphasizing task completion but failing to dissect the underlying
skills that drive these outcomes. This lack of granularity makes it difficult
to deeply discern where failures stem from. Additionally, setting up these
environments requires considerable effort, and issues of unreliability and
reproducibility sometimes arise, especially in interactive tasks. To address
these limitations, we introduce the Massive Multitask Agent Understanding
(MMAU) benchmark, featuring comprehensive offline tasks that eliminate the need
for complex environment setups. It evaluates models across five domains,
including Tool-use, Directed Acyclic Graph (DAG) QA, Data Science and Machine
Learning coding, Contest-level programming and Mathematics, and covers five
essential capabilities: Understanding, Reasoning, Planning, Problem-solving,
and Self-correction. With a total of 20 meticulously designed tasks
encompassing over 3K distinct prompts, MMAU provides a comprehensive framework
for evaluating the strengths and limitations of LLM agents. By testing 18
representative models on MMAU, we provide deep and insightful analyses.
Ultimately, MMAU not only sheds light on the capabilities and limitations of
LLM agents but also enhances the interpretability of their performance.
Datasets and evaluation scripts of MMAU are released at
https://github.com/apple/axlearn/tree/main/docs/research/mmau.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.12979v2' target='_blank'>Leveraging Environment Interaction for Automated PDDL Translation and
  Planning with Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sadegh Mahdavi, Raquel Aoki, Keyi Tang, Yanshuai Cao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-17 19:50:51</h6>
<p class='card-text'>Large Language Models (LLMs) have shown remarkable performance in various
natural language tasks, but they often struggle with planning problems that
require structured reasoning. To address this limitation, the conversion of
planning problems into the Planning Domain Definition Language (PDDL) has been
proposed as a potential solution, enabling the use of automated planners.
However, generating accurate PDDL files typically demands human inputs or
correction, which can be time-consuming and costly. In this paper, we propose a
novel approach that leverages LLMs and environment feedback to automatically
generate PDDL domain and problem description files without the need for human
intervention. Our method introduces an iterative refinement process that
generates multiple problem PDDL candidates and progressively refines the domain
PDDL based on feedback obtained from interacting with the environment. To guide
the refinement process, we develop an Exploration Walk (EW) metric, which
provides rich feedback signals for LLMs to update the PDDL file. We evaluate
our approach on $10$ PDDL environments. We achieve an average task solve rate
of 66% compared to a 29% solve rate by GPT-4's intrinsic planning with
chain-of-thought prompting. Our work enables the automated modeling of planning
environments using LLMs and environment feedback, eliminating the need for
human intervention in the PDDL translation process and paving the way for more
reliable LLM agents in challenging problems. Our code is available at
https://github.com/BorealisAI/llm-pddl-planning</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.12784v1' target='_blank'>AgentPoison: Red-teaming LLM Agents via Poisoning Memory or Knowledge
  Bases</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhaorun Chen, Zhen Xiang, Chaowei Xiao, Dawn Song, Bo Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-17 17:59:47</h6>
<p class='card-text'>LLM agents have demonstrated remarkable performance across various
applications, primarily due to their advanced capabilities in reasoning,
utilizing external knowledge and tools, calling APIs, and executing actions to
interact with environments. Current agents typically utilize a memory module or
a retrieval-augmented generation (RAG) mechanism, retrieving past knowledge and
instances with similar embeddings from knowledge bases to inform task planning
and execution. However, the reliance on unverified knowledge bases raises
significant concerns about their safety and trustworthiness. To uncover such
vulnerabilities, we propose a novel red teaming approach AgentPoison, the first
backdoor attack targeting generic and RAG-based LLM agents by poisoning their
long-term memory or RAG knowledge base. In particular, we form the trigger
generation process as a constrained optimization to optimize backdoor triggers
by mapping the triggered instances to a unique embedding space, so as to ensure
that whenever a user instruction contains the optimized backdoor trigger, the
malicious demonstrations are retrieved from the poisoned memory or knowledge
base with high probability. In the meantime, benign instructions without the
trigger will still maintain normal performance. Unlike conventional backdoor
attacks, AgentPoison requires no additional model training or fine-tuning, and
the optimized backdoor trigger exhibits superior transferability, in-context
coherence, and stealthiness. Extensive experiments demonstrate AgentPoison's
effectiveness in attacking three types of real-world LLM agents: RAG-based
autonomous driving agent, knowledge-intensive QA agent, and healthcare
EHRAgent. On each agent, AgentPoison achieves an average attack success rate
higher than 80% with minimal impact on benign performance (less than 1%) with a
poison rate less than 0.1%.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.12532v1' target='_blank'>Towards Collaborative Intelligence: Propagating Intentions and Reasoning
  for Multi-Agent Coordination with Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xihe Qiu, Haoyu Wang, Xiaoyu Tan, Chao Qu, Yujie Xiong, Yuan Cheng, Yinghui Xu, Wei Chu, Yuan Qi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-17 13:14:00</h6>
<p class='card-text'>Effective collaboration in multi-agent systems requires communicating goals
and intentions between agents. Current agent frameworks often suffer from
dependencies on single-agent execution and lack robust inter-module
communication, frequently leading to suboptimal multi-agent reinforcement
learning (MARL) policies and inadequate task coordination. To address these
challenges, we present a framework for training large language models (LLMs) as
collaborative agents to enable coordinated behaviors in cooperative MARL. Each
agent maintains a private intention consisting of its current goal and
associated sub-tasks. Agents broadcast their intentions periodically, allowing
other agents to infer coordination tasks. A propagation network transforms
broadcast intentions into teammate-specific communication messages, sharing
relevant goals with designated teammates. The architecture of our framework is
structured into planning, grounding, and execution modules. During execution,
multiple agents interact in a downstream environment and communicate intentions
to enable coordinated behaviors. The grounding module dynamically adapts
comprehension strategies based on emerging coordination patterns, while
feedback from execution agents influnces the planning module, enabling the
dynamic re-planning of sub-tasks. Results in collaborative environment
simulation demonstrate intention propagation reduces miscoordination errors by
aligning sub-task dependencies between agents. Agents learn when to communicate
intentions and which teammates require task details, resulting in emergent
coordinated behaviors. This demonstrates the efficacy of intention sharing for
cooperative multi-agent RL based on LLMs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.11919v1' target='_blank'>What's Wrong? Refining Meeting Summaries with LLM Feedback</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Frederic Kirstein, Terry Ruas, Bela Gipp</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-16 17:10:16</h6>
<p class='card-text'>Meeting summarization has become a critical task since digital encounters
have become a common practice. Large language models (LLMs) show great
potential in summarization, offering enhanced coherence and context
understanding compared to traditional methods. However, they still struggle to
maintain relevance and avoid hallucination. We introduce a multi-LLM correction
approach for meeting summarization using a two-phase process that mimics the
human review process: mistake identification and summary refinement. We release
QMSum Mistake, a dataset of 200 automatically generated meeting summaries
annotated by humans on nine error types, including structural, omission, and
irrelevance errors. Our experiments show that these errors can be identified
with high accuracy by an LLM. We transform identified mistakes into actionable
feedback to improve the quality of a given summary measured by relevance,
informativeness, conciseness, and coherence. This post-hoc refinement
effectively improves summary quality by leveraging multiple LLMs to validate
output quality. Our multi-LLM approach for meeting summarization shows
potential for similar complex text generation tasks requiring robustness,
action planning, and discussion towards a goal.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.11773v1' target='_blank'>Educational Personalized Learning Path Planning with Large Language
  Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chee Ng, Yuen Fung</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-16 14:32:56</h6>
<p class='card-text'>Educational Personalized Learning Path Planning (PLPP) aims to tailor
learning experiences to individual learners' needs, enhancing learning
efficiency and engagement. Despite its potential, traditional PLPP systems
often lack adaptability, interactivity, and transparency. This paper proposes a
novel approach integrating Large Language Models (LLMs) with prompt engineering
to address these challenges. By designing prompts that incorporate
learner-specific information, our method guides LLMs like LLama-2-70B and GPT-4
to generate personalized, coherent, and pedagogically sound learning paths. We
conducted experiments comparing our method with a baseline approach across
various metrics, including accuracy, user satisfaction, and the quality of
learning paths. The results show significant improvements in all areas,
particularly with GPT-4, demonstrating the effectiveness of prompt engineering
in enhancing PLPP. Additional long-term impact analysis further validates our
method's potential to improve learner performance and retention. This research
highlights the promise of LLMs and prompt engineering in advancing personalized
education.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.20242v4' target='_blank'>BadRobot: Jailbreaking Embodied LLMs in the Physical World</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hangtao Zhang, Chenyu Zhu, Xianlong Wang, Ziqi Zhou, Changgan Yin, Minghui Li, Lulu Xue, Yichen Wang, Shengshan Hu, Aishan Liu, Peijin Guo, Leo Yu Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-16 13:13:16</h6>
<p class='card-text'>Embodied AI represents systems where AI is integrated into physical entities.
Large Language Model (LLM), which exhibits powerful language understanding
abilities, has been extensively employed in embodied AI by facilitating
sophisticated task planning. However, a critical safety issue remains
overlooked: could these embodied LLMs perpetrate harmful behaviors? In
response, we introduce BadRobot, a novel attack paradigm aiming to make
embodied LLMs violate safety and ethical constraints through typical
voice-based user-system interactions. Specifically, three vulnerabilities are
exploited to achieve this type of attack: (i) manipulation of LLMs within
robotic systems, (ii) misalignment between linguistic outputs and physical
actions, and (iii) unintentional hazardous behaviors caused by world
knowledge's flaws. Furthermore, we construct a benchmark of various malicious
physical action queries to evaluate BadRobot's attack performance. Based on
this benchmark, extensive experiments against existing prominent embodied LLM
frameworks (e.g., Voxposer, Code as Policies, and ProgPrompt) demonstrate the
effectiveness of our BadRobot.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.11686v4' target='_blank'>CCoE: A Compact and Efficient LLM Framework with Multi-Expert
  Collaboration for Resource-Limited Settings</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shaomang Huang, Jianfeng Pan, Min Peng, Hanzhong Zheng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-16 13:03:58</h6>
<p class='card-text'>Large Language Models (LLMs) have achieved exceptional performance across
diverse domains through training on massive datasets. However, scaling LLMs to
support multiple downstream domain applications remains a significant
challenge, especially under resource constraints. Existing approaches often
struggle to balance performance across multiple domains with resource
efficiency, limiting their broader applicability. To address this, we introduce
the CCoE architecture, a modular framework that seamlessly integrates
domain-specific experts into a unified LLM. By leveraging independently trained
expert subnetworks on a shared backbone partition, CCoE achieves
state-of-the-art performance while significantly reducing the resource
requirements for multi-expert deployments. Furthermore, rule-based gating and
expert planning in CCoE enable flexible task allocation, promoting expert
collaboration to handle complex reasoning tasks. CCoE not only reduces
inference costs but also provides a flexible and scalable solution for
integrating domain expertise across diverse applications. Experiments on five
domains demonstrate that CCoE achieves comparable performance to current
domain-specific LLMs. Moreover, compared to existing multi-domain model
ensemble methods, CCoE reduces memory usage by 61.3%, while improving inference
efficiency by 0.76x over parameter-efficient multi-expert integration
approaches.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.12871v2' target='_blank'>MetaTool: Facilitating Large Language Models to Master Tools with
  Meta-task Augmentation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xiaohan Wang, Dian Li, Yilin Zhao, Sinbadliu, Hui Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-15 10:15:41</h6>
<p class='card-text'>Utilizing tools with Large Language Models (LLMs) is essential for grounding
AI agents in real-world applications. The prevailing approach involves few-shot
prompting with demonstrations or fine-tuning with expert annotations. However,
mere in-context demonstrations may fail to cover sufficient knowledge for
complex tools and tasks. Training on solution paths is also hindered by the
high cost of expert annotations and generalizing to new tools. A core challenge
of generalizable tool use lies in understanding the "meta", or fundamental
natures of tools that are transferable across tasks, such as causality and
constraints. In this paper, we present MetaTool, a novel tool learning
methodology designed to generalize across any reusable toolset. Our approach
incorporates a self-supervised augmentation technique derived from a series of
meta-tasks. This involves predicting masked elements in the tool execution
process. The self-supervised procedure enables scalable generation of
high-quality QA data, which is handy for supervising tool understanding. By
incorporating meta-task data into task-oriented training, our method
significantly enhances the performance of open-source LLMs, achieving results
comparable to ChatGPT in both tool-based planning and chatting scenarios.
Through large-scale instruction tuning, the MetaTool model demonstrates
impressive zero-shot generalizability on new tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.10362v3' target='_blank'>LAB-Bench: Measuring Capabilities of Language Models for Biology
  Research</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jon M. Laurent, Joseph D. Janizek, Michael Ruzo, Michaela M. Hinks, Michael J. Hammerling, Siddharth Narayanan, Manvitha Ponnapati, Andrew D. White, Samuel G. Rodriques</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-14 23:52:25</h6>
<p class='card-text'>There is widespread optimism that frontier Large Language Models (LLMs) and
LLM-augmented systems have the potential to rapidly accelerate scientific
discovery across disciplines. Today, many benchmarks exist to measure LLM
knowledge and reasoning on textbook-style science questions, but few if any
benchmarks are designed to evaluate language model performance on practical
tasks required for scientific research, such as literature search, protocol
planning, and data analysis. As a step toward building such benchmarks, we
introduce the Language Agent Biology Benchmark (LAB-Bench), a broad dataset of
over 2,400 multiple choice questions for evaluating AI systems on a range of
practical biology research capabilities, including recall and reasoning over
literature, interpretation of figures, access and navigation of databases, and
comprehension and manipulation of DNA and protein sequences. Importantly, in
contrast to previous scientific benchmarks, we expect that an AI system that
can achieve consistently high scores on the more difficult LAB-Bench tasks
would serve as a useful assistant for researchers in areas such as literature
search and molecular cloning. As an initial assessment of the emergent
scientific task capabilities of frontier language models, we measure
performance of several against our benchmark and report results compared to
human expert biology researchers. We will continue to update and expand
LAB-Bench over time, and expect it to serve as a useful tool in the development
of automated research systems going forward. A public subset of LAB-Bench is
available for use at the following URL:
https://huggingface.co/datasets/futurehouse/lab-bench</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.10064v4' target='_blank'>Revolutionizing Bridge Operation and Maintenance with LLM-based Agents:
  An Overview of Applications and Insights</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xinyu Chen, Lianzhen Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-14 03:31:33</h6>
<p class='card-text'>In various industrial fields of human social development, people have been
exploring methods aimed at freeing human labor. Constructing LLM-based agents
is considered to be one of the most effective tools to achieve this goal.
Agent, as a kind of human-like intelligent entity with the ability of
perception, planning, decision-making, and action, has created great production
value in many fields. However, the bridge O&M field shows a relatively low
level of intelligence compared to other industries. Nevertheless, the bridge
O&M field has developed numerous intelligent inspection devices, machine
learning algorithms, and autonomous evaluation and decision-making methods,
which provide a feasible basis for breakthroughs in artificial intelligence in
this field. The aim of this study is to explore the impact of AI bodies based
on large-scale language models on the field of bridge O&M and to analyze the
potential challenges and opportunities it brings to the core tasks of bridge
O&M. Through in-depth research and analysis, this paper expects to provide a
more comprehensive perspective for understanding the application of
intelligentsia in this field.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.09985v2' target='_blank'>A Training Data Recipe to Accelerate A* Search with Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Devaansh Gupta, Boyang Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-13 19:21:44</h6>
<p class='card-text'>Combining Large Language Models (LLMs) with heuristic search algorithms like
A* holds the promise of enhanced LLM reasoning and scalable inference. To
accelerate training and reduce computational demands, we investigate the
coreset selection problem for the training data of LLM heuristic learning. Few
methods to learn the heuristic functions consider the interaction between the
search algorithm and the machine learning model. In this work, we empirically
disentangle the requirements of A* search algorithm from the requirements of
the LLM to generalise on this task. Surprisingly, we find an overlap between
their requirements; A* requires more accurate predictions on search nodes near
the goal, and LLMs need the same set of nodes for effective generalisation.
With these insights, we derive a data-selection distribution for learning
LLM-based heuristics. On three classical planning domains, maze navigation,
Sokoban and sliding tile puzzles, our technique reduces the number of
iterations required to find the solutions by up to 15x, with a wall-clock
speed-up of search up to 5x. The codebase is at
https://github.com/devaansh100/a_star.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.09890v2' target='_blank'>Speech-Guided Sequential Planning for Autonomous Navigation using Large
  Language Model Meta AI 3 (Llama3)</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Alkesh K. Srivastava, Philip Dames</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-13 13:43:39</h6>
<p class='card-text'>In social robotics, a pivotal focus is enabling robots to engage with humans
in a more natural and seamless manner. The emergence of advanced large language
models (LLMs) such as Generative Pre-trained Transformers (GPTs) and
autoregressive models like Large Language Model Meta AI (Llamas) has driven
significant advancements in integrating natural language understanding
capabilities into social robots. This paper presents a system for speech-guided
sequential planning in autonomous navigation, utilizing Llama3 and the Robot
Operating System~(ROS). The proposed system involves using Llama3 to interpret
voice commands, extracting essential details through parsing, and decoding
these commands into sequential actions for tasks. Such sequential planning is
essential in various domains, particularly in the pickup and delivery of an
object. Once a sequential navigation task is evaluated, we employ DRL-VO, a
learning-based control policy that allows a robot to autonomously navigate
through social spaces with static infrastructure and (crowds of) people. We
demonstrate the effectiveness of the system in simulation experiment using
Turtlebot 2 in ROS1 and Turtlebot 3 in ROS2. We conduct hardware trials using a
Clearpath Robotics Jackal UGV, highlighting its potential for real-world
deployment in scenarios requiring flexible and interactive robotic behaviors.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.09811v1' target='_blank'>CellAgent: An LLM-driven Multi-Agent Framework for Automated Single-cell
  Data Analysis</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yihang Xiao, Jinyi Liu, Yan Zheng, Xiaohan Xie, Jianye Hao, Mingzhi Li, Ruitao Wang, Fei Ni, Yuxiao Li, Jintian Luo, Shaoqing Jiao, Jiajie Peng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-13 09:14:50</h6>
<p class='card-text'>Single-cell RNA sequencing (scRNA-seq) data analysis is crucial for
biological research, as it enables the precise characterization of cellular
heterogeneity. However, manual manipulation of various tools to achieve desired
outcomes can be labor-intensive for researchers. To address this, we introduce
CellAgent (http://cell.agent4science.cn/), an LLM-driven multi-agent framework,
specifically designed for the automatic processing and execution of scRNA-seq
data analysis tasks, providing high-quality results with no human intervention.
Firstly, to adapt general LLMs to the biological field, CellAgent constructs
LLM-driven biological expert roles - planner, executor, and evaluator - each
with specific responsibilities. Then, CellAgent introduces a hierarchical
decision-making mechanism to coordinate these biological experts, effectively
driving the planning and step-by-step execution of complex data analysis tasks.
Furthermore, we propose a self-iterative optimization mechanism, enabling
CellAgent to autonomously evaluate and optimize solutions, thereby guaranteeing
output quality. We evaluate CellAgent on a comprehensive benchmark dataset
encompassing dozens of tissues and hundreds of distinct cell types. Evaluation
results consistently show that CellAgent effectively identifies the most
suitable tools and hyperparameters for single-cell analysis tasks, achieving
optimal performance. This automated framework dramatically reduces the workload
for science data analyses, bringing us into the "Agent for Science" era.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.09792v1' target='_blank'>Language-Augmented Symbolic Planner for Open-World Task Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Guanqi Chen, Lei Yang, Ruixing Jia, Zhe Hu, Yizhou Chen, Wei Zhang, Wenping Wang, Jia Pan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-13 07:28:55</h6>
<p class='card-text'>Enabling robotic agents to perform complex long-horizon tasks has been a
long-standing goal in robotics and artificial intelligence (AI). Despite the
potential shown by large language models (LLMs), their planning capabilities
remain limited to short-horizon tasks and they are unable to replace the
symbolic planning approach. Symbolic planners, on the other hand, may encounter
execution errors due to their common assumption of complete domain knowledge
which is hard to manually prepare for an open-world setting. In this paper, we
introduce a Language-Augmented Symbolic Planner (LASP) that integrates
pre-trained LLMs to enable conventional symbolic planners to operate in an
open-world environment where only incomplete knowledge of action preconditions,
objects, and properties is initially available. In case of execution errors,
LASP can utilize the LLM to diagnose the cause of the error based on the
observation and interact with the environment to incrementally build up its
knowledge base necessary for accomplishing the given tasks. Experiments
demonstrate that LASP is proficient in solving planning problems in the
open-world setting, performing well even in situations where there are multiple
gaps in the knowledge.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.09287v1' target='_blank'>Instruction Following with Goal-Conditioned Reinforcement Learning in
  Virtual Environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zoya Volovikova, Alexey Skrynnik, Petr Kuderov, Aleksandr I. Panov</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-12 14:19:36</h6>
<p class='card-text'>In this study, we address the issue of enabling an artificial intelligence
agent to execute complex language instructions within virtual environments. In
our framework, we assume that these instructions involve intricate linguistic
structures and multiple interdependent tasks that must be navigated
successfully to achieve the desired outcomes. To effectively manage these
complexities, we propose a hierarchical framework that combines the deep
language comprehension of large language models with the adaptive
action-execution capabilities of reinforcement learning agents. The language
module (based on LLM) translates the language instruction into a high-level
action plan, which is then executed by a pre-trained reinforcement learning
agent. We have demonstrated the effectiveness of our approach in two different
environments: in IGLU, where agents are instructed to build structures, and in
Crafter, where agents perform tasks and interact with objects in the
surrounding environment according to language commands.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.08735v1' target='_blank'>Real-Time Anomaly Detection and Reactive Planning with Large Language
  Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Rohan Sinha, Amine Elhafsi, Christopher Agia, Matthew Foutter, Edward Schmerling, Marco Pavone</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-11 17:59:22</h6>
<p class='card-text'>Foundation models, e.g., large language models (LLMs), trained on
internet-scale data possess zero-shot generalization capabilities that make
them a promising technology towards detecting and mitigating
out-of-distribution failure modes of robotic systems. Fully realizing this
promise, however, poses two challenges: (i) mitigating the considerable
computational expense of these models such that they may be applied online, and
(ii) incorporating their judgement regarding potential anomalies into a safe
control framework. In this work, we present a two-stage reasoning framework:
First is a fast binary anomaly classifier that analyzes observations in an LLM
embedding space, which may then trigger a slower fallback selection stage that
utilizes the reasoning capabilities of generative LLMs. These stages correspond
to branch points in a model predictive control strategy that maintains the
joint feasibility of continuing along various fallback plans to account for the
slow reasoner's latency as soon as an anomaly is detected, thus ensuring
safety. We show that our fast anomaly classifier outperforms autoregressive
reasoning with state-of-the-art GPT models, even when instantiated with
relatively small language models. This enables our runtime monitor to improve
the trustworthiness of dynamic robotic systems, such as quadrotors or
autonomous vehicles, under resource and time constraints. Videos illustrating
our approach in both simulation and real-world experiments are available on
this project page: https://sites.google.com/view/aesop-llm.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.08713v2' target='_blank'>GTA: A Benchmark for General Tool Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jize Wang, Zerun Ma, Yining Li, Songyang Zhang, Cailian Chen, Kai Chen, Xinyi Le</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-11 17:50:09</h6>
<p class='card-text'>Significant focus has been placed on integrating large language models (LLMs)
with various tools in developing general-purpose agents. This poses a challenge
to LLMs' tool-use capabilities. However, there are evident gaps between
existing tool-use evaluations and real-world scenarios. Current evaluations
often use AI-generated queries, single-step tasks, dummy tools, and text-only
interactions, failing to reveal the agents' real-world problem-solving
abilities effectively. To address this, we propose GTA, a benchmark for General
Tool Agents, featuring three main aspects: (i) Real user queries: human-written
queries with simple real-world objectives but implicit tool-use, requiring the
LLM to reason the suitable tools and plan the solution steps. (ii) Real
deployed tools: an evaluation platform equipped with tools across perception,
operation, logic, and creativity categories to evaluate the agents' actual task
execution performance. (iii) Real multimodal inputs: authentic image files,
such as spatial scenes, web page screenshots, tables, code snippets, and
printed/handwritten materials, used as the query contexts to align with
real-world scenarios closely. We design 229 real-world tasks and executable
tool chains to evaluate mainstream LLMs. Our findings show that real-world user
queries are challenging for existing LLMs, with GPT-4 completing less than 50%
of the tasks and most LLMs achieving below 25%. This evaluation reveals the
bottlenecks in the tool-use capabilities of current LLMs in real-world
scenarios, which provides future direction for advancing general-purpose tool
agents. The code and dataset are available at
https://github.com/open-compass/GTA.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.08550v1' target='_blank'>Incorporating Large Language Models into Production Systems for Enhanced
  Task Automation and Flexibility</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuchen Xia, Jize Zhang, Nasser Jazdi, Michael Weyrich</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-11 14:34:43</h6>
<p class='card-text'>This paper introduces a novel approach to integrating large language model
(LLM) agents into automated production systems, aimed at enhancing task
automation and flexibility. We organize production operations within a
hierarchical framework based on the automation pyramid. Atomic operation
functionalities are modeled as microservices, which are executed through
interface invocation within a dedicated digital twin system. This allows for a
scalable and flexible foundation for orchestrating production processes. In
this digital twin system, low-level, hardware-specific data is semantically
enriched and made interpretable for LLMs for production planning and control
tasks. Large language model agents are systematically prompted to interpret
these production-specific data and knowledge. Upon receiving a user request or
identifying a triggering event, the LLM agents generate a process plan. This
plan is then decomposed into a series of atomic operations, executed as
microservices within the real-world automation system. We implement this
overall approach on an automated modular production facility at our laboratory,
demonstrating how the LLMs can handle production planning and control tasks
through a concrete case study. This results in an intuitive production facility
with higher levels of task automation and flexibility. Finally, we reveal the
several limitations in realizing the full potential of the large language
models in autonomous systems and point out promising benefits. Demos of this
series of ongoing research series can be accessed at:
https://github.com/YuchenXia/GPT4IndustrialAutomation</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.08474v1' target='_blank'>DIDUP: Dynamic Iterative Development for UI Prototyping</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jenny Ma, Karthik Sreedhar, Vivian Liu, Sitong Wang, Pedro Alejandro Perez, Lydia B. Chilton</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-11 13:10:11</h6>
<p class='card-text'>Large language models (LLMs) are remarkably good at writing code. A
particularly valuable case of human-LLM collaboration is code-based UI
prototyping, a method for creating interactive prototypes that allows users to
view and fully engage with a user interface. We conduct a formative study of
GPT Pilot, a leading LLM-generated code-prototyping system, and find that its
inflexibility towards change once development has started leads to weaknesses
in failure prevention and dynamic planning; it closely resembles the linear
workflow of the waterfall model. We introduce DIDUP, a system for code-based UI
prototyping that follows an iterative spiral model, which takes changes and
iterations that come up during the development process into account. We propose
three novel mechanisms for LLM-generated code-prototyping systems: (1) adaptive
planning, where plans should be dynamic and reflect changes during
implementation, (2) code injection, where the system should write a minimal
amount of code and inject it instead of rewriting code so users have a better
mental model of the code evolution, and (3) lightweight state management, a
simplified version of source control so users can quickly revert to different
working states. Together, this enables users to rapidly develop and iterate on
prototypes.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.07778v1' target='_blank'>WorldAPIs: The World Is Worth How Many APIs? A Thought Experiment</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiefu Ou, Arda Uzunoglu, Benjamin Van Durme, Daniel Khashabi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-10 15:52:44</h6>
<p class='card-text'>AI systems make decisions in physical environments through primitive actions
or affordances that are accessed via API calls. While deploying AI agents in
the real world involves numerous high-level actions, existing embodied
simulators offer a limited set of domain-salient APIs. This naturally brings up
the questions: how many primitive actions (APIs) are needed for a versatile
embodied agent, and what should they look like? We explore this via a thought
experiment: assuming that wikiHow tutorials cover a wide variety of
human-written tasks, what is the space of APIs needed to cover these
instructions? We propose a framework to iteratively induce new APIs by
grounding wikiHow instruction to situated agent policies. Inspired by recent
successes in large language models (LLMs) for embodied planning, we propose a
few-shot prompting to steer GPT-4 to generate Pythonic programs as agent
policies and bootstrap a universe of APIs by 1) reusing a seed set of APIs; and
then 2) fabricate new API calls when necessary. The focus of this thought
experiment is on defining these APIs rather than their executability. We apply
the proposed pipeline on instructions from wikiHow tutorials. On a small
fraction (0.5%) of tutorials, we induce an action space of 300+ APIs necessary
for capturing the rich variety of tasks in the physical world. A detailed
automatic and human analysis of the induction output reveals that the proposed
pipeline enables effective reuse and creation of APIs. Moreover, a manual
review revealed that existing simulators support only a small subset of the
induced APIs (9 of the top 50 frequent APIs), motivating the development of
action-rich embodied environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.07086v2' target='_blank'>Hypothetical Minds: Scaffolding Theory of Mind for Multi-Agent Tasks
  with Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Logan Cross, Violet Xiang, Agam Bhatia, Daniel LK Yamins, Nick Haber</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-09 17:57:15</h6>
<p class='card-text'>Multi-agent reinforcement learning (MARL) methods struggle with the
non-stationarity of multi-agent systems and fail to adaptively learn online
when tested with novel agents. Here, we leverage large language models (LLMs)
to create an autonomous agent that can handle these challenges. Our agent,
Hypothetical Minds, consists of a cognitively-inspired architecture, featuring
modular components for perception, memory, and hierarchical planning over two
levels of abstraction. We introduce the Theory of Mind module that scaffolds
the high-level planning process by generating hypotheses about other agents'
strategies in natural language. It then evaluates and iteratively refines these
hypotheses by reinforcing hypotheses that make correct predictions about the
other agents' behavior. Hypothetical Minds significantly improves performance
over previous LLM-agent and RL baselines on a range of competitive, mixed
motive, and collaborative domains in the Melting Pot benchmark, including both
dyadic and population-based environments. Additionally, comparisons against
LLM-agent baselines and ablations reveal the importance of hypothesis
evaluation and refinement for succeeding on complex scenarios.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.06813v4' target='_blank'>Richelieu: Self-Evolving LLM-Based Agents for AI Diplomacy</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhenyu Guan, Xiangyu Kong, Fangwei Zhong, Yizhou Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-09 12:37:54</h6>
<p class='card-text'>Diplomacy is one of the most sophisticated activities in human society,
involving complex interactions among multiple parties that require skills in
social reasoning, negotiation, and long-term strategic planning. Previous AI
agents have demonstrated their ability to handle multi-step games and large
action spaces in multi-agent tasks. However, diplomacy involves a staggering
magnitude of decision spaces, especially considering the negotiation stage
required. While recent agents based on large language models (LLMs) have shown
potential in various applications, they still struggle with extended planning
periods in complex multi-agent settings. Leveraging recent technologies for
LLM-based agents, we aim to explore AI's potential to create a human-like agent
capable of executing comprehensive multi-agent missions by integrating three
fundamental capabilities: 1) strategic planning with memory and reflection; 2)
goal-oriented negotiation with social reasoning; and 3) augmenting memory
through self-play games for self-evolution without human in the loop.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.06590v1' target='_blank'>Revolutionizing Battery Disassembly: The Design and Implementation of a
  Battery Disassembly Autonomous Mobile Manipulator Robot(BEAM-1)</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yanlong Peng, Zhigang Wang, Yisheng Zhang, Shengmin Zhang, Nan Cai, Fan Wu, Ming Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-09 06:44:20</h6>
<p class='card-text'>The efficient disassembly of end-of-life electric vehicle batteries(EOL-EVBs)
is crucial for green manufacturing and sustainable development. The current
pre-programmed disassembly conducted by the Autonomous Mobile Manipulator
Robot(AMMR) struggles to meet the disassembly requirements in dynamic
environments, complex scenarios, and unstructured processes. In this paper, we
propose a Battery Disassembly AMMR(BEAM-1) system based on NeuralSymbolic AI.
It detects the environmental state by leveraging a combination of multi-sensors
and neural predicates and then translates this information into a
quasi-symbolic space. In real-time, it identifies the optimal sequence of
action primitives through LLM-heuristic tree search, ensuring high-precision
execution of these primitives. Additionally, it employs positional speculative
sampling using intuitive networks and achieves the disassembly of various bolt
types with a meticulously designed end-effector. Importantly, BEAM-1 is a
continuously learning embodied intelligence system capable of subjective
reasoning like a human, and possessing intuition. A large number of real scene
experiments have proved that it can autonomously perceive, decide, and execute
to complete the continuous disassembly of bolts in multiple, multi-category,
and complex situations, with a success rate of 98.78%. This research attempts
to use NeuroSymbolic AI to give robots real autonomous reasoning, planning, and
learning capabilities. BEAM-1 realizes the revolution of battery disassembly.
Its framework can be easily ported to any robotic system to realize different
application scenarios, which provides a ground-breaking idea for the design and
implementation of future embodied intelligent robotic systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.06486v2' target='_blank'>Optimal Decision Making Through Scenario Simulations Using Large
  Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sumedh Rasal, E. J. Hauer</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-09 01:23:09</h6>
<p class='card-text'>The rapid evolution of Large Language Models (LLMs) has markedly expanded
their application across diverse domains, transforming how complex problems are
approached and solved. Initially conceived to predict subsequent words in
texts, these models have transcended their original design to comprehend and
respond to the underlying contexts of queries. Today, LLMs routinely perform
tasks that once seemed formidable, such as writing essays, poems, stories, and
even developing software code. As their capabilities continue to grow, so too
do the expectations of their performance in even more sophisticated domains.
  Despite these advancements, LLMs still encounter significant challenges,
particularly in scenarios requiring intricate decision-making, such as planning
trips or choosing among multiple viable options. These tasks often demand a
nuanced understanding of various outcomes and the ability to predict the
consequences of different choices, which are currently outside the typical
operational scope of LLMs.
  This paper proposes an innovative approach to bridge this capability gap. By
enabling LLMs to request multiple potential options and their respective
parameters from users, our system introduces a dynamic framework that
integrates an optimization function within the decision-making process. This
function is designed to analyze the provided options, simulate potential
outcomes, and determine the most advantageous solution based on a set of
predefined criteria. By harnessing this methodology, LLMs can offer tailored,
optimal solutions to complex, multi-variable problems, significantly enhancing
their utility and effectiveness in real-world applications. This approach not
only expands the functional envelope of LLMs but also paves the way for more
autonomous and intelligent systems capable of supporting sophisticated
decision-making tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.06188v1' target='_blank'>CrowdMoGen: Zero-Shot Text-Driven Collective Motion Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xinying Guo, Mingyuan Zhang, Haozhe Xie, Chenyang Gu, Ziwei Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-08 17:59:36</h6>
<p class='card-text'>Crowd Motion Generation is essential in entertainment industries such as
animation and games as well as in strategic fields like urban simulation and
planning. This new task requires an intricate integration of control and
generation to realistically synthesize crowd dynamics under specific spatial
and semantic constraints, whose challenges are yet to be fully explored. On the
one hand, existing human motion generation models typically focus on individual
behaviors, neglecting the complexities of collective behaviors. On the other
hand, recent methods for multi-person motion generation depend heavily on
pre-defined scenarios and are limited to a fixed, small number of inter-person
interactions, thus hampering their practicality. To overcome these challenges,
we introduce CrowdMoGen, a zero-shot text-driven framework that harnesses the
power of Large Language Model (LLM) to incorporate the collective intelligence
into the motion generation framework as guidance, thereby enabling
generalizable planning and generation of crowd motions without paired training
data. Our framework consists of two key components: 1) Crowd Scene Planner that
learns to coordinate motions and dynamics according to specific scene contexts
or introduced perturbations, and 2) Collective Motion Generator that
efficiently synthesizes the required collective motions based on the holistic
plans. Extensive quantitative and qualitative experiments have validated the
effectiveness of our framework, which not only fills a critical gap by
providing scalable and generalizable solutions for Crowd Motion Generation task
but also achieves high levels of realism and flexibility.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.05890v2' target='_blank'>Affordances-Oriented Planning using Foundation Models for Continuous
  Vision-Language Navigation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiaqi Chen, Bingqian Lin, Xinmin Liu, Lin Ma, Xiaodan Liang, Kwan-Yee K. Wong</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-08 12:52:46</h6>
<p class='card-text'>LLM-based agents have demonstrated impressive zero-shot performance in
vision-language navigation (VLN) task. However, existing LLM-based methods
often focus only on solving high-level task planning by selecting nodes in
predefined navigation graphs for movements, overlooking low-level control in
navigation scenarios. To bridge this gap, we propose AO-Planner, a novel
Affordances-Oriented Planner for continuous VLN task. Our AO-Planner integrates
various foundation models to achieve affordances-oriented low-level motion
planning and high-level decision-making, both performed in a zero-shot setting.
Specifically, we employ a Visual Affordances Prompting (VAP) approach, where
the visible ground is segmented by SAM to provide navigational affordances,
based on which the LLM selects potential candidate waypoints and plans
low-level paths towards selected waypoints. We further propose a high-level
PathAgent which marks planned paths into the image input and reasons the most
probable path by comprehending all environmental information. Finally, we
convert the selected path into 3D coordinates using camera intrinsic parameters
and depth information, avoiding challenging 3D predictions for LLMs.
Experiments on the challenging R2R-CE and RxR-CE datasets show that AO-Planner
achieves state-of-the-art zero-shot performance (8.8% improvement on SPL). Our
method can also serve as a data annotator to obtain pseudo-labels, distilling
its waypoint prediction ability into a learning-based predictor. This new
predictor does not require any waypoint data from the simulator and achieves
47% SR competing with supervised methods. We establish an effective connection
between LLM and 3D world, presenting novel prospects for employing foundation
models in low-level motion control.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.05600v2' target='_blank'>GenArtist: Multimodal LLM as an Agent for Unified Image Generation and
  Editing</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhenyu Wang, Aoxue Li, Zhenguo Li, Xihui Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-08 04:30:53</h6>
<p class='card-text'>Despite the success achieved by existing image generation and editing
methods, current models still struggle with complex problems including
intricate text prompts, and the absence of verification and self-correction
mechanisms makes the generated images unreliable. Meanwhile, a single model
tends to specialize in particular tasks and possess the corresponding
capabilities, making it inadequate for fulfilling all user requirements. We
propose GenArtist, a unified image generation and editing system, coordinated
by a multimodal large language model (MLLM) agent. We integrate a comprehensive
range of existing models into the tool library and utilize the agent for tool
selection and execution. For a complex problem, the MLLM agent decomposes it
into simpler sub-problems and constructs a tree structure to systematically
plan the procedure of generation, editing, and self-correction with
step-by-step verification. By automatically generating missing position-related
inputs and incorporating position information, the appropriate tool can be
effectively employed to address each sub-problem. Experiments demonstrate that
GenArtist can perform various generation and editing tasks, achieving
state-of-the-art performance and surpassing existing models such as SDXL and
DALL-E 3, as can be seen in Fig. 1. Project page is
https://zhenyuw16.github.io/GenArtist_page.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.05291v2' target='_blank'>WorkArena++: Towards Compositional Planning and Reasoning-based Common
  Knowledge Work Tasks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Léo Boisvert, Megh Thakkar, Maxime Gasse, Massimo Caccia, Thibault Le Sellier De Chezelles, Quentin Cappart, Nicolas Chapados, Alexandre Lacoste, Alexandre Drouin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-07 07:15:49</h6>
<p class='card-text'>The ability of large language models (LLMs) to mimic human-like intelligence
has led to a surge in LLM-based autonomous agents. Though recent LLMs seem
capable of planning and reasoning given user instructions, their effectiveness
in applying these capabilities for autonomous task solving remains
underexplored. This is especially true in enterprise settings, where automated
agents hold the promise of a high impact. To fill this gap, we propose
WorkArena++, a novel benchmark consisting of 682 tasks corresponding to
realistic workflows routinely performed by knowledge workers. WorkArena++ is
designed to evaluate the planning, problem-solving, logical/arithmetic
reasoning, retrieval, and contextual understanding abilities of web agents. Our
empirical studies across state-of-the-art LLMs and vision-language models
(VLMs), as well as human workers, reveal several challenges for such models to
serve as useful assistants in the workplace. In addition to the benchmark, we
provide a mechanism to effortlessly generate thousands of ground-truth
observation/action traces, which can be used for fine-tuning existing models.
Overall, we expect this work to serve as a useful resource to help the
community progress toward capable autonomous agents. The benchmark can be found
at https://github.com/ServiceNow/WorkArena.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.04899v1' target='_blank'>Algorithmic Language Models with Neurally Compiled Libraries</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lucas Saldyt, Subbarao Kambhampati</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-06 00:27:05</h6>
<p class='card-text'>Important tasks such as reasoning and planning are fundamentally algorithmic,
meaning that solving them robustly requires acquiring true reasoning or
planning algorithms, rather than shortcuts. Large Language Models lack true
algorithmic ability primarily because of the limitations of neural network
optimization algorithms, their optimization data and optimization objective,
but also due to architectural inexpressivity. To solve this, our paper proposes
augmenting LLMs with a library of fundamental operations and sophisticated
differentiable programs, so that common algorithms do not need to be learned
from scratch. We add memory, registers, basic operations, and adaptive
recurrence to a transformer architecture built on LLaMA3. Then, we define a
method for directly compiling algorithms into a differentiable starting
library, which is used natively and propagates gradients for optimization. In
this preliminary study, we explore the feasability of augmenting LLaMA3 with a
differentiable computer, for instance by fine-tuning small transformers on
simple algorithmic tasks with variable computational depth.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.04694v1' target='_blank'>Me, Myself, and AI: The Situational Awareness Dataset (SAD) for LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Rudolf Laine, Bilal Chughtai, Jan Betley, Kaivalya Hariharan, Jeremy Scheurer, Mikita Balesni, Marius Hobbhahn, Alexander Meinke, Owain Evans</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-05 17:57:02</h6>
<p class='card-text'>AI assistants such as ChatGPT are trained to respond to users by saying, "I
am a large language model". This raises questions. Do such models know that
they are LLMs and reliably act on this knowledge? Are they aware of their
current circumstances, such as being deployed to the public? We refer to a
model's knowledge of itself and its circumstances as situational awareness. To
quantify situational awareness in LLMs, we introduce a range of behavioral
tests, based on question answering and instruction following. These tests form
the $\textbf{Situational Awareness Dataset (SAD)}$, a benchmark comprising 7
task categories and over 13,000 questions. The benchmark tests numerous
abilities, including the capacity of LLMs to (i) recognize their own generated
text, (ii) predict their own behavior, (iii) determine whether a prompt is from
internal evaluation or real-world deployment, and (iv) follow instructions that
depend on self-knowledge.
  We evaluate 16 LLMs on SAD, including both base (pretrained) and chat models.
While all models perform better than chance, even the highest-scoring model
(Claude 3 Opus) is far from a human baseline on certain tasks. We also observe
that performance on SAD is only partially predicted by metrics of general
knowledge (e.g. MMLU). Chat models, which are finetuned to serve as AI
assistants, outperform their corresponding base models on SAD but not on
general knowledge tasks. The purpose of SAD is to facilitate scientific
understanding of situational awareness in LLMs by breaking it down into
quantitative abilities. Situational awareness is important because it enhances
a model's capacity for autonomous planning and action. While this has potential
benefits for automation, it also introduces novel risks related to AI safety
and control. Code and latest results available at
https://situational-awareness-dataset.org .</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.04363v2' target='_blank'>AriGraph: Learning Knowledge Graph World Models with Episodic Memory for
  LLM Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Petr Anokhin, Nikita Semenov, Artyom Sorokin, Dmitry Evseev, Mikhail Burtsev, Evgeny Burnaev</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-05 09:06:47</h6>
<p class='card-text'>Advancements in the capabilities of Large Language Models (LLMs) have created
a promising foundation for developing autonomous agents. With the right tools,
these agents could learn to solve tasks in new environments by accumulating and
updating their knowledge. Current LLM-based agents process past experiences
using a full history of observations, summarization, retrieval augmentation.
However, these unstructured memory representations do not facilitate the
reasoning and planning essential for complex decision-making. In our study, we
introduce AriGraph, a novel method wherein the agent constructs and updates a
memory graph that integrates semantic and episodic memories while exploring the
environment. We demonstrate that our Ariadne LLM agent, consisting of the
proposed memory architecture augmented with planning and decision-making,
effectively handles complex tasks within interactive text game environments
difficult even for human players. Results show that our approach markedly
outperforms other established memory methods and strong RL baselines in a range
of problems of varying complexity. Additionally, AriGraph demonstrates
competitive performance compared to dedicated knowledge graph-based methods in
static multi-hop question-answering.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.03913v1' target='_blank'>MobileExperts: A Dynamic Tool-Enabled Agent Team in Mobile Devices</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiayi Zhang, Chuang Zhao, Yihan Zhao, Zhaoyang Yu, Ming He, Jianping Fan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-04 13:12:19</h6>
<p class='card-text'>The attainment of autonomous operations in mobile computing devices has
consistently been a goal of human pursuit. With the development of Large
Language Models (LLMs) and Visual Language Models (VLMs), this aspiration is
progressively turning into reality. While contemporary research has explored
automation of simple tasks on mobile devices via VLMs, there remains
significant room for improvement in handling complex tasks and reducing high
reasoning costs. In this paper, we introduce MobileExperts, which for the first
time introduces tool formulation and multi-agent collaboration to address the
aforementioned challenges. More specifically, MobileExperts dynamically
assembles teams based on the alignment of agent portraits with the human
requirements. Following this, each agent embarks on an independent exploration
phase, formulating its tools to evolve into an expert. Lastly, we develop a
dual-layer planning mechanism to establish coordinate collaboration among
experts. To validate our effectiveness, we design a new benchmark of
hierarchical intelligence levels, offering insights into algorithm's capability
to address tasks across a spectrum of complexity. Experimental results
demonstrate that MobileExperts performs better on all intelligence levels and
achieves ~ 22% reduction in reasoning costs, thus verifying the superiority of
our design.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.03884v3' target='_blank'>ChatSOP: An SOP-Guided MCTS Planning Framework for Controllable LLM
  Dialogue Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhigen Li, Jianxiang Peng, Yanmeng Wang, Yong Cao, Tianhao Shen, Minghui Zhang, Linxi Su, Shang Wu, Yihang Wu, Yuqian Wang, Ye Wang, Wei Hu, Jianfeng Li, Shaojun Wang, Jing Xiao, Deyi Xiong</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-04 12:23:02</h6>
<p class='card-text'>Dialogue agents powered by Large Language Models (LLMs) show superior
performance in various tasks. Despite the better user understanding and
human-like responses, their lack of controllability remains a key challenge,
often leading to unfocused conversations or task failure. To address this, we
introduce Standard Operating Procedure (SOP) to regulate dialogue flow.
Specifically, we propose ChatSOP, a novel SOP-guided Monte Carlo Tree Search
(MCTS) planning framework designed to enhance the controllability of LLM-driven
dialogue agents. To enable this, we curate a dataset comprising SOP-annotated
multi-scenario dialogues, generated using a semi-automated role-playing system
with GPT-4o and validated through strict manual quality control. Additionally,
we propose a novel method that integrates Chain of Thought reasoning with
supervised fine-tuning for SOP prediction and utilizes SOP-guided Monte Carlo
Tree Search for optimal action planning during dialogues. Experimental results
demonstrate the effectiveness of our method, such as achieving a 27.95%
improvement in action accuracy compared to baseline models based on GPT-3.5 and
also showing notable gains for open-source models. Dataset and codes are
publicly available.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.03624v2' target='_blank'>Question-Analysis Prompting Improves LLM Performance in Reasoning Tasks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Dharunish Yugeswardeenoo, Kevin Zhu, Sean O'Brien</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-04 04:19:50</h6>
<p class='card-text'>Although LLMs have the potential to transform many fields, they still
underperform humans in reasoning tasks. Existing methods induce the model to
produce step-by-step calculations, but this research explores the question:
Does making the LLM analyze the question improve its performance? We propose a
novel prompting strategy called Question Analysis Prompting (QAP), in which the
model is prompted to explain the question in $n$ words before solving. The
value of $n$ influences the length of response generated by the model. QAP is
evaluated on GPT 3.5 Turbo and GPT 4 Turbo on arithmetic datasets GSM8K, AQuA,
and SAT and commonsense dataset StrategyQA. QAP is compared with other
state-of-the-art prompts including Chain-of-Thought (CoT), Plan and Solve
Prompting (PS+) and Take A Deep Breath (TADB). QAP outperforms all
state-of-the-art prompts on AQuA and SAT datasets on both GPT3.5 and GPT4. QAP
consistently ranks among the top-2 prompts on 75\% of the tests. A key factor
of QAP performance can be attributed to response length, where detailed
responses are beneficial when answering harder questions, but can negatively
affect easy questions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.03453v1' target='_blank'>On Large Language Models in National Security Applications</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:William N. Caballero, Phillip R. Jenkins</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-03 18:53:22</h6>
<p class='card-text'>The overwhelming success of GPT-4 in early 2023 highlighted the
transformative potential of large language models (LLMs) across various
sectors, including national security. This article explores the implications of
LLM integration within national security contexts, analyzing their potential to
revolutionize information processing, decision-making, and operational
efficiency. Whereas LLMs offer substantial benefits, such as automating tasks
and enhancing data analysis, they also pose significant risks, including
hallucinations, data privacy concerns, and vulnerability to adversarial
attacks. Through their coupling with decision-theoretic principles and Bayesian
reasoning, LLMs can significantly improve decision-making processes within
national security organizations. Namely, LLMs can facilitate the transition
from data to actionable decisions, enabling decision-makers to quickly receive
and distill available information with less manpower. Current applications
within the US Department of Defense and beyond are explored, e.g., the USAF's
use of LLMs for wargaming and automatic summarization, that illustrate their
potential to streamline operations and support decision-making. However, these
applications necessitate rigorous safeguards to ensure accuracy and
reliability. The broader implications of LLM integration extend to strategic
planning, international relations, and the broader geopolitical landscape, with
adversarial nations leveraging LLMs for disinformation and cyber operations,
emphasizing the need for robust countermeasures. Despite exhibiting "sparks" of
artificial general intelligence, LLMs are best suited for supporting roles
rather than leading strategic decisions. Their use in training and wargaming
can provide valuable insights and personalized learning experiences for
military personnel, thereby improving operational readiness.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.02651v2' target='_blank'>Improving Steering and Verification in AI-Assisted Data Analysis with
  Interactive Task Decomposition</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Majeed Kazemitabaar, Jack Williams, Ian Drosos, Tovi Grossman, Austin Henley, Carina Negreanu, Advait Sarkar</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-02 20:33:50</h6>
<p class='card-text'>LLM-powered tools like ChatGPT Data Analysis, have the potential to help
users tackle the challenging task of data analysis programming, which requires
expertise in data processing, programming, and statistics. However, our
formative study (n=15) uncovered serious challenges in verifying AI-generated
results and steering the AI (i.e., guiding the AI system to produce the desired
output). We developed two contrasting approaches to address these challenges.
The first (Stepwise) decomposes the problem into step-by-step subgoals with
pairs of editable assumptions and code until task completion, while the second
(Phasewise) decomposes the entire problem into three editable, logical phases:
structured input/output assumptions, execution plan, and code. A controlled,
within-subjects experiment (n=18) compared these systems against a
conversational baseline. Users reported significantly greater control with the
Stepwise and Phasewise systems, and found intervention, correction, and
verification easier, compared to the baseline. The results suggest design
guidelines and trade-offs for AI-assisted data analysis tools.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.02220v2' target='_blank'>Embodied AI in Mobile Robots: Coverage Path Planning with Large Language
  Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xiangrui Kong, Wenxiao Zhang, Jin Hong, Thomas Braunl</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-02 12:38:46</h6>
<p class='card-text'>In recent years, Large Language Models (LLMs) have demonstrated remarkable
capabilities in understanding and solving mathematical problems, leading to
advancements in various fields. We propose an LLM-embodied path planning
framework for mobile agents, focusing on solving high-level coverage path
planning issues and low-level control. Our proposed multi-layer architecture
uses prompted LLMs in the path planning phase and integrates them with the
mobile agents' low-level actuators. To evaluate the performance of various
LLMs, we propose a coverage-weighted path planning metric to assess the
performance of the embodied models. Our experiments show that the proposed
framework improves LLMs' spatial inference abilities. We demonstrate that the
proposed multi-layer framework significantly enhances the efficiency and
accuracy of these tasks by leveraging the natural language understanding and
generative capabilities of LLMs. Our experiments show that this framework can
improve LLMs' 2D plane reasoning abilities and complete coverage path planning
tasks. We also tested three LLM kernels: gpt-4o, gemini-1.5-flash, and
claude-3.5-sonnet. The experimental results show that claude-3.5 can complete
the coverage planning task in different scenarios, and its indicators are
better than those of the other models.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.01892v2' target='_blank'>GRASP: A Grid-Based Benchmark for Evaluating Commonsense Spatial
  Reasoning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhisheng Tang, Mayank Kejriwal</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-02 02:27:46</h6>
<p class='card-text'>Spatial reasoning, an important faculty of human cognition with many
practical applications, is one of the core commonsense skills that is not
purely language-based and, for satisfying (as opposed to optimal) solutions,
requires some minimum degree of planning. Existing benchmarks of Commonsense
Spatial Reasoning (CSR) tend to evaluate how Large Language Models (LLMs)
interpret text-based spatial $\textit{descriptions}$ rather than directly
evaluate a plan produced by the LLM in response to a $\textit{specific}$
spatial reasoning problem. In this paper, we construct a large-scale benchmark
called GRASP, which consists of 16,000 grid-based environments where the agent
is tasked with an energy collection problem. These environments include 100
grid instances instantiated using each of the 160 different grid settings,
involving five different energy distributions, two modes of agent starting
position, and two distinct obstacle configurations, as well as three kinds of
agent constraints. Using GRASP, we compare classic baseline approaches, such as
random walk and greedy search methods, with advanced LLMs like GPT-3.5-Turbo,
GPT-4o, and GPT-o1-mini. The experimental results indicate that even these
advanced LLMs struggle to consistently achieve satisfactory solutions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.01489v2' target='_blank'>Agentless: Demystifying LLM-based Software Engineering Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chunqiu Steven Xia, Yinlin Deng, Soren Dunn, Lingming Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-01 17:24:45</h6>
<p class='card-text'>Recent advancements in large language models (LLMs) have significantly
advanced the automation of software development tasks, including code
synthesis, program repair, and test generation. More recently, researchers and
industry practitioners have developed various autonomous LLM agents to perform
end-to-end software development tasks. These agents are equipped with the
ability to use tools, run commands, observe feedback from the environment, and
plan for future actions. However, the complexity of these agent-based
approaches, together with the limited abilities of current LLMs, raises the
following question: Do we really have to employ complex autonomous software
agents? To attempt to answer this question, we build Agentless -- an agentless
approach to automatically solve software development problems. Compared to the
verbose and complex setup of agent-based approaches, Agentless employs a
simplistic three-phase process of localization, repair, and patch validation,
without letting the LLM decide future actions or operate with complex tools.
Our results on the popular SWE-bench Lite benchmark show that surprisingly the
simplistic Agentless is able to achieve both the highest performance (32.00%,
96 correct fixes) and low cost ($0.70) compared with all existing open-source
software agents! Furthermore, we manually classified the problems in SWE-bench
Lite and found problems with exact ground truth patch or
insufficient/misleading issue descriptions. As such, we construct SWE-bench
Lite-S by excluding such problematic issues to perform more rigorous evaluation
and comparison. Our work highlights the current overlooked potential of a
simple, interpretable technique in autonomous software development. We hope
Agentless will help reset the baseline, starting point, and horizon for
autonomous software agents, and inspire future work along this crucial
direction.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.00993v1' target='_blank'>Mobile-Bench: An Evaluation Benchmark for LLM-based Mobile Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shihan Deng, Weikai Xu, Hongda Sun, Wei Liu, Tao Tan, Jianfeng Liu, Ang Li, Jian Luan, Bin Wang, Rui Yan, Shuo Shang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-01 06:10:01</h6>
<p class='card-text'>With the remarkable advancements of large language models (LLMs), LLM-based
agents have become a research hotspot in human-computer interaction. However,
there is a scarcity of benchmarks available for LLM-based mobile agents.
Benchmarking these agents generally faces three main challenges: (1) The
inefficiency of UI-only operations imposes limitations to task evaluation. (2)
Specific instructions within a singular application lack adequacy for assessing
the multi-dimensional reasoning and decision-making capacities of LLM mobile
agents. (3) Current evaluation metrics are insufficient to accurately assess
the process of sequential actions. To this end, we propose Mobile-Bench, a
novel benchmark for evaluating the capabilities of LLM-based mobile agents.
First, we expand conventional UI operations by incorporating 103 collected APIs
to accelerate the efficiency of task completion. Subsequently, we collect
evaluation data by combining real user queries with augmentation from LLMs. To
better evaluate different levels of planning capabilities for mobile agents,
our data is categorized into three distinct groups: SAST, SAMT, and MAMT,
reflecting varying levels of task complexity. Mobile-Bench comprises 832 data
entries, with more than 200 tasks specifically designed to evaluate multi-APP
collaboration scenarios. Furthermore, we introduce a more accurate evaluation
metric, named CheckPoint, to assess whether LLM-based mobile agents reach
essential points during their planning and reasoning steps.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.00959v1' target='_blank'>Tokenize the World into Object-level Knowledge to Address Long-tail
  Events in Autonomous Driving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ran Tian, Boyi Li, Xinshuo Weng, Yuxiao Chen, Edward Schmerling, Yue Wang, Boris Ivanovic, Marco Pavone</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-07-01 04:34:50</h6>
<p class='card-text'>The autonomous driving industry is increasingly adopting end-to-end learning
from sensory inputs to minimize human biases in system design. Traditional
end-to-end driving models, however, suffer from long-tail events due to rare or
unseen inputs within their training distributions. To address this, we propose
TOKEN, a novel Multi-Modal Large Language Model (MM-LLM) that tokenizes the
world into object-level knowledge, enabling better utilization of LLM's
reasoning capabilities to enhance autonomous vehicle planning in long-tail
scenarios. TOKEN effectively alleviates data scarcity and inefficient
tokenization by leveraging a traditional end-to-end driving model to produce
condensed and semantically enriched representations of the scene, which are
optimized for LLM planning compatibility through deliberate representation and
reasoning alignment training stages. Our results demonstrate that TOKEN excels
in grounding, reasoning, and planning capabilities, outperforming existing
frameworks with a 27% reduction in trajectory L2 error and a 39% decrease in
collision rates in long-tail scenarios. Additionally, our work highlights the
importance of representation alignment and structured reasoning in sparking the
common-sense reasoning capabilities of MM-LLMs for effective planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.00632v1' target='_blank'>CAMON: Cooperative Agents for Multi-Object Navigation with LLM-based
  Conversations</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Pengying Wu, Yao Mu, Kangjie Zhou, Ji Ma, Junting Chen, Chang Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-30 09:14:33</h6>
<p class='card-text'>Visual navigation tasks are critical for household service robots. As these
tasks become increasingly complex, effective communication and collaboration
among multiple robots become imperative to ensure successful completion. In
recent years, large language models (LLMs) have exhibited remarkable
comprehension and planning abilities in the context of embodied agents.
However, their application in household scenarios, specifically in the use of
multiple agents collaborating to complete complex navigation tasks through
communication, remains unexplored. Therefore, this paper proposes a framework
for decentralized multi-agent navigation, leveraging LLM-enabled communication
and collaboration. By designing the communication-triggered dynamic leadership
organization structure, we achieve faster team consensus with fewer
communication instances, leading to better navigation effectiveness and
collaborative exploration efficiency. With the proposed novel communication
scheme, our framework promises to be conflict-free and robust in multi-object
navigation tasks, even when there is a surge in team size.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.00361v1' target='_blank'>From RAG to RICHES: Retrieval Interlaced with Sequence Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Palak Jain, Livio Baldini Soares, Tom Kwiatkowski</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-29 08:16:58</h6>
<p class='card-text'>We present RICHES, a novel approach that interleaves retrieval with sequence
generation tasks. RICHES offers an alternative to conventional RAG systems by
eliminating the need for separate retriever and generator. It retrieves
documents by directly decoding their contents, constrained on the corpus.
Unifying retrieval with generation allows us to adapt to diverse new tasks via
prompting alone. RICHES can work with any Instruction-tuned model, without
additional training. It provides attributed evidence, supports multi-hop
retrievals and interleaves thoughts to plan on what to retrieve next, all
within a single decoding pass of the LLM. We demonstrate the strong performance
of RICHES across ODQA tasks including attributed and multi-hop QA.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.20041v3' target='_blank'>BMW Agents -- A Framework For Task Automation Through Multi-Agent
  Collaboration</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Noel Crawford, Edward B. Duffy, Iman Evazzade, Torsten Foehr, Gregory Robbins, Debbrata Kumar Saha, Jiya Varma, Marcin Ziolkowski</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-28 16:39:20</h6>
<p class='card-text'>Autonomous agents driven by Large Language Models (LLMs) offer enormous
potential for automation. Early proof of this technology can be found in
various demonstrations of agents solving complex tasks, interacting with
external systems to augment their knowledge, and triggering actions. In
particular, workflows involving multiple agents solving complex tasks in a
collaborative fashion exemplify their capacity to operate in less strict and
less well-defined environments. Thus, a multi-agent approach has great
potential for serving as a backbone in many industrial applications, ranging
from complex knowledge retrieval systems to next generation robotic process
automation. Given the reasoning abilities within the current generation of
LLMs, complex processes require a multi-step approach that includes a plan of
well-defined and modular tasks. Depending on the level of complexity, these
tasks can be executed either by a single agent or a group of agents. In this
work, we focus on designing a flexible agent engineering framework with careful
attention to planning and execution, capable of handling complex use case
applications across various domains. The proposed framework provides
reliability in industrial applications and presents techniques to ensure a
scalable, flexible, and collaborative workflow for multiple autonomous agents
working together towards solving tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.20030v1' target='_blank'>LEMoE: Advanced Mixture of Experts Adaptor for Lifelong Model Editing of
  Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Renzhi Wang, Piji Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-28 16:17:41</h6>
<p class='card-text'>Large language models (LLMs) require continual knowledge updates to stay
abreast of the ever-changing world facts, prompting the formulation of lifelong
model editing task. While recent years have witnessed the development of
various techniques for single and batch editing, these methods either fail to
apply or perform sub-optimally when faced with lifelong editing. In this paper,
we introduce LEMoE, an advanced Mixture of Experts (MoE) adaptor for lifelong
model editing. We first analyze the factors influencing the effectiveness of
conventional MoE adaptor in lifelong editing, including catastrophic
forgetting, inconsistent routing and order sensitivity. Based on these
insights, we propose a tailored module insertion method to achieve lifelong
editing, incorporating a novel KV anchor routing to enhance routing consistency
between training and inference stage, along with a concise yet effective
clustering-based editing order planning. Experimental results demonstrate the
effectiveness of our method in lifelong editing, surpassing previous model
editing techniques while maintaining outstanding performance in batch editing
task. Our code will be available.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.20015v2' target='_blank'>ToolBeHonest: A Multi-level Hallucination Diagnostic Benchmark for
  Tool-Augmented Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuxiang Zhang, Jing Chen, Junjie Wang, Yaxin Liu, Cheng Yang, Chufan Shi, Xinyu Zhu, Zihao Lin, Hanwen Wan, Yujiu Yang, Tetsuya Sakai, Tian Feng, Hayato Yamana</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-28 16:03:30</h6>
<p class='card-text'>Tool-augmented large language models (LLMs) are rapidly being integrated into
real-world applications. Due to the lack of benchmarks, the community has yet
to fully understand the hallucination issues within these models. To address
this challenge, we introduce a comprehensive diagnostic benchmark, ToolBH.
Specifically, we assess the LLM's hallucinations through two perspectives:
depth and breadth. In terms of depth, we propose a multi-level diagnostic
process, including (1) solvability detection, (2) solution planning, and (3)
missing-tool analysis. For breadth, we consider three scenarios based on the
characteristics of the toolset: missing necessary tools, potential tools, and
limited functionality tools. Furthermore, we developed seven tasks and
collected 700 evaluation samples through multiple rounds of manual annotation.
The results show the significant challenges presented by the ToolBH benchmark.
The current advanced models Gemini-1.5-Pro and GPT-4o only achieve total scores
of 45.3 and 37.0, respectively, on a scale of 100. In this benchmark, larger
model parameters do not guarantee better performance; the training data and
response strategies also play crucial roles in tool-enhanced LLM scenarios. Our
diagnostic analysis indicates that the primary reason for model errors lies in
assessing task solvability. Additionally, open-weight models suffer from
performance drops with verbose replies, whereas proprietary models excel with
longer reasoning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.00132v3' target='_blank'>ShortcutsBench: A Large-Scale Real-world Benchmark for API-based Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Haiyang Shen, Yue Li, Desong Meng, Dongqi Cai, Sheng Qi, Li Zhang, Mengwei Xu, Yun Ma</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-28 08:45:02</h6>
<p class='card-text'>Recent advancements in integrating large language models (LLMs) with
application programming interfaces (APIs) have gained significant interest in
both academia and industry. Recent work demonstrates that these API-based
agents exhibit relatively strong autonomy and planning capabilities. However,
their ability to handle multi-dimensional difficulty levels, diverse task
types, and real-world demands remains unknown. In this paper, we introduce
\textsc{ShortcutsBench}, a large-scale benchmark for the comprehensive
evaluation of API-based agents in solving real-world complex tasks.
\textsc{ShortcutsBench} includes a wealth of real APIs from Apple Inc., refined
user queries, human-annotated high-quality action sequences, detailed parameter
filling values, and parameters requesting necessary input from the system or
user. We revealed how existing benchmarks~/~datasets struggle to accommodate
the advanced reasoning capabilities of existing more intelligent LLMs.
Moreover, our extensive evaluation of agents built with $5$ leading open-source
(size $\geq$ 57B) and $5$ closed-source LLMs (e.g. Gemini-1.5-Pro and
GPT-4o-mini) with varying intelligence level reveals significant limitations of
existing API-based agents in the whole process of handling complex queries
related to API selection, parameter filling, and requesting necessary input
from the system and the user. These findings highlight the great challenges
that API-based agents face in effectively fulfilling real and complex user
queries. All datasets, code, experimental logs, and results are available at
\url{https://github.com/EachSheep/ShortcutsBench}.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.19693v1' target='_blank'>MMRo: Are Multimodal LLMs Eligible as the Brain for In-Home Robotics?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jinming Li, Yichen Zhu, Zhiyuan Xu, Jindong Gu, Minjie Zhu, Xin Liu, Ning Liu, Yaxin Peng, Feifei Feng, Jian Tang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-28 07:09:06</h6>
<p class='card-text'>It is fundamentally challenging for robots to serve as useful assistants in
human environments because this requires addressing a spectrum of sub-problems
across robotics, including perception, language understanding, reasoning, and
planning. The recent advancements in Multimodal Large Language Models (MLLMs)
have demonstrated their exceptional abilities in solving complex mathematical
problems, mastering commonsense and abstract reasoning. This has led to the
recent utilization of MLLMs as the brain in robotic systems, enabling these
models to conduct high-level planning prior to triggering low-level control
actions for task execution. However, it remains uncertain whether existing
MLLMs are reliable in serving the brain role of robots. In this study, we
introduce the first benchmark for evaluating Multimodal LLM for Robotic (MMRo)
benchmark, which tests the capability of MLLMs for robot applications.
Specifically, we identify four essential capabilities perception, task
planning, visual reasoning, and safety measurement that MLLMs must possess to
qualify as the robot's central processing unit. We have developed several
scenarios for each capability, resulting in a total of 14 metrics for
evaluation. We present experimental results for various MLLMs, including both
commercial and open-source models, to assess the performance of existing
systems. Our findings indicate that no single model excels in all areas,
suggesting that current MLLMs are not yet trustworthy enough to serve as the
cognitive core for robots. Our data can be found in
https://mm-robobench.github.io/.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.19228v1' target='_blank'>Tools Fail: Detecting Silent Errors in Faulty Tools</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jimin Sun, So Yeon Min, Yingshan Chang, Yonatan Bisk</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-27 14:52:34</h6>
<p class='card-text'>Tools have become a mainstay of LLMs, allowing them to retrieve knowledge not
in their weights, to perform tasks on the web, and even to control robots.
However, most ontologies and surveys of tool-use have assumed the core
challenge for LLMs is choosing the tool. Instead, we introduce a framework for
tools more broadly which guides us to explore a model's ability to detect
"silent" tool errors, and reflect on how to plan. This more directly aligns
with the increasingly popular use of models as tools. We provide an initial
approach to failure recovery with promising results both on a controlled
calculator setting and embodied agent planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.18762v2' target='_blank'>Categorical Syllogisms Revisited: A Review of the Logical Reasoning
  Abilities of LLMs for Analyzing Categorical Syllogism</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shi Zong, Jimmy Lin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-26 21:17:20</h6>
<p class='card-text'>There have been a huge number of benchmarks proposed to evaluate how large
language models (LLMs) behave for logic inference tasks. However, it remains an
open question how to properly evaluate this ability. In this paper, we provide
a systematic overview of prior works on the logical reasoning ability of LLMs
for analyzing categorical syllogisms. We first investigate all the possible
variations for the categorical syllogisms from a purely logical perspective and
then examine the underlying configurations (i.e., mood and figure) tested by
the existing datasets. Our results indicate that compared to template-based
synthetic datasets, crowdsourcing approaches normally sacrifice the coverage of
configurations (i.e., mood and figure) of categorical syllogisms for more
language variations, thus bringing challenges to fully testing LLMs under
different situations. We then proceed to summarize the findings and
observations for the performances of LLMs to infer the validity of syllogisms
from the current literature. The error rate breakdown analyses suggest that the
interpretation of the quantifiers seems to be the current bottleneck that
limits the performances of the LLMs and is thus worth more attention. Finally,
we discuss several points that might be worth considering when researchers plan
on the future release of categorical syllogism datasets. We hope our work will
not only provide a timely review of the current literature regarding
categorical syllogisms, but also motivate more interdisciplinary research
between communities, specifically computational linguists and logicians.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.18722v4' target='_blank'>Towards Open-World Grasping with Large Vision-Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Georgios Tziafas, Hamidreza Kasaei</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-26 19:42:08</h6>
<p class='card-text'>The ability to grasp objects in-the-wild from open-ended language
instructions constitutes a fundamental challenge in robotics. An open-world
grasping system should be able to combine high-level contextual with low-level
physical-geometric reasoning in order to be applicable in arbitrary scenarios.
Recent works exploit the web-scale knowledge inherent in large language models
(LLMs) to plan and reason in robotic context, but rely on external vision and
action models to ground such knowledge into the environment and parameterize
actuation. This setup suffers from two major bottlenecks: a) the LLM's
reasoning capacity is constrained by the quality of visual grounding, and b)
LLMs do not contain low-level spatial understanding of the world, which is
essential for grasping in contact-rich scenarios. In this work we demonstrate
that modern vision-language models (VLMs) are capable of tackling such
limitations, as they are implicitly grounded and can jointly reason about
semantics and geometry. We propose OWG, an open-world grasping pipeline that
combines VLMs with segmentation and grasp synthesis models to unlock grounded
world understanding in three stages: open-ended referring segmentation,
grounded grasp planning and grasp ranking via contact reasoning, all of which
can be applied zero-shot via suitable visual prompting mechanisms. We conduct
extensive evaluation in cluttered indoor scene datasets to showcase OWG's
robustness in grounding from open-ended language, as well as open-world robotic
grasping experiments in both simulation and hardware that demonstrate superior
performance compared to previous supervised and zero-shot LLM-based methods.
Project material is available at https://gtziafas.github.io/OWG_project/ .</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.01603v3' target='_blank'>A Review of Large Language Models and Autonomous Agents in Chemistry</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mayk Caldas Ramos, Christopher J. Collison, Andrew D. White</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-26 17:33:21</h6>
<p class='card-text'>Large language models (LLMs) have emerged as powerful tools in chemistry,
significantly impacting molecule design, property prediction, and synthesis
optimization. This review highlights LLM capabilities in these domains and
their potential to accelerate scientific discovery through automation. We also
review LLM-based autonomous agents: LLMs with a broader set of tools to
interact with their surrounding environment. These agents perform diverse tasks
such as paper scraping, interfacing with automated laboratories, and synthesis
planning. As agents are an emerging topic, we extend the scope of our review of
agents beyond chemistry and discuss across any scientific domains. This review
covers the recent history, current capabilities, and design of LLMs and
autonomous agents, addressing specific challenges, opportunities, and future
directions in chemistry. Key challenges include data quality and integration,
model interpretability, and the need for standard benchmarks, while future
directions point towards more sophisticated multi-modal agents and enhanced
collaboration between agents and experimental methods. Due to the quick pace of
this field, a repository has been built to keep track of the latest studies:
https://github.com/ur-whitelab/LLMs-in-science.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.18285v1' target='_blank'>LLCoach: Generating Robot Soccer Plans using Multi-Role Large Language
  Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Michele Brienza, Emanuele Musumeci, Vincenzo Suriani, Daniele Affinita, Andrea Pennisi, Daniele Nardi, Domenico Daniele Bloisi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-26 12:12:37</h6>
<p class='card-text'>The deployment of robots into human scenarios necessitates advanced planning
strategies, particularly when we ask robots to operate in dynamic, unstructured
environments. RoboCup offers the chance to deploy robots in one of those
scenarios, a human-shaped game represented by a soccer match. In such
scenarios, robots must operate using predefined behaviors that can fail in
unpredictable conditions. This paper introduces a novel application of Large
Language Models (LLMs) to address the challenge of generating actionable plans
in such settings, specifically within the context of the RoboCup Standard
Platform League (SPL) competitions where robots are required to autonomously
execute soccer strategies that emerge from the interactions of individual
agents. In particular, we propose a multi-role approach leveraging the
capabilities of LLMs to generate and refine plans for a robotic soccer team.
The potential of the proposed method is demonstrated through an experimental
evaluation,carried out simulating multiple matches where robots with
AI-generated plans play against robots running human-built code.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.18200v2' target='_blank'>SEED: Accelerating Reasoning Tree Construction via Scheduled Speculative
  Decoding</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhenglin Wang, Jialong Wu, Yilong Lai, Congzhi Zhang, Deyu Zhou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-26 09:33:41</h6>
<p class='card-text'>Large Language Models (LLMs) demonstrate remarkable emergent abilities across
various tasks, yet fall short of complex reasoning and planning tasks. The
tree-search-based reasoning methods address this by surpassing the capabilities
of chain-of-thought prompting, encouraging exploration of intermediate steps.
However, such methods introduce significant inference latency due to the
systematic exploration and evaluation of multiple thought paths. This paper
introduces SeeD, a novel and efficient inference framework to optimize runtime
speed and GPU memory management concurrently. By employing a scheduled
speculative execution, SeeD efficiently handles multiple iterations for the
thought generation and the state evaluation, leveraging a rounds-scheduled
strategy to manage draft model dispatching. Extensive experimental evaluations
on three reasoning datasets demonstrate superior speedup performance of SeeD,
providing a viable path for batched inference in training-free speculative
decoding.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.18115v1' target='_blank'>Open-vocabulary Mobile Manipulation in Unseen Dynamic Environments with
  3D Semantic Maps</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Dicong Qiu, Wenzong Ma, Zhenfu Pan, Hui Xiong, Junwei Liang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-26 07:06:42</h6>
<p class='card-text'>Open-Vocabulary Mobile Manipulation (OVMM) is a crucial capability for
autonomous robots, especially when faced with the challenges posed by unknown
and dynamic environments. This task requires robots to explore and build a
semantic understanding of their surroundings, generate feasible plans to
achieve manipulation goals, adapt to environmental changes, and comprehend
natural language instructions from humans. To address these challenges, we
propose a novel framework that leverages the zero-shot detection and grounded
recognition capabilities of pretraining visual-language models (VLMs) combined
with dense 3D entity reconstruction to build 3D semantic maps. Additionally, we
utilize large language models (LLMs) for spatial region abstraction and online
planning, incorporating human instructions and spatial semantic context. We
have built a 10-DoF mobile manipulation robotic platform JSR-1 and demonstrated
in real-world robot experiments that our proposed framework can effectively
capture spatial semantics and process natural language user instructions for
zero-shot OVMM tasks under dynamic environment settings, with an overall
navigation and task success rate of 80.95% and 73.33% over 105 episodes, and
better SFT and SPL by 157.18% and 19.53% respectively compared to the baseline.
Furthermore, the framework is capable of replanning towards the next most
probable candidate location based on the spatial semantic context derived from
the 3D semantic map when initial plans fail, keeping an average success rate of
76.67%.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.18082v1' target='_blank'>Octo-planner: On-device Language Model for Planner-Action Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wei Chen, Zhiyuan Li, Zhen Guo, Yikang Shen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-26 05:40:10</h6>
<p class='card-text'>AI agents have become increasingly significant in various domains, enabling
autonomous decision-making and problem-solving. To function effectively, these
agents require a planning process that determines the best course of action and
then executes the planned actions. In this paper, we present an efficient
on-device Planner-Action framework that separates planning and action execution
into two distinct components: a planner agent based on Phi-3 Mini, a 3.8
billion parameter LLM optimized for edge devices, and an action agent using the
Octopus model for function execution. The planner agent first responds to user
queries by decomposing tasks into a sequence of sub-steps, which are then
executed by the action agent. To optimize performance on resource-constrained
devices, we employ model fine-tuning instead of in-context learning, reducing
computational costs and energy consumption while improving response times. Our
approach involves using GPT-4 to generate diverse planning queries and
responses based on available functions, with subsequent validations to ensure
data quality. We fine-tune the Phi-3 Mini model on this curated dataset,
achieving a 97\% success rate in our in-domain test environment. To address
multi-domain planning challenges, we developed a multi-LoRA training method
that merges weights from LoRAs trained on distinct function subsets. This
approach enables flexible handling of complex, multi-domain queries while
maintaining computational efficiency on resource-constrained devices. To
support further research, we have open-sourced our model weights at
\url{https://huggingface.co/NexaAIDev/octopus-planning}. For the demo, please
refer to \url{https://www.nexa4ai.com/octo-planner}.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.17987v4' target='_blank'>Multi-step Inference over Unstructured Data</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Aditya Kalyanpur, Kailash Karthik Saravanakumar, Victor Barres, CJ McFate, Lori Moon, Nati Seifu, Maksim Eremeev, Jose Barrera, Abraham Bautista-Castillo, Eric Brown, David Ferrucci</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-26 00:00:45</h6>
<p class='card-text'>The advent of Large Language Models (LLMs) and Generative AI has
revolutionized natural language applications across various domains. However,
high-stakes decision-making tasks in fields such as medical, legal and finance
require a level of precision, comprehensiveness, and logical consistency that
pure LLM or Retrieval-Augmented-Generation (RAG) approaches often fail to
deliver. At Elemental Cognition (EC), we have developed a neuro-symbolic AI
platform to tackle these problems. The platform integrates fine-tuned LLMs for
knowledge extraction and alignment with a robust symbolic reasoning engine for
logical inference, planning and interactive constraint solving. We describe
Cora, a Collaborative Research Assistant built on this platform, that is
designed to perform complex research and discovery tasks in high-stakes
domains. This paper discusses the multi-step inference challenges inherent in
such domains, critiques the limitations of existing LLM-based methods, and
demonstrates how Cora's neuro-symbolic approach effectively addresses these
issues. We provide an overview of the system architecture, key algorithms for
knowledge extraction and formal reasoning, and present preliminary evaluation
results that highlight Cora's superior performance compared to well-known LLM
and RAG baselines.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.17840v2' target='_blank'>Human-Object Interaction from Human-Level Instructions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhen Wu, Jiaman Li, Pei Xu, C. Karen Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-25 17:46:28</h6>
<p class='card-text'>Intelligent agents must autonomously interact with the environments to
perform daily tasks based on human-level instructions. They need a foundational
understanding of the world to accurately interpret these instructions, along
with precise low-level movement and interaction skills to execute the derived
actions. In this work, we propose the first complete system for synthesizing
physically plausible, long-horizon human-object interactions for object
manipulation in contextual environments, driven by human-level instructions. We
leverage large language models (LLMs) to interpret the input instructions into
detailed execution plans. Unlike prior work, our system is capable of
generating detailed finger-object interactions, in seamless coordination with
full-body movements. We also train a policy to track generated motions in
physics simulation via reinforcement learning (RL) to ensure physical
plausibility of the motion. Our experiments demonstrate the effectiveness of
our system in synthesizing realistic interactions with diverse objects in
complex environments, highlighting its potential for real-world applications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.11003v1' target='_blank'>Using Large Language Models in Public Transit Systems, San Antonio as a
  case study</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ramya Jonnala, Gongbo Liang, Jeong Yang, Izzat Alsmadi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-25 16:32:56</h6>
<p class='card-text'>The integration of large language models into public transit systems
represents a significant advancement in urban transportation management and
passenger experience. This study examines the impact of LLMs within San
Antonio's public transit system, leveraging their capabilities in natural
language processing, data analysis, and real time communication. By utilizing
GTFS and other public transportation information, the research highlights the
transformative potential of LLMs in enhancing route planning, reducing wait
times, and providing personalized travel assistance. Our case study is the city
of San Antonio as part of a project aiming to demonstrate how LLMs can optimize
resource allocation, improve passenger satisfaction, and support decision
making processes in transit management. We evaluated LLM responses to questions
related to both information retrieval and also understanding. Ultimately, we
believe that the adoption of LLMs in public transit systems can lead to more
efficient, responsive, and user-friendly transportation networks, providing a
model for other cities to follow.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.17520v1' target='_blank'>Tell Me Where You Are: Multimodal LLMs Meet Place Recognition</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zonglin Lyu, Juexiao Zhang, Mingxuan Lu, Yiming Li, Chen Feng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-25 12:59:46</h6>
<p class='card-text'>Large language models (LLMs) exhibit a variety of promising capabilities in
robotics, including long-horizon planning and commonsense reasoning. However,
their performance in place recognition is still underexplored. In this work, we
introduce multimodal LLMs (MLLMs) to visual place recognition (VPR), where a
robot must localize itself using visual observations. Our key design is to use
vision-based retrieval to propose several candidates and then leverage
language-based reasoning to carefully inspect each candidate for a final
decision. Specifically, we leverage the robust visual features produced by
off-the-shelf vision foundation models (VFMs) to obtain several candidate
locations. We then prompt an MLLM to describe the differences between the
current observation and each candidate in a pairwise manner, and reason about
the best candidate based on these descriptions. Our results on three datasets
demonstrate that integrating the general-purpose visual features from VFMs with
the reasoning capabilities of MLLMs already provides an effective place
recognition solution, without any VPR-specific supervised training. We believe
our work can inspire new possibilities for applying and designing foundation
models, i.e., VFMs, LLMs, and MLLMs, to enhance the localization and navigation
of mobile robots.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.16294v1' target='_blank'>LangSuitE: Planning, Controlling and Interacting with Large Language
  Models in Embodied Text Environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zixia Jia, Mengmeng Wang, Baichen Tong, Song-Chun Zhu, Zilong Zheng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-24 03:36:29</h6>
<p class='card-text'>Recent advances in Large Language Models (LLMs) have shown inspiring
achievements in constructing autonomous agents that rely on language
descriptions as inputs. However, it remains unclear how well LLMs can function
as few-shot or zero-shot embodied agents in dynamic interactive environments.
To address this gap, we introduce LangSuitE, a versatile and simulation-free
testbed featuring 6 representative embodied tasks in textual embodied worlds.
Compared with previous LLM-based testbeds, LangSuitE (i) offers adaptability to
diverse environments without multiple simulation engines, (ii) evaluates
agents' capacity to develop ``internalized world knowledge'' with embodied
observations, and (iii) allows easy customization of communication and action
strategies. To address the embodiment challenge, we devise a novel
chain-of-thought (CoT) schema, EmMem, which summarizes embodied states w.r.t.
history information. Comprehensive benchmark results illustrate challenges and
insights of embodied planning. LangSuitE represents a significant step toward
building embodied generalists in the context of language models.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.16033v1' target='_blank'>Unlocking the Future: Exploring Look-Ahead Planning Mechanistic
  Interpretability in Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tianyi Men, Pengfei Cao, Zhuoran Jin, Yubo Chen, Kang Liu, Jun Zhao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-23 06:54:47</h6>
<p class='card-text'>Planning, as the core module of agents, is crucial in various fields such as
embodied agents, web navigation, and tool using. With the development of large
language models (LLMs), some researchers treat large language models as
intelligent agents to stimulate and evaluate their planning capabilities.
However, the planning mechanism is still unclear. In this work, we focus on
exploring the look-ahead planning mechanism in large language models from the
perspectives of information flow and internal representations. First, we study
how planning is done internally by analyzing the multi-layer perception (MLP)
and multi-head self-attention (MHSA) components at the last token. We find that
the output of MHSA in the middle layers at the last token can directly decode
the decision to some extent. Based on this discovery, we further trace the
source of MHSA by information flow, and we reveal that MHSA mainly extracts
information from spans of the goal states and recent steps. According to
information flow, we continue to study what information is encoded within it.
Specifically, we explore whether future decisions have been encoded in advance
in the representation of flow. We demonstrate that the middle and upper layers
encode a few short-term future decisions to some extent when planning is
successful. Overall, our research analyzes the look-ahead planning mechanisms
of LLMs, facilitating future research on LLMs performing planning tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.15823v3' target='_blank'>CaT-BENCH: Benchmarking Language Model Understanding of Causal and
  Temporal Dependencies in Plans</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yash Kumar Lal, Vanya Cohen, Nathanael Chambers, Niranjan Balasubramanian, Raymond Mooney</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-22 11:46:04</h6>
<p class='card-text'>Understanding the abilities of LLMs to reason about natural language plans,
such as instructional text and recipes, is critical to reliably using them in
decision-making systems. A fundamental aspect of plans is the temporal order in
which their steps needs to be executed, which reflects the underlying causal
dependencies between them. We introduce CaT-Bench, a benchmark of Step Order
Prediction questions, which test whether a step must necessarily occur before
or after another in cooking recipe plans. We use this to evaluate how well
frontier LLMs understand causal and temporal dependencies. We find that SOTA
LLMs are underwhelming (best zero-shot is only 0.59 in F1), and are biased
towards predicting dependence more often, perhaps relying on temporal order of
steps as a heuristic. While prompting for explanations and using few-shot
examples improve performance, the best F1 result is only 0.73. Further, human
evaluation of explanations along with answer correctness show that, on average,
humans do not agree with model reasoning. Surprisingly, we also find that
explaining after answering leads to better performance than normal
chain-of-thought prompting, and LLM answers are not consistent across questions
about the same step pairs. Overall, results show that LLMs' ability to detect
dependence between steps has significant room for improvement.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.15341v1' target='_blank'>GenoTEX: A Benchmark for Evaluating LLM-Based Exploration of Gene
  Expression Data in Alignment with Bioinformaticians</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Haoyang Liu, Haohan Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-21 17:55:24</h6>
<p class='card-text'>Recent advancements in machine learning have significantly improved the
identification of disease-associated genes from gene expression datasets.
However, these processes often require extensive expertise and manual effort,
limiting their scalability. Large Language Model (LLM)-based agents have shown
promise in automating these tasks due to their increasing problem-solving
abilities. To support the evaluation and development of such methods, we
introduce GenoTEX, a benchmark dataset for the automatic exploration of gene
expression data, involving the tasks of dataset selection, preprocessing, and
statistical analysis. GenoTEX provides annotated code and results for solving a
wide range of gene identification problems, in a full analysis pipeline that
follows the standard of computational genomics. These annotations are curated
by human bioinformaticians who carefully analyze the datasets to ensure
accuracy and reliability. To provide baselines for these tasks, we present
GenoAgents, a team of LLM-based agents designed with context-aware planning,
iterative correction, and domain expert consultation to collaboratively explore
gene datasets. Our experiments with GenoAgents demonstrate the potential of
LLM-based approaches in genomics data analysis, while error analysis highlights
the challenges and areas for future improvement. We propose GenoTEX as a
promising resource for benchmarking and enhancing AI-driven methods for
genomics data analysis. We make our benchmark publicly available at
\url{https://github.com/Liu-Hy/GenoTex}.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.14979v2' target='_blank'>Retrieve-Plan-Generation: An Iterative Planning and Answering Framework
  for Knowledge-Intensive LLM Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuanjie Lyu, Zihan Niu, Zheyong Xie, Chao Zhang, Tong Xu, Yang Wang, Enhong Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-21 08:45:52</h6>
<p class='card-text'>Despite the significant progress of large language models (LLMs) in various
tasks, they often produce factual errors due to their limited internal
knowledge. Retrieval-Augmented Generation (RAG), which enhances LLMs with
external knowledge sources, offers a promising solution. However, these methods
can be misled by irrelevant paragraphs in retrieved documents. Due to the
inherent uncertainty in LLM generation, inputting the entire document may
introduce off-topic information, causing the model to deviate from the central
topic and affecting the relevance of the generated content. To address these
issues, we propose the Retrieve-Plan-Generation (RPG) framework. RPG generates
plan tokens to guide subsequent generation in the plan stage. In the answer
stage, the model selects relevant fine-grained paragraphs based on the plan and
uses them for further answer generation. This plan-answer process is repeated
iteratively until completion, enhancing generation relevance by focusing on
specific topics. To implement this framework efficiently, we utilize a simple
but effective multi-task prompt-tuning method, enabling the existing LLMs to
handle both planning and answering. We comprehensively compare RPG with
baselines across 5 knowledge-intensive generation tasks, demonstrating the
effectiveness of our approach.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.14909v2' target='_blank'>MoA: Mixture of Sparse Attention for Automatic Large Language Model
  Compression</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tianyu Fu, Haofeng Huang, Xuefei Ning, Genghan Zhang, Boju Chen, Tianqi Wu, Hongyi Wang, Zixiao Huang, Shiyao Li, Shengen Yan, Guohao Dai, Huazhong Yang, Yu Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-21 06:58:37</h6>
<p class='card-text'>Sparse attention can effectively mitigate the significant memory and
throughput demands of Large Language Models (LLMs) in long contexts. Existing
methods typically employ a uniform sparse attention mask, applying the same
sparse pattern across different attention heads and input lengths. However,
this uniform approach fails to capture the diverse attention patterns inherent
in LLMs, ignoring their distinct accuracy-latency trade-offs. To address this
challenge, we propose the Mixture of Attention (MoA), which automatically
tailors distinct sparse attention configurations to different heads and layers.
MoA constructs and navigates a search space of various attention patterns and
their scaling rules relative to input sequence lengths. It profiles the model,
evaluates potential configurations, and pinpoints the optimal sparse attention
compression plan. MoA adapts to varying input sizes, revealing that some
attention heads expand their focus to accommodate longer sequences, while other
heads consistently concentrate on fixed-length local contexts. Experiments show
that MoA increases the effective context length by $3.9\times$ with the same
average attention span, boosting retrieval accuracy by $1.5-7.1\times$ over the
uniform-attention baseline across Vicuna-{7B,13B}, and Llama3-{8B,70B} models.
Moreover, MoA narrows the capability gaps between sparse and dense models,
reducing the maximum relative performance drop from $9\%-36\%$ to within $5\%$
across two long-context understanding benchmarks. MoA achieves a
$1.2-1.4\times$ GPU memory reduction, boosting decode throughput by
$6.6-8.2\times$ and $1.7-1.9\times$ compared to FlashAttention2 and vLLM, with
minimal impact on performance. Our code is available at
\url{https://github.com/thu-nics/MoA}.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.14884v1' target='_blank'>FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for
  LLM-based Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ruixuan Xiao, Wentao Ma, Ke Wang, Yuchuan Wu, Junbo Zhao, Haobo Wang, Fei Huang, Yongbin Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-21 06:13:00</h6>
<p class='card-text'>LLM-based agents have emerged as promising tools, which are crafted to
fulfill complex tasks by iterative planning and action. However, these agents
are susceptible to undesired planning hallucinations when lacking specific
knowledge for expertise-intensive tasks. To address this, preliminary attempts
are made to enhance planning reliability by incorporating external
workflow-related knowledge. Despite the promise, such infused knowledge is
mostly disorganized and diverse in formats, lacking rigorous formalization and
comprehensive comparisons. Motivated by this, we formalize different formats of
workflow knowledge and present FlowBench, the first benchmark for
workflow-guided planning. FlowBench covers 51 different scenarios from 6
domains, with knowledge presented in diverse formats. To assess different LLMs
on FlowBench, we design a multi-tiered evaluation framework. We evaluate the
efficacy of workflow knowledge across multiple formats, and the results
indicate that current LLM agents need considerable improvements for
satisfactory planning. We hope that our challenging benchmark can pave the way
for future agent planning research.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.14655v1' target='_blank'>HYPERmotion: Learning Hybrid Behavior Planning for Autonomous
  Loco-manipulation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jin Wang, Rui Dai, Weijie Wang, Luca Rossini, Francesco Ruscelli, Nikos Tsagarakis</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-20 18:21:24</h6>
<p class='card-text'>Enabling robots to autonomously perform hybrid motions in diverse
environments can be beneficial for long-horizon tasks such as material
handling, household chores, and work assistance. This requires extensive
exploitation of intrinsic motion capabilities, extraction of affordances from
rich environmental information, and planning of physical interaction behaviors.
Despite recent progress has demonstrated impressive humanoid whole-body control
abilities, they struggle to achieve versatility and adaptability for new tasks.
In this work, we propose HYPERmotion, a framework that learns, selects and
plans behaviors based on tasks in different scenarios. We combine reinforcement
learning with whole-body optimization to generate motion for 38 actuated joints
and create a motion library to store the learned skills. We apply the planning
and reasoning features of the large language models (LLMs) to complex
loco-manipulation tasks, constructing a hierarchical task graph that comprises
a series of primitive behaviors to bridge lower-level execution with
higher-level planning. By leveraging the interaction of distilled spatial
geometry and 2D observation with a visual language model (VLM) to ground
knowledge into a robotic morphology selector to choose appropriate actions in
single- or dual-arm, legged or wheeled locomotion. Experiments in simulation
and real-world show that learned motions can efficiently adapt to new tasks,
demonstrating high autonomy from free-text commands in unstructured scenes.
Videos and website: hy-motion.github.io/</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.14556v3' target='_blank'>Asynchronous Large Language Model Enhanced Planner for Autonomous
  Driving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuan Chen, Zi-han Ding, Ziqin Wang, Yan Wang, Lijun Zhang, Si Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-20 17:59:03</h6>
<p class='card-text'>Despite real-time planners exhibiting remarkable performance in autonomous
driving, the growing exploration of Large Language Models (LLMs) has opened
avenues for enhancing the interpretability and controllability of motion
planning. Nevertheless, LLM-based planners continue to encounter significant
challenges, including elevated resource consumption and extended inference
times, which pose substantial obstacles to practical deployment. In light of
these challenges, we introduce AsyncDriver, a new asynchronous LLM-enhanced
closed-loop framework designed to leverage scene-associated instruction
features produced by LLM to guide real-time planners in making precise and
controllable trajectory predictions. On one hand, our method highlights the
prowess of LLMs in comprehending and reasoning with vectorized scene data and a
series of routing instructions, demonstrating its effective assistance to
real-time planners. On the other hand, the proposed framework decouples the
inference processes of the LLM and real-time planners. By capitalizing on the
asynchronous nature of their inference frequencies, our approach have
successfully reduced the computational cost introduced by LLM, while
maintaining comparable performance. Experiments show that our approach achieves
superior closed-loop evaluation performance on nuPlan's challenging scenarios.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.14550v2' target='_blank'>GraphReader: Building Graph-based Agent to Enhance Long-Context
  Abilities of Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shilong Li, Yancheng He, Hangyu Guo, Xingyuan Bu, Ge Bai, Jie Liu, Jiaheng Liu, Xingwei Qu, Yangguang Li, Wanli Ouyang, Wenbo Su, Bo Zheng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-20 17:57:51</h6>
<p class='card-text'>Long-context capabilities are essential for large language models (LLMs) to
tackle complex and long-input tasks. Despite numerous efforts made to optimize
LLMs for long contexts, challenges persist in robustly processing long inputs.
In this paper, we introduce GraphReader, a graph-based agent system designed to
handle long texts by structuring them into a graph and employing an agent to
explore this graph autonomously. Upon receiving a question, the agent first
undertakes a step-by-step analysis and devises a rational plan. It then invokes
a set of predefined functions to read node content and neighbors, facilitating
a coarse-to-fine exploration of the graph. Throughout the exploration, the
agent continuously records new insights and reflects on current circumstances
to optimize the process until it has gathered sufficient information to
generate an answer. Experimental results on the LV-Eval dataset reveal that
GraphReader, using a 4k context window, consistently outperforms GPT-4-128k
across context lengths from 16k to 256k by a large margin. Additionally, our
approach demonstrates superior performance on four challenging single-hop and
multi-hop benchmarks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.14283v4' target='_blank'>Q*: Improving Multi-step Reasoning for LLMs with Deliberative Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chaojie Wang, Yanchen Deng, Zhiyi Lyu, Liang Zeng, Jujie He, Shuicheng Yan, Bo An</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-20 13:08:09</h6>
<p class='card-text'>Large Language Models (LLMs) have demonstrated impressive capability in many
natural language tasks. However, the auto-regressive generation process makes
LLMs prone to produce errors, hallucinations and inconsistent statements when
performing multi-step reasoning. In this paper, by casting multi-step reasoning
of LLMs as a heuristic search problem, we aim to alleviate the pathology by
introducing Q*, a general, versatile and agile framework for guiding LLMs
decoding process with deliberative planning. By learning a plug-and-play
Q-value model as heuristic function for estimating expected future rewards, our
Q* can effectively guide LLMs to select the most promising next reasoning step
without fine-tuning LLMs for the current task, which avoids the significant
computational overhead and potential risk of performance degeneration on other
tasks. Extensive experiments on GSM8K, MATH and MBPP demonstrate the
superiority of our method, contributing to improving the reasoning performance
of existing open-source LLMs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.14282v3' target='_blank'>Learning to Plan for Retrieval-Augmented Large Language Models from
  Knowledge Graphs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Junjie Wang, Mingyang Chen, Binbin Hu, Dan Yang, Ziqi Liu, Yue Shen, Peng Wei, Zhiqiang Zhang, Jinjie Gu, Jun Zhou, Jeff Z. Pan, Wen Zhang, Huajun Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-20 13:07:38</h6>
<p class='card-text'>Improving the performance of large language models (LLMs) in complex
question-answering (QA) scenarios has always been a research focal point.
Recent studies have attempted to enhance LLMs' performance by combining
step-wise planning with external retrieval. While effective for advanced models
like GPT-3.5, smaller LLMs face challenges in decomposing complex questions,
necessitating supervised fine-tuning. Previous work has relied on manual
annotation and knowledge distillation from teacher LLMs, which are
time-consuming and not accurate enough. In this paper, we introduce a novel
framework for enhancing LLMs' planning capabilities by using planning data
derived from knowledge graphs (KGs). LLMs fine-tuned with this data have
improved planning capabilities, better equipping them to handle complex QA
tasks that involve retrieval. Evaluations on multiple datasets, including our
newly proposed benchmark, highlight the effectiveness of our framework and the
benefits of KG-derived planning data.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.14277v2' target='_blank'>QPaug: Question and Passage Augmentation for Open-Domain Question
  Answering of LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Minsang Kim, Cheoneum Park, Seungjun Baek</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-20 12:59:27</h6>
<p class='card-text'>Retrieval-augmented generation (RAG) has received much attention for
Open-domain question-answering (ODQA) tasks as a means to compensate for the
parametric knowledge of large language models (LLMs). While previous approaches
focused on processing retrieved passages to remove irrelevant context, they
still rely heavily on the quality of retrieved passages which can degrade if
the question is ambiguous or complex. In this paper, we propose a simple yet
efficient method called question and passage augmentation (QPaug) via LLMs for
open-domain QA. QPaug first decomposes the original questions into
multiple-step sub-questions. By augmenting the original question with detailed
sub-questions and planning, we are able to make the query more specific on what
needs to be retrieved, improving the retrieval performance. In addition, to
compensate for the case where the retrieved passages contain distracting
information or divided opinions, we augment the retrieved passages with
self-generated passages by LLMs to guide the answer extraction. Experimental
results show that QPaug outperforms the previous state-of-the-art and achieves
significant performance gain over existing RAG methods. The source code is
available at \url{https://github.com/kmswin1/QPaug}.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.14097v2' target='_blank'>Enhancing the LLM-Based Robot Manipulation Through Human-Robot
  Collaboration</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Haokun Liu, Yaonan Zhu, Kenji Kato, Atsushi Tsukahara, Izumi Kondo, Tadayoshi Aoyama, Yasuhisa Hasegawa</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-20 08:23:49</h6>
<p class='card-text'>Large Language Models (LLMs) are gaining popularity in the field of robotics.
However, LLM-based robots are limited to simple, repetitive motions due to the
poor integration between language models, robots, and the environment. This
paper proposes a novel approach to enhance the performance of LLM-based
autonomous manipulation through Human-Robot Collaboration (HRC). The approach
involves using a prompted GPT-4 language model to decompose high-level language
commands into sequences of motions that can be executed by the robot. The
system also employs a YOLO-based perception algorithm, providing visual cues to
the LLM, which aids in planning feasible motions within the specific
environment. Additionally, an HRC method is proposed by combining teleoperation
and Dynamic Movement Primitives (DMP), allowing the LLM-based robot to learn
from human guidance. Real-world experiments have been conducted using the
Toyota Human Support Robot for manipulation tasks. The outcomes indicate that
tasks requiring complex trajectory planning and reasoning over environments can
be efficiently accomplished through the incorporation of human demonstrations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.14088v1' target='_blank'>ReaLHF: Optimized RLHF Training for Large Language Models through
  Parameter Reallocation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhiyu Mei, Wei Fu, Kaiwei Li, Guangju Wang, Huanchen Zhang, Yi Wu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-20 08:04:07</h6>
<p class='card-text'>Reinforcement Learning from Human Feedback (RLHF) stands as a pivotal
technique in empowering large language model (LLM) applications. Since RLHF
involves diverse computational workloads and intricate dependencies among
multiple LLMs, directly adopting parallelization techniques from supervised
training can result in sub-optimal performance. To overcome this limitation, we
propose a novel approach named parameter ReaLlocation, which dynamically
redistributes LLM parameters in the cluster and adapts parallelization
strategies during training. Building upon this idea, we introduce ReaLHF, a
pioneering system capable of automatically discovering and running efficient
execution plans for RLHF training given the desired algorithmic and hardware
configurations. ReaLHF formulates the execution plan for RLHF as an augmented
dataflow graph. Based on this formulation, ReaLHF employs a tailored search
algorithm with a lightweight cost estimator to discover an efficient execution
plan. Subsequently, the runtime engine deploys the selected plan by effectively
parallelizing computations and redistributing parameters. We evaluate ReaLHF on
the LLaMA-2 models with up to $4\times70$ billion parameters and 128 GPUs. The
experiment results showcase ReaLHF's substantial speedups of $2.0-10.6\times$
compared to baselines. Furthermore, the execution plans generated by ReaLHF
exhibit an average of $26\%$ performance improvement over heuristic approaches
based on Megatron-LM. The source code of ReaLHF is publicly available at
https://github.com/openpsi-project/ReaLHF .</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.13940v1' target='_blank'>AutoCAP: Towards Automatic Cross-lingual Alignment Planning for
  Zero-shot Chain-of-Thought</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yongheng Zhang, Qiguang Chen, Min Li, Wanxiang Che, Libo Qin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-20 02:19:33</h6>
<p class='card-text'>Cross-lingual chain-of-thought can effectively complete reasoning tasks
across languages, which gains increasing attention. Recently, dominant
approaches in the literature improve cross-lingual alignment capabilities by
integrating reasoning knowledge from different languages. Despite achieving
excellent performance, current methods still have two main challenges: (1)
Manual language specification: They still highly rely on manually selecting the
languages to integrate, severely affecting their generalizability; (2) Static
weight allocation: Current methods simply integrate all languages equally. In
fact, different language reasoning paths should have different weights to
achieve better complementation and integration. Motivated by this, we introduce
an Automatic Cross-lingual Alignment Planning (AutoCAP) for zero-shot
chain-of-thought to address the above challenges. The core of AutoCAP consists
of two components: (1) Automatic Language Selection Prompting to guide LLMs to
select appropriate languages and (2) Automatic Weight Allocation Prompting to
automatically allocate alignment weight scores to each reasoning path.
Extensive experiments on several benchmarks reveal that AutoCAP achieves
state-of-the-art performance, surpassing previous methods that required manual
effort.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.02511v1' target='_blank'>LLM-A*: Large Language Model Enhanced Incremental Heuristic Search on
  Path Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Silin Meng, Yiwei Wang, Cheng-Fu Yang, Nanyun Peng, Kai-Wei Chang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-20 01:24:30</h6>
<p class='card-text'>Path planning is a fundamental scientific problem in robotics and autonomous
navigation, requiring the derivation of efficient routes from starting to
destination points while avoiding obstacles. Traditional algorithms like A* and
its variants are capable of ensuring path validity but suffer from significant
computational and memory inefficiencies as the state space grows. Conversely,
large language models (LLMs) excel in broader environmental analysis through
contextual understanding, providing global insights into environments. However,
they fall short in detailed spatial and temporal reasoning, often leading to
invalid or inefficient routes. In this work, we propose LLM-A*, an new LLM
based route planning method that synergistically combines the precise
pathfinding capabilities of A* with the global reasoning capability of LLMs.
This hybrid approach aims to enhance pathfinding efficiency in terms of time
and space complexity while maintaining the integrity of path validity,
especially in large-scale scenarios. By integrating the strengths of both
methodologies, LLM-A* addresses the computational and memory limitations of
conventional algorithms without compromising on the validity required for
effective pathfinding.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.13381v1' target='_blank'>CoAct: A Global-Local Hierarchy for Autonomous Agent Collaboration</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xinming Hou, Mingming Yang, Wenxiang Jiao, Xing Wang, Zhaopeng Tu, Wayne Xin Zhao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-19 09:23:53</h6>
<p class='card-text'>Existing LLMs exhibit remarkable performance on various NLP tasks, but still
struggle with complex real-world tasks, even equipped with advanced strategies
like CoT and ReAct. In this work, we propose the CoAct framework, which
transfers the hierarchical planning and collaboration patterns in human society
to LLM systems. Specifically, our CoAct framework involves two agents: (1) A
global planning agent, to comprehend the problem scope, formulate macro-level
plans and provide detailed sub-task descriptions to local execution agents,
which serves as the initial rendition of a global plan. (2) A local execution
agent, to operate within the multi-tier task execution structure, focusing on
detailed execution and implementation of specific tasks within the global plan.
Experimental results on the WebArena benchmark show that CoAct can re-arrange
the process trajectory when facing failures, and achieves superior performance
over baseline methods on long-horizon web tasks. Code is available at
https://github.com/xmhou2002/CoAct.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.13094v2' target='_blank'>Exploring and Benchmarking the Planning Capabilities of Large Language
  Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Bernd Bohnet, Azade Nova, Aaron T Parisi, Kevin Swersky, Katayoon Goshvadi, Hanjun Dai, Dale Schuurmans, Noah Fiedel, Hanie Sedghi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-18 22:57:06</h6>
<p class='card-text'>Classical and natural language planning tasks remain a difficult domain for
modern large language models (LLMs). In this work, we lay the foundations for
improving planning capabilities of LLMs. First, we construct a comprehensive
benchmark suite encompassing both classical planning benchmarks and natural
language scenarios. This suite includes algorithms to methodically generate
instances of tasks with varying levels of difficulty, allowing for rigorous and
systematic evaluation of LLM performance. Next, we investigate the use of
many-shot in-context learning to enhance LLM planning, exploring the
relationship between increased context length and improved planning
performance. In addition, we demonstrate the positive impact of fine-tuning
LLMs on optimal planning paths. We also probe the efficacy of chain-of-thought
reasoning methods to improve LLM planning performance. Moreover, we probe the
performance of the proposed methods in out-of-distribution scenarios, assessing
the ability to generalize to novel and unseen planning challenges. Finally, we
investigate model's failure modes and reveal insights that hold true across
different benchmarks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.12651v1' target='_blank'>Transforming Surgical Interventions with Embodied Intelligence for
  Ultrasound Robotics</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Huan Xu, Jinlin Wu, Guanglin Cao, Zhen Chen, Zhen Lei, Hongbin Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-18 14:22:16</h6>
<p class='card-text'>Ultrasonography has revolutionized non-invasive diagnostic methodologies,
significantly enhancing patient outcomes across various medical domains.
Despite its advancements, integrating ultrasound technology with robotic
systems for automated scans presents challenges, including limited command
understanding and dynamic execution capabilities. To address these challenges,
this paper introduces a novel Ultrasound Embodied Intelligence system that
synergistically combines ultrasound robots with large language models (LLMs)
and domain-specific knowledge augmentation, enhancing ultrasound robots'
intelligence and operational efficiency. Our approach employs a dual strategy:
firstly, integrating LLMs with ultrasound robots to interpret doctors' verbal
instructions into precise motion planning through a comprehensive understanding
of ultrasound domain knowledge, including APIs and operational manuals;
secondly, incorporating a dynamic execution mechanism, allowing for real-time
adjustments to scanning plans based on patient movements or procedural errors.
We demonstrate the effectiveness of our system through extensive experiments,
including ablation studies and comparisons across various models, showcasing
significant improvements in executing medical procedures from verbal commands.
Our findings suggest that the proposed system improves the efficiency and
quality of ultrasound scans and paves the way for further advancements in
autonomous medical scanning technologies, with the potential to transform
non-invasive diagnostics and streamline medical workflows.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.12639v2' target='_blank'>Ask-before-Plan: Proactive Language Agents for Real-World Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xuan Zhang, Yang Deng, Zifeng Ren, See-Kiong Ng, Tat-Seng Chua</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-18 14:07:28</h6>
<p class='card-text'>The evolution of large language models (LLMs) has enhanced the planning
capabilities of language agents in diverse real-world scenarios. Despite these
advancements, the potential of LLM-powered agents to comprehend ambiguous user
instructions for reasoning and decision-making is still under exploration. In
this work, we introduce a new task, Proactive Agent Planning, which requires
language agents to predict clarification needs based on user-agent conversation
and agent-environment interaction, invoke external tools to collect valid
information, and generate a plan to fulfill the user's demands. To study this
practical problem, we establish a new benchmark dataset, Ask-before-Plan. To
tackle the deficiency of LLMs in proactive planning, we propose a novel
multi-agent framework, Clarification-Execution-Planning (\texttt{CEP}), which
consists of three agents specialized in clarification, execution, and planning.
We introduce the trajectory tuning scheme for the clarification agent and
static execution agent, as well as the memory recollection mechanism for the
dynamic execution agent. Extensive evaluations and comprehensive analyses
conducted on the Ask-before-Plan dataset validate the effectiveness of our
proposed framework.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.12572v3' target='_blank'>Mathador-LM: A Dynamic Benchmark for Mathematical Reasoning on Large
  Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Eldar Kurtic, Amir Moeini, Dan Alistarh</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-18 13:02:12</h6>
<p class='card-text'>We introduce Mathador-LM, a new benchmark for evaluating the mathematical
reasoning on large language models (LLMs), combining ruleset interpretation,
planning, and problem-solving. This benchmark is inspired by the Mathador game,
where the objective is to reach a target number using basic arithmetic
operations on a given set of base numbers, following a simple set of rules. We
show that, across leading LLMs, we obtain stable average performance while
generating benchmark instances \emph{dynamically}, following a target
difficulty level. Thus, our benchmark alleviates concerns about test-set
leakage into training data, an issue that often undermines popular benchmarks.
Additionally, we conduct a comprehensive evaluation of both open and
closed-source state-of-the-art LLMs on Mathador-LM. Our findings reveal that
contemporary models struggle with Mathador-LM, scoring significantly lower than
average 3rd graders. This stands in stark contrast to their strong performance
on popular mathematical reasoning benchmarks. The implementation of Mathador-LM
benchmark is available at
\href{https://github.com/IST-DASLab/Mathador-LM}{github.com/IST-DASLab/Mathador-LM}.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.12430v1' target='_blank'>PlanRAG: A Plan-then-Retrieval Augmented Generation for Generative Large
  Language Models as Decision Makers</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Myeonghwa Lee, Seonho An, Min-Soo Kim</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-18 09:25:35</h6>
<p class='card-text'>In this paper, we conduct a study to utilize LLMs as a solution for decision
making that requires complex data analysis. We define Decision QA as the task
of answering the best decision, $d_{best}$, for a decision-making question $Q$,
business rules $R$ and a database $D$. Since there is no benchmark that can
examine Decision QA, we propose Decision QA benchmark, DQA. It has two
scenarios, Locating and Building, constructed from two video games (Europa
Universalis IV and Victoria 3) that have almost the same goal as Decision QA.
To address Decision QA effectively, we also propose a new RAG technique called
the iterative plan-then-retrieval augmented generation (PlanRAG). Our
PlanRAG-based LM generates the plan for decision making as the first step, and
the retriever generates the queries for data analysis as the second step. The
proposed method outperforms the state-of-the-art iterative RAG method by 15.8%
in the Locating scenario and by 7.4% in the Building scenario, respectively. We
release our code and benchmark at https://github.com/myeon9h/PlanRAG.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2407.12791v1' target='_blank'>TourLLM: Enhancing LLMs with Tourism Knowledge</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Qikai Wei, Mingzhi Yang, Jinqiang Wang, Wenwei Mao, Jiabo Xu, Huansheng Ning</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-18 09:15:46</h6>
<p class='card-text'>Recently, large language models (LLMs) have demonstrated their effectiveness
in various natural language processing (NLP) tasks. However, the lack of
tourism knowledge limits the performance of LLMs in tourist attraction
presentations and travel planning. To address this challenge, we constructed a
supervised fine-tuning dataset for the culture and tourism domain, named
Cultour. This dataset consists of three parts: tourism knowledge base QA data,
travelogues data, and tourism diversity QA data. Additionally, we propose
TourLLM, a Qwen-based model supervised fine-tuned with Cultour, to improve the
quality of the information provided about attractions and travel planning. To
evaluate the performance of TourLLM, we employed both automatic and human
evaluation, and we proposed a human evaluation criterion named CRA
(Consistency, Readability, Availability). The experimental results demonstrate
the effectiveness of the responses generated by the TourLLM. Our proposed
Cultour is accessible at https://github.com/mrweiqk/Cultour.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.12360v1' target='_blank'>UrbanLLM: Autonomous Urban Activity Planning and Management with Large
  Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yue Jiang, Qin Chao, Yile Chen, Xiucheng Li, Shuai Liu, Gao Cong</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-18 07:41:42</h6>
<p class='card-text'>Location-based services play an critical role in improving the quality of our
daily lives. Despite the proliferation of numerous specialized AI models within
spatio-temporal context of location-based services, these models struggle to
autonomously tackle problems regarding complex urban planing and management. To
bridge this gap, we introduce UrbanLLM, a fine-tuned large language model (LLM)
designed to tackle diverse problems in urban scenarios. UrbanLLM functions as a
problem-solver by decomposing urban-related queries into manageable sub-tasks,
identifying suitable spatio-temporal AI models for each sub-task, and
generating comprehensive responses to the given queries. Our experimental
results indicate that UrbanLLM significantly outperforms other established
LLMs, such as Llama and the GPT series, in handling problems concerning complex
urban activity planning and management. UrbanLLM exhibits considerable
potential in enhancing the effectiveness of solving problems in urban
scenarios, reducing the workload and reliance for human experts.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.12000v2' target='_blank'>Look Further Ahead: Testing the Limits of GPT-4 in Path Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mohamed Aghzal, Erion Plaku, Ziyu Yao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-17 18:12:56</h6>
<p class='card-text'>Large Language Models (LLMs) have shown impressive capabilities across a wide
variety of tasks. However, they still face challenges with long-horizon
planning. To study this, we propose path planning tasks as a platform to
evaluate LLMs' ability to navigate long trajectories under geometric
constraints. Our proposed benchmark systematically tests path-planning skills
in complex settings. Using this, we examined GPT-4's planning abilities using
various task representations and prompting approaches. We found that framing
prompts as Python code and decomposing long trajectory tasks improve GPT-4's
path planning effectiveness. However, while these approaches show some promise
toward improving the planning ability of the model, they do not obtain optimal
paths and fail at generalizing over extended horizons.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.11709v4' target='_blank'>Instruct, Not Assist: LLM-based Multi-Turn Planning and Hierarchical
  Questioning for Socratic Code Debugging</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Priyanka Kargupta, Ishika Agarwal, Dilek Hakkani-Tur, Jiawei Han</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-17 16:28:21</h6>
<p class='card-text'>Socratic questioning is an effective teaching strategy, encouraging critical
thinking and problem-solving. The conversational capabilities of large language
models (LLMs) show great potential for providing scalable, real-time student
guidance. However, current LLMs often give away solutions directly, making them
ineffective instructors. We tackle this issue in the code debugging domain with
TreeInstruct, an Instructor agent guided by a novel state space-based planning
algorithm. TreeInstruct asks probing questions to help students independently
identify and resolve errors. It estimates a student's conceptual and
syntactical knowledge to dynamically construct a question tree based on their
responses and current knowledge state, effectively addressing both independent
and dependent mistakes concurrently in a multi-turn interaction setting. In
addition to using an existing single-bug debugging benchmark, we construct a
more challenging multi-bug dataset of 150 coding problems, incorrect solutions,
and bug fixes -- all carefully constructed and annotated by experts. Extensive
evaluation shows TreeInstruct's state-of-the-art performance on both datasets,
proving it to be a more effective instructor than baselines. Furthermore, a
real-world case study with five students of varying skill levels further
demonstrates TreeInstruct's ability to guide students to debug their code
efficiently with minimal turns and highly Socratic questioning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.11455v2' target='_blank'>Adaptive Reinforcement Learning Planning: Harnessing Large Language
  Models for Complex Information Extraction</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zepeng Ding, Ruiyang Ke, Wenhao Huang, Guochao Jiang, Yanda Li, Deqing Yang, Jiaqing Liang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-17 12:11:01</h6>
<p class='card-text'>Existing research on large language models (LLMs) shows that they can solve
information extraction tasks through multi-step planning. However, their
extraction behavior on complex sentences and tasks is unstable, emerging issues
such as false positives and missing elements. We observe that decomposing
complex extraction tasks and extracting them step by step can effectively
improve LLMs' performance, and the extraction orders of entities significantly
affect the final results of LLMs. This paper proposes a two-stage multi-step
method for LLM-based information extraction and adopts the RL framework to
execute the multi-step planning. We regard sequential extraction as a Markov
decision process, build an LLM-based extraction environment, design a decision
module to adaptively provide the optimal order for sequential entity extraction
on different sentences, and utilize the DDQN algorithm to train the decision
model. We also design the rewards and evaluation metrics suitable for the
extraction results of LLMs. We conduct extensive experiments on multiple public
datasets to demonstrate the effectiveness of our method in improving the
information extraction capabilities of LLMs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.11925v2' target='_blank'>DocCGen: Document-based Controlled Code Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sameer Pimparkhede, Mehant Kammakomati, Srikanth Tamilselvam, Prince Kumar, Ashok Pon Kumar, Pushpak Bhattacharyya</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-17 08:34:57</h6>
<p class='card-text'>Recent developments show that Large Language Models (LLMs) produce
state-of-the-art performance on natural language (NL) to code generation for
resource-rich general-purpose languages like C++, Java, and Python. However,
their practical usage for structured domain-specific languages (DSLs) such as
YAML, JSON is limited due to domain-specific schema, grammar, and
customizations generally unseen by LLMs during pre-training. Efforts have been
made to mitigate this challenge via in-context learning through relevant
examples or by fine-tuning. However, it suffers from problems, such as limited
DSL samples and prompt sensitivity but enterprises maintain good documentation
of the DSLs. Therefore, we propose DocCGen, a framework that can leverage such
rich knowledge by breaking the NL-to-Code generation task for structured code
languages into a two-step process. First, it detects the correct libraries
using the library documentation that best matches the NL query. Then, it
utilizes schema rules extracted from the documentation of these libraries to
constrain the decoding. We evaluate our framework for two complex structured
languages, Ansible YAML and Bash command, consisting of two settings:
Out-of-domain (OOD) and In-domain (ID). Our extensive experiments show that
DocCGen consistently improves different-sized language models across all six
evaluation metrics, reducing syntactic and semantic errors in structured code.
We plan to open-source the datasets and code to motivate research in
constrained code generation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.11132v2' target='_blank'>RePrompt: Planning by Automatic Prompt Engineering for Large Language
  Models Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Weizhe Chen, Sven Koenig, Bistra Dilkina</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-17 01:23:11</h6>
<p class='card-text'>In the past year, large language models (LLMs) have had remarkable success in
domains outside the traditional natural language processing, and their capacity
is further expanded into the so-called LLM agents when connected with external
tools. In all domains, the prompt to the LLMs has been shown to make a big
difference in what the LLM would generate and thus affect the performance of
the LLM agents. Therefore, automatic prompt engineering (APE) has become an
important question for many researchers and users of LLMs. However, previous
works in APE rely on a final checker to evaluate the performance of the given
prompt -- a requirement that is hard to meet in the case of LLM agents, where
intermediate feedback is easier to obtain, and the final evaluation could be
expensive, inaccurate, or even missing. In this paper, we propose a novel
method, \textsc{RePrompt}, which does a ``gradient descent"-like approach to
optimize the step-by-step instructions in the prompts given to LLM agents,
based on the chat history obtained from interactions and reflections with LLM
agents. By leveraging intermediate feedback, \textsc{RePrompt} can optimize the
prompt without the need for a final solution checker. We evaluate our approach
on PDDL generation, TravelPlanner, and Meeting Planning to show that our method
could generally improve performance for different reasoning tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.11047v1' target='_blank'>Enhancing Supermarket Robot Interaction: A Multi-Level LLM
  Conversational Interface for Handling Diverse Customer Intents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chandran Nandkumar, Luka Peternel</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-16 19:13:01</h6>
<p class='card-text'>This paper presents the design and evaluation of a novel multi-level LLM
interface for supermarket robots to assist customers. The proposed interface
allows customers to convey their needs through both generic and specific
queries. While state-of-the-art systems like OpenAI's GPTs are highly adaptable
and easy to build and deploy, they still face challenges such as increased
response times and limitations in strategic control of the underlying model for
tailored use-case and cost optimization. Driven by the goal of developing
faster and more efficient conversational agents, this paper advocates for using
multiple smaller, specialized LLMs fine-tuned to handle different user queries
based on their specificity and user intent. We compare this approach to a
specialized GPT model powered by GPT-4 Turbo, using the Artificial Social Agent
Questionnaire (ASAQ) and qualitative participant feedback in a counterbalanced
within-subjects experiment. Our findings show that our multi-LLM chatbot
architecture outperformed the benchmarked GPT model across all 13 measured
criteria, with statistically significant improvements in four key areas:
performance, user satisfaction, user-agent partnership, and self-image
enhancement. The paper also presents a method for supermarket robot navigation
by mapping the final chatbot response to correct shelf numbers, enabling the
robot to sequentially navigate towards the respective products, after which
lower-level robot perception, control, and planning can be used for automated
object retrieval. We hope this work encourages more efforts into using
multiple, specialized smaller models instead of relying on a single powerful,
but more expensive and slower model.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.10923v1' target='_blank'>Investigating Video Reasoning Capability of Large Language Models with
  Tropes in Movies</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hung-Ting Su, Chun-Tong Chao, Ya-Ching Hsu, Xudong Lin, Yulei Niu, Hung-Yi Lee, Winston H. Hsu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-16 12:58:31</h6>
<p class='card-text'>Large Language Models (LLMs) have demonstrated effectiveness not only in
language tasks but also in video reasoning. This paper introduces a novel
dataset, Tropes in Movies (TiM), designed as a testbed for exploring two
critical yet previously overlooked video reasoning skills: (1) Abstract
Perception: understanding and tokenizing abstract concepts in videos, and (2)
Long-range Compositional Reasoning: planning and integrating intermediate
reasoning steps for understanding long-range videos with numerous frames.
Utilizing tropes from movie storytelling, TiM evaluates the reasoning
capabilities of state-of-the-art LLM-based approaches. Our experiments show
that current methods, including Captioner-Reasoner, Large Multimodal Model
Instruction Fine-tuning, and Visual Programming, only marginally outperform a
random baseline when tackling the challenges of Abstract Perception and
Long-range Compositional Reasoning. To address these deficiencies, we propose
Face-Enhanced Viper of Role Interactions (FEVoRI) and Context Query Reduction
(ConQueR), which enhance Visual Programming by fostering role interaction
awareness and progressively refining movie contexts and trope queries during
reasoning processes, significantly improving performance by 15 F1 points.
However, this performance still lags behind human levels (40 vs. 65 F1).
Additionally, we introduce a new protocol to evaluate the necessity of Abstract
Perception and Long-range Compositional Reasoning for task resolution. This is
done by analyzing the code generated through Visual Programming using an
Abstract Syntax Tree (AST), thereby confirming the increased complexity of TiM.
The dataset and code are available at: https://ander1119.github.io/TiM</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.11903v1' target='_blank'>A Survey of Large Language Models for Financial Applications: Progress,
  Prospects and Challenges</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuqi Nie, Yaxuan Kong, Xiaowen Dong, John M. Mulvey, H. Vincent Poor, Qingsong Wen, Stefan Zohren</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-15 16:11:35</h6>
<p class='card-text'>Recent advances in large language models (LLMs) have unlocked novel
opportunities for machine learning applications in the financial domain. These
models have demonstrated remarkable capabilities in understanding context,
processing vast amounts of data, and generating human-preferred contents. In
this survey, we explore the application of LLMs on various financial tasks,
focusing on their potential to transform traditional practices and drive
innovation. We provide a discussion of the progress and advantages of LLMs in
financial contexts, analyzing their advanced technologies as well as
prospective capabilities in contextual understanding, transfer learning
flexibility, complex emotion detection, etc. We then highlight this survey for
categorizing the existing literature into key application areas, including
linguistic tasks, sentiment analysis, financial time series, financial
reasoning, agent-based modeling, and other applications. For each application
area, we delve into specific methodologies, such as textual analysis,
knowledge-based analysis, forecasting, data augmentation, planning, decision
support, and simulations. Furthermore, a comprehensive collection of datasets,
model assets, and useful codes associated with mainstream applications are
presented as resources for the researchers and practitioners. Finally, we
outline the challenges and opportunities for future research, particularly
emphasizing a number of distinctive aspects in this field. We hope our work can
help facilitate the adoption and further development of LLMs in the financial
sector.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.10479v1' target='_blank'>Unlocking Large Language Model's Planning Capabilities with Maximum
  Diversity Fine-tuning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wenjun Li, Changyu Chen, Pradeep Varakantham</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-15 03:06:14</h6>
<p class='card-text'>Large language models (LLMs) have demonstrated impressive task-solving
capabilities, achieved through either prompting techniques or system designs.
However, concerns have arisen regarding their proficiency in planning tasks, as
they often struggle to generate valid plans. This paper investigates the impact
of fine-tuning on LLMs' planning capabilities. Our findings indicate that LLMs
can achieve good performance in planning through substantial (thousands of
specific examples) fine-tuning. However, fine-tuning is associated with
significant economic and computational costs. To address this challenge, we
propose the Maximum Diversity Fine-Tuning (MDFT) strategy to improve the sample
efficiency of fine-tuning in the planning domain. Specifically, our algorithm,
referred to as MDFT-g, encodes the planning task instances with their graph
representations and selects a subset of samples in the vector space that
maximizes data diversity. We empirically demonstrate that MDFT-g consistently
outperforms existing baselines at various scales across multiple benchmark
domains.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.10370v2' target='_blank'>Let's Get to the Point: LLM-Supported Planning, Drafting, and Revising
  of Research-Paper Blog Posts</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Marissa Radensky, Daniel S. Weld, Joseph Chee Chang, Pao Siangliulue, Jonathan Bragg</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-14 18:56:40</h6>
<p class='card-text'>Research-paper blog posts help scientists to disseminate their work to a
larger audience, but translating scientific long documents into long-form
summaries like blog posts raises unique challenges: 1) planning what paper
content to include in the blog post, 2) drafting the selected content in
sections amenable to a paper blog post, and 3) revising the blog post to be
scientifically accurate but also concise, easy to understand, and engaging. Can
we harness the power of large language models (LLMs) to assist researchers with
these challenges? To investigate this question, we developed Papers-to-Posts,
an LLM-powered tool that implements a new Plan-Draft-Revise workflow for
mixed-initiative long-form paper summarization. An LLM-generated paper outline
with pre-selected yet adjustable bullet points helps users to plan what
information to include. Meanwhile, customizable LLM instructions support
drafting the text with a suitable structure and revising the text to have an
appropriate tone. Through two studies, we compared Papers-to-Posts to a strong
baseline tool that provides an LLM-generated draft and access to free-form LLM
prompting, and we found that Papers-to-Posts improved researchers' editing
power. In a within-subjects lab study (N=20 participants), Papers-to-Posts led
participants to make significantly more change to initial LLM drafts within a
fixed amount of time and to be significantly more satisfied with their final
blog post, without increasing cognitive load. Furthermore, in a
between-subjects deployment study (N=37 blog posts, 26 participants),
Papers-to-Posts led participants to make more change to initial LLM drafts
within a given amount of time as well as writing actions, without decreasing
satisfaction with the final blog posts or increasing cognitive load.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.10196v1' target='_blank'>TRIP-PAL: Travel Planning with Guarantees by Combining Large Language
  Models and Automated Planners</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tomas de la Rosa, Sriram Gopalakrishnan, Alberto Pozanco, Zhen Zeng, Daniel Borrajo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-14 17:31:16</h6>
<p class='card-text'>Travel planning is a complex task that involves generating a sequence of
actions related to visiting places subject to constraints and maximizing some
user satisfaction criteria. Traditional approaches rely on problem formulation
in a given formal language, extracting relevant travel information from web
sources, and use an adequate problem solver to generate a valid solution. As an
alternative, recent Large Language Model (LLM) based approaches directly output
plans from user requests using language. Although LLMs possess extensive travel
domain knowledge and provide high-level information like points of interest and
potential routes, current state-of-the-art models often generate plans that
lack coherence, fail to satisfy constraints fully, and do not guarantee the
generation of high-quality solutions. We propose TRIP-PAL, a hybrid method that
combines the strengths of LLMs and automated planners, where (i) LLMs get and
translate travel information and user information into data structures that can
be fed into planners; and (ii) automated planners generate travel plans that
guarantee constraint satisfaction and optimize for users' utility. Our
experiments across various travel scenarios show that TRIP-PAL outperforms an
LLM when generating travel plans.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.09988v2' target='_blank'>Details Make a Difference: Object State-Sensitive Neurorobotic Task
  Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xiaowen Sun, Xufeng Zhao, Jae Hee Lee, Wenhao Lu, Matthias Kerzel, Stefan Wermter</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-14 12:52:42</h6>
<p class='card-text'>The state of an object reflects its current status or condition and is
important for a robot's task planning and manipulation. However, detecting an
object's state and generating a state-sensitive plan for robots is challenging.
Recently, pre-trained Large Language Models (LLMs) and Vision-Language Models
(VLMs) have shown impressive capabilities in generating plans. However, to the
best of our knowledge, there is hardly any investigation on whether LLMs or
VLMs can also generate object state-sensitive plans. To study this, we
introduce an Object State-Sensitive Agent (OSSA), a task-planning agent
empowered by pre-trained neural networks. We propose two methods for OSSA: (i)
a modular model consisting of a pre-trained vision processing module (dense
captioning model, DCM) and a natural language processing model (LLM), and (ii)
a monolithic model consisting only of a VLM. To quantitatively evaluate the
performances of the two methods, we use tabletop scenarios where the task is to
clear the table. We contribute a multimodal benchmark dataset that takes object
states into consideration. Our results show that both methods can be used for
object state-sensitive tasks, but the monolithic approach outperforms the
modular approach. The code for OSSA is available at
https://github.com/Xiao-wen-Sun/OSSA</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.09953v2' target='_blank'>DAG-Plan: Generating Directed Acyclic Dependency Graphs for Dual-Arm
  Cooperative Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zeyu Gao, Yao Mu, Jinye Qu, Mengkang Hu, Lingyue Guo, Ping Luo, Yanfeng Lu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-14 11:58:51</h6>
<p class='card-text'>Dual-arm robots offer enhanced versatility and efficiency over single-arm
counterparts by enabling concurrent manipulation of multiple objects or
cooperative execution of tasks using both arms. However, effectively
coordinating the two arms for complex long-horizon tasks remains a significant
challenge. Existing task planning methods predominantly focus on single-arm
robots or rely on predefined bimanual operations, failing to fully leverage the
capabilities of dual-arm systems. To address this limitation, we introduce
DAG-Plan, a structured task planning framework tailored for dual-arm robots.
DAG-Plan harnesses large language models (LLMs) to decompose intricate tasks
into actionable sub-tasks represented as nodes within a directed acyclic graph
(DAG). Critically, DAG-Plan dynamically assigns these sub-tasks to the
appropriate arm based on real-time environmental observations, enabling
parallel and adaptive execution. We evaluate DAG-Plan on the novel Dual-Arm
Kitchen Benchmark, comprising 9 sequential tasks with 78 sub-tasks and 26
objects. Extensive experiments demonstrate the superiority of DAG-Plan over
directly using LLM to generate plans, achieving nearly 50% higher efficiency
compared to the single-arm task planning baseline and nearly double the success
rate of the dual-arm task planning baseline.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.10303v2' target='_blank'>A Survey on Large Language Models from General Purpose to Medical
  Applications: Datasets, Methodologies, and Evaluations</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jinqiang Wang, Huansheng Ning, Yi Peng, Qikai Wei, Daniel Tesfai, Wenwei Mao, Tao Zhu, Runhe Huang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-14 02:42:20</h6>
<p class='card-text'>Large Language Models (LLMs) have demonstrated surprising performance across
various natural language processing tasks. Recently, medical LLMs enhanced with
domain-specific knowledge have exhibited excellent capabilities in medical
consultation and diagnosis. These models can smoothly simulate doctor-patient
dialogues and provide professional medical advice. Most medical LLMs are
developed through continued training of open-source general LLMs, which require
significantly fewer computational resources than training LLMs from scratch.
Additionally, this approach offers better patient privacy protection than
API-based solutions. Given the above advantages, this survey systematically
summarizes how to train medical LLMs based on open-source general LLMs from a
more fine-grained perspective. It covers (a) how to acquire training corpus and
construct customized medical training sets, (b) how to choose an appropriate
training paradigm, (c) how to choose a suitable evaluation benchmark, and (d)
existing challenges and promising research directions are discussed. This
survey can provide guidance for the development of LLMs focused on various
medical applications, such as medical education, diagnostic planning, and
clinical assistants. Related resources and supplemental information can be
found on the GitHub repository.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.09187v1' target='_blank'>GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled
  Reasoning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhen Xiang, Linzhi Zheng, Yanjie Li, Junyuan Hong, Qinbin Li, Han Xie, Jiawei Zhang, Zidi Xiong, Chulin Xie, Carl Yang, Dawn Song, Bo Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-13 14:49:26</h6>
<p class='card-text'>The rapid advancement of large language models (LLMs) has catalyzed the
deployment of LLM-powered agents across numerous applications, raising new
concerns regarding their safety and trustworthiness. Existing methods for
enhancing the safety of LLMs are not directly transferable to LLM-powered
agents due to their diverse objectives and output modalities. In this paper, we
propose GuardAgent, the first LLM agent as a guardrail to other LLM agents.
Specifically, GuardAgent oversees a target LLM agent by checking whether its
inputs/outputs satisfy a set of given guard requests defined by the users.
GuardAgent comprises two steps: 1) creating a task plan by analyzing the
provided guard requests, and 2) generating guardrail code based on the task
plan and executing the code by calling APIs or using external engines. In both
steps, an LLM is utilized as the core reasoning component, supplemented by
in-context demonstrations retrieved from a memory module. Such
knowledge-enabled reasoning allows GuardAgent to understand various textual
guard requests and accurately "translate" them into executable code that
provides reliable guardrails. Furthermore, GuardAgent is equipped with an
extendable toolbox containing functions and APIs and requires no additional LLM
training, which underscores its generalization capabilities and low operational
overhead. Additionally, we propose two novel benchmarks: an EICU-AC benchmark
for assessing privacy-related access control for healthcare agents and a
Mind2Web-SC benchmark for safety evaluation for web agents. We show the
effectiveness of GuardAgent on these two benchmarks with 98.7% and 90.0%
accuracy in moderating invalid inputs and outputs for the two types of agents,
respectively. We also show that GuardAgent is able to define novel functions in
adaption to emergent LLM agents and guard requests, which underscores its
strong generalization capabilities.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.08862v1' target='_blank'>Cognitively Inspired Energy-Based World Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Alexi Gladstone, Ganesh Nanduru, Md Mofijul Islam, Aman Chadha, Jundong Li, Tariq Iqbal</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-13 06:54:37</h6>
<p class='card-text'>One of the predominant methods for training world models is autoregressive
prediction in the output space of the next element of a sequence. In Natural
Language Processing (NLP), this takes the form of Large Language Models (LLMs)
predicting the next token; in Computer Vision (CV), this takes the form of
autoregressive models predicting the next frame/token/pixel. However, this
approach differs from human cognition in several respects. First, human
predictions about the future actively influence internal cognitive processes.
Second, humans naturally evaluate the plausibility of predictions regarding
future states. Based on this capability, and third, by assessing when
predictions are sufficient, humans allocate a dynamic amount of time to make a
prediction. This adaptive process is analogous to System 2 thinking in
psychology. All these capabilities are fundamental to the success of humans at
high-level reasoning and planning. Therefore, to address the limitations of
traditional autoregressive models lacking these human-like capabilities, we
introduce Energy-Based World Models (EBWM). EBWM involves training an
Energy-Based Model (EBM) to predict the compatibility of a given context and a
predicted future state. In doing so, EBWM enables models to achieve all three
facets of human cognition described. Moreover, we developed a variant of the
traditional autoregressive transformer tailored for Energy-Based models, termed
the Energy-Based Transformer (EBT). Our results demonstrate that EBWM scales
better with data and GPU Hours than traditional autoregressive transformers in
CV, and that EBWM offers promising early scaling in NLP. Consequently, this
approach offers an exciting path toward training future models capable of
System 2 thinking and intelligently searching across state spaces.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.07496v1' target='_blank'>TextGrad: Automatic "Differentiation" via Text</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mert Yuksekgonul, Federico Bianchi, Joseph Boen, Sheng Liu, Zhi Huang, Carlos Guestrin, James Zou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-11 17:32:21</h6>
<p class='card-text'>AI is undergoing a paradigm shift, with breakthroughs achieved by systems
orchestrating multiple large language models (LLMs) and other complex
components. As a result, developing principled and automated optimization
methods for compound AI systems is one of the most important new challenges.
Neural networks faced a similar challenge in its early days until
backpropagation and automatic differentiation transformed the field by making
optimization turn-key. Inspired by this, we introduce TextGrad, a powerful
framework performing automatic ``differentiation'' via text. TextGrad
backpropagates textual feedback provided by LLMs to improve individual
components of a compound AI system. In our framework, LLMs provide rich,
general, natural language suggestions to optimize variables in computation
graphs, ranging from code snippets to molecular structures. TextGrad follows
PyTorch's syntax and abstraction and is flexible and easy-to-use. It works
out-of-the-box for a variety of tasks, where the users only provide the
objective function without tuning components or prompts of the framework. We
showcase TextGrad's effectiveness and generality across a diverse range of
applications, from question answering and molecule optimization to radiotherapy
treatment planning. Without modifying the framework, TextGrad improves the
zero-shot accuracy of GPT-4o in Google-Proof Question Answering from $51\%$ to
$55\%$, yields $20\%$ relative performance gain in optimizing LeetCode-Hard
coding problem solutions, improves prompts for reasoning, designs new druglike
small molecules with desirable in silico binding, and designs radiation
oncology treatment plans with high specificity. TextGrad lays a foundation to
accelerate the development of the next-generation of AI systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.07485v1' target='_blank'>PITCH: Productivity and Mental Well-being Coaching through Daily
  Conversational Interaction</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Adnan Abbas, Sang Won Lee</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-11 17:26:58</h6>
<p class='card-text'>Efficient task planning is essential for productivity and mental well-being,
yet individuals often struggle to create realistic plans and reflect upon their
productivity. Leveraging the advancement in artificial intelligence (AI),
conversational agents have emerged as a promising tool for enhancing
productivity. Our work focuses on externalizing plans through conversation,
aiming to solidify intentions and foster focused action, thereby positively
impacting their productivity and mental well-being. We share our plan of
designing a conversational agent to offer insightful questions and reflective
prompts for increasing plan adherence by leveraging the social interactivity of
natural conversations. Previous studies have shown the effectiveness of such
agents, but many interventions remain static, leading to decreased user
engagement over time. To address this limitation, we propose a novel rotation
and context-aware prompting strategy, providing users with varied interventions
daily. Our system, PITCH, utilizes large language models (LLMs) to facilitate
externalization and reflection on daily plans. Through this study, we
investigate the impact of externalizing tasks with conversational agents on
productivity and mental well-being, and the effectiveness of a rotation
strategy in maintaining user engagement.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.07296v1' target='_blank'>Instruct Large Language Models to Drive like Humans</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ruijun Zhang, Xianda Guo, Wenzhao Zheng, Chenming Zhang, Kurt Keutzer, Long Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-11 14:24:45</h6>
<p class='card-text'>Motion planning in complex scenarios is the core challenge in autonomous
driving. Conventional methods apply predefined rules or learn from driving data
to plan the future trajectory. Recent methods seek the knowledge preserved in
large language models (LLMs) and apply them in the driving scenarios. Despite
the promising results, it is still unclear whether the LLM learns the
underlying human logic to drive. In this paper, we propose an InstructDriver
method to transform LLM into a motion planner with explicit instruction tuning
to align its behavior with humans. We derive driving instruction data based on
human logic (e.g., do not cause collisions) and traffic rules (e.g., proceed
only when green lights). We then employ an interpretable InstructChain module
to further reason the final planning reflecting the instructions. Our
InstructDriver allows the injection of human rules and learning from driving
data, enabling both interpretability and data scalability. Different from
existing methods that experimented on closed-loop or simulated settings, we
adopt the real-world closed-loop motion planning nuPlan benchmark for better
evaluation. InstructDriver demonstrates the effectiveness of the LLM planner in
a real-world closed-loop setting. Our code is publicly available at
https://github.com/bonbon-rj/InstructDriver.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.07115v1' target='_blank'>Advancing Tool-Augmented Large Language Models: Integrating Insights
  from Errors in Inference Trees</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sijia Chen, Yibo Wang, Yi-Feng Wu, Qing-Guo Chen, Zhao Xu, Weihua Luo, Kaifu Zhang, Lijun Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-11 10:00:18</h6>
<p class='card-text'>Tool-augmented large language models (LLMs) leverage tools, often in the form
of APIs, to enhance their reasoning capabilities on complex tasks, thus taking
on the role of intelligent agents interacting with the real world. The recently
introduced ToolLLaMA model by Qin et al. [2024] utilizes the depth-first
search-based decision tree (DFSDT) method for reasoning with $16000+$
real-world APIs, which effectively improves the planning and inferencing
performance of tool-augmented LLMs compared to traditional chain reasoning
approaches. However, their approach only employs successful paths from decision
trees (also called inference trees) for supervised fine-tuning (SFT) during
training, which does not fully exploit the advantages of the tree of thought.
In this study, we propose an inference trajectory optimization framework based
on the preference data extracted from decision trees to address this
limitation. We first introduce a novel method for constructing preference data
from the tree of thought, capitalizing on the failed explorations previously
overlooked in the trees. Specifically, we generate an effective step-wise
preference dataset, named ToolPreference, for tool use based on the ToolBench
dataset. In the subsequent training phase, we first fine-tune the LLM with
tool-usage expert trajectories and then use these step-wise preference pairs
for direct preference optimization (DPO) to update the policy of the LLM,
resulting in our ToolPrefer-LLaMA (TP-LLaMA) model. Our experiments demonstrate
that by obtaining insights from errors in inference trees, TP-LLaMA
significantly outperforms the baselines across almost all test scenarios by a
large margin and exhibits better generalization capabilities with unseen APIs.
At the same time, TP-LLaMA has also demonstrated superior reasoning efficiency
compared to the baselines, making it more suitable for complex tool-usage
reasoning tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.07025v1' target='_blank'>Entropy-Reinforced Planning with Large Language Models for Drug
  Discovery</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xuefeng Liu, Chih-chan Tien, Peng Ding, Songhao Jiang, Rick L. Stevens</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-11 07:29:13</h6>
<p class='card-text'>The objective of drug discovery is to identify chemical compounds that
possess specific pharmaceutical properties toward a binding target. Existing
large language models (LLMS) can achieve high token matching scores in terms of
likelihood for molecule generation. However, relying solely on LLM decoding
often results in the generation of molecules that are either invalid due to a
single misused token, or suboptimal due to unbalanced exploration and
exploitation as a consequence of the LLMs prior experience. Here we propose
ERP, Entropy-Reinforced Planning for Transformer Decoding, which employs an
entropy-reinforced planning algorithm to enhance the Transformer decoding
process and strike a balance between exploitation and exploration. ERP aims to
achieve improvements in multiple properties compared to direct sampling from
the Transformer. We evaluated ERP on the SARS-CoV-2 virus (3CLPro) and human
cancer cell target protein (RTCB) benchmarks and demonstrated that, in both
benchmarks, ERP consistently outperforms the current state-of-the-art algorithm
by 1-5 percent, and baselines by 5-10 percent, respectively. Moreover, such
improvement is robust across Transformer models trained with different
objectives. Finally, to further illustrate the capabilities of ERP, we tested
our algorithm on three code generation benchmarks and outperformed the current
state-of-the-art approach as well. Our code is publicly available at:
https://github.com/xuefeng-cs/ERP.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.06947v3' target='_blank'>CAAP: Context-Aware Action Planning Prompting to Solve Computer Tasks
  with Front-End UI Only</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Junhee Cho, Jihoon Kim, Daseul Bae, Jinho Choo, Youngjune Gwon, Yeong-Dae Kwon</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-11 05:21:20</h6>
<p class='card-text'>Software robots have long been used in Robotic Process Automation (RPA) to
automate mundane and repetitive computer tasks. With the advent of Large
Language Models (LLMs) and their advanced reasoning capabilities, these agents
are now able to handle more complex or previously unseen tasks. However,
LLM-based automation techniques in recent literature frequently rely on HTML
source code for input or application-specific API calls for actions, limiting
their applicability to specific environments. We propose an LLM-based agent
that mimics human behavior in solving computer tasks. It perceives its
environment solely through screenshot images, which are then converted into
text for an LLM to process. By leveraging the reasoning capability of the LLM,
we eliminate the need for large-scale human demonstration data typically
required for model training. The agent only executes keyboard and mouse
operations on Graphical User Interface (GUI), removing the need for
pre-provided APIs to function. To further enhance the agent's performance in
this setting, we propose a novel prompting strategy called Context-Aware Action
Planning (CAAP) prompting, which enables the agent to thoroughly examine the
task context from multiple perspectives. Our agent achieves an average success
rate of 94.5% on MiniWoB++ and an average task score of 62.3 on WebShop,
outperforming all previous studies of agents that rely solely on screen images.
This method demonstrates potential for broader applications, particularly for
tasks requiring coordination across multiple applications on desktops or
smartphones, marking a significant advancement in the field of automation
agents. Codes and models are accessible at
https://github.com/caap-agent/caap-agent.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.06485v1' target='_blank'>Can Language Models Serve as Text-Based World Simulators?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ruoyao Wang, Graham Todd, Ziang Xiao, Xingdi Yuan, Marc-Alexandre Côté, Peter Clark, Peter Jansen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-10 17:24:44</h6>
<p class='card-text'>Virtual environments play a key role in benchmarking advances in complex
planning and decision-making tasks but are expensive and complicated to build
by hand. Can current language models themselves serve as world simulators,
correctly predicting how actions change different world states, thus bypassing
the need for extensive manual coding? Our goal is to answer this question in
the context of text-based simulators. Our approach is to build and use a new
benchmark, called ByteSized32-State-Prediction, containing a dataset of text
game state transitions and accompanying game tasks. We use this to directly
quantify, for the first time, how well LLMs can serve as text-based world
simulators. We test GPT-4 on this dataset and find that, despite its impressive
performance, it is still an unreliable world simulator without further
innovations. This work thus contributes both new insights into current LLM's
capabilities and weaknesses, as well as a novel benchmark to track future
progress as new models appear.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.06379v1' target='_blank'>FinVerse: An Autonomous Agent System for Versatile Financial Analysis</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Siyu An, Qin Li, Junru Lu, Di Yin, Xing Sun</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-10 15:40:23</h6>
<p class='card-text'>With the significant advancements in cognitive intelligence driven by LLMs,
autonomous agent systems have attracted extensive attention. Despite this
growing interest, the development of stable and efficient agent systems poses
substantial practical challenges. In this paper, we introduce FinVerse, a
meticulously crafted agent system designed for a broad range of financial
topics. FinVerse integrates over 600 financial APIs, enabling access to more
accurate and extensive financial information compared to generalist agents. To
enhance financial information processing capabilities, FinVerse is equipped
with an embedded code interpreter, enabling the execution of complex data
analysis tasks with precision and efficiency. Our work includes an empirical
comparison of several LLMs in driving FinVerse. Specifically, we propose our
own scheme for training LLMs using SFT to optimize LLM performance within
FinVerse. Recognizing the scarcity of specialized datasets to build LLMs for
agents, we have constructed a dataset and plan to make it open-source,
providing a valuable resource for peer application developers. The demo video
has been released on YouTube at https://www.youtube.com/watch?v=sk8L9_Wv7J4</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.05804v6' target='_blank'>A Review of Prominent Paradigms for LLM-Based Agents: Tool Use
  (Including RAG), Planning, and Feedback Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xinzhe Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-09 14:42:55</h6>
<p class='card-text'>Tool use, planning, and feedback learning are currently three prominent
paradigms for developing Large Language Model (LLM)-based agents across various
tasks. Although numerous frameworks have been devised for each paradigm, their
intricate workflows and inconsistent taxonomy create challenges in
understanding and reviewing the frameworks across different paradigms. This
survey introduces a unified taxonomy to systematically review and discuss these
frameworks. Specifically, 1) the taxonomy defines environments/tasks, common
LLM-profiled roles or LMPRs (policy models, evaluators, and dynamic models),
and universally applicable workflows found in prior work, and 2) it enables a
comparison of key perspectives on the implementations of LMPRs and workflow
designs across different agent paradigms and frameworks. 3) Finally, we
identify three limitations in existing workflow designs and systematically
discuss the future work. Resources have been made publicly available at in our
GitHub repository https://github.com/xinzhel/LLM-Agent-Survey.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.10249v1' target='_blank'>A Reality check of the benefits of LLM in business</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ming Cheung</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-09 02:36:00</h6>
<p class='card-text'>Large language models (LLMs) have achieved remarkable performance in language
understanding and generation tasks by leveraging vast amounts of online texts.
Unlike conventional models, LLMs can adapt to new domains through prompt
engineering without the need for retraining, making them suitable for various
business functions, such as strategic planning, project implementation, and
data-driven decision-making. However, their limitations in terms of bias,
contextual understanding, and sensitivity to prompts raise concerns about their
readiness for real-world applications. This paper thoroughly examines the
usefulness and readiness of LLMs for business processes. The limitations and
capacities of LLMs are evaluated through experiments conducted on four
accessible LLMs using real-world data. The findings have significant
implications for organizations seeking to leverage generative AI and provide
valuable insights into future research directions. To the best of our
knowledge, this represents the first quantified study of LLMs applied to core
business operations and challenges.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.05590v3' target='_blank'>NYU CTF Bench: A Scalable Open-Source Benchmark Dataset for Evaluating
  LLMs in Offensive Security</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Minghao Shao, Sofija Jancheska, Meet Udeshi, Brendan Dolan-Gavitt, Haoran Xi, Kimberly Milner, Boyuan Chen, Max Yin, Siddharth Garg, Prashanth Krishnamurthy, Farshad Khorrami, Ramesh Karri, Muhammad Shafique</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-08 22:21:42</h6>
<p class='card-text'>Large Language Models (LLMs) are being deployed across various domains today.
However, their capacity to solve Capture the Flag (CTF) challenges in
cybersecurity has not been thoroughly evaluated. To address this, we develop a
novel method to assess LLMs in solving CTF challenges by creating a scalable,
open-source benchmark database specifically designed for these applications.
This database includes metadata for LLM testing and adaptive learning,
compiling a diverse range of CTF challenges from popular competitions.
Utilizing the advanced function calling capabilities of LLMs, we build a fully
automated system with an enhanced workflow and support for external tool calls.
Our benchmark dataset and automated framework allow us to evaluate the
performance of five LLMs, encompassing both black-box and open-source models.
This work lays the foundation for future research into improving the efficiency
of LLMs in interactive cybersecurity tasks and automated task planning. By
providing a specialized benchmark, our project offers an ideal platform for
developing, testing, and refining LLM-based approaches to vulnerability
detection and resolution. Evaluating LLMs on these challenges and comparing
with human performance yields insights into their potential for AI-driven
cybersecurity solutions to perform real-world threat management. We make our
benchmark dataset open source to public
https://github.com/NYU-LLM-CTF/NYU_CTF_Bench along with our playground
automated framework https://github.com/NYU-LLM-CTF/llm_ctf_automation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.05572v2' target='_blank'>Trust the PRoC3S: Solving Long-Horizon Robotics Problems with LLMs and
  Constraint Satisfaction</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Aidan Curtis, Nishanth Kumar, Jing Cao, Tomás Lozano-Pérez, Leslie Pack Kaelbling</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-08 20:56:14</h6>
<p class='card-text'>Recent developments in pretrained large language models (LLMs) applied to
robotics have demonstrated their capacity for sequencing a set of discrete
skills to achieve open-ended goals in simple robotic tasks. In this paper, we
examine the topic of LLM planning for a set of continuously parameterized
skills whose execution must avoid violations of a set of kinematic, geometric,
and physical constraints. We prompt the LLM to output code for a function with
open parameters, which, together with environmental constraints, can be viewed
as a Continuous Constraint Satisfaction Problem (CCSP). This CCSP can be solved
through sampling or optimization to find a skill sequence and continuous
parameter settings that achieve the goal while avoiding constraint violations.
Additionally, we consider cases where the LLM proposes unsatisfiable CCSPs,
such as those that are kinematically infeasible, dynamically unstable, or lead
to collisions, and re-prompt the LLM to form a new CCSP accordingly.
Experiments across three different simulated 3D domains demonstrate that our
proposed strategy, PRoC3S, is capable of solving a wide range of complex
manipulation tasks with realistic constraints on continuous parameters much
more efficiently and effectively than existing baselines.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.05506v2' target='_blank'>Towards a Benchmark for Causal Business Process Reasoning with LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Fabiana Fournier, Lior Limonad, Inna Skarbovsky</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-08 16:10:53</h6>
<p class='card-text'>Large Language Models (LLMs) are increasingly used for boosting
organizational efficiency and automating tasks. While not originally designed
for complex cognitive processes, recent efforts have further extended to employ
LLMs in activities such as reasoning, planning, and decision-making. In
business processes, such abilities could be invaluable for leveraging on the
massive corpora LLMs have been trained on for gaining deep understanding of
such processes. In this work, we plant the seeds for the development of a
benchmark to assess the ability of LLMs to reason about causal and process
perspectives of business operations. We refer to this view as
Causally-augmented Business Processes (BP^C). The core of the benchmark
comprises a set of BP^C related situations, a set of questions about these
situations, and a set of deductive rules employed to systematically resolve the
ground truth answers to these questions. Also with the power of LLMs, the seed
is then instantiated into a larger-scale set of domain-specific situations and
questions. Reasoning on BP^C is of crucial importance for process interventions
and process improvement. Our benchmark, accessible at
https://huggingface.co/datasets/ibm/BPC, can be used in one of two possible
modalities: testing the performance of any target LLM and training an LLM to
advance its capability to reason about BP^C.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.05374v1' target='_blank'>Planning Like Human: A Dual-process Framework for Dialogue Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tao He, Lizi Liao, Yixin Cao, Yuanxing Liu, Ming Liu, Zerui Chen, Bing Qin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-08 06:52:47</h6>
<p class='card-text'>In proactive dialogue, the challenge lies not just in generating responses
but in steering conversations toward predetermined goals, a task where Large
Language Models (LLMs) typically struggle due to their reactive nature.
Traditional approaches to enhance dialogue planning in LLMs, ranging from
elaborate prompt engineering to the integration of policy networks, either face
efficiency issues or deliver suboptimal performance. Inspired by the
dualprocess theory in psychology, which identifies two distinct modes of
thinking - intuitive (fast) and analytical (slow), we propose the Dual-Process
Dialogue Planning (DPDP) framework. DPDP embodies this theory through two
complementary planning systems: an instinctive policy model for familiar
contexts and a deliberative Monte Carlo Tree Search (MCTS) mechanism for
complex, novel scenarios. This dual strategy is further coupled with a novel
two-stage training regimen: offline Reinforcement Learning for robust initial
policy model formation followed by MCTS-enhanced on-the-fly learning, which
ensures a dynamic balance between efficiency and strategic depth. Our empirical
evaluations across diverse dialogue tasks affirm DPDP's superiority in
achieving both high-quality dialogues and operational efficiency, outpacing
existing methods.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.04983v1' target='_blank'>CityCraft: A Real Crafter for 3D City Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jie Deng, Wenhao Chai, Junsheng Huang, Zhonghan Zhao, Qixuan Huang, Mingyan Gao, Jianshu Guo, Shengyu Hao, Wenhao Hu, Jenq-Neng Hwang, Xi Li, Gaoang Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-07 14:49:00</h6>
<p class='card-text'>City scene generation has gained significant attention in autonomous driving,
smart city development, and traffic simulation. It helps enhance infrastructure
planning and monitoring solutions. Existing methods have employed a two-stage
process involving city layout generation, typically using Variational
Autoencoders (VAEs), Generative Adversarial Networks (GANs), or Transformers,
followed by neural rendering. These techniques often exhibit limited diversity
and noticeable artifacts in the rendered city scenes. The rendered scenes lack
variety, resembling the training images, resulting in monotonous styles.
Additionally, these methods lack planning capabilities, leading to less
realistic generated scenes. In this paper, we introduce CityCraft, an
innovative framework designed to enhance both the diversity and quality of
urban scene generation. Our approach integrates three key stages: initially, a
diffusion transformer (DiT) model is deployed to generate diverse and
controllable 2D city layouts. Subsequently, a Large Language Model(LLM) is
utilized to strategically make land-use plans within these layouts based on
user prompts and language guidelines. Based on the generated layout and city
plan, we utilize the asset retrieval module and Blender for precise asset
placement and scene construction. Furthermore, we contribute two new datasets
to the field: 1)CityCraft-OSM dataset including 2D semantic layouts of urban
areas, corresponding satellite images, and detailed annotations. 2)
CityCraft-Buildings dataset, featuring thousands of diverse, high-quality 3D
building assets. CityCraft achieves state-of-the-art performance in generating
realistic 3D cities.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.04594v1' target='_blank'>Boosting Large-scale Parallel Training Efficiency with C4: A
  Communication-Driven Approach</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jianbo Dong, Bin Luo, Jun Zhang, Pengcheng Zhang, Fei Feng, Yikai Zhu, Ang Liu, Zian Chen, Yi Shi, Hairong Jiao, Gang Lu, Yu Guan, Ennan Zhai, Wencong Xiao, Hanyu Zhao, Man Yuan, Siran Yang, Xiang Li, Jiamang Wang, Rui Men, Jianwei Zhang, Huang Zhong, Dennis Cai, Yuan Xie, Binzhang Fu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-07 02:58:35</h6>
<p class='card-text'>The emergence of Large Language Models (LLMs) has necessitated the adoption
of parallel training techniques, involving the deployment of thousands of GPUs
to train a single model. Unfortunately, we have found that the efficiency of
current parallel training is often suboptimal, largely due to the following two
main issues. Firstly, hardware failures are inevitable, leading to
interruptions in the training tasks. The inability to quickly identify the
faulty components results in a substantial waste of GPU resources. Secondly,
since GPUs must wait for parameter synchronization to complete before
proceeding to the next round of computation, network congestions can greatly
increase the waiting time for GPUs. To address these challenges, this paper
introduces a communication-driven solution, namely the C4. The key insights of
C4 are two folds. First, in parallel training, collective communication
exhibits periodic and homogeneous characteristics, so any anomalies are
certainly due to some form of hardware malfunction. By leveraging this feature,
C4 can rapidly identify the faulty components, swiftly isolate the anomaly, and
restart the task, thereby avoiding resource wastage caused by delays in anomaly
detection. Second, the predictable communication model of collective
communication, involving few large flows, allows C4 to efficiently execute
traffic planning, substantially reducing network congestion. C4 has been
extensively implemented across our production systems, cutting error-induced
overhead by roughly 30% and enhancing runtime performance by about 15% for
certain applications with moderate communication costs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.06613v2' target='_blank'>GameBench: Evaluating Strategic Reasoning Abilities of LLM Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Anthony Costarelli, Mat Allen, Roman Hauksson, Grace Sodunke, Suhas Hariharan, Carlson Cheng, Wenjie Li, Joshua Clymer, Arjun Yadav</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-07 00:28:43</h6>
<p class='card-text'>Large language models have demonstrated remarkable few-shot performance on
many natural language understanding tasks. Despite several demonstrations of
using large language models in complex, strategic scenarios, there lacks a
comprehensive framework for evaluating agents' performance across various types
of reasoning found in games. To address this gap, we introduce GameBench, a
cross-domain benchmark for evaluating strategic reasoning abilities of LLM
agents. We focus on 9 different game environments, where each covers at least
one axis of key reasoning skill identified in strategy games, and select games
for which strategy explanations are unlikely to form a significant portion of
models' pretraining corpuses. Our evaluations use GPT-3 and GPT-4 in their base
form along with two scaffolding frameworks designed to enhance strategic
reasoning ability: Chain-of-Thought (CoT) prompting and Reasoning Via Planning
(RAP). Our results show that none of the tested models match human performance,
and at worst GPT-4 performs worse than random action. CoT and RAP both improve
scores but not comparable to human levels.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.04520v1' target='_blank'>NATURAL PLAN: Benchmarking LLMs on Natural Language Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Huaixiu Steven Zheng, Swaroop Mishra, Hugh Zhang, Xinyun Chen, Minmin Chen, Azade Nova, Le Hou, Heng-Tze Cheng, Quoc V. Le, Ed H. Chi, Denny Zhou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-06 21:27:35</h6>
<p class='card-text'>We introduce NATURAL PLAN, a realistic planning benchmark in natural language
containing 3 key tasks: Trip Planning, Meeting Planning, and Calendar
Scheduling. We focus our evaluation on the planning capabilities of LLMs with
full information on the task, by providing outputs from tools such as Google
Flights, Google Maps, and Google Calendar as contexts to the models. This
eliminates the need for a tool-use environment for evaluating LLMs on Planning.
We observe that NATURAL PLAN is a challenging benchmark for state of the art
models. For example, in Trip Planning, GPT-4 and Gemini 1.5 Pro could only
achieve 31.1% and 34.8% solve rate respectively. We find that model performance
drops drastically as the complexity of the problem increases: all models
perform below 5% when there are 10 cities, highlighting a significant gap in
planning in natural language for SoTA LLMs. We also conduct extensive ablation
studies on NATURAL PLAN to further shed light on the (in)effectiveness of
approaches such as self-correction, few-shot generalization, and in-context
planning with long-contexts on improving LLM planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.03866v1' target='_blank'>LLplace: The 3D Indoor Scene Layout Generation and Editing via Large
  Language Model</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yixuan Yang, Junru Lu, Zixiang Zhao, Zhen Luo, James J. Q. Yu, Victor Sanchez, Feng Zheng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-06 08:53:01</h6>
<p class='card-text'>Designing 3D indoor layouts is a crucial task with significant applications
in virtual reality, interior design, and automated space planning. Existing
methods for 3D layout design either rely on diffusion models, which utilize
spatial relationship priors, or heavily leverage the inferential capabilities
of proprietary Large Language Models (LLMs), which require extensive prompt
engineering and in-context exemplars via black-box trials. These methods often
face limitations in generalization and dynamic scene editing. In this paper, we
introduce LLplace, a novel 3D indoor scene layout designer based on lightweight
fine-tuned open-source LLM Llama3. LLplace circumvents the need for spatial
relationship priors and in-context exemplars, enabling efficient and credible
room layout generation based solely on user inputs specifying the room type and
desired objects. We curated a new dialogue dataset based on the 3D-Front
dataset, expanding the original data volume and incorporating dialogue data for
adding and removing objects. This dataset can enhance the LLM's spatial
understanding. Furthermore, through dialogue, LLplace activates the LLM's
capability to understand 3D layouts and perform dynamic scene editing, enabling
the addition and removal of objects. Our approach demonstrates that LLplace can
effectively generate and edit 3D indoor layouts interactively and outperform
existing methods in delivering high-quality 3D design solutions. Code and
dataset will be released.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.03816v3' target='_blank'>ReST-MCTS*: LLM Self-Training via Process Reward Guided Tree Search</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Dan Zhang, Sining Zhoubian, Ziniu Hu, Yisong Yue, Yuxiao Dong, Jie Tang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-06 07:40:00</h6>
<p class='card-text'>Recent methodologies in LLM self-training mostly rely on LLM generating
responses and filtering those with correct output answers as training data.
This approach often yields a low-quality fine-tuning training set (e.g.,
incorrect plans or intermediate reasoning). In this paper, we develop a
reinforced self-training approach, called ReST-MCTS*, based on integrating
process reward guidance with tree search MCTS* for collecting higher-quality
reasoning traces as well as per-step value to train policy and reward models.
ReST-MCTS* circumvents the per-step manual annotation typically used to train
process rewards by tree-search-based reinforcement learning: Given oracle final
correct answers, ReST-MCTS* is able to infer the correct process rewards by
estimating the probability this step can help lead to the correct answer. These
inferred rewards serve dual purposes: they act as value targets for further
refining the process reward model and also facilitate the selection of
high-quality traces for policy model self-training. We first show that the
tree-search policy in ReST-MCTS* achieves higher accuracy compared with prior
LLM reasoning baselines such as Best-of-N and Tree-of-Thought, within the same
search budget. We then show that by using traces searched by this tree-search
policy as training data, we can continuously enhance the three language models
for multiple iterations, and outperform other self-training algorithms such as
ReST$^\text{EM}$ and Self-Rewarding LM. We release all code at
https://github.com/THUDM/ReST-MCTS.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.03807v2' target='_blank'>Tool-Planner: Task Planning with Clusters across Multiple Tools</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yanming Liu, Xinyue Peng, Jiannan Cao, Shi Bo, Yuwei Zhang, Xuhong Zhang, Sheng Cheng, Xun Wang, Jianwei Yin, Tianyu Du</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-06 07:30:14</h6>
<p class='card-text'>Large language models (LLMs) have demonstrated exceptional reasoning
capabilities, enabling them to solve various complex problems. Recently, this
ability has been applied to the paradigm of tool learning. Tool learning
involves providing examples of tool usage and their corresponding functions,
allowing LLMs to formulate plans and demonstrate the process of invoking and
executing each tool. LLMs can address tasks that they cannot complete
independently, thereby enhancing their potential across different tasks.
However, this approach faces two key challenges. First, redundant error
correction leads to unstable planning and long execution time. Additionally,
designing a correct plan among multiple tools is also a challenge in tool
learning. To address these issues, we propose Tool-Planner, a task-processing
framework based on toolkits. Tool-Planner groups tools based on the API
functions with the same function into a toolkit and allows LLMs to implement
planning across the various toolkits. When a tool error occurs, the language
model can reselect and adjust tools based on the toolkit. Experiments show that
our approach demonstrates a high pass and win rate across different datasets
and optimizes the planning scheme for tool learning in models such as GPT-4 and
Claude 3, showcasing the potential of our method. Our code is public at
\url{https://github.com/OceannTwT/Tool-Planner}</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.03367v1' target='_blank'>CLMASP: Coupling Large Language Models with Answer Set Programming for
  Robotic Task Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xinrui Lin, Yangfan Wu, Huanyu Yang, Yu Zhang, Yanyong Zhang, Jianmin Ji</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-05 15:21:44</h6>
<p class='card-text'>Large Language Models (LLMs) possess extensive foundational knowledge and
moderate reasoning abilities, making them suitable for general task planning in
open-world scenarios. However, it is challenging to ground a LLM-generated plan
to be executable for the specified robot with certain restrictions. This paper
introduces CLMASP, an approach that couples LLMs with Answer Set Programming
(ASP) to overcome the limitations, where ASP is a non-monotonic logic
programming formalism renowned for its capacity to represent and reason about a
robot's action knowledge. CLMASP initiates with a LLM generating a basic
skeleton plan, which is subsequently tailored to the specific scenario using a
vector database. This plan is then refined by an ASP program with a robot's
action knowledge, which integrates implementation details into the skeleton,
grounding the LLM's abstract outputs in practical robot contexts. Our
experiments conducted on the VirtualHome platform demonstrate CLMASP's
efficacy. Compared to the baseline executable rate of under 2% with LLM
approaches, CLMASP significantly improves this to over 90%.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.02903v1' target='_blank'>Open Grounded Planning: Challenges and Benchmark Construction</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shiguang Guo, Ziliang Deng, Hongyu Lin, Yaojie Lu, Xianpei Han, Le Sun</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-05 03:46:52</h6>
<p class='card-text'>The emergence of large language models (LLMs) has increasingly drawn
attention to the use of LLMs for human-like planning. Existing work on
LLM-based planning either focuses on leveraging the inherent language
generation capabilities of LLMs to produce free-style plans, or employs
reinforcement learning approaches to learn decision-making for a limited set of
actions within restricted environments. However, both approaches exhibit
significant discrepancies from the open and executable requirements in
real-world planning. In this paper, we propose a new planning task--open
grounded planning. The primary objective of open grounded planning is to ask
the model to generate an executable plan based on a variable action set,
thereby ensuring the executability of the produced plan. To this end, we
establishes a benchmark for open grounded planning spanning a wide range of
domains. Then we test current state-of-the-art LLMs along with five planning
approaches, revealing that existing LLMs and methods still struggle to address
the challenges posed by grounded planning in open domains. The outcomes of this
paper define and establish a foundational dataset for open grounded planning,
and shed light on the potential challenges and future directions of LLM-based
planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.02791v2' target='_blank'>Language Models can Infer Action Semantics for Symbolic Planners from
  Environment Feedback</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wang Zhu, Ishika Singh, Robin Jia, Jesse Thomason</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-04 21:29:56</h6>
<p class='card-text'>Symbolic planners can discover a sequence of actions from initial to goal
states given expert-defined, domain-specific logical action semantics. Large
Language Models (LLMs) can directly generate such sequences, but limitations in
reasoning and state-tracking often result in plans that are insufficient or
unexecutable. We propose Predicting Semantics of Actions with Language Models
(PSALM), which automatically learns action semantics by leveraging the
strengths of both symbolic planners and LLMs. PSALM repeatedly proposes and
executes plans, using the LLM to partially generate plans and to infer
domain-specific action semantics based on execution outcomes. PSALM maintains a
belief over possible action semantics that is iteratively updated until a goal
state is reached. Experiments on 7 environments show that when learning just
from one goal, PSALM boosts plan success rate from 36.4% (on Claude-3.5) to
100%, and explores the environment more efficiently than prior work to infer
ground truth domain action semantics.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.02746v5' target='_blank'>RATT: A Thought Structure for Coherent and Correct LLM Reasoning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jinghan Zhang, Xiting Wang, Weijieying Ren, Lu Jiang, Dongjie Wang, Kunpeng Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-04 20:02:52</h6>
<p class='card-text'>Large Language Models (LLMs) gain substantial reasoning and decision-making
capabilities from thought structures. However, existing methods such as Tree of
Thought and Retrieval Augmented Thoughts often fall short in complex tasks due
to the limitations of insufficient local retrieval of factual knowledge and
inadequate global selection of strategies. These limitations make it
challenging for these methods to balance factual accuracy and comprehensive
logical optimization effectively. To address these limitations, we introduce
the Retrieval Augmented Thought Tree (RATT), a novel thought structure that
considers both overall logical soundness and factual correctness at each step
of the thinking process. Specifically, at every point of a thought branch, RATT
performs planning and lookahead to explore and evaluate multiple potential
reasoning steps, and integrate the fact-checking ability of Retrieval-Augmented
Generation (RAG) with LLM's ability to assess overall strategy. Through this
combination of factual knowledge and strategic feasibility, the RATT adjusts
and integrates the thought tree structure to search for the most promising
branches within the search space. This thought structure significantly enhances
the model's coherence in logical inference and efficiency in decision-making,
and thus increases the limit of the capacity of LLM to generate reliable
inferences and decisions based on thought structures. A broad range of
experiments on different types of tasks showcases that the RATT structure
significantly outperforms existing methods in factual correctness and logical
coherence.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.01422v1' target='_blank'>How to Understand Whole Software Repository?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yingwei Ma, Qingping Yang, Rongyu Cao, Binhua Li, Fei Huang, Yongbin Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-03 15:20:06</h6>
<p class='card-text'>Recently, Large Language Model (LLM) based agents have advanced the
significant development of Automatic Software Engineering (ASE). Although
verified effectiveness, the designs of the existing methods mainly focus on the
local information of codes, e.g., issues, classes, and functions, leading to
limitations in capturing the global context and interdependencies within the
software system. From the practical experiences of the human SE developers, we
argue that an excellent understanding of the whole repository will be the
critical path to ASE. However, understanding the whole repository raises
various challenges, e.g., the extremely long code input, the noisy code
information, the complex dependency relationships, etc. To this end, we develop
a novel ASE method named RepoUnderstander by guiding agents to comprehensively
understand the whole repositories. Specifically, we first condense the critical
information of the whole repository into the repository knowledge graph in a
top-to-down mode to decrease the complexity of repository. Subsequently, we
empower the agents the ability of understanding whole repository by proposing a
Monte Carlo tree search based repository exploration strategy. In addition, to
better utilize the repository-level knowledge, we guide the agents to
summarize, analyze, and plan. Then, they can manipulate the tools to
dynamically acquire information and generate the patches to solve the
real-world GitHub issues. Extensive experiments demonstrate the superiority and
effectiveness of the proposed RepoUnderstander. It achieved 18.5\% relative
improvement on the SWE-bench Lite benchmark compared to SWE-agent.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.01238v3' target='_blank'>EffiQA: Efficient Question-Answering with Strategic Multi-Model
  Collaboration on Knowledge Graphs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zixuan Dong, Baoyun Peng, Yufei Wang, Jia Fu, Xiaodong Wang, Yongxue Shan, Xin Zhou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-03 11:56:07</h6>
<p class='card-text'>While large language models (LLMs) have shown remarkable capabilities in
natural language processing, they struggle with complex, multi-step reasoning
tasks involving knowledge graphs (KGs). Existing approaches that integrate LLMs
and KGs either underutilize the reasoning abilities of LLMs or suffer from
prohibitive computational costs due to tight coupling. To address these
limitations, we propose a novel collaborative framework named EffiQA that can
strike a balance between performance and efficiency via an iterative paradigm.
EffiQA consists of three stages: global planning, efficient KG exploration, and
self-reflection. Specifically, EffiQA leverages the commonsense capability of
LLMs to explore potential reasoning pathways through global planning. Then, it
offloads semantic pruning to a small plug-in model for efficient KG
exploration. Finally, the exploration results are fed to LLMs for
self-reflection to further improve the global planning and efficient KG
exploration. Empirical evidence on multiple KBQA benchmarks shows EffiQA's
effectiveness, achieving an optimal balance between reasoning accuracy and
computational costs. We hope the proposed new framework will pave the way for
efficient, knowledge-intensive querying by redefining the integration of LLMs
and KGs, fostering future research on knowledge-based question answering.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.06566v4' target='_blank'>Natural Language Interaction with a Household Electricity
  Knowledge-based Digital Twin</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Carolina Fortuna, Vid Hanžel, Blaž Bertalanič</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-03 07:44:32</h6>
<p class='card-text'>Domain specific digital twins, representing a digital replica of various
segments of the smart grid, are foreseen as able to model, simulate, and
control the respective segments. At the same time, knowledge-based digital
twins, coupled with AI, may also empower humans to understand aspects of the
system through natural language interaction in view of planning and policy
making. This paper is the first to assess and report on the potential of
Retrieval Augmented Generation (RAG) question answers related to household
electrical energy measurement aspects leveraging a knowledge-based energy
digital twin. Relying on the recently published electricity consumption
knowledge graph that actually represents a knowledge-based digital twin, we
study the capabilities of ChatGPT, Gemini and Llama in answering electricity
related questions. Furthermore, we compare the answers with the ones generated
through a RAG techniques that leverages an existing electricity knowledge-based
digital twin. Our findings illustrate that the RAG approach not only reduces
the incidence of incorrect information typically generated by LLMs but also
significantly improves the quality of the output by grounding responses in
verifiable data. This paper details our methodology, presents a comparative
analysis of responses with and without RAG, and discusses the implications of
our findings for future applications of AI in specialized sectors like energy
data analysis.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.00965v4' target='_blank'>HBTP: Heuristic Behavior Tree Planning with Large Language Model
  Reasoning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yishuai Cai, Xinglin Chen, Yunxin Mao, Minglong Li, Shaowu Yang, Wenjing Yang, Ji Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-03 03:38:56</h6>
<p class='card-text'>Behavior Trees (BTs) are increasingly becoming a popular control structure in
robotics due to their modularity, reactivity, and robustness. In terms of BT
generation methods, BT planning shows promise for generating reliable BTs.
However, the scalability of BT planning is often constrained by prolonged
planning times in complex scenarios, largely due to a lack of domain knowledge.
In contrast, pre-trained Large Language Models (LLMs) have demonstrated task
reasoning capabilities across various domains, though the correctness and
safety of their planning remain uncertain. This paper proposes integrating BT
planning with LLM reasoning, introducing Heuristic Behavior Tree Planning
(HBTP)-a reliable and efficient framework for BT generation. The key idea in
HBTP is to leverage LLMs for task-specific reasoning to generate a heuristic
path, which BT planning can then follow to expand efficiently. We first
introduce the heuristic BT expansion process, along with two heuristic variants
designed for optimal planning and satisficing planning, respectively. Then, we
propose methods to address the inaccuracies of LLM reasoning, including action
space pruning and reflective feedback, to further enhance both reasoning
accuracy and planning efficiency. Experiments demonstrate the theoretical
bounds of HBTP, and results from four datasets confirm its practical
effectiveness in everyday service robot applications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.00936v1' target='_blank'>A Survey of Useful LLM Evaluation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ji-Lun Peng, Sijia Cheng, Egil Diau, Yung-Yu Shih, Po-Heng Chen, Yen-Ting Lin, Yun-Nung Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-03 02:20:03</h6>
<p class='card-text'>LLMs have gotten attention across various research domains due to their
exceptional performance on a wide range of complex tasks. Therefore, refined
methods to evaluate the capabilities of LLMs are needed to determine the tasks
and responsibility they should undertake. Our study mainly discussed how LLMs,
as useful tools, should be effectively assessed. We proposed the two-stage
framework: from ``core ability'' to ``agent'', clearly explaining how LLMs can
be applied based on their specific capabilities, along with the evaluation
methods in each stage. Core ability refers to the capabilities that LLMs need
in order to generate high-quality natural language texts. After confirming LLMs
possess core ability, they can solve real-world and complex tasks as agent. In
the "core ability" stage, we discussed the reasoning ability, societal impact,
and domain knowledge of LLMs. In the ``agent'' stage, we demonstrated embodied
action, planning, and tool learning of LLMs agent applications. Finally, we
examined the challenges currently confronting the evaluation methods for LLMs,
as well as the directions for future development.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.16903v1' target='_blank'>Towards a copilot in BIM authoring tool using a large language
  model-based agent for intelligent human-machine interaction</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Changyu Du, Stavros Nousias, André Borrmann</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-02 17:47:57</h6>
<p class='card-text'>Facing increasingly complex BIM authoring software and the accompanying
expensive learning costs, designers often seek to interact with the software in
a more intelligent and lightweight manner. They aim to automate modeling
workflows, avoiding obstacles and difficulties caused by software usage,
thereby focusing on the design process itself. To address this issue, we
proposed an LLM-based autonomous agent framework that can function as a copilot
in the BIM authoring tool, answering software usage questions, understanding
the user's design intentions from natural language, and autonomously executing
modeling tasks by invoking the appropriate tools. In a case study based on the
BIM authoring software Vectorworks, we implemented a software prototype to
integrate the proposed framework seamlessly into the BIM authoring scenario. We
evaluated the planning and reasoning capabilities of different LLMs within this
framework when faced with complex instructions. Our work demonstrates the
significant potential of LLM-based agents in design automation and intelligent
interaction.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.01637v1' target='_blank'>Teams of LLM Agents can Exploit Zero-Day Vulnerabilities</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Richard Fang, Rohan Bindu, Akul Gupta, Qiusi Zhan, Daniel Kang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-02 16:25:26</h6>
<p class='card-text'>LLM agents have become increasingly sophisticated, especially in the realm of
cybersecurity. Researchers have shown that LLM agents can exploit real-world
vulnerabilities when given a description of the vulnerability and toy
capture-the-flag problems. However, these agents still perform poorly on
real-world vulnerabilities that are unknown to the agent ahead of time
(zero-day vulnerabilities).
  In this work, we show that teams of LLM agents can exploit real-world,
zero-day vulnerabilities. Prior agents struggle with exploring many different
vulnerabilities and long-range planning when used alone. To resolve this, we
introduce HPTSA, a system of agents with a planning agent that can launch
subagents. The planning agent explores the system and determines which
subagents to call, resolving long-term planning issues when trying different
vulnerabilities. We construct a benchmark of 15 real-world vulnerabilities and
show that our team of agents improve over prior work by up to 4.5$\times$.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.00554v2' target='_blank'>Guiding and Diversifying LLM-Based Story Generation via Answer Set
  Programming</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Phoebe J. Wang, Max Kreminski</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-01 21:14:25</h6>
<p class='card-text'>Instruction-tuned large language models (LLMs) are capable of generating
stories in response to open-ended user requests, but the resulting stories tend
to be limited in their diversity. Older, symbolic approaches to story
generation (such as planning) can generate substantially more diverse plot
outlines, but are limited to producing stories that recombine a fixed set of
hand-engineered character action templates. Can we combine the strengths of
these approaches while mitigating their weaknesses? We propose to do so by
using a higher-level and more abstract symbolic specification of high-level
story structure -- implemented via answer set programming (ASP) -- to guide and
diversify LLM-based story generation. Via semantic similarity analysis, we
demonstrate that our approach produces more diverse stories than an unguided
LLM, and via code excerpts, we demonstrate the improved compactness and
flexibility of ASP-based outline generation over full-fledged narrative
planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.00430v1' target='_blank'>Evaluating Uncertainty-based Failure Detection for Closed-Loop LLM
  Planners</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhi Zheng, Qian Feng, Hang Li, Alois Knoll, Jianxiang Feng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-06-01 12:52:06</h6>
<p class='card-text'>Recently, Large Language Models (LLMs) have witnessed remarkable performance
as zero-shot task planners for robotic manipulation tasks. However, the
open-loop nature of previous works makes LLM-based planning error-prone and
fragile. On the other hand, failure detection approaches for closed-loop
planning are often limited by task-specific heuristics or following an
unrealistic assumption that the prediction is trustworthy all the time. As a
general-purpose reasoning machine, LLMs or Multimodal Large Language Models
(MLLMs) are promising for detecting failures. However, However, the
appropriateness of the aforementioned assumption diminishes due to the
notorious hullucination problem. In this work, we attempt to mitigate these
issues by introducing a framework for closed-loop LLM-based planning called
KnowLoop, backed by an uncertainty-based MLLMs failure detector, which is
agnostic to any used MLLMs or LLMs. Specifically, we evaluate three different
ways for quantifying the uncertainty of MLLMs, namely token probability,
entropy, and self-explained confidence as primary metrics based on three
carefully designed representative prompting strategies. With a self-collected
dataset including various manipulation tasks and an LLM-based robot system, our
experiments demonstrate that token probability and entropy are more reflective
compared to self-explained confidence. By setting an appropriate threshold to
filter out uncertain predictions and seek human help actively, the accuracy of
failure detection can be significantly enhanced. This improvement boosts the
effectiveness of closed-loop planning and the overall success rate of tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.20625v1' target='_blank'>Robust Planning with LLM-Modulo Framework: Case Study in Travel Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Atharva Gundawar, Mudit Verma, Lin Guan, Karthik Valmeekam, Siddhant Bhambri, Subbarao Kambhampati</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-31 05:23:35</h6>
<p class='card-text'>As the applicability of Large Language Models (LLMs) extends beyond
traditional text processing tasks, there is a burgeoning interest in their
potential to excel in planning and reasoning assignments, realms traditionally
reserved for System 2 cognitive competencies. Despite their perceived
versatility, the research community is still unraveling effective strategies to
harness these models in such complex domains. The recent discourse introduced
by the paper on LLM Modulo marks a significant stride, proposing a conceptual
framework that enhances the integration of LLMs into diverse planning and
reasoning activities. This workshop paper delves into the practical application
of this framework within the domain of travel planning, presenting a specific
instance of its implementation. We are using the Travel Planning benchmark by
the OSU NLP group, a benchmark for evaluating the performance of LLMs in
producing valid itineraries based on user queries presented in natural
language. While popular methods of enhancing the reasoning abilities of LLMs
such as Chain of Thought, ReAct, and Reflexion achieve a meager 0%, 0.6%, and
0% with GPT3.5-Turbo respectively, our operationalization of the LLM-Modulo
framework for TravelPlanning domain provides a remarkable improvement,
enhancing baseline performances by 4.6x for GPT4-Turbo and even more for older
models like GPT3.5-Turbo from 0% to 5%. Furthermore, we highlight the other
useful roles of LLMs in the planning pipeline, as suggested in LLM-Modulo,
which can be reliably operationalized such as extraction of useful critics and
reformulator for critics.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.20455v5' target='_blank'>DepsRAG: Towards Agentic Reasoning and Planning for Software Dependency
  Management</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mohannad Alhanahnah, Yazan Boshmaf</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-30 20:05:44</h6>
<p class='card-text'>In the era of Large Language Models (LLMs) with their advanced capabilities,
a unique opportunity arises to develop LLM-based digital assistant tools that
can support software developers by facilitating comprehensive reasoning about
software dependencies and open-source libraries before importing them. This
reasoning process is daunting, mandating multiple specialized tools and
dedicated expertise, each focusing on distinct aspects (e.g., security analysis
tools may overlook design flaws such as circular dependencies, which hinder
software maintainability). Creating a significant bottleneck in the software
development lifecycle. In this paper, we introduce DepsRAG, a multi-agent
framework designed to assist developers in reasoning about software
dependencies. DepsRAG first constructs a comprehensive Knowledge Graph (KG)
that includes both direct and transitive dependencies. Developers can interact
with DepsRAG through a conversational interface, posing queries about the
dependencies. DepsRAG employs Retrieval-Augmented Generation (RAG) to enhance
these queries by retrieving relevant information from the KG as well as
external sources, such as the Web and vulnerability databases, thus
demonstrating its adaptability to novel scenarios. DepsRAG incorporates a
Critic-Agent feedback loop to ensure the accuracy and clarity of LLM-generated
responses. We evaluated DepsRAG using GPT-4-Turbo and Llama-3 on three
multi-step reasoning tasks, observing a threefold increase in accuracy with the
integration of the Critic-Agent mechanism. DepsRAG demo and implementation are
available: https://github.com/Mohannadcse/DepsRAG.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.20195v2' target='_blank'>Using Large Language Models for Humanitarian Frontline Negotiation:
  Opportunities and Considerations</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zilin Ma, Susannah, Su, Nathan Zhao, Linn Bieske, Blake Bullwinkel, Yanyi Zhang, Sophia, Yang, Ziqing Luo, Siyao Li, Gekai Liao, Boxiang Wang, Jinglun Gao, Zihan Wen, Claude Bruderlein, Weiwei Pan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-30 15:58:49</h6>
<p class='card-text'>Humanitarian negotiations in conflict zones, called \emph{frontline
negotiation}, are often highly adversarial, complex, and high-risk. Several
best-practices have emerged over the years that help negotiators extract
insights from large datasets to navigate nuanced and rapidly evolving
scenarios. Recent advances in large language models (LLMs) have sparked
interest in the potential for AI to aid decision making in frontline
negotiation. Through in-depth interviews with 13 experienced frontline
negotiators, we identified their needs for AI-assisted case analysis and
creativity support, as well as concerns surrounding confidentiality and model
bias. We further explored the potential for AI augmentation of three standard
tools used in frontline negotiation planning. We evaluated the quality and
stability of our ChatGPT-based negotiation tools in the context of two real
cases. Our findings highlight the potential for LLMs to enhance humanitarian
negotiations and underscore the need for careful ethical and practical
considerations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.19883v2' target='_blank'>From Words to Actions: Unveiling the Theoretical Underpinnings of
  LLM-Driven Autonomous Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jianliang He, Siyu Chen, Fengzhuo Zhang, Zhuoran Yang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-30 09:42:54</h6>
<p class='card-text'>In this work, from a theoretical lens, we aim to understand why large
language model (LLM) empowered agents are able to solve decision-making
problems in the physical world. To this end, consider a hierarchical
reinforcement learning (RL) model where the LLM Planner and the Actor perform
high-level task planning and low-level execution, respectively. Under this
model, the LLM Planner navigates a partially observable Markov decision process
(POMDP) by iteratively generating language-based subgoals via prompting. Under
proper assumptions on the pretraining data, we prove that the pretrained LLM
Planner effectively performs Bayesian aggregated imitation learning (BAIL)
through in-context learning. Additionally, we highlight the necessity for
exploration beyond the subgoals derived from BAIL by proving that naively
executing the subgoals returned by LLM leads to a linear regret. As a remedy,
we introduce an $\epsilon$-greedy exploration strategy to BAIL, which is proven
to incur sublinear regret when the pretraining error is small. Finally, we
extend our theoretical framework to include scenarios where the LLM Planner
serves as a world model for inferring the transition model of the environment
and to multi-agent settings, enabling coordination among multiple Actors.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.19850v1' target='_blank'>Deciphering Human Mobility: Inferring Semantics of Trajectories with
  Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuxiao Luo, Zhongcai Cao, Xin Jin, Kang Liu, Ling Yin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-30 08:55:48</h6>
<p class='card-text'>Understanding human mobility patterns is essential for various applications,
from urban planning to public safety. The individual trajectory such as mobile
phone location data, while rich in spatio-temporal information, often lacks
semantic detail, limiting its utility for in-depth mobility analysis. Existing
methods can infer basic routine activity sequences from this data, lacking
depth in understanding complex human behaviors and users' characteristics.
Additionally, they struggle with the dependency on hard-to-obtain auxiliary
datasets like travel surveys. To address these limitations, this paper defines
trajectory semantic inference through three key dimensions: user occupation
category, activity sequence, and trajectory description, and proposes the
Trajectory Semantic Inference with Large Language Models (TSI-LLM) framework to
leverage LLMs infer trajectory semantics comprehensively and deeply. We adopt
spatio-temporal attributes enhanced data formatting (STFormat) and design a
context-inclusive prompt, enabling LLMs to more effectively interpret and infer
the semantics of trajectory data. Experimental validation on real-world
trajectory datasets demonstrates the efficacy of TSI-LLM in deciphering complex
human mobility patterns. This study explores the potential of LLMs in enhancing
the semantic analysis of trajectory data, paving the way for more sophisticated
and accessible human mobility research.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.19802v3' target='_blank'>Exploring the Robustness of Decision-Level Through Adversarial Attacks
  on LLM-Based Embodied Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shuyuan Liu, Jiawei Chen, Shouwei Ruan, Hang Su, Zhaoxia Yin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-30 08:12:08</h6>
<p class='card-text'>Embodied intelligence empowers agents with a profound sense of perception,
enabling them to respond in a manner closely aligned with real-world
situations. Large Language Models (LLMs) delve into language instructions with
depth, serving a crucial role in generating plans for intricate tasks. Thus,
LLM-based embodied models further enhance the agent's capacity to comprehend
and process information. However, this amalgamation also ushers in new
challenges in the pursuit of heightened intelligence. Specifically, attackers
can manipulate LLMs to produce irrelevant or even malicious outputs by altering
their prompts. Confronted with this challenge, we observe a notable absence of
multi-modal datasets essential for comprehensively evaluating the robustness of
LLM-based embodied models. Consequently, we construct the Embodied Intelligent
Robot Attack Dataset (EIRAD), tailored specifically for robustness evaluation.
Additionally, two attack strategies are devised, including untargeted attacks
and targeted attacks, to effectively simulate a range of diverse attack
scenarios. At the same time, during the attack process, to more accurately
ascertain whether our method is successful in attacking the LLM-based embodied
model, we devise a new attack success evaluation method utilizing the BLIP2
model. Recognizing the time and cost-intensive nature of the GCG algorithm in
attacks, we devise a scheme for prompt suffix initialization based on various
target tasks, thus expediting the convergence process. Experimental results
demonstrate that our method exhibits a superior attack success rate when
targeting LLM-based embodied models, indicating a lower level of decision-level
robustness in these models.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.19793v2' target='_blank'>PDDLEGO: Iterative Planning in Textual Environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Li Zhang, Peter Jansen, Tianyi Zhang, Peter Clark, Chris Callison-Burch, Niket Tandon</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-30 08:01:20</h6>
<p class='card-text'>Planning in textual environments have been shown to be a long-standing
challenge even for current models. A recent, promising line of work uses LLMs
to generate a formal representation of the environment that can be solved by a
symbolic planner. However, existing methods rely on a fully-observed
environment where all entity states are initially known, so a one-off
representation can be constructed, leading to a complete plan. In contrast, we
tackle partially-observed environments where there is initially no sufficient
information to plan for the end-goal. We propose PDDLEGO that iteratively
construct a planning representation that can lead to a partial plan for a given
sub-goal. By accomplishing the sub-goal, more information is acquired to
augment the representation, eventually achieving the end-goal. We show that
plans produced by few-shot PDDLEGO are 43% more efficient than generating plans
end-to-end on the Coin Collector simulation, with strong performance (98%) on
the more complex Cooking World simulation where end-to-end LLMs fail to
generate coherent plans (4%).</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.19758v1' target='_blank'>InterPreT: Interactive Predicate Learning from Language Feedback for
  Generalizable Task Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Muzhi Han, Yifeng Zhu, Song-Chun Zhu, Ying Nian Wu, Yuke Zhu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-30 07:08:40</h6>
<p class='card-text'>Learning abstract state representations and knowledge is crucial for
long-horizon robot planning. We present InterPreT, an LLM-powered framework for
robots to learn symbolic predicates from language feedback of human non-experts
during embodied interaction. The learned predicates provide relational
abstractions of the environment state, facilitating the learning of symbolic
operators that capture action preconditions and effects. By compiling the
learned predicates and operators into a PDDL domain on-the-fly, InterPreT
allows effective planning toward arbitrary in-domain goals using a PDDL
planner. In both simulated and real-world robot manipulation domains, we
demonstrate that InterPreT reliably uncovers the key predicates and operators
governing the environment dynamics. Although learned from simple training
tasks, these predicates and operators exhibit strong generalization to novel
tasks with significantly higher complexity. In the most challenging
generalization setting, InterPreT attains success rates of 73% in simulation
and 40% in the real world, substantially outperforming baseline methods.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.19561v1' target='_blank'>Quo Vadis ChatGPT? From Large Language Models to Large Knowledge Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Venkat Venkatasubramanian, Arijit Chakraborty</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-29 23:06:54</h6>
<p class='card-text'>The startling success of ChatGPT and other large language models (LLMs) using
transformer-based generative neural network architecture in applications such
as natural language processing and image synthesis has many researchers excited
about potential opportunities in process systems engineering (PSE). The almost
human-like performance of LLMs in these areas is indeed very impressive,
surprising, and a major breakthrough. Their capabilities are very useful in
certain tasks, such as writing first drafts of documents, code writing
assistance, text summarization, etc. However, their success is limited in
highly scientific domains as they cannot yet reason, plan, or explain due to
their lack of in-depth domain knowledge. This is a problem in domains such as
chemical engineering as they are governed by fundamental laws of physics and
chemistry (and biology), constitutive relations, and highly technical knowledge
about materials, processes, and systems. Although purely data-driven machine
learning has its immediate uses, the long-term success of AI in scientific and
engineering domains would depend on developing hybrid AI systems that use first
principles and technical knowledge effectively. We call these hybrid AI systems
Large Knowledge Models (LKMs), as they will not be limited to only NLP-based
techniques or NLP-like applications. In this paper, we discuss the challenges
and opportunities in developing such systems in chemical engineering.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.19119v3' target='_blank'>Can Graph Learning Improve Planning in LLM-based Agents?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xixi Wu, Yifei Shen, Caihua Shan, Kaitao Song, Siwei Wang, Bohang Zhang, Jiarui Feng, Hong Cheng, Wei Chen, Yun Xiong, Dongsheng Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-29 14:26:24</h6>
<p class='card-text'>Task planning in language agents is emerging as an important research topic
alongside the development of large language models (LLMs). It aims to break
down complex user requests in natural language into solvable sub-tasks, thereby
fulfilling the original requests. In this context, the sub-tasks can be
naturally viewed as a graph, where the nodes represent the sub-tasks, and the
edges denote the dependencies among them. Consequently, task planning is a
decision-making problem that involves selecting a connected path or subgraph
within the corresponding graph and invoking it. In this paper, we explore graph
learning-based methods for task planning, a direction that is orthogonal to the
prevalent focus on prompt design. Our interest in graph learning stems from a
theoretical discovery: the biases of attention and auto-regressive loss impede
LLMs' ability to effectively navigate decision-making on graphs, which is
adeptly addressed by graph neural networks (GNNs). This theoretical insight led
us to integrate GNNs with LLMs to enhance overall performance. Extensive
experiments demonstrate that GNN-based methods surpass existing solutions even
without training, and minimal training can further enhance their performance.
The performance gain increases with a larger task graph size.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.18361v1' target='_blank'>Is a 3D-Tokenized LLM the Key to Reliable Autonomous Driving?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yifan Bai, Dongming Wu, Yingfei Liu, Fan Jia, Weixin Mao, Ziheng Zhang, Yucheng Zhao, Jianbing Shen, Xing Wei, Tiancai Wang, Xiangyu Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-28 16:57:44</h6>
<p class='card-text'>Rapid advancements in Autonomous Driving (AD) tasks turned a significant
shift toward end-to-end fashion, particularly in the utilization of
vision-language models (VLMs) that integrate robust logical reasoning and
cognitive abilities to enable comprehensive end-to-end planning. However, these
VLM-based approaches tend to integrate 2D vision tokenizers and a large
language model (LLM) for ego-car planning, which lack 3D geometric priors as a
cornerstone of reliable planning. Naturally, this observation raises a critical
concern: Can a 2D-tokenized LLM accurately perceive the 3D environment? Our
evaluation of current VLM-based methods across 3D object detection, vectorized
map construction, and environmental caption suggests that the answer is,
unfortunately, NO. In other words, 2D-tokenized LLM fails to provide reliable
autonomous driving. In response, we introduce DETR-style 3D perceptrons as 3D
tokenizers, which connect LLM with a one-layer linear projector. This simple
yet elegant strategy, termed Atlas, harnesses the inherent priors of the 3D
physical world, enabling it to simultaneously process high-resolution
multi-view images and employ spatiotemporal modeling. Despite its simplicity,
Atlas demonstrates superior performance in both 3D detection and ego planning
tasks on nuScenes dataset, proving that 3D-tokenized LLM is the key to reliable
autonomous driving. The code and datasets will be released.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.18357v2' target='_blank'>Faithful Logical Reasoning via Symbolic Chain-of-Thought</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jundong Xu, Hao Fei, Liangming Pan, Qian Liu, Mong-Li Lee, Wynne Hsu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-28 16:55:33</h6>
<p class='card-text'>While the recent Chain-of-Thought (CoT) technique enhances the reasoning
ability of large language models (LLMs) with the theory of mind, it might still
struggle in handling logical reasoning that relies much on symbolic expressions
and rigid deducing rules. To strengthen the logical reasoning capability of
LLMs, we propose a novel Symbolic Chain-of-Thought, namely SymbCoT, a fully
LLM-based framework that integrates symbolic expressions and logic rules with
CoT prompting. Technically, building upon an LLM, SymbCoT 1) first translates
the natural language context into the symbolic format, and then 2) derives a
step-by-step plan to solve the problem with symbolic logical rules, 3) followed
by a verifier to check the translation and reasoning chain. Via thorough
evaluations on 5 standard datasets with both First-Order Logic and Constraint
Optimization symbolic expressions, SymbCoT shows striking improvements over the
CoT method consistently, meanwhile refreshing the current state-of-the-art
performances. We further demonstrate that our system advances in more faithful,
flexible, and explainable logical reasoning. To our knowledge, this is the
first to combine symbolic expressions and rules into CoT for logical reasoning
with LLMs. Code is open at https://github.com/Aiden0526/SymbCoT.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.18346v1' target='_blank'>Intelligent Clinical Documentation: Harnessing Generative AI for
  Patient-Centric Clinical Note Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Anjanava Biswas, Wrick Talukdar</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-28 16:43:41</h6>
<p class='card-text'>Comprehensive clinical documentation is crucial for effective healthcare
delivery, yet it poses a significant burden on healthcare professionals,
leading to burnout, increased medical errors, and compromised patient safety.
This paper explores the potential of generative AI (Artificial Intelligence) to
streamline the clinical documentation process, specifically focusing on
generating SOAP (Subjective, Objective, Assessment, Plan) and BIRP (Behavior,
Intervention, Response, Plan) notes. We present a case study demonstrating the
application of natural language processing (NLP) and automatic speech
recognition (ASR) technologies to transcribe patient-clinician interactions,
coupled with advanced prompting techniques to generate draft clinical notes
using large language models (LLMs). The study highlights the benefits of this
approach, including time savings, improved documentation quality, and enhanced
patient-centered care. Additionally, we discuss ethical considerations, such as
maintaining patient confidentiality and addressing model biases, underscoring
the need for responsible deployment of generative AI in healthcare settings.
The findings suggest that generative AI has the potential to revolutionize
clinical documentation practices, alleviating administrative burdens and
enabling healthcare professionals to focus more on direct patient care.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.18208v1' target='_blank'>A Human-Like Reasoning Framework for Multi-Phases Planning Task with
  Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chengxing Xie, Difan Zou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-28 14:13:32</h6>
<p class='card-text'>Recent studies have highlighted their proficiency in some simple tasks like
writing and coding through various reasoning strategies. However, LLM agents
still struggle with tasks that require comprehensive planning, a process that
challenges current models and remains a critical research issue. In this study,
we concentrate on travel planning, a Multi-Phases planning problem, that
involves multiple interconnected stages, such as outlining, information
gathering, and planning, often characterized by the need to manage various
constraints and uncertainties. Existing reasoning approaches have struggled to
effectively address this complex task. Our research aims to address this
challenge by developing a human-like planning framework for LLM agents, i.e.,
guiding the LLM agent to simulate various steps that humans take when solving
Multi-Phases problems. Specifically, we implement several strategies to enable
LLM agents to generate a coherent outline for each travel query, mirroring
human planning patterns. Additionally, we integrate Strategy Block and
Knowledge Block into our framework: Strategy Block facilitates information
collection, while Knowledge Block provides essential information for detailed
planning. Through our extensive experiments, we demonstrate that our framework
significantly improves the planning capabilities of LLM agents, enabling them
to tackle the travel planning task with improved efficiency and effectiveness.
Our experimental results showcase the exceptional performance of the proposed
framework; when combined with GPT-4-Turbo, it attains $10\times$ the
performance gains in comparison to the baseline framework deployed on
GPT-4-Turbo.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.17935v3' target='_blank'>Tool Learning with Large Language Models: A Survey</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Changle Qu, Sunhao Dai, Xiaochi Wei, Hengyi Cai, Shuaiqiang Wang, Dawei Yin, Jun Xu, Ji-Rong Wen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-28 08:01:26</h6>
<p class='card-text'>Recently, tool learning with large language models (LLMs) has emerged as a
promising paradigm for augmenting the capabilities of LLMs to tackle highly
complex problems. Despite growing attention and rapid advancements in this
field, the existing literature remains fragmented and lacks systematic
organization, posing barriers to entry for newcomers. This gap motivates us to
conduct a comprehensive survey of existing works on tool learning with LLMs. In
this survey, we focus on reviewing existing literature from the two primary
aspects (1) why tool learning is beneficial and (2) how tool learning is
implemented, enabling a comprehensive understanding of tool learning with LLMs.
We first explore the "why" by reviewing both the benefits of tool integration
and the inherent benefits of the tool learning paradigm from six specific
aspects. In terms of "how", we systematically review the literature according
to a taxonomy of four key stages in the tool learning workflow: task planning,
tool selection, tool calling, and response generation. Additionally, we provide
a detailed summary of existing benchmarks and evaluation methods, categorizing
them according to their relevance to different stages. Finally, we discuss
current challenges and outline potential future directions, aiming to inspire
both researchers and industrial developers to further explore this emerging and
promising area. We also maintain a GitHub repository to continually keep track
of the relevant papers and resources in this rising area at
https://github.com/quchangle1/LLM-Tool-Survey.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.17533v1' target='_blank'>PAE: LLM-based Product Attribute Extraction for E-Commerce Fashion
  Trends</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Apurva Sinha, Ekta Gujral</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-27 17:50:25</h6>
<p class='card-text'>Product attribute extraction is an growing field in e-commerce business, with
several applications including product ranking, product recommendation, future
assortment planning and improving online shopping customer experiences.
Understanding the customer needs is critical part of online business,
specifically fashion products. Retailers uses assortment planning to determine
the mix of products to offer in each store and channel, stay responsive to
market dynamics and to manage inventory and catalogs. The goal is to offer the
right styles, in the right sizes and colors, through the right channels. When
shoppers find products that meet their needs and desires, they are more likely
to return for future purchases, fostering customer loyalty. Product attributes
are a key factor in assortment planning. In this paper we present PAE, a
product attribute extraction algorithm for future trend reports consisting text
and images in PDF format. Most existing methods focus on attribute extraction
from titles or product descriptions or utilize visual information from existing
product images. Compared to the prior works, our work focuses on attribute
extraction from PDF files where upcoming fashion trends are explained. This
work proposes a more comprehensive framework that fully utilizes the different
modalities for attribute extraction and help retailers to plan the assortment
in advance. Our contributions are three-fold: (a) We develop PAE, an efficient
framework to extract attributes from unstructured data (text and images); (b)
We provide catalog matching methodology based on BERT representations to
discover the existing attributes using upcoming attribute values; (c) We
conduct extensive experiments with several baselines and show that PAE is an
effective, flexible and on par or superior (avg 92.5% F1-Score) framework to
existing state-of-the-art for attribute value extraction task.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.16710v1' target='_blank'>REX: Designing User-centered Repair and Explanations to Address Robot
  Failures</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Christine P Lee, Pragathi Praveena, Bilge Mutlu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-26 22:08:58</h6>
<p class='card-text'>Robots in real-world environments continuously engage with multiple users and
encounter changes that lead to unexpected conflicts in fulfilling user
requests. Recent technical advancements (e.g., large-language models (LLMs),
program synthesis) offer various methods for automatically generating repair
plans that address such conflicts. In this work, we understand how automated
repair and explanations can be designed to improve user experience with robot
failures through two user studies. In our first, online study ($n=162$), users
expressed increased trust, satisfaction, and utility with the robot performing
automated repair and explanations. However, we also identified risk factors --
safety, privacy, and complexity -- that require adaptive repair strategies. The
second, in-person study ($n=24$) elucidated distinct repair and explanation
strategies depending on the level of risk severity and type. Using a
design-based approach, we explore automated repair with explanations as a
solution for robots to handle conflicts and failures, complemented by adaptive
strategies for risk factors. Finally, we discuss the implications of
incorporating such strategies into robot designs to achieve seamless operation
among changing user needs and environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.16533v1' target='_blank'>Chain of Tools: Large Language Model is an Automatic Multi-tool Learner</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhengliang Shi, Shen Gao, Xiuyi Chen, Yue Feng, Lingyong Yan, Haibo Shi, Dawei Yin, Zhumin Chen, Suzan Verberne, Zhaochun Ren</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-26 11:40:58</h6>
<p class='card-text'>Augmenting large language models (LLMs) with external tools has emerged as a
promising approach to extend their utility, empowering them to solve practical
tasks. Existing work typically empowers LLMs as tool users with a manually
designed workflow, where the LLM plans a series of tools in a step-by-step
manner, and sequentially executes each tool to obtain intermediate results
until deriving the final answer. However, they suffer from two challenges in
realistic scenarios: (1) The handcrafted control flow is often ad-hoc and
constraints the LLM to local planning; (2) The LLM is instructed to use only
manually demonstrated tools or well-trained Python functions, which limits its
generalization to new tools. In this work, we first propose Automatic Tool
Chain (ATC), a framework that enables the LLM to act as a multi-tool user,
which directly utilizes a chain of tools through programming. To scale up the
scope of the tools, we next propose a black-box probing method. This further
empowers the LLM as a tool learner that can actively discover and document tool
usages, teaching themselves to properly master new tools. For a comprehensive
evaluation, we build a challenging benchmark named ToolFlow, which diverges
from previous benchmarks by its long-term planning scenarios and complex
toolset. Experiments on both existing datasets and ToolFlow illustrate the
superiority of our framework. Analysis on different settings also validates the
effectiveness and the utility of our black-box probing algorithm.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.16510v4' target='_blank'>Planning with Multi-Constraints via Collaborative Language Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Cong Zhang, Derrick Goh Xin Deik, Dexun Li, Hao Zhang, Yong Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-26 10:33:17</h6>
<p class='card-text'>The rapid advancement of neural language models has sparked a new surge of
intelligent agent research. Unlike traditional agents, large language
model-based agents (LLM agents) have emerged as a promising paradigm for
achieving artificial general intelligence (AGI) due to their superior reasoning
and generalization capabilities. Effective planning is crucial for the success
of LLM agents in real-world tasks, making it a highly pursued topic in the
community. Current planning methods typically translate tasks into executable
action sequences. However, determining a feasible or optimal sequence for
complex tasks with multiple constraints at fine granularity, which often
requires compositing long chains of heterogeneous actions, remains challenging.
This paper introduces Planning with Multi-Constraints (PMC), a zero-shot
methodology for collaborative LLM-based multi-agent systems that simplifies
complex task planning with constraints by decomposing it into a hierarchy of
subordinate tasks. Each subtask is then mapped into executable actions. PMC was
assessed on two constraint-intensive benchmarks, TravelPlanner and API-Bank.
Notably, PMC achieved an average 42.68% success rate on TravelPlanner,
significantly higher than GPT-4 (2.92%), and outperforming GPT-4 with ReAct on
API-Bank by 13.64%, showing the immense potential of integrating LLM with
multi-agent systems. We also show that PMC works with small LLM as the planning
core, e.g., LLaMA-3.1-8B.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.16376v2' target='_blank'>STRIDE: A Tool-Assisted LLM Agent Framework for Strategic and
  Interactive Decision-Making</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chuanhao Li, Runhan Yang, Tiankai Li, Milad Bafarassat, Kourosh Sharifi, Dirk Bergemann, Zhuoran Yang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-25 23:25:10</h6>
<p class='card-text'>Large Language Models (LLMs) like GPT-4 have revolutionized natural language
processing, showing remarkable linguistic proficiency and reasoning
capabilities. However, their application in strategic multi-agent
decision-making environments is hampered by significant limitations including
poor mathematical reasoning, difficulty in following instructions, and a
tendency to generate incorrect information. These deficiencies hinder their
performance in strategic and interactive tasks that demand adherence to nuanced
game rules, long-term planning, exploration in unknown environments, and
anticipation of opponents' moves. To overcome these obstacles, this paper
presents a novel LLM agent framework equipped with memory and specialized tools
to enhance their strategic decision-making capabilities. We deploy the tools in
a number of economically important environments, in particular bilateral
bargaining and multi-agent and dynamic mechanism design. We employ quantitative
metrics to assess the framework's performance in various strategic
decision-making problems. Our findings establish that our enhanced framework
significantly improves the strategic decision-making capability of LLMs. While
we highlight the inherent limitations of current LLM models, we demonstrate the
improvements through targeted enhancements, suggesting a promising direction
for future developments in LLM applications for interactive environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.16334v4' target='_blank'>Devil's Advocate: Anticipatory Reflection for LLM Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Haoyu Wang, Tao Li, Zhiwei Deng, Dan Roth, Yang Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-25 19:20:15</h6>
<p class='card-text'>In this work, we introduce a novel approach that equips LLM agents with
introspection, enhancing consistency and adaptability in solving complex tasks.
Our approach prompts LLM agents to decompose a given task into manageable
subtasks (i.e., to make a plan), and to continuously introspect upon the
suitability and results of their actions. %; and when necessary, to explore
``the road not taken.'' We implement a three-fold introspective intervention:
1) anticipatory reflection on potential failures and alternative remedy before
action execution, 2) post-action alignment with subtask objectives and
backtracking with remedy to ensure utmost effort in plan execution, and 3)
comprehensive review upon plan completion for future strategy refinement. By
deploying and experimenting with this methodology -- a zero-shot approach --
within WebArena for practical tasks in web environments, our agent demonstrates
superior performance with a success rate of 23.5% over existing zero-shot
methods by 3.5%. The experimental results suggest that our introspection-driven
approach not only enhances the agent's ability to navigate unanticipated
challenges through a robust mechanism of plan execution, but also improves
efficiency by reducing the number of trials and plan revisions by 45% needed to
achieve a task.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.16247v4' target='_blank'>AutoManual: Constructing Instruction Manuals by LLM Agents via
  Interactive Environmental Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Minghao Chen, Yihang Li, Yanting Yang, Shiyu Yu, Binbin Lin, Xiaofei He</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-25 14:11:44</h6>
<p class='card-text'>Large Language Models (LLM) based agents have shown promise in autonomously
completing tasks across various domains, e.g., robotics, games, and web
navigation. However, these agents typically require elaborate design and expert
prompts to solve tasks in specific domains, which limits their adaptability. We
introduce AutoManual, a framework enabling LLM agents to autonomously build
their understanding through interaction and adapt to new environments.
AutoManual categorizes environmental knowledge into diverse rules and optimizes
them in an online fashion by two agents: 1) The Planner codes actionable plans
based on current rules for interacting with the environment. 2) The Builder
updates the rules through a well-structured rule system that facilitates online
rule management and essential detail retention. To mitigate hallucinations in
managing rules, we introduce a *case-conditioned prompting* strategy for the
Builder. Finally, the Formulator agent compiles these rules into a
comprehensive manual. The self-generated manual can not only improve the
adaptability but also guide the planning of smaller LLMs while being
human-readable. Given only one simple demonstration, AutoManual significantly
improves task success rates, achieving 97.4\% with GPT-4-turbo and 86.2\% with
GPT-3.5-turbo on ALFWorld benchmark tasks. The code is available at
https://github.com/minghchen/automanual.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.15646v1' target='_blank'>LLM-based Robot Task Planning with Exceptional Handling for General
  Purpose Service Robots</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ruoyu Wang, Zhipeng Yang, Zinan Zhao, Xinyan Tong, Zhi Hong, Kun Qian</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-24 15:35:49</h6>
<p class='card-text'>The development of a general purpose service robot for daily life
necessitates the robot's ability to deploy a myriad of fundamental behaviors
judiciously. Recent advancements in training Large Language Models (LLMs) can
be used to generate action sequences directly, given an instruction in natural
language with no additional domain information. However, while the outputs of
LLMs are semantically correct, the generated task plans may not accurately map
to acceptable actions and might encompass various linguistic ambiguities. LLM
hallucinations pose another challenge for robot task planning, which results in
content that is inconsistent with real-world facts or user inputs. In this
paper, we propose a task planning method based on a constrained LLM prompt
scheme, which can generate an executable action sequence from a command. An
exceptional handling module is further proposed to deal with LLM hallucinations
problem. This module can ensure the LLM-generated results are admissible in the
current environment. We evaluate our method on the commands generated by the
RoboCup@Home Command Generator, observing that the robot demonstrates
exceptional performance in both comprehending instructions and executing tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.15452v2' target='_blank'>Leveraging Logical Rules in Knowledge Editing: A Cherry on the Top</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Keyuan Cheng, Muhammad Asif Ali, Shu Yang, Gang Lin, Yuxuan Zhai, Haoyang Fei, Ke Xu, Lu Yu, Lijie Hu, Di Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-24 11:30:00</h6>
<p class='card-text'>Multi-hop Question Answering (MQA) under knowledge editing (KE) is a key
challenge in Large Language Models (LLMs). While best-performing solutions in
this domain use a plan and solve paradigm to split a question into
sub-questions followed by response generation, we claim that this approach is
sub-optimal as it fails for hard to decompose questions, and it does not
explicitly cater to correlated knowledge updates resulting as a consequence of
knowledge edits. This has a detrimental impact on the overall consistency of
the updated knowledge. To address these issues, in this paper, we propose a
novel framework named RULE-KE, i.e., RULE based Knowledge Editing, which is a
cherry on the top for augmenting the performance of all existing MQA methods
under KE. Specifically, RULE-KE leverages rule discovery to discover a set of
logical rules. Then, it uses these discovered rules to update knowledge about
facts highly correlated with the edit. Experimental evaluation using existing
and newly curated datasets (i.e., RKE-EVAL) shows that RULE-KE helps augment
both performances of parameter-based and memory-based solutions up to 92% and
112.9%, respectively.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.15383v2' target='_blank'>Generating Code World Models with Large Language Models Guided by Monte
  Carlo Tree Search</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nicola Dainese, Matteo Merler, Minttu Alakuijala, Pekka Marttinen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-24 09:31:26</h6>
<p class='card-text'>In this work we consider Code World Models, world models generated by a Large
Language Model (LLM) in the form of Python code for model-based Reinforcement
Learning (RL). Calling code instead of LLMs for planning has potential to be
more precise, reliable, interpretable, and extremely efficient. However,
writing appropriate Code World Models requires the ability to understand
complex instructions, to generate exact code with non-trivial logic and to
self-debug a long program with feedback from unit tests and environment
trajectories. To address these challenges, we propose Generate, Improve and Fix
with Monte Carlo Tree Search (GIF-MCTS), a new code generation strategy for
LLMs. To test our approach in an offline RL setting, we introduce the Code
World Models Benchmark (CWMB), a suite of program synthesis and planning tasks
comprised of 18 diverse RL environments paired with corresponding textual
descriptions and curated trajectories. GIF-MCTS surpasses all baselines on the
CWMB and two other benchmarks, and we show that the Code World Models
synthesized with it can be successfully used for planning, resulting in
model-based RL agents with greatly improved sample efficiency and inference
speed.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.15194v2' target='_blank'>Extracting Heuristics from Large Language Models for Reward Shaping in
  Reinforcement Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Siddhant Bhambri, Amrita Bhattacharjee, Durgesh Kalwar, Lin Guan, Huan Liu, Subbarao Kambhampati</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-24 03:53:57</h6>
<p class='card-text'>Reinforcement Learning (RL) suffers from sample inefficiency in sparse reward
domains, and the problem is further pronounced in case of stochastic
transitions. To improve the sample efficiency, reward shaping is a well-studied
approach to introduce intrinsic rewards that can help the RL agent converge to
an optimal policy faster. However, designing a useful reward shaping function
for all desirable states in the Markov Decision Process (MDP) is challenging,
even for domain experts. Given that Large Language Models (LLMs) have
demonstrated impressive performance across a magnitude of natural language
tasks, we aim to answer the following question: `Can we obtain heuristics using
LLMs for constructing a reward shaping function that can boost an RL agent's
sample efficiency?' To this end, we aim to leverage off-the-shelf LLMs to
generate a plan for an abstraction of the underlying MDP. We further use this
LLM-generated plan as a heuristic to construct the reward shaping signal for
the downstream RL agent. By characterizing the type of abstraction based on the
MDP horizon length, we analyze the quality of heuristics when generated using
an LLM, with and without a verifier in the loop. Our experiments across
multiple domains with varying horizon length and number of sub-goals from the
BabyAI environment suite, Household, Mario, and, Minecraft domain, show 1) the
advantages and limitations of querying LLMs with and without a verifier to
generate a reward shaping heuristic, and, 2) a significant improvement in the
sample efficiency of PPO, A2C, and Q-learning when guided by the LLM-generated
heuristics.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.14655v2' target='_blank'>Multi-turn Reinforcement Learning from Preference Human Feedback</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lior Shani, Aviv Rosenberg, Asaf Cassel, Oran Lang, Daniele Calandriello, Avital Zipori, Hila Noga, Orgad Keller, Bilal Piot, Idan Szpektor, Avinatan Hassidim, Yossi Matias, Rémi Munos</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-23 14:53:54</h6>
<p class='card-text'>Reinforcement Learning from Human Feedback (RLHF) has become the standard
approach for aligning Large Language Models (LLMs) with human preferences,
allowing LLMs to demonstrate remarkable abilities in various tasks. Existing
methods work by emulating the preferences at the single decision (turn) level,
limiting their capabilities in settings that require planning or multi-turn
interactions to achieve a long-term goal. In this paper, we address this issue
by developing novel methods for Reinforcement Learning (RL) from preference
feedback between two full multi-turn conversations. In the tabular setting, we
present a novel mirror-descent-based policy optimization algorithm for the
general multi-turn preference-based RL problem, and prove its convergence to
Nash equilibrium. To evaluate performance, we create a new environment,
Education Dialogue, where a teacher agent guides a student in learning a random
topic, and show that a deep RL variant of our algorithm outperforms RLHF
baselines. Finally, we show that in an environment with explicit rewards, our
algorithm recovers the same performance as a reward-based RL baseline, despite
relying solely on a weaker preference signal.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.14314v2' target='_blank'>Towards Efficient LLM Grounding for Embodied Multi-Agent Collaboration</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yang Zhang, Shixin Yang, Chenjia Bai, Fei Wu, Xiu Li, Zhen Wang, Xuelong Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-23 08:33:19</h6>
<p class='card-text'>Grounding the reasoning ability of large language models (LLMs) for embodied
tasks is challenging due to the complexity of the physical world. Especially,
LLM planning for multi-agent collaboration requires communication of agents or
credit assignment as the feedback to re-adjust the proposed plans and achieve
effective coordination. However, existing methods that overly rely on physical
verification or self-reflection suffer from excessive and inefficient querying
of LLMs. In this paper, we propose a novel framework for multi-agent
collaboration that introduces Reinforced Advantage feedback (ReAd) for
efficient self-refinement of plans. Specifically, we perform critic regression
to learn a sequential advantage function from LLM-planned data, and then treat
the LLM planner as an optimizer to generate actions that maximize the advantage
function. It endows the LLM with the foresight to discern whether the action
contributes to accomplishing the final task. We provide theoretical analysis by
extending advantage-weighted regression in reinforcement learning to
multi-agent systems. Experiments on Overcooked-AI and a difficult variant of
RoCoBench show that ReAd surpasses baselines in success rate, and also
significantly decreases the interaction steps of agents and query rounds of
LLMs, demonstrating its high efficiency for grounding LLMs. More results are
given at https://read-llm.github.io/.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.14205v4' target='_blank'>Agent Planning with World Knowledge Model</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shuofei Qiao, Runnan Fang, Ningyu Zhang, Yuqi Zhu, Xiang Chen, Shumin Deng, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-23 06:03:19</h6>
<p class='card-text'>Recent endeavors towards directly using large language models (LLMs) as agent
models to execute interactive planning tasks have shown commendable results.
Despite their achievements, however, they still struggle with brainless
trial-and-error in global planning and generating hallucinatory actions in
local planning due to their poor understanding of the ``real'' physical world.
Imitating humans' mental world knowledge model which provides global prior
knowledge before the task and maintains local dynamic knowledge during the
task, in this paper, we introduce parametric World Knowledge Model (WKM) to
facilitate agent planning. Concretely, we steer the agent model to
self-synthesize knowledge from both expert and sampled trajectories. Then we
develop WKM, providing prior task knowledge to guide the global planning and
dynamic state knowledge to assist the local planning. Experimental results on
three complex real-world simulated datasets with three state-of-the-art
open-source LLMs, Mistral-7B, Gemma-7B, and Llama-3-8B, demonstrate that our
method can achieve superior performance compared to various strong baselines.
Besides, we analyze to illustrate that our WKM can effectively alleviate the
blind trial-and-error and hallucinatory action issues, providing strong support
for the agent's understanding of the world. Other interesting findings include:
1) our instance-level task knowledge can generalize better to unseen tasks, 2)
weak WKM can guide strong agent model planning, and 3) unified WKM training has
promising potential for further development. The code is available at
https://github.com/zjunlp/WKM.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.14169v1' target='_blank'>Towards Transferable Attacks Against Vision-LLMs in Autonomous Driving
  with Typography</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nhat Chung, Sensen Gao, Tuan-Anh Vu, Jie Zhang, Aishan Liu, Yun Lin, Jin Song Dong, Qing Guo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-23 04:52:02</h6>
<p class='card-text'>Vision-Large-Language-Models (Vision-LLMs) are increasingly being integrated
into autonomous driving (AD) systems due to their advanced visual-language
reasoning capabilities, targeting the perception, prediction, planning, and
control mechanisms. However, Vision-LLMs have demonstrated susceptibilities
against various types of adversarial attacks, which would compromise their
reliability and safety. To further explore the risk in AD systems and the
transferability of practical threats, we propose to leverage typographic
attacks against AD systems relying on the decision-making capabilities of
Vision-LLMs. Different from the few existing works developing general datasets
of typographic attacks, this paper focuses on realistic traffic scenarios where
these attacks can be deployed, on their potential effects on the
decision-making autonomy, and on the practical ways in which these attacks can
be physically presented. To achieve the above goals, we first propose a
dataset-agnostic framework for automatically generating false answers that can
mislead Vision-LLMs' reasoning. Then, we present a linguistic augmentation
scheme that facilitates attacks at image-level and region-level reasoning, and
we extend it with attack patterns against multiple reasoning tasks
simultaneously. Based on these, we conduct a study on how these attacks can be
realized in physical traffic scenarios. Through our empirical study, we
evaluate the effectiveness, transferability, and realizability of typographic
attacks in traffic scenes. Our findings demonstrate particular harmfulness of
the typographic attacks against existing Vision-LLMs (e.g., LLaVA, Qwen-VL,
VILA, and Imp), thereby raising community awareness of vulnerabilities when
incorporating such models into AD systems. We will release our source code upon
acceptance.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.13890v2' target='_blank'>An empirical study to understand how students use ChatGPT for writing
  essays and how it affects their ownership</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Andrew Jelson, Sang Won Lee</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-22 18:01:24</h6>
<p class='card-text'>As large language models (LLMs) become more powerful and ubiquitous, systems
like ChatGPT are increasingly used by students to help them with writing tasks.
To better understand how these tools are used, we investigate how students
might use an LLM for essay writing, for example, to study the queries asked to
ChatGPT and the responses that ChatGPT gives. To that end, we plan to conduct a
user study that will record the user writing process and present them with the
opportunity to use ChatGPT as an AI assistant. This study's findings will help
us understand how these tools are used and how practitioners -- such as
educators and essay readers -- should consider writing education and evaluation
based on essay writing.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.13740v1' target='_blank'>Mining Action Rules for Defect Reduction Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Khouloud Oueslati, Gabriel Laberge, Maxime Lamothe, Foutse Khomh</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-22 15:31:09</h6>
<p class='card-text'>Defect reduction planning plays a vital role in enhancing software quality
and minimizing software maintenance costs. By training a black box machine
learning model and "explaining" its predictions, explainable AI for software
engineering aims to identify the code characteristics that impact maintenance
risks. However, post-hoc explanations do not always faithfully reflect what the
original model computes. In this paper, we introduce CounterACT, a
Counterfactual ACTion rule mining approach that can generate defect reduction
plans without black-box models. By leveraging action rules, CounterACT provides
a course of action that can be considered as a counterfactual explanation for
the class (e.g., buggy or not buggy) assigned to a piece of code. We compare
the effectiveness of CounterACT with the original action rule mining algorithm
and six established defect reduction approaches on 9 software projects. Our
evaluation is based on (a) overlap scores between proposed code changes and
actual developer modifications; (b) improvement scores in future releases; and
(c) the precision, recall, and F1-score of the plans. Our results show that,
compared to competing approaches, CounterACT's explainable plans achieve higher
overlap scores at the release level (median 95%) and commit level (median
85.97%), and they offer better trade-off between precision and recall (median
F1-score 88.12%). Finally, we venture beyond planning and explore leveraging
Large Language models (LLM) for generating code edits from our generated plans.
Our results show that suggested LLM code edits supported by our plans are
actionable and are more likely to pass relevant test cases than vanilla LLM
code recommendations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.13448v2' target='_blank'>Distilling Instruction-following Abilities of Large Language Models with
  Task-aware Curriculum Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuanhao Yue, Chengyu Wang, Jun Huang, Peng Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-22 08:38:26</h6>
<p class='card-text'>Instruction tuning aims to align large language models (LLMs) with
open-domain instructions and human-preferred responses. While several studies
have explored autonomous approaches to distilling and annotating instructions
from powerful proprietary LLMs, such as ChatGPT, they often neglect the impact
of the distributions and characteristics of tasks, together with the varying
difficulty of instructions in training sets. This oversight can lead to
imbalanced knowledge capabilities and poor generalization powers of student
LLMs. To address these challenges, we introduce Task-Aware Curriculum Planning
for Instruction Refinement (TAPIR), a multi-round distillation framework that
utilizes an oracle LLM to select instructions that are difficult for a student
LLM to follow. To balance the student's capabilities, task distributions in
training sets are adjusted with responses automatically refined according to
their corresponding tasks. In addition, by incorporating curriculum planning,
our approach systematically escalates the difficulty levels of tasks,
progressively enhancing the student LLM's capabilities. We rigorously evaluate
TAPIR using several widely recognized benchmarks (such as AlpacaEval 2.0,
MT-Bench, etc.) and multiple student LLMs. Empirical results demonstrate that
student LLMs, trained with our method and less training data, outperform larger
instruction-tuned models and strong distillation baselines.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.13209v1' target='_blank'>Investigating Symbolic Capabilities of Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Neisarg Dave, Daniel Kifer, C. Lee Giles, Ankur Mali</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-21 21:24:34</h6>
<p class='card-text'>Prompting techniques have significantly enhanced the capabilities of Large
Language Models (LLMs) across various complex tasks, including reasoning,
planning, and solving math word problems. However, most research has
predominantly focused on language-based reasoning and word problems, often
overlooking the potential of LLMs in handling symbol-based calculations and
reasoning. This study aims to bridge this gap by rigorously evaluating LLMs on
a series of symbolic tasks, such as addition, multiplication, modulus
arithmetic, numerical precision, and symbolic counting. Our analysis
encompasses eight LLMs, including four enterprise-grade and four open-source
models, of which three have been pre-trained on mathematical tasks. The
assessment framework is anchored in Chomsky's Hierarchy, providing a robust
measure of the computational abilities of these models. The evaluation employs
minimally explained prompts alongside the zero-shot Chain of Thoughts
technique, allowing models to navigate the solution process autonomously. The
findings reveal a significant decline in LLMs' performance on context-free and
context-sensitive symbolic tasks as the complexity, represented by the number
of symbols, increases. Notably, even the fine-tuned GPT3.5 exhibits only
marginal improvements, mirroring the performance trends observed in other
models. Across the board, all models demonstrated a limited generalization
ability on these symbol-intensive tasks. This research underscores LLMs'
challenges with increasing symbolic complexity and highlights the need for
specialized training, memory and architectural adjustments to enhance their
proficiency in symbol-based reasoning tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.12433v3' target='_blank'>LLM+Reasoning+Planning for Supporting Incomplete User Queries in
  Presence of APIs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sudhir Agarwal, Anu Sreepathy, David H. Alonso, Prarit Lamba</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-21 01:16:34</h6>
<p class='card-text'>Recent availability of Large Language Models (LLMs) has led to the
development of numerous LLM-based approaches aimed at providing natural
language interfaces for various end-user tasks. These end-user tasks in turn
can typically be accomplished by orchestrating a given set of APIs. In
practice, natural language task requests (user queries) are often incomplete,
i.e., they may not contain all the information required by the APIs. While LLMs
excel at natural language processing (NLP) tasks, they frequently hallucinate
on missing information or struggle with orchestrating the APIs. The key idea
behind our proposed approach is to leverage logical reasoning and classical AI
planning along with an LLM for accurately answering user queries including
identification and gathering of any missing information in these queries. Our
approach uses an LLM and ASP (Answer Set Programming) solver to translate a
user query to a representation in Planning Domain Definition Language (PDDL)
via an intermediate representation in ASP. We introduce a special API
"get_info_api" for gathering missing information. We model all the APIs as PDDL
actions in a way that supports dataflow between the APIs. Our approach then
uses a classical AI planner to generate an orchestration of API calls
(including calls to get_info_api) to answer the user query. Our evaluation
results show that our approach significantly outperforms a pure LLM based
approach by achieving over 95% success rate in most cases on a dataset
containing complete and incomplete single goal and multi-goal queries where the
multi-goal queries may or may not require dataflow among the APIs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.11983v2' target='_blank'>A review on the use of large language models as virtual tutors</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Silvia García-Méndez, Francisco de Arriba-Pérez, María del Carmen Somoza-López</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-20 12:33:42</h6>
<p class='card-text'>Transformer architectures contribute to managing long-term dependencies for
Natural Language Processing, representing one of the most recent changes in the
field. These architectures are the basis of the innovative, cutting-edge Large
Language Models (LLMs) that have produced a huge buzz in several fields and
industrial sectors, among the ones education stands out. Accordingly, these
generative Artificial Intelligence-based solutions have directed the change in
techniques and the evolution in educational methods and contents, along with
network infrastructure, towards high-quality learning. Given the popularity of
LLMs, this review seeks to provide a comprehensive overview of those solutions
designed specifically to generate and evaluate educational materials and which
involve students and teachers in their design or experimental plan. To the best
of our knowledge, this is the first review of educational applications (e.g.,
student assessment) of LLMs. As expected, the most common role of these systems
is as virtual tutors for automatic question generation. Moreover, the most
popular models are GTP-3 and BERT. However, due to the continuous launch of new
generative models, new works are expected to be published shortly.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.11841v1' target='_blank'>Evaluating and Modeling Social Intelligence: A Comparative Study of
  Human and AI Capabilities</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Junqi Wang, Chunhui Zhang, Jiapeng Li, Yuxi Ma, Lixing Niu, Jiaheng Han, Yujia Peng, Yixin Zhu, Lifeng Fan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-20 07:34:48</h6>
<p class='card-text'>Facing the current debate on whether Large Language Models (LLMs) attain
near-human intelligence levels (Mitchell & Krakauer, 2023; Bubeck et al., 2023;
Kosinski, 2023; Shiffrin & Mitchell, 2023; Ullman, 2023), the current study
introduces a benchmark for evaluating social intelligence, one of the most
distinctive aspects of human cognition. We developed a comprehensive
theoretical framework for social dynamics and introduced two evaluation tasks:
Inverse Reasoning (IR) and Inverse Inverse Planning (IIP). Our approach also
encompassed a computational model based on recursive Bayesian inference, adept
at elucidating diverse human behavioral patterns. Extensive experiments and
detailed analyses revealed that humans surpassed the latest GPT models in
overall performance, zero-shot learning, one-shot generalization, and
adaptability to multi-modalities. Notably, GPT models demonstrated social
intelligence only at the most basic order (order = 0), in stark contrast to
human social intelligence (order >= 2). Further examination indicated a
propensity of LLMs to rely on pattern recognition for shortcuts, casting doubt
on their possession of authentic human-level social intelligence. Our codes,
dataset, appendix and human data are released at
https://github.com/bigai-ai/Evaluate-n-Model-Social-Intelligence.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.13050v2' target='_blank'>Human-Centered LLM-Agent User Interface: A Position Paper</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Daniel Chin, Yuxuan Wang, Gus Xia</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-19 13:02:45</h6>
<p class='card-text'>Large Language Model (LLM) -in-the-loop applications have been shown to
effectively interpret the human user's commands, make plans, and operate
external tools/systems accordingly. Still, the operation scope of the LLM agent
is limited to passively following the user, requiring the user to frame his/her
needs with regard to the underlying tools/systems. We note that the potential
of an LLM-Agent User Interface (LAUI) is much greater. A user mostly ignorant
to the underlying tools/systems should be able to work with a LAUI to discover
an emergent workflow. Contrary to the conventional way of designing an
explorable GUI to teach the user a predefined set of ways to use the system, in
the ideal LAUI, the LLM agent is initialized to be proficient with the system,
proactively studies the user and his/her needs, and proposes new interaction
schemes to the user. To illustrate LAUI, we present Flute X GPT, a concrete
example using an LLM agent, a prompt manager, and a flute-tutoring multi-modal
software-hardware system to facilitate the complex, real-time user experience
of learning to play the flute.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.11458v1' target='_blank'>CPS-LLM: Large Language Model based Safe Usage Plan Generator for
  Human-in-the-Loop Human-in-the-Plant Cyber-Physical System</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ayan Banerjee, Aranyak Maity, Payal Kamboj, Sandeep K. S. Gupta</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-19 06:00:18</h6>
<p class='card-text'>We explore the usage of large language models (LLM) in human-in-the-loop
human-in-the-plant cyber-physical systems (CPS) to translate a high-level
prompt into a personalized plan of actions, and subsequently convert that plan
into a grounded inference of sequential decision-making automated by a
real-world CPS controller to achieve a control goal. We show that it is
relatively straightforward to contextualize an LLM so it can generate
domain-specific plans. However, these plans may be infeasible for the physical
system to execute or the plan may be unsafe for human users. To address this,
we propose CPS-LLM, an LLM retrained using an instruction tuning framework,
which ensures that generated plans not only align with the physical system
dynamics of the CPS but are also safe for human users. The CPS-LLM consists of
two innovative components: a) a liquid time constant neural network-based
physical dynamics coefficient estimator that can derive coefficients of
dynamical models with some unmeasured state variables; b) the model
coefficients are then used to train an LLM with prompts embodied with traces
from the dynamical system and the corresponding model coefficients. We show
that when the CPS-LLM is integrated with a contextualized chatbot such as BARD
it can generate feasible and safe plans to manage external events such as meals
for automated insulin delivery systems used by Type 1 Diabetes subjects.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.11403v1' target='_blank'>MapCoder: Multi-Agent Code Generation for Competitive Problem Solving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Md. Ashraful Islam, Mohammed Eunus Ali, Md Rizwan Parvez</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-18 22:10:15</h6>
<p class='card-text'>Code synthesis, which requires a deep understanding of complex natural
language problem descriptions, generation of code instructions for complex
algorithms and data structures, and the successful execution of comprehensive
unit tests, presents a significant challenge. While large language models
(LLMs) demonstrate impressive proficiency in natural language processing, their
performance in code generation tasks remains limited. In this paper, we
introduce a new approach to code generation tasks leveraging multi-agent
prompting that uniquely replicates the full cycle of program synthesis as
observed in human developers. Our framework, MapCoder, consists of four LLM
agents specifically designed to emulate the stages of this cycle: recalling
relevant examples, planning, code generation, and debugging. After conducting
thorough experiments, with multiple LLM ablations and analyses across eight
challenging competitive problem-solving and program synthesis benchmarks,
MapCoder showcases remarkable code generation capabilities, achieving new
state-of-the-art results (pass@1) on HumanEval (93.9%), MBPP (83.1%), APPS
(22.0%), CodeContests (28.5%), and xCodeEval (45.3%). Moreover, our method
consistently delivers superior performance across various programming languages
and varying problem difficulties. We open-source our framework at
https://github.com/Md-Ashraful-Pramanik/MapCoder.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.11286v2' target='_blank'>Motion Avatar: Generate Human and Animal Avatars with Arbitrary Motion</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zeyu Zhang, Yiran Wang, Biao Wu, Shuo Chen, Zhiyuan Zhang, Shiya Huang, Wenbo Zhang, Meng Fang, Ling Chen, Yang Zhao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-18 13:21:14</h6>
<p class='card-text'>In recent years, there has been significant interest in creating 3D avatars
and motions, driven by their diverse applications in areas like film-making,
video games, AR/VR, and human-robot interaction. However, current efforts
primarily concentrate on either generating the 3D avatar mesh alone or
producing motion sequences, with integrating these two aspects proving to be a
persistent challenge. Additionally, while avatar and motion generation
predominantly target humans, extending these techniques to animals remains a
significant challenge due to inadequate training data and methods. To bridge
these gaps, our paper presents three key contributions. Firstly, we proposed a
novel agent-based approach named Motion Avatar, which allows for the automatic
generation of high-quality customizable human and animal avatars with motions
through text queries. The method significantly advanced the progress in dynamic
3D character generation. Secondly, we introduced a LLM planner that coordinates
both motion and avatar generation, which transforms a discriminative planning
into a customizable Q&A fashion. Lastly, we presented an animal motion dataset
named Zoo-300K, comprising approximately 300,000 text-motion pairs across 65
animal categories and its building pipeline ZooGen, which serves as a valuable
resource for the community. See project website
https://steve-zeyu-zhang.github.io/MotionAvatar/</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.13042v2' target='_blank'>StoryVerse: Towards Co-authoring Dynamic Plot with LLM-based Character
  Simulation via Narrative Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yi Wang, Qian Zhou, David Ledo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-17 23:04:51</h6>
<p class='card-text'>Automated plot generation for games enhances the player's experience by
providing rich and immersive narrative experience that adapts to the player's
actions. Traditional approaches adopt a symbolic narrative planning method
which limits the scale and complexity of the generated plot by requiring
extensive knowledge engineering work. Recent advancements use Large Language
Models (LLMs) to drive the behavior of virtual characters, allowing plots to
emerge from interactions between characters and their environments. However,
the emergent nature of such decentralized plot generation makes it difficult
for authors to direct plot progression. We propose a novel plot creation
workflow that mediates between a writer's authorial intent and the emergent
behaviors from LLM-driven character simulation, through a novel authorial
structure called "abstract acts". The writers define high-level plot outlines
that are later transformed into concrete character action sequences via an
LLM-based narrative planning process, based on the game world state. The
process creates "living stories" that dynamically adapt to various game world
states, resulting in narratives co-created by the author, character simulation,
and player. We present StoryVerse as a proof-of-concept system to demonstrate
this plot creation workflow. We showcase the versatility of our approach with
examples in different stories and game environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.10255v1' target='_blank'>When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks
  via Multi-modal Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xianzheng Ma, Yash Bhalgat, Brandon Smart, Shuai Chen, Xinghui Li, Jian Ding, Jindong Gu, Dave Zhenyu Chen, Songyou Peng, Jia-Wang Bian, Philip H Torr, Marc Pollefeys, Matthias Nießner, Ian D Reid, Angel X. Chang, Iro Laina, Victor Adrian Prisacariu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-16 16:59:58</h6>
<p class='card-text'>As large language models (LLMs) evolve, their integration with 3D spatial
data (3D-LLMs) has seen rapid progress, offering unprecedented capabilities for
understanding and interacting with physical spaces. This survey provides a
comprehensive overview of the methodologies enabling LLMs to process,
understand, and generate 3D data. Highlighting the unique advantages of LLMs,
such as in-context learning, step-by-step reasoning, open-vocabulary
capabilities, and extensive world knowledge, we underscore their potential to
significantly advance spatial comprehension and interaction within embodied
Artificial Intelligence (AI) systems. Our investigation spans various 3D data
representations, from point clouds to Neural Radiance Fields (NeRFs). It
examines their integration with LLMs for tasks such as 3D scene understanding,
captioning, question-answering, and dialogue, as well as LLM-based agents for
spatial reasoning, planning, and navigation. The paper also includes a brief
review of other methods that integrate 3D and language. The meta-analysis
presented in this paper reveals significant progress yet underscores the
necessity for novel approaches to harness the full potential of 3D-LLMs. Hence,
with this paper, we aim to chart a course for future research that explores and
expands the capabilities of 3D-LLMs in understanding and interacting with the
complex 3D world. To support this survey, we have established a project page
where papers related to our topic are organized and listed:
https://github.com/ActiveVisionLab/Awesome-LLM-3D.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.13034v2' target='_blank'>Autonomous Workflow for Multimodal Fine-Grained Training Assistants
  Towards Mixed Reality</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiahuan Pei, Irene Viola, Haochen Huang, Junxiao Wang, Moonisa Ahsan, Fanghua Ye, Jiang Yiming, Yao Sai, Di Wang, Zhumin Chen, Pengjie Ren, Pablo Cesar</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-16 14:20:30</h6>
<p class='card-text'>Autonomous artificial intelligence (AI) agents have emerged as promising
protocols for automatically understanding the language-based environment,
particularly with the exponential development of large language models (LLMs).
However, a fine-grained, comprehensive understanding of multimodal environments
remains under-explored. This work designs an autonomous workflow tailored for
integrating AI agents seamlessly into extended reality (XR) applications for
fine-grained training. We present a demonstration of a multimodal fine-grained
training assistant for LEGO brick assembly in a pilot XR environment.
Specifically, we design a cerebral language agent that integrates LLM with
memory, planning, and interaction with XR tools and a vision-language agent,
enabling agents to decide their actions based on past experiences. Furthermore,
we introduce LEGO-MRTA, a multimodal fine-grained assembly dialogue dataset
synthesized automatically in the workflow served by a commercial LLM. This
dataset comprises multimodal instruction manuals, conversations, XR responses,
and vision question answering. Last, we present several prevailing
open-resource LLMs as benchmarks, assessing their performance with and without
fine-tuning on the proposed dataset. We anticipate that the broader impact of
this workflow will advance the development of smarter assistants for seamless
user interaction in XR environments, fostering research in both AI and HCI
communities.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.09822v2' target='_blank'>SEEK: Semantic Reasoning for Object Goal Navigation in Real World
  Inspection Tasks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Muhammad Fadhil Ginting, Sung-Kyun Kim, David D. Fan, Matteo Palieri, Mykel J. Kochenderfer, Ali-akbar Agha-Mohammadi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-16 05:39:08</h6>
<p class='card-text'>This paper addresses the problem of object-goal navigation in autonomous
inspections in real-world environments. Object-goal navigation is crucial to
enable effective inspections in various settings, often requiring the robot to
identify the target object within a large search space. Current object
inspection methods fall short of human efficiency because they typically cannot
bootstrap prior and common sense knowledge as humans do. In this paper, we
introduce a framework that enables robots to use semantic knowledge from prior
spatial configurations of the environment and semantic common sense knowledge.
We propose SEEK (Semantic Reasoning for Object Inspection Tasks) that combines
semantic prior knowledge with the robot's observations to search for and
navigate toward target objects more efficiently. SEEK maintains two
representations: a Dynamic Scene Graph (DSG) and a Relational Semantic Network
(RSN). The RSN is a compact and practical model that estimates the probability
of finding the target object across spatial elements in the DSG. We propose a
novel probabilistic planning framework to search for the object using
relational semantic knowledge. Our simulation analyses demonstrate that SEEK
outperforms the classical planning and Large Language Models (LLMs)-based
methods that are examined in this study in terms of efficiency for object-goal
inspection tasks. We validated our approach on a physical legged robot in urban
environments, showcasing its practicality and effectiveness in real-world
inspection scenarios.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.09220v3' target='_blank'>ALPINE: Unveiling the Planning Capability of Autoregressive Learning in
  Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Siwei Wang, Yifei Shen, Shi Feng, Haoran Sun, Shang-Hua Teng, Wei Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-15 09:59:37</h6>
<p class='card-text'>Planning is a crucial element of both human intelligence and contemporary
large language models (LLMs). In this paper, we initiate a theoretical
investigation into the emergence of planning capabilities in Transformer-based
LLMs via their next-word prediction mechanisms. We model planning as a network
path-finding task, where the objective is to generate a valid path from a
specified source node to a designated target node. Our mathematical
characterization shows that Transformer architectures can execute path-finding
by embedding the adjacency and reachability matrices within their weights.
Furthermore, our theoretical analysis of gradient-based learning dynamics
reveals that LLMs can learn both the adjacency and a limited form of the
reachability matrices. These theoretical insights are then validated through
experiments, which demonstrate that Transformer architectures indeed learn the
adjacency and an incomplete reachability matrices, consistent with our
theoretical predictions. When applying our methodology to the real-world
planning benchmark Blocksworld, our observations remain consistent.
Additionally, our analyses uncover a fundamental limitation of current
Transformer architectures in path-finding: these architectures cannot identify
reachability relationships through transitivity, which leads to failures in
generating paths when concatenation is required. These findings provide new
insights into how the internal mechanisms of autoregressive learning facilitate
intelligent planning and deepen our understanding of how future LLMs might
achieve more advanced and general planning-and-reasoning capabilities across
diverse applications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.07474v2' target='_blank'>Integrating Intent Understanding and Optimal Behavior Planning for
  Behavior Tree Generation from Human Instructions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xinglin Chen, Yishuai Cai, Yunxin Mao, Minglong Li, Wenjing Yang, Weixia Xu, Ji Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-13 05:23:48</h6>
<p class='card-text'>Robots executing tasks following human instructions in domestic or industrial
environments essentially require both adaptability and reliability. Behavior
Tree (BT) emerges as an appropriate control architecture for these scenarios
due to its modularity and reactivity. Existing BT generation methods, however,
either do not involve interpreting natural language or cannot theoretically
guarantee the BTs' success. This paper proposes a two-stage framework for BT
generation, which first employs large language models (LLMs) to interpret goals
from high-level instructions, then constructs an efficient goal-specific BT
through the Optimal Behavior Tree Expansion Algorithm (OBTEA). We represent
goals as well-formed formulas in first-order logic, effectively bridging intent
understanding and optimal behavior planning. Experiments in the service robot
validate the proficiency of LLMs in producing grammatically correct and
accurately interpreted goals, demonstrate OBTEA's superiority over the baseline
BT Expansion algorithm in various metrics, and finally confirm the practical
deployability of our framework. The project website is
https://dids-ei.github.io/Project/LLM-OBTEA/.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.06964v2' target='_blank'>ManiFoundation Model for General-Purpose Robotic Manipulation of Contact
  Synthesis with Arbitrary Objects and Robots</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhixuan Xu, Chongkai Gao, Zixuan Liu, Gang Yang, Chenrui Tie, Haozhuo Zheng, Haoyu Zhou, Weikun Peng, Debang Wang, Tianrun Hu, Tianyi Chen, Zhouliang Yu, Lin Shao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-11 09:18:37</h6>
<p class='card-text'>To substantially enhance robot intelligence, there is a pressing need to
develop a large model that enables general-purpose robots to proficiently
undertake a broad spectrum of manipulation tasks, akin to the versatile
task-planning ability exhibited by LLMs. The vast diversity in objects, robots,
and manipulation tasks presents huge challenges. Our work introduces a
comprehensive framework to develop a foundation model for general robotic
manipulation that formalizes a manipulation task as contact synthesis.
Specifically, our model takes as input object and robot manipulator point
clouds, object physical attributes, target motions, and manipulation region
masks. It outputs contact points on the object and associated contact forces or
post-contact motions for robots to achieve the desired manipulation task. We
perform extensive experiments both in the simulation and real-world settings,
manipulating articulated rigid objects, rigid objects, and deformable objects
that vary in dimensionality, ranging from one-dimensional objects like ropes to
two-dimensional objects like cloth and extending to three-dimensional objects
such as plasticine. Our model achieves average success rates of around 90\%.
Supplementary materials and videos are available on our project website at
https://manifoundationmodel.github.io/.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.06093v2' target='_blank'>Selective Fine-tuning on LLM-labeled Data May Reduce Reliance on Human
  Annotation: A Case Study Using Schedule-of-Event Table Detection</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Bhawesh Kumar, Jonathan Amar, Eric Yang, Nan Li, Yugang Jia</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-09 20:45:58</h6>
<p class='card-text'>Large Language Models (LLMs) have demonstrated their efficacy across a broad
spectrum of tasks in healthcare applications. However, often LLMs need to be
fine-tuned on task-specific expert annotated data to achieve optimal
performance, which can be expensive and time consuming. In this study, we
fine-tune PaLM-2 with parameter efficient fine-tuning (PEFT) using noisy labels
obtained from gemini-pro 1.0 for the detection of Schedule-of-Event (SoE)
tables, which specify care plan in clinical trial protocols. We introduce a
filtering mechanism to select high-confidence labels for this table
classification task, thereby reducing the noise in the auto-generated labels.
We show that fine-tuned PaLM-2 with those labels achieves performance that
exceeds the gemini-pro 1.0 and other LLMs. Furthermore, its performance is
close to a PaLM-2 fine-tuned on labels obtained from non-expert annotators. Our
results show that leveraging LLM-generated labels through powerful models like
gemini-pro can potentially serve as a viable strategy for improving LLM
performance through fine-tuning in specialized tasks, particularly in domains
where expert annotations are scarce, expensive, or time-consuming to obtain.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.05956v2' target='_blank'>Probing Multimodal LLMs as World Models for Driving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shiva Sreeram, Tsun-Hsuan Wang, Alaa Maalouf, Guy Rosman, Sertac Karaman, Daniela Rus</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-09 17:52:42</h6>
<p class='card-text'>We provide a sober look at the application of Multimodal Large Language
Models (MLLMs) in autonomous driving, challenging common assumptions about
their ability to interpret dynamic driving scenarios. Despite advances in
models like GPT-4o, their performance in complex driving environments remains
largely unexplored. Our experimental study assesses various MLLMs as world
models using in-car camera perspectives and reveals that while these models
excel at interpreting individual images, they struggle to synthesize coherent
narratives across frames, leading to considerable inaccuracies in understanding
(i) ego vehicle dynamics, (ii) interactions with other road actors, (iii)
trajectory planning, and (iv) open-set scene reasoning. We introduce the
Eval-LLM-Drive dataset and DriveSim simulator to enhance our evaluation,
highlighting gaps in current MLLM capabilities and the need for improved models
in dynamic real-world environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.05955v3' target='_blank'>Smurfs: Leveraging Multiple Proficiency Agents with Context-Efficiency
  for Tool Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Junzhi Chen, Juhao Liang, Benyou Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-09 17:49:04</h6>
<p class='card-text'>The emergence of large language models (LLMs) has opened up unprecedented
possibilities for automating complex tasks that are often comparable to human
performance. Despite their capabilities, LLMs still encounter difficulties in
completing tasks that require high levels of accuracy and complexity due to
their inherent limitations in handling multifaceted problems single-handedly.
This paper introduces `Smurfs', a cutting-edge multi-agent framework designed
to revolutionize the application of LLMs. By seamlessly transforming a
conventional LLM into a synergistic multi-agent ensemble, Smurfs can enhance
the model's ability to solve complex tasks at no additional cost. This is
achieved through innovative prompting strategies that allocate distinct roles
within the model, thereby facilitating collaboration among specialized agents
and forming an intelligent multi-agent system. Our empirical investigation on
both open-ended task of StableToolBench and closed-ended task on HotpotQA
showcases Smurfs' superior capability in intricate tool utilization scenarios.
Notably, Smurfs outmatches all the baseline methods in both experiments,
setting new state-of-the-art performance. Furthermore, through comprehensive
ablation studies, we dissect the contribution of the core components of the
multi-agent framework to its overall efficacy. This not only verifies the
effectiveness of the framework, but also sets a route for future exploration of
multi-agent LLM systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.05526v3' target='_blank'>Benchmarking Neural Radiance Fields for Autonomous Robots: An Overview</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuhang Ming, Xingrui Yang, Weihan Wang, Zheng Chen, Jinglun Feng, Yifan Xing, Guofeng Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-09 03:34:09</h6>
<p class='card-text'>Neural Radiance Fields (NeRF) have emerged as a powerful paradigm for 3D
scene representation, offering high-fidelity renderings and reconstructions
from a set of sparse and unstructured sensor data. In the context of autonomous
robotics, where perception and understanding of the environment are pivotal,
NeRF holds immense promise for improving performance. In this paper, we present
a comprehensive survey and analysis of the state-of-the-art techniques for
utilizing NeRF to enhance the capabilities of autonomous robots. We especially
focus on the perception, localization and navigation, and decision-making
modules of autonomous robots and delve into tasks crucial for autonomous
operation, including 3D reconstruction, segmentation, pose estimation,
simultaneous localization and mapping (SLAM), navigation and planning, and
interaction. Our survey meticulously benchmarks existing NeRF-based methods,
providing insights into their strengths and limitations. Moreover, we explore
promising avenues for future research and development in this domain. Notably,
we discuss the integration of advanced techniques such as 3D Gaussian splatting
(3DGS), large language models (LLM), and generative AIs, envisioning enhanced
reconstruction efficiency, scene understanding, decision-making capabilities.
This survey serves as a roadmap for researchers seeking to leverage NeRFs to
empower autonomous robots, paving the way for innovative solutions that can
navigate and interact seamlessly in complex environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.05226v1' target='_blank'>SuFIA: Language-Guided Augmented Dexterity for Robotic Surgical
  Assistants</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Masoud Moghani, Lars Doorenbos, William Chung-Ho Panitch, Sean Huver, Mahdi Azizian, Ken Goldberg, Animesh Garg</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-08 17:22:25</h6>
<p class='card-text'>In this work, we present SuFIA, the first framework for natural
language-guided augmented dexterity for robotic surgical assistants. SuFIA
incorporates the strong reasoning capabilities of large language models (LLMs)
with perception modules to implement high-level planning and low-level control
of a robot for surgical sub-task execution. This enables a learning-free
approach to surgical augmented dexterity without any in-context examples or
motion primitives. SuFIA uses a human-in-the-loop paradigm by restoring control
to the surgeon in the case of insufficient information, mitigating unexpected
errors for mission-critical tasks. We evaluate SuFIA on four surgical sub-tasks
in a simulation environment and two sub-tasks on a physical surgical robotic
platform in the lab, demonstrating its ability to perform common surgical
sub-tasks through supervised autonomous operation under challenging physical
and workspace conditions. Project website: orbit-surgical.github.io/sufia</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.04798v2' target='_blank'>From LLMs to Actions: Latent Codes as Bridges in Hierarchical Robot
  Control</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yide Shentu, Philipp Wu, Aravind Rajeswaran, Pieter Abbeel</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-08 04:14:06</h6>
<p class='card-text'>Hierarchical control for robotics has long been plagued by the need to have a
well defined interface layer to communicate between high-level task planners
and low-level policies. With the advent of LLMs, language has been emerging as
a prospective interface layer. However, this has several limitations. Not all
tasks can be decomposed into steps that are easily expressible in natural
language (e.g. performing a dance routine). Further, it makes end-to-end
finetuning on embodied data challenging due to domain shift and catastrophic
forgetting. We introduce our method -- Learnable Latent Codes as Bridges (LCB)
-- as an alternate architecture to overcome these limitations. \method~uses a
learnable latent code to act as a bridge between LLMs and low-level policies.
This enables LLMs to flexibly communicate goals in the task plan without being
entirely constrained by language limitations. Additionally, it enables
end-to-end finetuning without destroying the embedding space of word tokens
learned during pre-training. Through experiments on Language Table and Calvin,
two common language based benchmarks for embodied agents, we find that
\method~outperforms baselines (including those w/ GPT-4V) that leverage pure
language as the interface layer on tasks that require reasoning and multi-step
behaviors.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.04777v1' target='_blank'>Empathy Through Multimodality in Conversational Interfaces</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mahyar Abbasian, Iman Azimi, Mohammad Feli, Amir M. Rahmani, Ramesh Jain</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-08 02:48:29</h6>
<p class='card-text'>Agents represent one of the most emerging applications of Large Language
Models (LLMs) and Generative AI, with their effectiveness hinging on multimodal
capabilities to navigate complex user environments. Conversational Health
Agents (CHAs), a prime example of this, are redefining healthcare by offering
nuanced support that transcends textual analysis to incorporate emotional
intelligence. This paper introduces an LLM-based CHA engineered for rich,
multimodal dialogue-especially in the realm of mental health support. It
adeptly interprets and responds to users' emotional states by analyzing
multimodal cues, thus delivering contextually aware and empathetically resonant
verbal responses. Our implementation leverages the versatile openCHA framework,
and our comprehensive evaluation involves neutral prompts expressed in diverse
emotional tones: sadness, anger, and joy. We evaluate the consistency and
repeatability of the planning capability of the proposed CHA. Furthermore,
human evaluators critique the CHA's empathic delivery, with findings revealing
a striking concordance between the CHA's outputs and evaluators' assessments.
These results affirm the indispensable role of vocal (soon multimodal) emotion
recognition in strengthening the empathetic connection built by CHAs, cementing
their place at the forefront of interactive, compassionate digital health
solutions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.04776v2' target='_blank'>Chain of Thoughtlessness? An Analysis of CoT in Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kaya Stechly, Karthik Valmeekam, Subbarao Kambhampati</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-08 02:48:28</h6>
<p class='card-text'>Large language model (LLM) performance on reasoning problems typically does
not generalize out of distribution. Previous work has claimed that this can be
mitigated with chain of thought prompting-a method of demonstrating solution
procedures-with the intuition that it is possible to in-context teach an LLM an
algorithm for solving the problem. This paper presents a case study of chain of
thought on problems from Blocksworld, a classical planning domain, and examines
the performance of two state-of-the-art LLMs across two axes: generality of
examples given in prompt, and complexity of problems queried with each prompt.
While our problems are very simple, we only find meaningful performance
improvements from chain of thought prompts when those prompts are exceedingly
specific to their problem class, and that those improvements quickly
deteriorate as the size n of the query-specified stack grows past the size of
stacks shown in the examples. We also create scalable variants of three domains
commonly studied in previous CoT papers and demonstrate the existence of
similar failure modes. Our results hint that, contrary to previous claims in
the literature, CoT's performance improvements do not stem from the model
learning general algorithmic procedures via demonstrations but depend on
carefully engineering highly problem specific prompts. This spotlights
drawbacks of chain of thought, especially the sharp tradeoff between possible
performance gains and the amount of human labor necessary to generate examples
with correct reasoning traces.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.04497v2' target='_blank'>Unveiling Disparities in Web Task Handling Between Human and Web Agent</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kihoon Son, Jinhyeon Kwon, DaEun Choi, Tae Soo Kim, Young-Ho Kim, Sangdoo Yun, Juho Kim</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-07 17:10:31</h6>
<p class='card-text'>With the advancement of Large-Language Models (LLMs) and Large
Vision-Language Models (LVMs), agents have shown significant capabilities in
various tasks, such as data analysis, gaming, or code generation. Recently,
there has been a surge in research on web agents, capable of performing tasks
within the web environment. However, the web poses unforeseeable scenarios,
challenging the generalizability of these agents. This study investigates the
disparities between human and web agents' performance in web tasks (e.g.,
information search) by concentrating on planning, action, and reflection
aspects during task execution. We conducted a web task study with a think-aloud
protocol, revealing distinct cognitive actions and operations on websites
employed by humans. Comparative examination of existing agent structures and
human behavior with thought processes highlighted differences in knowledge
updating and ambiguity handling when performing the task. Humans demonstrated a
propensity for exploring and modifying plans based on additional information
and investigating reasons for failure. These findings offer insights into
designing planning, reflection, and information discovery modules for web
agents and designing the capturing method for implicit human knowledge in a web
task.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.04215v1' target='_blank'>NL2Plan: Robust LLM-Driven Planning from Minimal Text Descriptions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Elliot Gestrin, Marco Kuhlmann, Jendrik Seipp</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-07 11:27:13</h6>
<p class='card-text'>Today's classical planners are powerful, but modeling input tasks in formats
such as PDDL is tedious and error-prone. In contrast, planning with Large
Language Models (LLMs) allows for almost any input text, but offers no
guarantees on plan quality or even soundness. In an attempt to merge the best
of these two approaches, some work has begun to use LLMs to automate parts of
the PDDL creation process. However, these methods still require various degrees
of expert input. We present NL2Plan, the first domain-agnostic offline
LLM-driven planning system. NL2Plan uses an LLM to incrementally extract the
necessary information from a short text prompt before creating a complete PDDL
description of both the domain and the problem, which is finally solved by a
classical planner. We evaluate NL2Plan on four planning domains and find that
it solves 10 out of 15 tasks - a clear improvement over a plain
chain-of-thought reasoning LLM approach, which only solves 2 tasks. Moreover,
in two out of the five failure cases, instead of returning an invalid plan,
NL2Plan reports that it failed to solve the task. In addition to using NL2Plan
in end-to-end mode, users can inspect and correct all of its intermediate
results, such as the PDDL representation, increasing explainability and making
it an assistive tool for PDDL creation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.03998v2' target='_blank'>Sketch Then Generate: Providing Incremental User Feedback and Guiding
  LLM Code Generation through Language-Oriented Code Sketches</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chen Zhu-Tian, Zeyu Xiong, Xiaoshuo Yao, Elena Glassman</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-07 04:21:07</h6>
<p class='card-text'>Crafting effective prompts for code generation or editing with Large Language
Models (LLMs) is not an easy task. Particularly, the absence of immediate,
stable feedback during prompt crafting hinders effective interaction, as users
are left to mentally imagine possible outcomes until the code is generated. In
response, we introduce Language-Oriented Code Sketching, an interactive
approach that provides instant, incremental feedback in the form of code
sketches (i.e., incomplete code outlines) during prompt crafting. This approach
converts a prompt into a code sketch by leveraging the inherent linguistic
structures within the prompt and applying classic natural language processing
techniques. The sketch then serves as an intermediate placeholder that not only
previews the intended code structure but also guides the LLM towards the
desired code, thereby enhancing human-LLM interaction. We conclude by
discussing the approach's applicability and future plans.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.03734v1' target='_blank'>FOKE: A Personalized and Explainable Education Framework Integrating
  Foundation Models, Knowledge Graphs, and Prompt Engineering</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Silan Hu, Xiaoning Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-06 15:11:05</h6>
<p class='card-text'>Integrating large language models (LLMs) and knowledge graphs (KGs) holds
great promise for revolutionizing intelligent education, but challenges remain
in achieving personalization, interactivity, and explainability. We propose
FOKE, a Forest Of Knowledge and Education framework that synergizes foundation
models, knowledge graphs, and prompt engineering to address these challenges.
FOKE introduces three key innovations: (1) a hierarchical knowledge forest for
structured domain knowledge representation; (2) a multi-dimensional user
profiling mechanism for comprehensive learner modeling; and (3) an interactive
prompt engineering scheme for generating precise and tailored learning
guidance.
  We showcase FOKE's application in programming education, homework assessment,
and learning path planning, demonstrating its effectiveness and practicality.
Additionally, we implement Scholar Hero, a real-world instantiation of FOKE.
Our research highlights the potential of integrating foundation models,
knowledge graphs, and prompt engineering to revolutionize intelligent education
practices, ultimately benefiting learners worldwide. FOKE provides a principled
and unified approach to harnessing cutting-edge AI technologies for
personalized, interactive, and explainable educational services, paving the way
for further research and development in this critical direction.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.03726v1' target='_blank'>sc-OTGM: Single-Cell Perturbation Modeling by Solving Optimal Mass
  Transport on the Manifold of Gaussian Mixtures</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Andac Demir, Elizaveta Solovyeva, James Boylan, Mei Xiao, Fabrizio Serluca, Sebastian Hoersch, Jeremy Jenkins, Murthy Devarakonda, Bulent Kiziltan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-06 06:46:11</h6>
<p class='card-text'>Influenced by breakthroughs in LLMs, single-cell foundation models are
emerging. While these models show successful performance in cell type
clustering, phenotype classification, and gene perturbation response
prediction, it remains to be seen if a simpler model could achieve comparable
or better results, especially with limited data. This is important, as the
quantity and quality of single-cell data typically fall short of the standards
in textual data used for training LLMs. Single-cell sequencing often suffers
from technical artifacts, dropout events, and batch effects. These challenges
are compounded in a weakly supervised setting, where the labels of cell states
can be noisy, further complicating the analysis. To tackle these challenges, we
present sc-OTGM, streamlined with less than 500K parameters, making it
approximately 100x more compact than the foundation models, offering an
efficient alternative. sc-OTGM is an unsupervised model grounded in the
inductive bias that the scRNAseq data can be generated from a combination of
the finite multivariate Gaussian distributions. The core function of sc-OTGM is
to create a probabilistic latent space utilizing a GMM as its prior
distribution and distinguish between distinct cell populations by learning
their respective marginal PDFs. It uses a Hit-and-Run Markov chain sampler to
determine the OT plan across these PDFs within the GMM framework. We evaluated
our model against a CRISPR-mediated perturbation dataset, called CROP-seq,
consisting of 57 one-gene perturbations. Our results demonstrate that sc-OTGM
is effective in cell state classification, aids in the analysis of differential
gene expression, and ranks genes for target identification through a
recommender system. It also predicts the effects of single-gene perturbations
on downstream gene regulation and generates synthetic scRNA-seq data
conditioned on specific cell states.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.03010v1' target='_blank'>High Order Reasoning for Time Critical Recommendation in Evidence-based
  Medicine</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Manjiang Yu, Xue Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-05 17:36:22</h6>
<p class='card-text'>In time-critical decisions, human decision-makers can interact with
AI-enabled situation-aware software to evaluate many imminent and possible
scenarios, retrieve billions of facts, and estimate different outcomes based on
trillions of parameters in a fraction of a second. In high-order reasoning,
"what-if" questions can be used to challenge the assumptions or pre-conditions
of the reasoning, "why-not" questions can be used to challenge on the method
applied in the reasoning, "so-what" questions can be used to challenge the
purpose of the decision, and "how-about" questions can be used to challenge the
applicability of the method. When above high-order reasoning questions are
applied to assist human decision-making, it can help humans to make
time-critical decisions and avoid false-negative or false-positive types of
errors. In this paper, we present a model of high-order reasoning to offer
recommendations in evidence-based medicine in a time-critical fashion for the
applications in ICU. The Large Language Model (LLM) is used in our system. The
experiments demonstrated the LLM exhibited optimal performance in the "What-if"
scenario, achieving a similarity of 88.52% with the treatment plans of human
doctors. In the "Why-not" scenario, the best-performing model tended to opt for
alternative treatment plans in 70% of cases for patients who died after being
discharged from the ICU. In the "So-what" scenario, the optimal model provided
a detailed analysis of the motivation and significance of treatment plans for
ICU patients, with its reasoning achieving a similarity of 55.6% with actual
diagnostic information. In the "How-about" scenario, the top-performing LLM
demonstrated a content similarity of 66.5% in designing treatment plans
transferring for similar diseases. Meanwhile, LLMs managed to predict the life
status of patients after their discharge from the ICU with an accuracy of 70%.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.02957v3' target='_blank'>Agent Hospital: A Simulacrum of Hospital with Evolvable Medical Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Junkai Li, Yunghwei Lai, Weitao Li, Jingyi Ren, Meng Zhang, Xinhui Kang, Siyu Wang, Peng Li, Ya-Qin Zhang, Weizhi Ma, Yang Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-05 14:53:51</h6>
<p class='card-text'>The recent rapid development of large language models (LLMs) has sparked a
new wave of technological revolution in medical artificial intelligence (AI).
While LLMs are designed to understand and generate text like a human,
autonomous agents that utilize LLMs as their "brain" have exhibited
capabilities beyond text processing such as planning, reflection, and using
tools by enabling their "bodies" to interact with the environment. We introduce
a simulacrum of hospital called Agent Hospital that simulates the entire
process of treating illness, in which all patients, nurses, and doctors are
LLM-powered autonomous agents. Within the simulacrum, doctor agents are able to
evolve by treating a large number of patient agents without the need to label
training data manually. After treating tens of thousands of patient agents in
the simulacrum (human doctors may take several years in the real world), the
evolved doctor agents outperform state-of-the-art medical agent methods on the
MedQA benchmark comprising US Medical Licensing Examination (USMLE) test
questions. Our methods of simulacrum construction and agent evolution have the
potential in benefiting a broad range of applications beyond medical AI.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.02749v1' target='_blank'>Sub-goal Distillation: A Method to Improve Small Language Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Maryam Hashemzadeh, Elias Stengel-Eskin, Sarath Chandar, Marc-Alexandre Cote</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-04 20:34:06</h6>
<p class='card-text'>While Large Language Models (LLMs) have demonstrated significant promise as
agents in interactive tasks, their substantial computational requirements and
restricted number of calls constrain their practical utility, especially in
long-horizon interactive tasks such as decision-making or in scenarios
involving continuous ongoing tasks. To address these constraints, we propose a
method for transferring the performance of an LLM with billions of parameters
to a much smaller language model (770M parameters). Our approach involves
constructing a hierarchical agent comprising a planning module, which learns
through Knowledge Distillation from an LLM to generate sub-goals, and an
execution module, which learns to accomplish these sub-goals using elementary
actions. In detail, we leverage an LLM to annotate an oracle path with a
sequence of sub-goals towards completing a goal. Subsequently, we utilize this
annotated data to fine-tune both the planning and execution modules.
Importantly, neither module relies on real-time access to an LLM during
inference, significantly reducing the overall cost associated with LLM
interactions to a fixed cost. In ScienceWorld, a challenging and multi-task
interactive text environment, our method surpasses standard imitation learning
based solely on elementary actions by 16.7% (absolute). Our analysis highlights
the efficiency of our approach compared to other LLM-based methods. Our code
and annotated data for distillation can be found on GitHub.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.01868v1' target='_blank'>Incorporating External Knowledge and Goal Guidance for LLM-based
  Conversational Recommender Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chuang Li, Yang Deng, Hengchang Hu, Min-Yen Kan, Haizhou Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-03 05:42:57</h6>
<p class='card-text'>This paper aims to efficiently enable large language models (LLMs) to use
external knowledge and goal guidance in conversational recommender system (CRS)
tasks. Advanced LLMs (e.g., ChatGPT) are limited in domain-specific CRS tasks
for 1) generating grounded responses with recommendation-oriented knowledge, or
2) proactively leading the conversations through different dialogue goals. In
this work, we first analyze those limitations through a comprehensive
evaluation, showing the necessity of external knowledge and goal guidance which
contribute significantly to the recommendation accuracy and language quality.
In light of this finding, we propose a novel ChatCRS framework to decompose the
complex CRS task into several sub-tasks through the implementation of 1) a
knowledge retrieval agent using a tool-augmented approach to reason over
external Knowledge Bases and 2) a goal-planning agent for dialogue goal
prediction. Experimental results on two multi-goal CRS datasets reveal that
ChatCRS sets new state-of-the-art benchmarks, improving language quality of
informativeness by 17% and proactivity by 27%, and achieving a tenfold
enhancement in recommendation accuracy.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.02357v2' target='_blank'>Large Language Models for Mobility Analysis in Transportation Systems: A
  Survey on Forecasting Tasks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zijian Zhang, Yujie Sun, Zepu Wang, Yuqi Nie, Xiaobo Ma, Ruolin Li, Peng Sun, Xuegang Ban</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-03 02:54:43</h6>
<p class='card-text'>Mobility analysis is a crucial element in the research area of transportation
systems. Forecasting traffic information offers a viable solution to address
the conflict between increasing transportation demands and the limitations of
transportation infrastructure. Predicting human travel is significant in aiding
various transportation and urban management tasks, such as taxi dispatch and
urban planning. Machine learning and deep learning methods are favored for
their flexibility and accuracy. Nowadays, with the advent of large language
models (LLMs), many researchers have combined these models with previous
techniques or applied LLMs to directly predict future traffic information and
human travel behaviors. However, there is a lack of comprehensive studies on
how LLMs can contribute to this field. This survey explores existing approaches
using LLMs for time series forecasting problems for mobility in transportation
systems. We provide a literature review concerning the forecasting applications
within transportation systems, elucidating how researchers utilize LLMs,
showcasing recent state-of-the-art advancements, and identifying the challenges
that must be overcome to fully leverage LLMs in this domain.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.01534v1' target='_blank'>Plan-Seq-Learn: Language Model Guided RL for Solving Long Horizon
  Robotics Tasks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Murtaza Dalal, Tarun Chiruvolu, Devendra Chaplot, Ruslan Salakhutdinov</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-02 17:59:31</h6>
<p class='card-text'>Large Language Models (LLMs) have been shown to be capable of performing
high-level planning for long-horizon robotics tasks, yet existing methods
require access to a pre-defined skill library (e.g. picking, placing, pulling,
pushing, navigating). However, LLM planning does not address how to design or
learn those behaviors, which remains challenging particularly in long-horizon
settings. Furthermore, for many tasks of interest, the robot needs to be able
to adjust its behavior in a fine-grained manner, requiring the agent to be
capable of modifying low-level control actions. Can we instead use the
internet-scale knowledge from LLMs for high-level policies, guiding
reinforcement learning (RL) policies to efficiently solve robotic control tasks
online without requiring a pre-determined set of skills? In this paper, we
propose Plan-Seq-Learn (PSL): a modular approach that uses motion planning to
bridge the gap between abstract language and learned low-level control for
solving long-horizon robotics tasks from scratch. We demonstrate that PSL
achieves state-of-the-art results on over 25 challenging robotics tasks with up
to 10 stages. PSL solves long-horizon tasks from raw visual input spanning four
benchmarks at success rates of over 85%, out-performing language-based,
classical, and end-to-end approaches. Video results and code at
https://mihdalal.github.io/planseqlearn/</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.01533v1' target='_blank'>OmniDrive: A Holistic LLM-Agent Framework for Autonomous Driving with 3D
  Perception, Reasoning and Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shihao Wang, Zhiding Yu, Xiaohui Jiang, Shiyi Lan, Min Shi, Nadine Chang, Jan Kautz, Ying Li, Jose M. Alvarez</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-02 17:59:24</h6>
<p class='card-text'>The advances in multimodal large language models (MLLMs) have led to growing
interests in LLM-based autonomous driving agents to leverage their strong
reasoning capabilities. However, capitalizing on MLLMs' strong reasoning
capabilities for improved planning behavior is challenging since planning
requires full 3D situational awareness beyond 2D reasoning. To address this
challenge, our work proposes a holistic framework for strong alignment between
agent models and 3D driving tasks. Our framework starts with a novel 3D MLLM
architecture that uses sparse queries to lift and compress visual
representations into 3D before feeding them into an LLM. This query-based
representation allows us to jointly encode dynamic objects and static map
elements (e.g., traffic lanes), providing a condensed world model for
perception-action alignment in 3D. We further propose OmniDrive-nuScenes, a new
visual question-answering dataset challenging the true 3D situational awareness
of a model with comprehensive visual question-answering (VQA) tasks, including
scene description, traffic regulation, 3D grounding, counterfactual reasoning,
decision making and planning. Extensive studies show the effectiveness of the
proposed architecture as well as the importance of the VQA tasks for reasoning
and planning in complex 3D scenes.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.00552v4' target='_blank'>Long-Term Human Trajectory Prediction using 3D Dynamic Scene Graphs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nicolas Gorlo, Lukas Schmid, Luca Carlone</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-01 14:50:58</h6>
<p class='card-text'>We present a novel approach for long-term human trajectory prediction in
indoor human-centric environments, which is essential for long-horizon robot
planning in these environments. State-of-the-art human trajectory prediction
methods are limited by their focus on collision avoidance and short-term
planning, and their inability to model complex interactions of humans with the
environment. In contrast, our approach overcomes these limitations by
predicting sequences of human interactions with the environment and using this
information to guide trajectory predictions over a horizon of up to 60s. We
leverage Large Language Models (LLMs) to predict interactions with the
environment by conditioning the LLM prediction on rich contextual information
about the scene. This information is given as a 3D Dynamic Scene Graph that
encodes the geometry, semantics, and traversability of the environment into a
hierarchical representation. We then ground these interaction sequences into
multi-modal spatio-temporal distributions over human positions using a
probabilistic approach based on continuous-time Markov Chains. To evaluate our
approach, we introduce a new semi-synthetic dataset of long-term human
trajectories in complex indoor environments, which also includes annotations of
human-object interactions. We show in thorough experimental evaluations that
our approach achieves a 54% lower average negative log-likelihood and a 26.5%
lower Best-of-20 displacement error compared to the best non-privileged (i.e.,
evaluated in a zero-shot fashion on the dataset) baselines for a time horizon
of 60s.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.00461v1' target='_blank'>Enhancing Surgical Robots with Embodied Intelligence for Autonomous
  Ultrasound Scanning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Huan Xu, Jinlin Wu, Guanglin Cao, Zhen Lei, Zhen Chen, Hongbin Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-01 11:39:38</h6>
<p class='card-text'>Ultrasound robots are increasingly used in medical diagnostics and early
disease screening. However, current ultrasound robots lack the intelligence to
understand human intentions and instructions, hindering autonomous ultrasound
scanning. To solve this problem, we propose a novel Ultrasound Embodied
Intelligence system that equips ultrasound robots with the large language model
(LLM) and domain knowledge, thereby improving the efficiency of ultrasound
robots. Specifically, we first design an ultrasound operation knowledge
database to add expertise in ultrasound scanning to the LLM, enabling the LLM
to perform precise motion planning. Furthermore, we devise a dynamic ultrasound
scanning strategy based on a \textit{think-observe-execute} prompt engineering,
allowing LLMs to dynamically adjust motion planning strategies during the
scanning procedures. Extensive experiments demonstrate that our system
significantly improves ultrasound scan efficiency and quality from verbal
commands. This advancement in autonomous medical scanning technology
contributes to non-invasive diagnostics and streamlined medical workflows.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.00330v1' target='_blank'>Integrating A.I. in Higher Education: Protocol for a Pilot Study with
  'SAMCares: An Adaptive Learning Hub'</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Syed Hasib Akhter Faruqui, Nazia Tasnim, Iftekhar Ibne Basith, Suleiman Obeidat, Faruk Yildiz</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-05-01 05:39:07</h6>
<p class='card-text'>Learning never ends, and there is no age limit to grow yourself. However, the
educational landscape may face challenges in effectively catering to students'
inclusion and diverse learning needs. These students should have access to
state-of-the-art methods for lecture delivery, online resources, and technology
needs. However, with all the diverse learning sources, it becomes harder for
students to comprehend a large amount of knowledge in a short period of time.
Traditional assistive technologies and learning aids often lack the dynamic
adaptability required for individualized education plans. Large Language Models
(LLM) have been used in language translation, text summarization, and content
generation applications. With rapid growth in AI over the past years,
AI-powered chatbots and virtual assistants have been developed. This research
aims to bridge this gap by introducing an innovative study buddy we will be
calling the 'SAMCares'. The system leverages a Large Language Model (LLM) (in
our case, LLaMa-2 70B as the base model) and Retriever-Augmented Generation
(RAG) to offer real-time, context-aware, and adaptive educational support. The
context of the model will be limited to the knowledge base of Sam Houston State
University (SHSU) course notes. The LLM component enables a chat-like
environment to interact with it to meet the unique learning requirements of
each student. For this, we will build a custom web-based GUI. At the same time,
RAG enhances real-time information retrieval and text generation, in turn
providing more accurate and context-specific assistance. An option to upload
additional study materials in the web GUI is added in case additional knowledge
support is required. The system's efficacy will be evaluated through controlled
trials and iterative feedback mechanisms.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.19065v1' target='_blank'>HELPER-X: A Unified Instructable Embodied Agent to Tackle Four
  Interactive Vision-Language Domains with Memory-Augmented Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Gabriel Sarch, Sahil Somani, Raghav Kapoor, Michael J. Tarr, Katerina Fragkiadaki</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-29 19:12:42</h6>
<p class='card-text'>Recent research on instructable agents has used memory-augmented Large
Language Models (LLMs) as task planners, a technique that retrieves
language-program examples relevant to the input instruction and uses them as
in-context examples in the LLM prompt to improve the performance of the LLM in
inferring the correct action and task plans. In this technical report, we
extend the capabilities of HELPER, by expanding its memory with a wider array
of examples and prompts, and by integrating additional APIs for asking
questions. This simple expansion of HELPER into a shared memory enables the
agent to work across the domains of executing plans from dialogue, natural
language instruction following, active question asking, and commonsense room
reorganization. We evaluate the agent on four diverse interactive
visual-language embodied agent benchmarks: ALFRED, TEACh, DialFRED, and the
Tidy Task. HELPER-X achieves few-shot, state-of-the-art performance across
these benchmarks using a single agent, without requiring in-domain training,
and remains competitive with agents that have undergone in-domain training.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.17833v1' target='_blank'>Testing and Understanding Erroneous Planning in LLM Agents through
  Synthesized User Inputs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhenlan Ji, Daoyuan Wu, Pingchuan Ma, Zongjie Li, Shuai Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-27 08:56:45</h6>
<p class='card-text'>Agents based on large language models (LLMs) have demonstrated effectiveness
in solving a wide range of tasks by integrating LLMs with key modules such as
planning, memory, and tool usage. Increasingly, customers are adopting LLM
agents across a variety of commercial applications critical to reliability,
including support for mental well-being, chemical synthesis, and software
development. Nevertheless, our observations and daily use of LLM agents
indicate that they are prone to making erroneous plans, especially when the
tasks are complex and require long-term planning.
  In this paper, we propose PDoctor, a novel and automated approach to testing
LLM agents and understanding their erroneous planning. As the first work in
this direction, we formulate the detection of erroneous planning as a
constraint satisfiability problem: an LLM agent's plan is considered erroneous
if its execution violates the constraints derived from the user inputs. To this
end, PDoctor first defines a domain-specific language (DSL) for user queries
and synthesizes varying inputs with the assistance of the Z3 constraint solver.
These synthesized inputs are natural language paragraphs that specify the
requirements for completing a series of tasks. Then, PDoctor derives
constraints from these requirements to form a testing oracle. We evaluate
PDoctor with three mainstream agent frameworks and two powerful LLMs (GPT-3.5
and GPT-4). The results show that PDoctor can effectively detect diverse errors
in agent planning and provide insights and error characteristics that are
valuable to both agent developers and users. We conclude by discussing
potential alternative designs and directions to extend PDoctor.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.17525v2' target='_blank'>Large Language Model Agent as a Mechanical Designer</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yayati Jadhav, Amir Barati Farimani</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-26 16:41:24</h6>
<p class='card-text'>Conventional mechanical design paradigms rely on experts systematically
refining concepts through experience-guided modification and FEA to meet
specific requirements. However, this approach can be time-consuming and heavily
dependent on prior knowledge and experience. While numerous machine learning
models have been developed to streamline this intensive and expert-driven
iterative process, these methods typically demand extensive training data and
considerable computational resources. Furthermore, methods based on deep
learning are usually restricted to the specific domains and tasks for which
they were trained, limiting their applicability across different tasks. This
creates a trade-off between the efficiency of automation and the demand for
resources. In this study, we present a novel approach that integrates
pre-trained LLMs with a FEM module. The FEM module evaluates each design and
provides essential feedback, guiding the LLMs to continuously learn, plan,
generate, and optimize designs without the need for domain-specific training.
We demonstrate the effectiveness of our proposed framework in managing the
iterative optimization of truss structures, showcasing its capability to reason
about and refine designs according to structured feedback and criteria. Our
results reveal that these LLM-based agents can successfully generate truss
designs that comply with natural language specifications with a success rate of
up to 90%, which varies according to the applied constraints. By employing
prompt-based optimization techniques we show that LLM based agents exhibit
optimization behavior when provided with solution-score pairs to iteratively
refine designs to meet specifications. This ability of LLM agents to produce
viable designs and optimize them based on their inherent reasoning capabilities
highlights their potential to develop and implement effective design strategies
autonomously.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.16921v1' target='_blank'>A Short Survey of Human Mobility Prediction in Epidemic Modeling from
  Transformers to LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Christian N. Mayemba, D'Jeff K. Nkashama, Jean Marie Tshimula, Maximilien V. Dialufuma, Jean Tshibangu Muabila, Mbuyi Mukendi Didier, Hugues Kanda, René Manassé Galekwa, Heber Dibwe Fita, Serge Mundele, Kalonji Kalala, Aristarque Ilunga, Lambert Mukendi Ntobo, Dominique Muteba, Aaron Aruna Abedi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-25 17:52:19</h6>
<p class='card-text'>This paper provides a comprehensive survey of recent advancements in
leveraging machine learning techniques, particularly Transformer models, for
predicting human mobility patterns during epidemics. Understanding how people
move during epidemics is essential for modeling the spread of diseases and
devising effective response strategies. Forecasting population movement is
crucial for informing epidemiological models and facilitating effective
response planning in public health emergencies. Predicting mobility patterns
can enable authorities to better anticipate the geographical and temporal
spread of diseases, allocate resources more efficiently, and implement targeted
interventions. We review a range of approaches utilizing both pretrained
language models like BERT and Large Language Models (LLMs) tailored
specifically for mobility prediction tasks. These models have demonstrated
significant potential in capturing complex spatio-temporal dependencies and
contextual patterns in textual data.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.16698v4' target='_blank'>Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society
  of LLM Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Giorgio Piatti, Zhijing Jin, Max Kleiman-Weiner, Bernhard Schölkopf, Mrinmaya Sachan, Rada Mihalcea</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-25 15:59:16</h6>
<p class='card-text'>As AI systems pervade human life, ensuring that large language models (LLMs)
make safe decisions remains a significant challenge. We introduce the
Governance of the Commons Simulation (GovSim), a generative simulation platform
designed to study strategic interactions and cooperative decision-making in
LLMs. In GovSim, a society of AI agents must collectively balance exploiting a
common resource with sustaining it for future use. This environment enables the
study of how ethical considerations, strategic planning, and negotiation skills
impact cooperative outcomes. We develop an LLM-based agent architecture and
test it with the leading open and closed LLMs. We find that all but the most
powerful LLM agents fail to achieve a sustainable equilibrium in GovSim, with
the highest survival rate below 54%. Ablations reveal that successful
multi-agent communication between agents is critical for achieving cooperation
in these cases. Furthermore, our analyses show that the failure to achieve
sustainable cooperation in most LLMs stems from their inability to formulate
and analyze hypotheses about the long-term effects of their actions on the
equilibrium of the group. Finally, we show that agents that leverage
"Universalization"-based reasoning, a theory of moral thinking, are able to
achieve significantly better sustainability. Taken together, GovSim enables us
to study the mechanisms that underlie sustainable self-government with
specificity and scale. We open source the full suite of our research results,
including the simulation environment, agent prompts, and a comprehensive web
interface.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.00715v4' target='_blank'>Adapting Open-Source Large Language Models for Cost-Effective,
  Expert-Level Clinical Note Generation with On-Policy Reinforcement Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hanyin Wang, Chufan Gao, Bolun Liu, Qiping Xu, Guleid Hussein, Mohamad El Labban, Kingsley Iheasirim, Hariprasad Korsapati, Chuck Outcalt, Jimeng Sun</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-25 15:34:53</h6>
<p class='card-text'>Proprietary Large Language Models (LLMs) such as GPT-4 and Gemini have
demonstrated promising capabilities in clinical text summarization tasks.
However, due to patient data privacy concerns and computational costs, many
healthcare providers prefer using small, locally-hosted models over external
generic LLMs. This study presents a comprehensive domain- and task-specific
adaptation process for the open-source LLaMA-2 13 billion parameter model,
enabling it to generate high-quality clinical notes from outpatient
patient-doctor dialogues. Our process incorporates continued pre-training,
supervised fine-tuning, and reinforcement learning from both AI and human
feedback. We introduced a new approach, DistillDirect, for performing on-policy
reinforcement learning with Gemini 1.0 Pro as the teacher model. Our resulting
model, LLaMA-Clinic, can generate clinical notes comparable in quality to those
authored by physicians. In a blinded physician reader study, the majority
(90.4%) of individual evaluations rated the notes generated by LLaMA-Clinic as
"acceptable" or higher across all three criteria: real-world readiness,
completeness, and accuracy. In the more challenging "Assessment and Plan"
section, LLaMA-Clinic scored higher (4.2/5) in real-world readiness than
physician-authored notes (4.1/5). Our cost analysis for inference shows that
our LLaMA-Clinic model achieves a 3.75-fold cost reduction compared to an
external generic LLM service. Additionally, we highlight key considerations for
future clinical note-generation tasks, emphasizing the importance of
pre-defining a best-practice note format, rather than relying on LLMs to
determine this for clinical practice. We have made our newly created synthetic
clinic dialogue-note dataset and the physician feedback dataset publicly
available to foster future research.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.17605v1' target='_blank'>Autonomous LLM-driven research from data to human-verifiable research
  papers</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tal Ifargan, Lukas Hafner, Maor Kern, Ori Alcalay, Roy Kishony</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-24 23:15:49</h6>
<p class='card-text'>As AI promises to accelerate scientific discovery, it remains unclear whether
fully AI-driven research is possible and whether it can adhere to key
scientific values, such as transparency, traceability and verifiability.
Mimicking human scientific practices, we built data-to-paper, an automation
platform that guides interacting LLM agents through a complete stepwise
research process, while programmatically back-tracing information flow and
allowing human oversight and interactions. In autopilot mode, provided with
annotated data alone, data-to-paper raised hypotheses, designed research plans,
wrote and debugged analysis codes, generated and interpreted results, and
created complete and information-traceable research papers. Even though
research novelty was relatively limited, the process demonstrated autonomous
generation of de novo quantitative insights from data. For simple research
goals, a fully-autonomous cycle can create manuscripts which recapitulate
peer-reviewed publications without major errors in about 80-90%, yet as goal
complexity increases, human co-piloting becomes critical for assuring accuracy.
Beyond the process itself, created manuscripts too are inherently verifiable,
as information-tracing allows to programmatically chain results, methods and
data. Our work thereby demonstrates a potential for AI-driven acceleration of
scientific discovery while enhancing, rather than jeopardizing, traceability,
transparency and verifiability.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.14871v1' target='_blank'>Exploring Human-AI Collaboration in Agile: Customised LLM Meeting
  Assistants</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Beatriz Cabrero-Daniel, Tomas Herda, Victoria Pichler, Martin Eder</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-23 09:55:25</h6>
<p class='card-text'>This action research study focuses on the integration of "AI assistants" in
two Agile software development meetings: the Daily Scrum and a feature
refinement, a planning meeting that is part of an in-house Scaled Agile
framework. We discuss the critical drivers of success, and establish a link
between the use of AI and team collaboration dynamics. We conclude with a list
of lessons learnt during the interventions in an industrial context, and
provide a assessment checklist for companies and teams to reflect on their
readiness level. This paper is thus a road-map to facilitate the integration of
AI tools in Agile setups.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.14705v1' target='_blank'>Think-Program-reCtify: 3D Situated Reasoning with Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Qingrong He, Kejun Lin, Shizhe Chen, Anwen Hu, Qin Jin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-23 03:22:06</h6>
<p class='card-text'>This work addresses the 3D situated reasoning task which aims to answer
questions given egocentric observations in a 3D environment. The task remains
challenging as it requires comprehensive 3D perception and complex reasoning
skills. End-to-end models trained on supervised data for 3D situated reasoning
suffer from data scarcity and generalization ability. Inspired by the recent
success of leveraging large language models (LLMs) for visual reasoning, we
propose LLM-TPC, a novel framework that leverages the planning, tool usage, and
reflection capabilities of LLMs through a ThinkProgram-reCtify loop. The Think
phase first decomposes the compositional question into a sequence of steps, and
then the Program phase grounds each step to a piece of code and calls carefully
designed 3D visual perception modules. Finally, the Rectify phase adjusts the
plan and code if the program fails to execute. Experiments and analysis on the
SQA3D benchmark demonstrate the effectiveness, interpretability and robustness
of our method. Our code is publicly available at
https://qingrongh.github.io/LLM-TPC/.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.14547v1' target='_blank'>Integrating Disambiguation and User Preferences into Large Language
  Models for Robot Motion Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mohammed Abugurain, Shinkyu Park</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-22 19:38:37</h6>
<p class='card-text'>This paper presents a framework that can interpret humans' navigation
commands containing temporal elements and directly translate their natural
language instructions into robot motion planning. Central to our framework is
utilizing Large Language Models (LLMs). To enhance the reliability of LLMs in
the framework and improve user experience, we propose methods to resolve the
ambiguity in natural language instructions and capture user preferences. The
process begins with an ambiguity classifier, identifying potential
uncertainties in the instructions. Ambiguous statements trigger a GPT-4-based
mechanism that generates clarifying questions, incorporating user responses for
disambiguation. Also, the framework assesses and records user preferences for
non-ambiguous instructions, enhancing future interactions. The last part of
this process is the translation of disambiguated instructions into a robot
motion plan using Linear Temporal Logic. This paper details the development of
this framework and the evaluation of its performance in various test scenarios.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.14356v1' target='_blank'>Rethinking Legal Compliance Automation: Opportunities with Large
  Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shabnam Hassani, Mehrdad Sabetzadeh, Daniel Amyot, Jain Liao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-22 17:10:27</h6>
<p class='card-text'>As software-intensive systems face growing pressure to comply with laws and
regulations, providing automated support for compliance analysis has become
paramount. Despite advances in the Requirements Engineering (RE) community on
legal compliance analysis, important obstacles remain in developing accurate
and generalizable compliance automation solutions. This paper highlights some
observed limitations of current approaches and examines how adopting new
automation strategies that leverage Large Language Models (LLMs) can help
address these shortcomings and open up fresh opportunities. Specifically, we
argue that the examination of (textual) legal artifacts should, first, employ a
broader context than sentences, which have widely been used as the units of
analysis in past research. Second, the mode of analysis with legal artifacts
needs to shift from classification and information extraction to more
end-to-end strategies that are not only accurate but also capable of providing
explanation and justification. We present a compliance analysis approach
designed to address these limitations. We further outline our evaluation plan
for the approach and provide preliminary evaluation results based on data
processing agreements (DPAs) that must comply with the General Data Protection
Regulation (GDPR). Our initial findings suggest that our approach yields
substantial accuracy improvements and, at the same time, provides justification
for compliance decisions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.14285v3' target='_blank'>LLM-Personalize: Aligning LLM Planners with Human Preferences via
  Reinforced Self-Training for Housekeeping Robots</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Dongge Han, Trevor McInroe, Adam Jelley, Stefano V. Albrecht, Peter Bell, Amos Storkey</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-22 15:35:33</h6>
<p class='card-text'>Large language models (LLMs) have shown significant potential for robotics
applications, particularly task planning, by harnessing their language
comprehension and text generation capabilities. However, in applications such
as household robotics, a critical gap remains in the personalization of these
models to individual user preferences. We introduce LLM-Personalize, a novel
framework with an optimization pipeline designed to personalize LLM planners
for household robotics. Our LLM-Personalize framework features an LLM planner
that performs iterative planning in multi-room, partially-observable household
scenarios, making use of a scene graph constructed with local observations. The
generated plan consists of a sequence of high-level actions which are
subsequently executed by a controller. Central to our approach is the
optimization pipeline, which combines imitation learning and iterative
self-training to personalize the LLM planner. In particular, the imitation
learning phase performs initial LLM alignment from demonstrations, and
bootstraps the model to facilitate effective iterative self-training, which
further explores and aligns the model to user preferences. We evaluate
LLM-Personalize on Housekeep, a challenging simulated real-world 3D benchmark
for household rearrangements, and show that LLM-Personalize achieves more than
a 30 percent increase in success rate over existing LLM planners, showcasing
significantly improved alignment with human preferences. Project page:
https://gdg94.github.io/projectllmpersonalize/.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.13919v2' target='_blank'>Navigating the Path of Writing: Outline-guided Text Generation with
  Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yukyung Lee, Soonwon Ka, Bokyung Son, Pilsung Kang, Jaewook Kang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-22 06:57:43</h6>
<p class='card-text'>Large Language Models (LLMs) have impacted the writing process, enhancing
productivity by collaborating with humans in content creation platforms.
However, generating high-quality, user-aligned text to satisfy real-world
content creation needs remains challenging. We propose WritingPath, a framework
that uses explicit outlines to guide LLMs in generating goal-oriented,
high-quality text. Our approach draws inspiration from structured writing
planning and reasoning paths, focusing on reflecting user intentions throughout
the writing process. To validate our approach in real-world scenarios, we
construct a diverse dataset from unstructured blog posts to benchmark writing
performance and introduce a comprehensive evaluation framework assessing the
quality of outlines and generated texts. Our evaluations with various LLMs
demonstrate that the WritingPath approach significantly enhances text quality
according to evaluations by both LLMs and professional writers.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.01573v2' target='_blank'>Class-Level Code Generation from Natural Language Using Iterative,
  Tool-Enhanced Reasoning over Repository</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ajinkya Deshpande, Anmol Agarwal, Shashank Shet, Arun Iyer, Aditya Kanade, Ramakrishna Bairi, Suresh Parthasarathy</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-22 03:52:54</h6>
<p class='card-text'>LLMs have demonstrated significant potential in code generation tasks,
achieving promising results at the function or statement level across various
benchmarks. However, the complexities associated with creating code artifacts
like classes, particularly within the context of real-world software
repositories, remain underexplored. Prior research treats class-level
generation as an isolated task, neglecting the intricate dependencies &
interactions that characterize real-world software environments. To address
this gap, we introduce RepoClassBench, a comprehensive benchmark designed to
rigorously evaluate LLMs in generating complex, class-level code within
real-world repositories. RepoClassBench includes "Natural Language to Class
generation" tasks across Java, Python & C# from a selection of repositories. We
ensure that each class in our dataset not only has cross-file dependencies
within the repository but also includes corresponding test cases to verify its
functionality. We find that current models struggle with the realistic
challenges posed by our benchmark, primarily due to their limited exposure to
relevant repository contexts. To address this shortcoming, we introduce
Retrieve-Repotools-Reflect (RRR), a novel approach that equips LLMs with static
analysis tools to iteratively navigate & reason about repository-level context
in an agent-based framework. Our experiments demonstrate that RRR significantly
outperforms existing baselines on RepoClassBench, showcasing its effectiveness
across programming languages & under various settings. Our findings emphasize
the critical need for code-generation benchmarks to incorporate repo-level
dependencies to more accurately reflect the complexities of software
development. Our work shows the benefits of leveraging specialized tools to
enhance LLMs' understanding of repository context. We plan to make our dataset
& evaluation harness public.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.13784v1' target='_blank'>Iteratively Prompting Multimodal LLMs to Reproduce Natural and
  AI-Generated Images</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ali Naseh, Katherine Thai, Mohit Iyyer, Amir Houmansadr</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-21 21:30:17</h6>
<p class='card-text'>With the digital imagery landscape rapidly evolving, image stocks and
AI-generated image marketplaces have become central to visual media.
Traditional stock images now exist alongside innovative platforms that trade in
prompts for AI-generated visuals, driven by sophisticated APIs like DALL-E 3
and Midjourney. This paper studies the possibility of employing multi-modal
models with enhanced visual understanding to mimic the outputs of these
platforms, introducing an original attack strategy. Our method leverages
fine-tuned CLIP models, a multi-label classifier, and the descriptive
capabilities of GPT-4V to create prompts that generate images similar to those
available in marketplaces and from premium stock image providers, yet at a
markedly lower expense. In presenting this strategy, we aim to spotlight a new
class of economic and security considerations within the realm of digital
imagery. Our findings, supported by both automated metrics and human
assessment, reveal that comparable visual content can be produced for a
fraction of the prevailing market prices ($0.23 - $0.27 per image), emphasizing
the need for awareness and strategic discussions about the integrity of digital
media in an increasingly AI-integrated landscape. Our work also contributes to
the field by assembling a dataset consisting of approximately 19 million
prompt-image pairs generated by the popular Midjourney platform, which we plan
to release publicly.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.13558v2' target='_blank'>LASER: Tuning-Free LLM-Driven Attention Control for Efficient
  Text-conditioned Image-to-Animation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Haoyu Zheng, Wenqiao Zhang, Yaoke Wang, Hao Zhou, Jiang Liu, Juncheng Li, Zheqi Lv, Siliang Tang, Yueting Zhuang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-21 07:13:56</h6>
<p class='card-text'>Revolutionary advancements in text-to-image models have unlocked new
dimensions for sophisticated content creation, e.g., text-conditioned image
editing, allowing us to edit the diverse images that convey highly complex
visual concepts according to the textual guidance. Despite being promising,
existing methods focus on texture- or non-rigid-based visual manipulation,
which struggles to produce the fine-grained animation of smooth
text-conditioned image morphing without fine-tuning, i.e., due to their highly
unstructured latent space. In this paper, we introduce a tuning-free LLM-driven
attention control framework, encapsulated by the progressive process of LLM
planning, prompt-Aware editing, StablE animation geneRation, abbreviated as
LASER. LASER employs a large language model (LLM) to refine coarse descriptions
into detailed prompts, guiding pre-trained text-to-image models for subsequent
image generation. We manipulate the model's spatial features and self-attention
mechanisms to maintain animation integrity and enable seamless morphing
directly from text prompts, eliminating the need for additional fine-tuning or
annotations. Our meticulous control over spatial features and self-attention
ensures structural consistency in the images. This paper presents a novel
framework integrating LLMs with text-to-image models to create high-quality
animations from a single text input. We also propose a Text-conditioned
Image-to-Animation Benchmark to validate the effectiveness and efficacy of
LASER. Extensive experiments demonstrate that LASER produces impressive,
consistent, and efficient results in animation generation, positioning it as a
powerful tool for advanced digital content creation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.13191v3' target='_blank'>Action Contextualization: Adaptive Task Planning and Action Tuning using
  Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sthithpragya Gupta, Kunpeng Yao, Loïc Niederhauser, Aude Billard</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-19 21:39:15</h6>
<p class='card-text'>Large Language Models (LLMs) present a promising frontier in robotic task
planning by leveraging extensive human knowledge. Nevertheless, the current
literature often overlooks the critical aspects of robots' adaptability and
error correction. This work aims to overcome this limitation by enabling robots
to modify their motions and select the most suitable task plans based on the
context. We introduce a novel framework to achieve action contextualization,
aimed at tailoring robot actions to the context of specific tasks, thereby
enhancing adaptability through applying LLM-derived contextual insights. Our
framework integrates motion metrics that evaluate robot performances for each
motion to resolve redundancy in planning. Moreover, it supports online feedback
between the robot and the LLM, enabling immediate modifications to the task
plans and corrections of errors. An overall success rate of 81.25% has been
achieved through extensive experimental validation. Finally, when integrated
with dynamical system (DS)-based robot controllers, the robotic arm-hand system
demonstrates its proficiency in autonomously executing LLM-generated motion
plans for sequential table-clearing tasks, rectifying errors without human
intervention, and showcasing robustness against external disturbances. Our
proposed framework also features the potential to be integrated with modular
control approaches, significantly enhancing robots' adaptability and autonomy
in performing sequential tasks in the real world.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.12494v2' target='_blank'>BIRD: A Trustworthy Bayesian Inference Framework for Large Language
  Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yu Feng, Ben Zhou, Weidong Lin, Dan Roth</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-18 20:17:23</h6>
<p class='card-text'>Predictive models often need to work with incomplete information in
real-world tasks. Consequently, they must provide reliable probability or
confidence estimation, especially in large-scale decision making and planning
tasks. Current large language models (LLM) are insufficient for such accurate
estimations, but they can generate relevant factors that may affect the
probabilities, produce coarse-grained probabilities when the information is
more complete, and help determine which factors are relevant to specific
downstream contexts. In this paper, we make use of these capabilities of LLMs
to provide a significantly more accurate probabilistic estimation. We propose
BIRD, a novel probabilistic inference framework that aligns a Bayesian network
with LLM abductions and then estimates more accurate probabilities in a
deduction step. We show BIRD provides reliable probability estimations that are
30\% better than those provided directly by LLM baselines. These estimates can
further contribute to better and more trustworthy decision-making.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.12317v4' target='_blank'>Synthetic Participatory Planning of Shard Automated Electric Mobility
  Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiangbo Yu, Graeme McKinley</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-18 16:51:23</h6>
<p class='card-text'>Unleashing the synergies among rapidly evolving mobility technologies in a
multi-stakeholder setting presents unique challenges and opportunities for
addressing urban transportation problems. This paper introduces a novel
synthetic participatory method that critically leverages large language models
(LLMs) to create digital avatars representing diverse stakeholders to plan
shared automated electric mobility systems (SAEMS). These calibratable agents
collaboratively identify objectives, envision and evaluate SAEMS alternatives,
and strategize implementation under risks and constraints. The results of a
Montreal case study indicate that a structured and parameterized workflow
provides outputs with higher controllability and comprehensiveness on an SAEMS
plan than that generated using a single LLM-enabled expert agent. Consequently,
this approach provides a promising avenue for cost-efficiently improving the
inclusivity and interpretability of multi-objective transportation planning,
suggesting a paradigm shift in how we envision and strategize for sustainable
transportation systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.12253v2' target='_blank'>Toward Self-Improvement of LLMs via Imagination, Searching, and
  Criticizing</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ye Tian, Baolin Peng, Linfeng Song, Lifeng Jin, Dian Yu, Haitao Mi, Dong Yu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-18 15:21:34</h6>
<p class='card-text'>Despite the impressive capabilities of Large Language Models (LLMs) on
various tasks, they still struggle with scenarios that involves complex
reasoning and planning. Recent work proposed advanced prompting techniques and
the necessity of fine-tuning with high-quality data to augment LLMs' reasoning
abilities. However, these approaches are inherently constrained by data
availability and quality. In light of this, self-correction and self-learning
emerge as viable solutions, employing strategies that allow LLMs to refine
their outputs and learn from self-assessed rewards. Yet, the efficacy of LLMs
in self-refining its response, particularly in complex reasoning and planning
task, remains dubious. In this paper, we introduce AlphaLLM for the
self-improvements of LLMs, which integrates Monte Carlo Tree Search (MCTS) with
LLMs to establish a self-improving loop, thereby enhancing the capabilities of
LLMs without additional annotations. Drawing inspiration from the success of
AlphaGo, AlphaLLM addresses the unique challenges of combining MCTS with LLM
for self-improvement, including data scarcity, the vastness search spaces of
language tasks, and the subjective nature of feedback in language tasks.
AlphaLLM is comprised of prompt synthesis component, an efficient MCTS approach
tailored for language tasks, and a trio of critic models for precise feedback.
Our experimental results in mathematical reasoning tasks demonstrate that
AlphaLLM significantly enhances the performance of LLMs without additional
annotations, showing the potential for self-improvement in LLMs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.11891v3' target='_blank'>Large Language Models Can Solve Real-World Planning Rigorously with
  Formal Verification Tools</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yilun Hao, Yongchao Chen, Yang Zhang, Chuchu Fan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-18 04:36:37</h6>
<p class='card-text'>Large Language Models (LLMs) struggle to directly generate correct plans for
complex multi-constraint planning problems, even with self-verification and
self-critique. For example, a U.S. domestic travel planning benchmark
TravelPlanner was proposed in Xie et al. (2024), where the best LLM OpenAI
o1-preview can only find viable travel plans with a 10% success rate given all
needed information. In this work, we tackle this by proposing an LLM-based
planning framework that formalizes and solves complex multi-constraint planning
problems as constrained satisfiability problems, which are further consumed by
sound and complete satisfiability solvers. We start with TravelPlanner as the
primary use case and show that our framework achieves a success rate of 93.9%
and is effective with diverse paraphrased prompts. More importantly, our
framework has strong zero-shot generalizability, successfully handling unseen
constraints in our newly created unseen international travel dataset and
generalizing well to new fundamentally different domains. Moreover, when user
input queries are infeasible, our framework can identify the unsatisfiable
core, provide failure reasons, and offers personalized modification
suggestions. We show that our framework can modify and solve for an average of
81.6% and 91.7% unsatisfiable queries from two datasets and prove with
ablations that all key components of our framework are effective and necessary.
Project page: https://sites.google.com/view/llm-rwplanning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.11833v2' target='_blank'>Thought of Search: Planning with Language Models Through The Lens of
  Efficiency</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Michael Katz, Harsha Kokel, Kavitha Srinivas, Shirin Sohrabi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-18 01:27:29</h6>
<p class='card-text'>Among the most important properties of algorithms investigated in computer
science are soundness, completeness, and complexity. These properties, however,
are rarely analyzed for the vast collection of recently proposed methods for
planning with large language models. In this work, we alleviate this gap. We
analyse these properties of using LLMs for planning and highlight that recent
trends abandon both soundness and completeness for the sake of inefficiency. We
propose a significantly more efficient approach that can, at the same time,
maintain both soundness and completeness. We exemplify on four representative
search problems, comparing to the LLM-based solutions from the literature that
attempt to solve these problems. We show that by using LLMs to produce the code
for the search components we can solve the entire datasets with 100\% accuracy
with only a few calls to the LLM. We argue for a responsible use of compute
resources; urging research community to investigate sound and complete
LLM-based approaches that uphold efficiency.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.11794v2' target='_blank'>Automated Social Science: Language Models as Scientist and Subjects</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Benjamin S. Manning, Kehang Zhu, John J. Horton</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-17 23:02:43</h6>
<p class='card-text'>We present an approach for automatically generating and testing, in silico,
social scientific hypotheses. This automation is made possible by recent
advances in large language models (LLM), but the key feature of the approach is
the use of structural causal models. Structural causal models provide a
language to state hypotheses, a blueprint for constructing LLM-based agents, an
experimental design, and a plan for data analysis. The fitted structural causal
model becomes an object available for prediction or the planning of follow-on
experiments. We demonstrate the approach with several scenarios: a negotiation,
a bail hearing, a job interview, and an auction. In each case, causal
relationships are both proposed and tested by the system, finding evidence for
some and not others. We provide evidence that the insights from these
simulations of social interactions are not available to the LLM purely through
direct elicitation. When given its proposed structural causal model for each
scenario, the LLM is good at predicting the signs of estimated effects, but it
cannot reliably predict the magnitudes of those estimates. In the auction
experiment, the in silico simulation results closely match the predictions of
auction theory, but elicited predictions of the clearing prices from the LLM
are inaccurate. However, the LLM's predictions are dramatically improved if the
model can condition on the fitted structural causal model. In short, the LLM
knows more than it can (immediately) tell.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.11792v2' target='_blank'>Enhancing Q&A with Domain-Specific Fine-Tuning and Iterative Reasoning:
  A Comparative Study</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zooey Nguyen, Anthony Annunziata, Vinh Luong, Sang Dinh, Quynh Le, Anh Hai Ha, Chanh Le, Hong An Phan, Shruti Raghavan, Christopher Nguyen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-17 23:00:03</h6>
<p class='card-text'>This paper investigates the impact of domain-specific model fine-tuning and
of reasoning mechanisms on the performance of question-answering (Q&A) systems
powered by large language models (LLMs) and Retrieval-Augmented Generation
(RAG). Using the FinanceBench SEC financial filings dataset, we observe that,
for RAG, combining a fine-tuned embedding model with a fine-tuned LLM achieves
better accuracy than generic models, with relatively greater gains attributable
to fine-tuned embedding models. Additionally, employing reasoning iterations on
top of RAG delivers an even bigger jump in performance, enabling the Q&A
systems to get closer to human-expert quality. We discuss the implications of
such findings, propose a structured technical design space capturing major
technical components of Q&A AI, and provide recommendations for making
high-impact technical choices for such components. We plan to follow up on this
work with actionable guides for AI teams and further investigations into the
impact of domain-specific augmentation in RAG and into agentic AI capabilities
such as advanced planning and reasoning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.11483v2' target='_blank'>AgentKit: Structured LLM Reasoning with Dynamic Graphs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yue Wu, Yewen Fan, So Yeon Min, Shrimai Prabhumoye, Stephen McAleer, Yonatan Bisk, Ruslan Salakhutdinov, Yuanzhi Li, Tom Mitchell</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-17 15:40:45</h6>
<p class='card-text'>We propose an intuitive LLM prompting framework (AgentKit) for
multifunctional agents. AgentKit offers a unified framework for explicitly
constructing a complex "thought process" from simple natural language prompts.
The basic building block in AgentKit is a node, containing a natural language
prompt for a specific subtask. The user then puts together chains of nodes,
like stacking LEGO pieces. The chains of nodes can be designed to explicitly
enforce a naturally structured "thought process". For example, for the task of
writing a paper, one may start with the thought process of 1) identify a core
message, 2) identify prior research gaps, etc. The nodes in AgentKit can be
designed and combined in different ways to implement multiple advanced
capabilities including on-the-fly hierarchical planning, reflection, and
learning from interactions. In addition, due to the modular nature and the
intuitive design to simulate explicit human thought process, a basic agent
could be implemented as simple as a list of prompts for the subtasks and
therefore could be designed and tuned by someone without any programming
experience. Quantitatively, we show that agents designed through AgentKit
achieve SOTA performance on WebShop and Crafter. These advances underscore
AgentKit's potential in making LLM agents effective and accessible for a wider
range of applications. https://github.com/holmeswww/AgentKit</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.11267v1' target='_blank'>Towards Human Awareness in Robot Task Planning with Large Language
  Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuchen Liu, Luigi Palmieri, Sebastian Koch, Ilche Georgievski, Marco Aiello</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-17 11:19:04</h6>
<p class='card-text'>The recent breakthroughs in the research on Large Language Models (LLMs) have
triggered a transformation across several research domains. Notably, the
integration of LLMs has greatly enhanced performance in robot Task And Motion
Planning (TAMP). However, previous approaches often neglect the consideration
of dynamic environments, i.e., the presence of dynamic objects such as humans.
In this paper, we propose a novel approach to address this gap by incorporating
human awareness into LLM-based robot task planning. To obtain an effective
representation of the dynamic environment, our approach integrates humans'
information into a hierarchical scene graph. To ensure the plan's
executability, we leverage LLMs to ground the environmental topology and
actionable knowledge into formal planning language. Most importantly, we use
LLMs to predict future human activities and plan tasks for the robot
considering the predictions. Our contribution facilitates the development of
integrating human awareness into LLM-driven robot task planning, and paves the
way for proactive robot decision-making in dynamic environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.11041v2' target='_blank'>On the Empirical Complexity of Reasoning and Planning in LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Liwei Kang, Zirui Zhao, David Hsu, Wee Sun Lee</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-17 03:34:27</h6>
<p class='card-text'>Chain-of-thought (CoT), tree-of-thought (ToT), and related techniques work
surprisingly well in practice for some complex reasoning tasks with Large
Language Models (LLMs), but why? This work seeks the underlying reasons by
conducting experimental case studies and linking the performance benefits to
well-established sample and computational complexity principles in machine
learning. We experimented with 6 reasoning tasks, ranging from grade school
math, air travel planning, ..., to Blocksworld. The results suggest that (i)
both CoT and ToT benefit significantly from task decomposition, which breaks a
complex reasoning task into a sequence of steps with low sample complexity and
explicitly outlines the reasoning structure, and (ii) for computationally hard
reasoning tasks, the more sophisticated tree structure of ToT outperforms the
linear structure of CoT. These findings provide useful guidelines for the use
of LLM in solving reasoning tasks in practice.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.11027v1' target='_blank'>Empowering Large Language Models on Robotic Manipulation with Affordance
  Prompting</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Guangran Cheng, Chuheng Zhang, Wenzhe Cai, Li Zhao, Changyin Sun, Jiang Bian</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-17 03:06:32</h6>
<p class='card-text'>While large language models (LLMs) are successful in completing various
language processing tasks, they easily fail to interact with the physical world
by generating control sequences properly. We find that the main reason is that
LLMs are not grounded in the physical world. Existing LLM-based approaches
circumvent this problem by relying on additional pre-defined skills or
pre-trained sub-policies, making it hard to adapt to new tasks. In contrast, we
aim to address this problem and explore the possibility to prompt pre-trained
LLMs to accomplish a series of robotic manipulation tasks in a training-free
paradigm. Accordingly, we propose a framework called LLM+A(ffordance) where the
LLM serves as both the sub-task planner (that generates high-level plans) and
the motion controller (that generates low-level control sequences). To ground
these plans and control sequences on the physical world, we develop the
affordance prompting technique that stimulates the LLM to 1) predict the
consequences of generated plans and 2) generate affordance values for relevant
objects. Empirically, we evaluate the effectiveness of LLM+A in various
language-conditioned robotic manipulation tasks, which show that our approach
substantially improves performance by enhancing the feasibility of generated
plans and control and can easily generalize to different environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.09228v5' target='_blank'>A Survey on Integration of Large Language Models with Intelligent Robots</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yeseung Kim, Dohyun Kim, Jieun Choi, Jisang Park, Nayoung Oh, Daehyung Park</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-14 12:15:21</h6>
<p class='card-text'>In recent years, the integration of large language models (LLMs) has
revolutionized the field of robotics, enabling robots to communicate,
understand, and reason with human-like proficiency. This paper explores the
multifaceted impact of LLMs on robotics, addressing key challenges and
opportunities for leveraging these models across various domains. By
categorizing and analyzing LLM applications within core robotics elements --
communication, perception, planning, and control -- we aim to provide
actionable insights for researchers seeking to integrate LLMs into their
robotic systems. Our investigation focuses on LLMs developed post-GPT-3.5,
primarily in text-based modalities while also considering multimodal approaches
for perception and control. We offer comprehensive guidelines and examples for
prompt engineering, facilitating beginners' access to LLM-based robotics
solutions. Through tutorial-level examples and structured prompt construction,
we illustrate how LLM-guided enhancements can be seamlessly integrated into
robotics applications. This survey serves as a roadmap for researchers
navigating the evolving landscape of LLM-driven robotics, offering a
comprehensive overview and practical guidance for harnessing the power of
language models in robotics development.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.01392v1' target='_blank'>LLMSat: A Large Language Model-Based Goal-Oriented Agent for Autonomous
  Space Exploration</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:David Maranto</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-13 03:33:17</h6>
<p class='card-text'>As spacecraft journey further from Earth with more complex missions, systems
of greater autonomy and onboard intelligence are called for. Reducing reliance
on human-based mission control becomes increasingly critical if we are to
increase our rate of solar-system-wide exploration. Recent work has explored
AI-based goal-oriented systems to increase the level of autonomy in mission
execution. These systems make use of symbolic reasoning managers to make
inferences from the state of a spacecraft and a handcrafted knowledge base,
enabling autonomous generation of tasks and re-planning. Such systems have
proven to be successful in controlled cases, but they are difficult to
implement as they require human-crafted ontological models to allow the
spacecraft to understand the world. Reinforcement learning has been applied to
train robotic agents to pursue a goal. A new architecture for autonomy is
called for. This work explores the application of Large Language Models (LLMs)
as the high-level control system of a spacecraft. Using a systems engineering
approach, this work presents the design and development of an agentic
spacecraft controller by leveraging an LLM as a reasoning engine, to evaluate
the utility of such an architecture in achieving higher levels of spacecraft
autonomy. A series of deep space mission scenarios simulated within the popular
game engine Kerbal Space Program (KSP) are used as case studies to evaluate the
implementation against the requirements. It is shown the reasoning and planning
abilities of present-day LLMs do not scale well as the complexity of a mission
increases, but this can be alleviated with adequate prompting frameworks and
strategic selection of the agent's level of authority over the host spacecraft.
This research evaluates the potential of LLMs in augmenting autonomous
decision-making systems for future robotic space applications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.08825v2' target='_blank'>Inverse Kinematics for Neuro-Robotic Grasping with Humanoid Embodied
  Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jan-Gerrit Habekost, Connor Gäde, Philipp Allgeuer, Stefan Wermter</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-12 21:42:34</h6>
<p class='card-text'>This paper introduces a novel zero-shot motion planning method that allows
users to quickly design smooth robot motions in Cartesian space. A B\'ezier
curve-based Cartesian plan is transformed into a joint space trajectory by our
neuro-inspired inverse kinematics (IK) method CycleIK, for which we enable
platform independence by scaling it to arbitrary robot designs. The motion
planner is evaluated on the physical hardware of the two humanoid robots NICO
and NICOL in a human-in-the-loop grasping scenario. Our method is deployed with
an embodied agent that is a large language model (LLM) at its core. We
generalize the embodied agent, that was introduced for NICOL, to also embody
NICO. The agent can execute a discrete set of physical actions and allows the
user to verbally instruct various different robots. We contribute a grasping
primitive to its action space that allows for precise manipulation of household
objects. The updated CycleIK method is compared to popular numerical IK solvers
and state-of-the-art neural IK methods in simulation and is shown to be
competitive with or outperform all evaluated methods when the algorithm runtime
is very short. The grasping primitive is evaluated on both NICOL and NICO
robots with a reported grasp success of 72% to 82% for each robot,
respectively.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.07774v2' target='_blank'>Sketch-Plan-Generalize: Continual Few-Shot Learning of Inductively
  Generalizable Spatial Concepts</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Namasivayam Kalithasan, Sachit Sachdeva, Himanshu Gaurav Singh, Vishal Bindal, Arnav Tuli, Gurarmaan Singh Panjeta, Divyanshu Aggarwal, Rohan Paul, Parag Singla</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-11 14:09:41</h6>
<p class='card-text'>Our goal is to enable embodied agents to learn inductively generalizable
spatial concepts, e.g., learning staircase as an inductive composition of
towers of increasing height. Given a human demonstration, we seek a learning
architecture that infers a succinct ${program}$ representation that explains
the observed instance. Additionally, the approach should generalize inductively
to novel structures of different sizes or complex structures expressed as a
hierarchical composition of previously learned concepts. Existing approaches
that use code generation capabilities of pre-trained large (visual) language
models, as well as purely neural models, show poor generalization to a-priori
unseen complex concepts. Our key insight is to factor inductive concept
learning as (i) ${\it Sketch:}$ detecting and inferring a coarse signature of a
new concept (ii) ${\it Plan:}$ performing MCTS search over grounded action
sequences (iii) ${\it Generalize:}$ abstracting out grounded plans as inductive
programs. Our pipeline facilitates generalization and modular reuse, enabling
continual concept learning. Our approach combines the benefits of the code
generation ability of large language models (LLM) along with grounded neural
representations, resulting in neuro-symbolic programs that show stronger
inductive generalization on the task of constructing complex structures in
relation to LLM-only and neural-only approaches. Furthermore, we demonstrate
reasoning and planning capabilities with learned concepts for embodied
instruction following.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.07751v1' target='_blank'>Generating consistent PDDL domains with Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Pavel Smirnov, Frank Joublin, Antonello Ceravola, Michael Gienger</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-11 13:48:48</h6>
<p class='card-text'>Large Language Models (LLMs) are capable of transforming natural language
domain descriptions into plausibly looking PDDL markup. However, ensuring that
actions are consistent within domains still remains a challenging task. In this
paper we present a novel concept to significantly improve the quality of
LLM-generated PDDL models by performing automated consistency checking during
the generation process. Although the proposed consistency checking strategies
still can't guarantee absolute correctness of generated models, they can serve
as valuable source of feedback reducing the amount of correction efforts
expected from a human in the loop. We demonstrate the capabilities of our error
detection approach on a number of classical and custom planning domains
(logistics, gripper, tyreworld, household, pizza).</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.07569v2' target='_blank'>Can Vehicle Motion Planning Generalize to Realistic Long-tail Scenarios?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Marcel Hallgarten, Julian Zapata, Martin Stoll, Katrin Renz, Andreas Zell</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-11 08:57:48</h6>
<p class='card-text'>Real-world autonomous driving systems must make safe decisions in the face of
rare and diverse traffic scenarios. Current state-of-the-art planners are
mostly evaluated on real-world datasets like nuScenes (open-loop) or nuPlan
(closed-loop). In particular, nuPlan seems to be an expressive evaluation
method since it is based on real-world data and closed-loop, yet it mostly
covers basic driving scenarios. This makes it difficult to judge a planner's
capabilities to generalize to rarely-seen situations. Therefore, we propose a
novel closed-loop benchmark interPlan containing several edge cases and
challenging driving scenarios. We assess existing state-of-the-art planners on
our benchmark and show that neither rule-based nor learning-based planners can
safely navigate the interPlan scenarios. A recently evolving direction is the
usage of foundation models like large language models (LLM) to handle
generalization. We evaluate an LLM-only planner and introduce a novel hybrid
planner that combines an LLM-based behavior planner with a rule-based motion
planner that achieves state-of-the-art performance on our benchmark.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.05993v2' target='_blank'>AEGIS: Online Adaptive AI Content Safety Moderation with Ensemble of LLM
  Experts</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shaona Ghosh, Prasoon Varshney, Erick Galinkin, Christopher Parisien</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-09 03:54:28</h6>
<p class='card-text'>As Large Language Models (LLMs) and generative AI become more widespread, the
content safety risks associated with their use also increase. We find a notable
deficiency in high-quality content safety datasets and benchmarks that
comprehensively cover a wide range of critical safety areas. To address this,
we define a broad content safety risk taxonomy, comprising 13 critical risk and
9 sparse risk categories. Additionally, we curate AEGISSAFETYDATASET, a new
dataset of approximately 26, 000 human-LLM interaction instances, complete with
human annotations adhering to the taxonomy. We plan to release this dataset to
the community to further research and to help benchmark LLM models for safety.
To demonstrate the effectiveness of the dataset, we instruction-tune multiple
LLM-based safety models. We show that our models (named AEGISSAFETYEXPERTS),
not only surpass or perform competitively with the state-of-the-art LLM-based
safety models and general purpose LLMs, but also exhibit robustness across
multiple jail-break attack categories. We also show how using
AEGISSAFETYDATASET during the LLM alignment phase does not negatively impact
the performance of the aligned models on MT Bench scores. Furthermore, we
propose AEGIS, a novel application of a no-regret online adaptation framework
with strong theoretical guarantees, to perform content moderation with an
ensemble of LLM content safety experts in deployment</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.05449v3' target='_blank'>RoT: Enhancing Large Language Models with Reflection on Search Trees</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wenyang Hui, Kewei Tu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-08 12:31:23</h6>
<p class='card-text'>Large language models (LLMs) have demonstrated impressive capability in
reasoning and planning when integrated with tree-search-based prompting
methods. However, since these methods ignore the previous search experiences,
they often make the same mistakes in the search process. To address this issue,
we introduce Reflection on search Trees (RoT), an LLM reflection framework
designed to improve the performance of tree-search-based prompting methods. It
uses a strong LLM to summarize guidelines from previous tree search experiences
to enhance the ability of a weak LLM. The guidelines are instructions about
solving this task through tree search which can prevent the weak LLMs from
making similar mistakes in the past search process. In addition, we proposed a
novel state selection method, which identifies the critical information from
historical search processes to help RoT generate more specific and meaningful
guidelines. In our extensive experiments, we find that RoT significantly
improves the performance of LLMs in reasoning or planning tasks with various
tree-search-based prompting methods (e.g., BFS and MCTS). Non-tree-search-based
prompting methods such as Chain-of-Thought (CoT) can also benefit from RoT
guidelines since RoT can provide task-specific knowledge collected from the
search experience.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.05399v2' target='_blank'>SafetyPrompts: a Systematic Review of Open Datasets for Evaluating and
  Improving Large Language Model Safety</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Paul Röttger, Fabio Pernisi, Bertie Vidgen, Dirk Hovy</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-08 10:57:25</h6>
<p class='card-text'>The last two years have seen a rapid growth in concerns around the safety of
large language models (LLMs). Researchers and practitioners have met these
concerns by creating an abundance of datasets for evaluating and improving LLM
safety. However, much of this work has happened in parallel, and with very
different goals in mind, ranging from the mitigation of near-term risks around
bias and toxic content generation to the assessment of longer-term catastrophic
risk potential. This makes it difficult for researchers and practitioners to
find the most relevant datasets for their use case, and to identify gaps in
dataset coverage that future work may fill. To remedy these issues, we conduct
a first systematic review of open datasets for evaluating and improving LLM
safety. We review 144 datasets, which we identified through an iterative and
community-driven process over the course of several months. We highlight
patterns and trends, such as a trend towards fully synthetic datasets, as well
as gaps in dataset coverage, such as a clear lack of non-English and
naturalistic datasets. We also examine how LLM safety datasets are used in
practice -- in LLM release publications and popular LLM benchmarks -- finding
that current evaluation practices are highly idiosyncratic and make use of only
a small fraction of available datasets. Our contributions are based on
SafetyPrompts.com, a living catalogue of open datasets for LLM safety, which we
plan to update continuously as the field of LLM safety develops.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.05291v2' target='_blank'>Long-horizon Locomotion and Manipulation on a Quadrupedal Robot with
  Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yutao Ouyang, Jinhan Li, Yunfei Li, Zhongyu Li, Chao Yu, Koushil Sreenath, Yi Wu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-08 08:29:00</h6>
<p class='card-text'>We present a large language model (LLM) based system to empower quadrupedal
robots with problem-solving abilities for long-horizon tasks beyond short-term
motions. Long-horizon tasks for quadrupeds are challenging since they require
both a high-level understanding of the semantics of the problem for task
planning and a broad range of locomotion and manipulation skills to interact
with the environment. Our system builds a high-level reasoning layer with large
language models, which generates hybrid discrete-continuous plans as robot code
from task descriptions. It comprises multiple LLM agents: a semantic planner
for sketching a plan, a parameter calculator for predicting arguments in the
plan, and a code generator to convert the plan into executable robot code. At
the low level, we adopt reinforcement learning to train a set of motion
planning and control skills to unleash the flexibility of quadrupeds for rich
environment interactions. Our system is tested on long-horizon tasks that are
infeasible to complete with one single skill. Simulation and real-world
experiments show that it successfully figures out multi-step strategies and
demonstrates non-trivial behaviors, including building tools or notifying a
human for help. Demos are available on our project page:
https://sites.google.com/view/long-horizon-robot.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.05144v1' target='_blank'>Enhancing Clinical Efficiency through LLM: Discharge Note Generation for
  Cardiac Patients</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:HyoJe Jung, Yunha Kim, Heejung Choi, Hyeram Seo, Minkyoung Kim, JiYe Han, Gaeun Kee, Seohyun Park, Soyoung Ko, Byeolhee Kim, Suyeon Kim, Tae Joon Jun, Young-Hak Kim</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-08 01:55:28</h6>
<p class='card-text'>Medical documentation, including discharge notes, is crucial for ensuring
patient care quality, continuity, and effective medical communication. However,
the manual creation of these documents is not only time-consuming but also
prone to inconsistencies and potential errors. The automation of this
documentation process using artificial intelligence (AI) represents a promising
area of innovation in healthcare. This study directly addresses the
inefficiencies and inaccuracies in creating discharge notes manually,
particularly for cardiac patients, by employing AI techniques, specifically
large language model (LLM). Utilizing a substantial dataset from a cardiology
center, encompassing wide-ranging medical records and physician assessments,
our research evaluates the capability of LLM to enhance the documentation
process. Among the various models assessed, Mistral-7B distinguished itself by
accurately generating discharge notes that significantly improve both
documentation efficiency and the continuity of care for patients. These notes
underwent rigorous qualitative evaluation by medical expert, receiving high
marks for their clinical relevance, completeness, readability, and contribution
to informed decision-making and care planning. Coupled with quantitative
analyses, these results confirm Mistral-7B's efficacy in distilling complex
medical information into concise, coherent summaries. Overall, our findings
illuminate the considerable promise of specialized LLM, such as Mistral-7B, in
refining healthcare documentation workflows and advancing patient care. This
study lays the groundwork for further integrating advanced AI technologies in
healthcare, demonstrating their potential to revolutionize patient
documentation and support better care outcomes.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.04869v2' target='_blank'>Prompting Multi-Modal Tokens to Enhance End-to-End Autonomous Driving
  Imitation Learning with LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yiqun Duan, Qiang Zhang, Renjing Xu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-07 08:31:12</h6>
<p class='card-text'>The utilization of Large Language Models (LLMs) within the realm of
reinforcement learning, particularly as planners, has garnered a significant
degree of attention in recent scholarly literature. However, a substantial
proportion of existing research predominantly focuses on planning models for
robotics that transmute the outputs derived from perception models into
linguistic forms, thus adopting a `pure-language' strategy. In this research,
we propose a hybrid End-to-End learning framework for autonomous driving by
combining basic driving imitation learning with LLMs based on multi-modality
prompt tokens. Instead of simply converting perception results from the
separated train model into pure language input, our novelty lies in two
aspects. 1) The end-to-end integration of visual and LiDAR sensory input into
learnable multi-modality tokens, thereby intrinsically alleviating description
bias by separated pre-trained perception models. 2) Instead of directly letting
LLMs drive, this paper explores a hybrid setting of letting LLMs help the
driving model correct mistakes and complicated scenarios. The results of our
experiments suggest that the proposed methodology can attain driving scores of
49.21%, coupled with an impressive route completion rate of 91.34% in the
offline evaluation conducted via CARLA. These performance metrics are
comparable to the most advanced driving models.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.04834v3' target='_blank'>LLM-Based Multi-Agent Systems for Software Engineering: Literature
  Review, Vision and the Road Ahead</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Junda He, Christoph Treude, David Lo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-07 07:05:40</h6>
<p class='card-text'>Integrating Large Language Models (LLMs) into autonomous agents marks a
significant shift in the research landscape by offering cognitive abilities
that are competitive with human planning and reasoning. This paper explores the
transformative potential of integrating Large Language Models into Multi-Agent
(LMA) systems for addressing complex challenges in software engineering (SE).
By leveraging the collaborative and specialized abilities of multiple agents,
LMA systems enable autonomous problem-solving, improve robustness, and provide
scalable solutions for managing the complexity of real-world software projects.
In this paper, we conduct a systematic review of recent primary studies to map
the current landscape of LMA applications across various stages of the software
development lifecycle (SDLC). To illustrate current capabilities and
limitations, we perform two case studies to demonstrate the effectiveness of
state-of-the-art LMA frameworks. Additionally, we identify critical research
gaps and propose a comprehensive research agenda focused on enhancing
individual agent capabilities and optimizing agent synergy. Our work outlines a
forward-looking vision for developing fully autonomous, scalable, and
trustworthy LMA systems, laying the foundation for the evolution of Software
Engineering 2.0.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.04667v1' target='_blank'>Autonomous Artificial Intelligence Agents for Clinical Decision Making
  in Oncology</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Dyke Ferber, Omar S. M. El Nahhas, Georg Wölflein, Isabella C. Wiest, Jan Clusmann, Marie-Elisabeth Leßman, Sebastian Foersch, Jacqueline Lammert, Maximilian Tschochohei, Dirk Jäger, Manuel Salto-Tellez, Nikolaus Schultz, Daniel Truhn, Jakob Nikolas Kather</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-06 15:50:19</h6>
<p class='card-text'>Multimodal artificial intelligence (AI) systems have the potential to enhance
clinical decision-making by interpreting various types of medical data.
However, the effectiveness of these models across all medical fields is
uncertain. Each discipline presents unique challenges that need to be addressed
for optimal performance. This complexity is further increased when attempting
to integrate different fields into a single model. Here, we introduce an
alternative approach to multimodal medical AI that utilizes the generalist
capabilities of a large language model (LLM) as a central reasoning engine.
This engine autonomously coordinates and deploys a set of specialized medical
AI tools. These tools include text, radiology and histopathology image
interpretation, genomic data processing, web searches, and document retrieval
from medical guidelines. We validate our system across a series of clinical
oncology scenarios that closely resemble typical patient care workflows. We
show that the system has a high capability in employing appropriate tools
(97%), drawing correct conclusions (93.6%), and providing complete (94%), and
helpful (89.2%) recommendations for individual patient cases while consistently
referencing relevant literature (82.5%) upon instruction. This work provides
evidence that LLMs can effectively plan and execute domain-specific models to
retrieve or synthesize new information when used as autonomous agents. This
enables them to function as specialist, patient-tailored clinical assistants.
It also simplifies regulatory compliance by allowing each component tool to be
individually validated and approved. We believe, that our work can serve as a
proof-of-concept for more advanced LLM-agents in the medical domain.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.04540v1' target='_blank'>The Case for Developing a Foundation Model for Planning-like Tasks from
  Scratch</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Biplav Srivastava, Vishal Pallagani</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-06 07:44:40</h6>
<p class='card-text'>Foundation Models (FMs) have revolutionized many areas of computing,
including Automated Planning and Scheduling (APS). For example, a recent study
found them useful for planning problems: plan generation, language translation,
model construction, multi-agent planning, interactive planning, heuristics
optimization, tool integration, and brain-inspired planning. Besides APS, there
are many seemingly related tasks involving the generation of a series of
actions with varying guarantees of their executability to achieve intended
goals, which we collectively call planning-like (PL) tasks like business
processes, programs, workflows, and guidelines, where researchers have
considered using FMs. However, previous works have primarily focused on
pre-trained, off-the-shelf FMs and optionally fine-tuned them. This paper
discusses the need for a comprehensive FM for PL tasks from scratch and
explores its design considerations. We argue that such an FM will open new and
efficient avenues for PL problem-solving, just like LLMs are creating for APS.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.04066v2' target='_blank'>VoicePilot: Harnessing LLMs as Speech Interfaces for Physically
  Assistive Robots</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Akhil Padmanabha, Jessie Yuan, Janavi Gupta, Zulekha Karachiwalla, Carmel Majidi, Henny Admoni, Zackory Erickson</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-05 12:45:10</h6>
<p class='card-text'>Physically assistive robots present an opportunity to significantly increase
the well-being and independence of individuals with motor impairments or other
forms of disability who are unable to complete activities of daily living.
Speech interfaces, especially ones that utilize Large Language Models (LLMs),
can enable individuals to effectively and naturally communicate high-level
commands and nuanced preferences to robots. Frameworks for integrating LLMs as
interfaces to robots for high level task planning and code generation have been
proposed, but fail to incorporate human-centric considerations which are
essential while developing assistive interfaces. In this work, we present a
framework for incorporating LLMs as speech interfaces for physically assistive
robots, constructed iteratively with 3 stages of testing involving a feeding
robot, culminating in an evaluation with 11 older adults at an independent
living facility. We use both quantitative and qualitative data from the final
study to validate our framework and additionally provide design guidelines for
using LLMs as speech interfaces for assistive robots. Videos and supporting
files are located on our project website:
https://sites.google.com/andrew.cmu.edu/voicepilot/</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.03891v1' target='_blank'>Can only LLMs do Reasoning?: Potential of Small Language Models in Task
  Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Gawon Choi, Hyemin Ahn</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-05 04:58:34</h6>
<p class='card-text'>In robotics, the use of Large Language Models (LLMs) is becoming prevalent,
especially for understanding human commands. In particular, LLMs are utilized
as domain-agnostic task planners for high-level human commands. LLMs are
capable of Chain-of-Thought (CoT) reasoning, and this allows LLMs to be task
planners. However, we need to consider that modern robots still struggle to
perform complex actions, and the domains where robots can be deployed are
limited in practice. This leads us to pose a question: If small LMs can be
trained to reason in chains within a single domain, would even small LMs be
good task planners for the robots? To train smaller LMs to reason in chains, we
build `COmmand-STeps datasets' (COST) consisting of high-level commands along
with corresponding actionable low-level steps, via LLMs. We release not only
our datasets but also the prompt templates used to generate them, to allow
anyone to build datasets for their domain. We compare GPT3.5 and GPT4 with the
finetuned GPT2 for task domains, in tabletop and kitchen environments, and the
result shows that GPT2-medium is comparable to GPT3.5 for task planning in a
specific domain. Our dataset, code, and more output samples can be found in
https://github.com/Gawon-Choi/small-LMs-Task-Planning</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.03587v1' target='_blank'>Anticipate & Collab: Data-driven Task Anticipation and Knowledge-driven
  Planning for Human-robot Collaboration</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shivam Singh, Karthik Swaminathan, Raghav Arora, Ramandeep Singh, Ahana Datta, Dipanjan Das, Snehasis Banerjee, Mohan Sridharan, Madhava Krishna</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-04 16:52:48</h6>
<p class='card-text'>An agent assisting humans in daily living activities can collaborate more
effectively by anticipating upcoming tasks. Data-driven methods represent the
state of the art in task anticipation, planning, and related problems, but
these methods are resource-hungry and opaque. Our prior work introduced a proof
of concept framework that used an LLM to anticipate 3 high-level tasks that
served as goals for a classical planning system that computed a sequence of
low-level actions for the agent to achieve these goals. This paper describes
DaTAPlan, our framework that significantly extends our prior work toward
human-robot collaboration. Specifically, DaTAPlan planner computes actions for
an agent and a human to collaboratively and jointly achieve the tasks
anticipated by the LLM, and the agent automatically adapts to unexpected
changes in human action outcomes and preferences. We evaluate DaTAPlan
capabilities in a realistic simulation environment, demonstrating accurate task
anticipation, effective human-robot collaboration, and the ability to adapt to
unexpected changes. Project website: https://dataplan-hrc.github.io</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.03381v3' target='_blank'>Learning to Plan and Generate Text with Citations</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Constanza Fierro, Reinald Kim Amplayo, Fantine Huot, Nicola De Cao, Joshua Maynez, Shashi Narayan, Mirella Lapata</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-04 11:27:54</h6>
<p class='card-text'>The increasing demand for the deployment of LLMs in information-seeking
scenarios has spurred efforts in creating verifiable systems, which generate
responses to queries along with supporting evidence. In this paper, we explore
the attribution capabilities of plan-based models which have been recently
shown to improve the faithfulness, grounding, and controllability of generated
text. We conceptualize plans as a sequence of questions which serve as
blueprints of the generated content and its organization. We propose two
attribution models that utilize different variants of blueprints, an
abstractive model where questions are generated from scratch, and an extractive
model where questions are copied from the input. Experiments on long-form
question-answering show that planning consistently improves attribution
quality. Moreover, the citations generated by blueprint models are more
accurate compared to those obtained from LLM-based pipelines lacking a planning
component.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.03275v2' target='_blank'>DELTA: Decomposed Efficient Long-Term Robot Task Planning using Large
  Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuchen Liu, Luigi Palmieri, Sebastian Koch, Ilche Georgievski, Marco Aiello</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-04 07:59:24</h6>
<p class='card-text'>Recent advancements in Large Language Models (LLMs) have sparked a revolution
across many research fields. In robotics, the integration of common-sense
knowledge from LLMs into task and motion planning has drastically advanced the
field by unlocking unprecedented levels of context awareness. Despite their
vast collection of knowledge, large language models may generate infeasible
plans due to hallucinations or missing domain information. To address these
challenges and improve plan feasibility and computational efficiency, we
introduce DELTA, a novel LLM-informed task planning approach. By using scene
graphs as environment representations within LLMs, DELTA achieves rapid
generation of precise planning problem descriptions. To enhance planning
performance, DELTA decomposes long-term task goals with LLMs into an
autoregressive sequence of sub-goals, enabling automated task planners to
efficiently solve complex problems. In our extensive evaluation, we show that
DELTA enables an efficient and fully automatic task planning pipeline,
achieving higher planning success rates and significantly shorter planning
times compared to the state of the art.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.04292v5' target='_blank'>Conversational Disease Diagnosis via External Planner-Controlled Large
  Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhoujian Sun, Cheng Luo, Ziyi Liu, Zhengxing Huang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-04 06:16:35</h6>
<p class='card-text'>The development of large language models (LLMs) has brought unprecedented
possibilities for artificial intelligence (AI) based medical diagnosis.
However, the application perspective of LLMs in real diagnostic scenarios is
still unclear because they are not adept at collecting patient data
proactively. This study presents a LLM-based diagnostic system that enhances
planning capabilities by emulating doctors. Our system involves two external
planners to handle planning tasks. The first planner employs a reinforcement
learning approach to formulate disease screening questions and conduct initial
diagnoses. The second planner uses LLMs to parse medical guidelines and conduct
differential diagnoses. By utilizing real patient electronic medical record
data, we constructed simulated dialogues between virtual patients and doctors
and evaluated the diagnostic abilities of our system. We demonstrated that our
system obtained impressive performance in both disease screening and
differential diagnoses tasks. This research represents a step towards more
seamlessly integrating AI into clinical settings, potentially enhancing the
accuracy and accessibility of medical diagnostics.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.03122v1' target='_blank'>Towards Standards-Compliant Assistive Technology Product Specifications
  via LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chetan Arora, John Grundy, Louise Puli, Natasha Layton</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-04 00:10:39</h6>
<p class='card-text'>In the rapidly evolving field of assistive technology (AT), ensuring that
products meet national and international standards is essential for user
safety, efficacy, and accessibility. In this vision paper, we introduce
CompliAT, a pioneering framework designed to streamline the compliance process
of AT product specifications with these standards through the innovative use of
Large Language Models (LLMs). CompliAT addresses three critical tasks: checking
terminology consistency, classifying products according to standards, and
tracing key product specifications to standard requirements. We tackle the
challenge of terminology consistency to ensure that the language used in
product specifications aligns with relevant standards, reducing
misunderstandings and non-compliance risks. We propose a novel approach for
product classification, leveraging a retrieval-augmented generation model to
accurately categorize AT products aligning to international standards, despite
the sparse availability of training data. Finally, CompliAT implements a
traceability and compliance mechanism from key product specifications to
standard requirements, ensuring all aspects of an AT product are thoroughly
vetted against the corresponding standards. By semi-automating these processes,
CompliAT aims to significantly reduce the time and effort required for AT
product standards compliance and uphold quality and safety standards. We
outline our planned implementation and evaluation plan for CompliAT.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.04285v1' target='_blank'>MIMIR: A Streamlined Platform for Personalized Agent Tuning in Domain
  Expertise</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chunyuan Deng, Xiangru Tang, Yilun Zhao, Hanming Wang, Haoran Wang, Wangchunshu Zhou, Arman Cohan, Mark Gerstein</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-03 23:42:38</h6>
<p class='card-text'>Recently, large language models (LLMs) have evolved into interactive agents,
proficient in planning, tool use, and task execution across a wide variety of
tasks. However, without specific agent tuning, open-source models like LLaMA
currently struggle to match the efficiency of GPT- 4, particularly given the
scarcity of agent-tuning datasets for fine-tuning. In response, we introduce
\textsc{Mimir}: a streamlined platform offering a customizable pipeline that
enables users to leverage both private knowledge and publicly available,
legally compliant datasets at scale for \textbf{personalized agent tuning}.
Additionally, \textsc{Mimir} supports the generation of general
instruction-tuning datasets from the same input. This dual capability ensures
that language agents developed through the platform possess both specific agent
abilities and general competencies. \textsc{Mimir} integrates these features
into a cohesive end-to-end platform, facilitating everything from the uploading
of personalized files to one-click agent fine-tuning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.06650v1' target='_blank'>Large Language Models as Planning Domain Generators</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:James Oswald, Kavitha Srinivas, Harsha Kokel, Junkyu Lee, Michael Katz, Shirin Sohrabi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-02 19:39:23</h6>
<p class='card-text'>Developing domain models is one of the few remaining places that require
manual human labor in AI planning. Thus, in order to make planning more
accessible, it is desirable to automate the process of domain model generation.
To this end, we investigate if large language models (LLMs) can be used to
generate planning domain models from simple textual descriptions. Specifically,
we introduce a framework for automated evaluation of LLM-generated domains by
comparing the sets of plans for domain instances. Finally, we perform an
empirical analysis of 7 large language models, including coding and chat models
across 9 different planning domains, and under three classes of natural
language domain descriptions. Our results indicate that LLMs, particularly
those with high parameter counts, exhibit a moderate level of proficiency in
generating correct planning domains from natural language descriptions. Our
code is available at https://github.com/IBM/NL2PDDL.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.02078v1' target='_blank'>Advancing LLM Reasoning Generalists with Preference Trees</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lifan Yuan, Ganqu Cui, Hanbin Wang, Ning Ding, Xingyao Wang, Jia Deng, Boji Shan, Huimin Chen, Ruobing Xie, Yankai Lin, Zhenghao Liu, Bowen Zhou, Hao Peng, Zhiyuan Liu, Maosong Sun</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-02 16:25:30</h6>
<p class='card-text'>We introduce Eurus, a suite of large language models (LLMs) optimized for
reasoning. Finetuned from Mistral-7B and CodeLlama-70B, Eurus models achieve
state-of-the-art results among open-source models on a diverse set of
benchmarks covering mathematics, code generation, and logical reasoning
problems. Notably, Eurus-70B beats GPT-3.5 Turbo in reasoning through a
comprehensive benchmarking across 12 tests covering five tasks, and achieves a
33.3% pass@1 accuracy on LeetCode and 32.6% on TheoremQA, two challenging
benchmarks, substantially outperforming existing open-source models by margins
more than 13.3%. The strong performance of Eurus can be primarily attributed to
UltraInteract, our newly-curated large-scale, high-quality alignment dataset
specifically designed for complex reasoning tasks. UltraInteract can be used in
both supervised fine-tuning and preference learning. For each instruction, it
includes a preference tree consisting of (1) reasoning chains with diverse
planning strategies in a unified format, (2) multi-turn interaction
trajectories with the environment and the critique, and (3) pairwise data to
facilitate preference learning. UltraInteract allows us to conduct an in-depth
exploration of preference learning for reasoning tasks. Our investigation
reveals that some well-established preference learning algorithms may be less
suitable for reasoning tasks compared to their effectiveness in general
conversations. Inspired by this, we derive a novel reward modeling objective
which, together with UltraInteract, leads to a strong reward model.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.01589v1' target='_blank'>Classifying Cancer Stage with Open-Source Clinical Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chia-Hsuan Chang, Mary M. Lucas, Grace Lu-Yao, Christopher C. Yang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-02 02:30:47</h6>
<p class='card-text'>Cancer stage classification is important for making treatment and care
management plans for oncology patients. Information on staging is often
included in unstructured form in clinical, pathology, radiology and other
free-text reports in the electronic health record system, requiring extensive
work to parse and obtain. To facilitate the extraction of this information,
previous NLP approaches rely on labeled training datasets, which are
labor-intensive to prepare. In this study, we demonstrate that without any
labeled training data, open-source clinical large language models (LLMs) can
extract pathologic tumor-node-metastasis (pTNM) staging information from
real-world pathology reports. Our experiments compare LLMs and a BERT-based
model fine-tuned using the labeled data. Our findings suggest that while LLMs
still exhibit subpar performance in Tumor (T) classification, with the
appropriate adoption of prompting strategies, they can achieve comparable
performance on Metastasis (M) classification and improved performance on Node
(N) classification.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2405.14876v2' target='_blank'>Precise and Robust Sidewalk Detection: Leveraging Ensemble Learning to
  Surpass LLM Limitations in Urban Environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ibne Farabi Shihab, Sudesh Ramesh Bhagat, Anuj Sharma</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-02 01:42:32</h6>
<p class='card-text'>This study aims to compare the effectiveness of a robust ensemble model with
the state-of-the-art ONE-PEACE Large Language Model (LLM) for accurate
detection of sidewalks. Accurate sidewalk detection is crucial in improving
road safety and urban planning. The study evaluated the model's performance on
Cityscapes, Ade20k, and the Boston Dataset. The results showed that the
ensemble model performed better than the individual models, achieving mean
Intersection Over Union (mIOU) scores of 93.1\%, 90.3\%, and 90.6\% on these
datasets under ideal conditions. Additionally, the ensemble model maintained a
consistent level of performance even in challenging conditions such as
Salt-and-Pepper and Speckle noise, with only a gradual decrease in efficiency
observed. On the other hand, the ONE-PEACE LLM performed slightly better than
the ensemble model in ideal scenarios but experienced a significant decline in
performance under noisy conditions. These findings demonstrate the robustness
and reliability of the ensemble model, making it a valuable asset for improving
urban infrastructure related to road safety and curb space management. This
study contributes positively to the broader context of urban health and
mobility.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.01189v1' target='_blank'>Generating Faithful and Complete Hospital-Course Summaries from the
  Electronic Health Record</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Griffin Adams</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-01 15:47:21</h6>
<p class='card-text'>The rapid adoption of Electronic Health Records (EHRs) has been instrumental
in streamlining administrative tasks, increasing transparency, and enabling
continuity of care across providers. An unintended consequence of the increased
documentation burden, however, has been reduced face-time with patients and,
concomitantly, a dramatic rise in clinician burnout. In this thesis, we
pinpoint a particularly time-intensive, yet critical, documentation task:
generating a summary of a patient's hospital admissions, and propose and
evaluate automated solutions. In Chapter 2, we construct a dataset based on
109,000 hospitalizations (2M source notes) and perform exploratory analyses to
motivate future work on modeling and evaluation [NAACL 2021]. In Chapter 3, we
address faithfulness from a modeling perspective by revising noisy references
[EMNLP 2022] and, to reduce the reliance on references, directly calibrating
model outputs to metrics [ACL 2023]. These works relied heavily on automatic
metrics as human annotations were limited. To fill this gap, in Chapter 4, we
conduct a fine-grained expert annotation of system errors in order to
meta-evaluate existing metrics and better understand task-specific issues of
domain adaptation and source-summary alignments. To learn a metric less
correlated to extractiveness (copy-and-paste), we derive noisy faithfulness
labels from an ensemble of existing metrics and train a faithfulness classifier
on these pseudo labels [MLHC 2023]. Finally, in Chapter 5, we demonstrate that
fine-tuned LLMs (Mistral and Zephyr) are highly prone to entity hallucinations
and cover fewer salient entities. We improve both coverage and faithfulness by
performing sentence-level entity planning based on a set of pre-computed
salient entities from the source text, which extends our work on entity-guided
news summarization [ACL, 2023], [EMNLP, 2023].</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2406.15363v2' target='_blank'>Exploring LLM Multi-Agents for ICD Coding</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Rumeng Li, Xun Wang, Hong Yu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-01 15:17:39</h6>
<p class='card-text'>To address the limitations of Large Language Models (LLMs) in the
International Classification of Diseases (ICD) coding task, where they often
produce inaccurate and incomplete prediction results due to the
high-dimensional and skewed distribution of the ICD codes, and often lack
interpretability and reliability as well. We introduce an innovative
multi-agent approach for ICD coding which mimics the ICD coding assignment
procedure in real-world settings, comprising five distinct agents: the patient,
physician, coder, reviewer, and adjuster. Each agent utilizes an LLM-based
model tailored to their specific role within the coding process. We also
integrate the system with Electronic Health Record (HER)'s SOAP (subjective,
objective, assessment and plan) structure to boost the performances. We compare
our method with a system of agents designed solely by LLMs and other strong
baselines and evaluate it using the Medical Information Mart for Intensive Care
III (MIMIC-III) dataset. Our multi-agent coding framework significantly
outperforms Zero-shot Chain of Thought (CoT) prompting and self-consistency
with CoT (CoT-SC) in coding common and rare ICD codes. An ablation study
validates the effectiveness of the designated agent roles. it also outperforms
the LLM-designed agent system. Moreover, our method achieves comparable results
to state-of-the-art ICD coding methods that require extensive pre-training or
fine-tuning, and outperforms them in rare code accuracy, and explainability.
Additionally, we demonstrate the method's practical applicability by presenting
its performance in scenarios not limited by the common or rare ICD code
constraints.The proposed multi-agent method for ICD coding effectively mimics
the real-world coding process and improves performance on both common and rare
codes.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.01023v1' target='_blank'>Large Language Model Evaluation Via Multi AI Agents: Preliminary results</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zeeshan Rasheed, Muhammad Waseem, Kari Systä, Pekka Abrahamsson</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-04-01 10:06:04</h6>
<p class='card-text'>As Large Language Models (LLMs) have become integral to both research and
daily operations, rigorous evaluation is crucial. This assessment is important
not only for individual tasks but also for understanding their societal impact
and potential risks. Despite extensive efforts to examine LLMs from various
perspectives, there is a noticeable lack of multi-agent AI models specifically
designed to evaluate the performance of different LLMs. To address this gap, we
introduce a novel multi-agent AI model that aims to assess and compare the
performance of various LLMs. Our model consists of eight distinct AI agents,
each responsible for retrieving code based on a common description from
different advanced language models, including GPT-3.5, GPT-3.5 Turbo, GPT-4,
GPT-4 Turbo, Google Bard, LLAMA, and Hugging Face. Our developed model utilizes
the API of each language model to retrieve code for a given high-level
description. Additionally, we developed a verification agent, tasked with the
critical role of evaluating the code generated by its counterparts. We
integrate the HumanEval benchmark into our verification agent to assess the
generated code's performance, providing insights into their respective
capabilities and efficiencies. Our initial results indicate that the GPT-3.5
Turbo model's performance is comparatively better than the other models. This
preliminary analysis serves as a benchmark, comparing their performances side
by side. Our future goal is to enhance the evaluation process by incorporating
the Massively Multitask Benchmark for Python (MBPP) benchmark, which is
expected to further refine our assessment. Additionally, we plan to share our
developed model with twenty practitioners from various backgrounds to test our
model and collect their feedback for further improvement.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.00756v1' target='_blank'>Recover: A Neuro-Symbolic Framework for Failure Detection and Recovery</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Cristina Cornelio, Mohammed Diab</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-31 17:54:22</h6>
<p class='card-text'>Recognizing failures during task execution and implementing recovery
procedures is challenging in robotics. Traditional approaches rely on the
availability of extensive data or a tight set of constraints, while more recent
approaches leverage large language models (LLMs) to verify task steps and
replan accordingly. However, these methods often operate offline, necessitating
scene resets and incurring in high costs. This paper introduces Recover, a
neuro-symbolic framework for online failure identification and recovery. By
integrating ontologies, logical rules, and LLM-based planners, Recover exploits
symbolic information to enhance the ability of LLMs to generate recovery plans
and also to decrease the associated costs. In order to demonstrate the
capabilities of our method in a simulated kitchen environment, we introduce
OntoThor, an ontology describing the AI2Thor simulator setting. Empirical
evaluation shows that OntoThor's logical rules accurately detect all failures
in the analyzed tasks, and that Recover considerably outperforms, for both
failure detection and recovery, a baseline method reliant solely on LLMs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.00450v2' target='_blank'>Planning and Editing What You Retrieve for Enhanced Tool Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tenghao Huang, Dongwon Jung, Muhao Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-30 18:41:51</h6>
<p class='card-text'>Recent advancements in integrating external tools with Large Language Models
(LLMs) have opened new frontiers, with applications in mathematical reasoning,
code generators, and smart assistants. However, existing methods, relying on
simple one-time retrieval strategies, fall short on effectively and accurately
shortlisting relevant tools. This paper introduces a novel PLUTO (Planning,
Learning, and Understanding for TOols) approach, encompassing
`Plan-and-Retrieve (P&R)` and `Edit-and-Ground (E&G)` paradigms. The P&R
paradigm consists of a neural retrieval module for shortlisting relevant tools
and an LLM-based query planner that decomposes complex queries into actionable
tasks, enhancing the effectiveness of tool utilization. The E&G paradigm
utilizes LLMs to enrich tool descriptions based on user scenarios, bridging the
gap between user queries and tool functionalities. Experiment results
demonstrate that these paradigms significantly improve the recall and NDCG in
tool retrieval tasks, significantly surpassing current state-of-the-art models.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.00405v1' target='_blank'>A Taxonomy for Human-LLM Interaction Modes: An Initial Exploration</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jie Gao, Simret Araya Gebreegziabher, Kenny Tsu Wei Choo, Toby Jia-Jun Li, Simon Tangi Perrault, Thomas W. Malone</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-30 16:05:17</h6>
<p class='card-text'>With ChatGPT's release, conversational prompting has become the most popular
form of human-LLM interaction. However, its effectiveness is limited for more
complex tasks involving reasoning, creativity, and iteration. Through a
systematic analysis of HCI papers published since 2021, we identified four key
phases in the human-LLM interaction flow - planning, facilitating, iterating,
and testing - to precisely understand the dynamics of this process.
Additionally, we have developed a taxonomy of four primary interaction modes:
Mode 1: Standard Prompting, Mode 2: User Interface, Mode 3: Context-based, and
Mode 4: Agent Facilitator. This taxonomy was further enriched using the "5W1H"
guideline method, which involved a detailed examination of definitions,
participant roles (Who), the phases that happened (When), human objectives and
LLM abilities (What), and the mechanics of each interaction mode (How). We
anticipate this taxonomy will contribute to the future design and evaluation of
human-LLM interaction.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.00361v1' target='_blank'>Controllable and Diverse Data Augmentation with Large Language Model for
  Low-Resource Open-Domain Dialogue Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhenhua Liu, Tong Zhu, Jianxiang Xiang, Wenliang Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-30 13:28:51</h6>
<p class='card-text'>Data augmentation (DA) is crucial to mitigate model training instability and
over-fitting problems in low-resource open-domain dialogue generation. However,
traditional DA methods often neglect semantic data diversity, restricting the
overall quality. Recently, large language models (LLM) have been used for DA to
generate diversified dialogues. However, they have limited controllability and
tend to generate dialogues with a distribution shift compared to the seed
dialogues. To maximize the augmentation diversity and address the
controllability problem, we propose \textbf{S}ummary-based \textbf{D}ialogue
\textbf{A}ugmentation with LLM (SDA). Our approach enhances the controllability
of LLM by using dialogue summaries as a planning tool. Based on summaries, SDA
can generate high-quality and diverse dialogue data even with a small seed
dataset. To evaluate the efficacy of data augmentation methods for open-domain
dialogue, we designed a clustering-based metric to characterize the semantic
diversity of the augmented dialogue data. The experimental results show that
SDA can augment high-quality and semantically diverse dialogues given a small
seed dataset and an LLM, and the augmented data can boost the performance of
open-domain dialogue models.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.00318v2' target='_blank'>Cognitive Planning for Object Goal Navigation using Generative AI Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Arjun P S, Andrew Melnik, Gora Chand Nandi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-30 10:54:59</h6>
<p class='card-text'>Recent advancements in Generative AI, particularly in Large Language Models
(LLMs) and Large Vision-Language Models (LVLMs), offer new possibilities for
integrating cognitive planning into robotic systems. In this work, we present a
novel framework for solving the object goal navigation problem that generates
efficient exploration strategies. Our approach enables a robot to navigate
unfamiliar environments by leveraging LLMs and LVLMs to understand the semantic
structure of the scene. To address the challenge of representing complex
environments without overwhelming the system, we propose a 3D modular scene
representation, enriched with semantic descriptions. This representation is
dynamically pruned using an LLM-based mechanism, which filters irrelevant
information and focuses on task-specific data. By combining these elements, our
system generates high-level sub-goals that guide the exploration of the robot
toward the target object. We validate our approach in simulated environments,
demonstrating its ability to enhance object search efficiency while maintaining
scalability in complex settings.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2404.00282v3' target='_blank'>Survey on Large Language Model-Enhanced Reinforcement Learning: Concept,
  Taxonomy, and Methods</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuji Cao, Huan Zhao, Yuheng Cheng, Ting Shu, Yue Chen, Guolong Liu, Gaoqi Liang, Junhua Zhao, Jinyue Yan, Yun Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-30 08:28:08</h6>
<p class='card-text'>With extensive pre-trained knowledge and high-level general capabilities,
large language models (LLMs) emerge as a promising avenue to augment
reinforcement learning (RL) in aspects such as multi-task learning, sample
efficiency, and high-level task planning. In this survey, we provide a
comprehensive review of the existing literature in LLM-enhanced RL and
summarize its characteristics compared to conventional RL methods, aiming to
clarify the research scope and directions for future studies. Utilizing the
classical agent-environment interaction paradigm, we propose a structured
taxonomy to systematically categorize LLMs' functionalities in RL, including
four roles: information processor, reward designer, decision-maker, and
generator. For each role, we summarize the methodologies, analyze the specific
RL challenges that are mitigated, and provide insights into future directions.
Lastly, a comparative analysis of each role, potential applications,
prospective opportunities, and challenges of the LLM-enhanced RL are discussed.
By proposing this taxonomy, we aim to provide a framework for researchers to
effectively leverage LLMs in the RL field, potentially accelerating RL
applications in complex applications such as robotics, autonomous driving, and
energy systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.19962v1' target='_blank'>Enhancing the General Agent Capabilities of Low-Parameter LLMs through
  Tuning and Multi-Branch Reasoning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Qinhao Zhou, Zihan Zhang, Xiang Xiang, Ke Wang, Yuchuan Wu, Yongbin Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-29 03:48:12</h6>
<p class='card-text'>Open-source pre-trained Large Language Models (LLMs) exhibit strong language
understanding and generation capabilities, making them highly successful in a
variety of tasks. However, when used as agents for dealing with complex
problems in the real world, their performance is far inferior to large
commercial models such as ChatGPT and GPT-4. As intelligent agents, LLMs need
to have the capabilities of task planning, long-term memory, and the ability to
leverage external tools to achieve satisfactory performance. Various methods
have been proposed to enhance the agent capabilities of LLMs. On the one hand,
methods involve constructing agent-specific data and fine-tuning the models. On
the other hand, some methods focus on designing prompts that effectively
activate the reasoning abilities of the LLMs. We explore both strategies on the
7B and 13B models. We propose a comprehensive method for constructing
agent-specific data using GPT-4. Through supervised fine-tuning with
constructed data, we find that for these models with a relatively small number
of parameters, supervised fine-tuning can significantly reduce hallucination
outputs and formatting errors in agent tasks. Furthermore, techniques such as
multi-path reasoning and task decomposition can effectively decrease problem
complexity and enhance the performance of LLMs as agents. We evaluate our
method on five agent tasks of AgentBench and achieve satisfactory results.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.18778v1' target='_blank'>3P-LLM: Probabilistic Path Planning using Large Language Model for
  Autonomous Robot Navigation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ehsan Latif</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-27 17:26:42</h6>
<p class='card-text'>Much worldly semantic knowledge can be encoded in large language models
(LLMs). Such information could be of great use to robots that want to carry out
high-level, temporally extended commands stated in natural language. However,
the lack of real-world experience that language models have is a key limitation
that makes it challenging to use them for decision-making inside a particular
embodiment. This research assesses the feasibility of using LLM (GPT-3.5-turbo
chatbot by OpenAI) for robotic path planning. The shortcomings of conventional
approaches to managing complex environments and developing trustworthy plans
for shifting environmental conditions serve as the driving force behind the
research. Due to the sophisticated natural language processing abilities of
LLM, the capacity to provide effective and adaptive path-planning algorithms in
real-time, great accuracy, and few-shot learning capabilities, GPT-3.5-turbo is
well suited for path planning in robotics. In numerous simulated scenarios, the
research compares the performance of GPT-3.5-turbo with that of
state-of-the-art path planners like Rapidly Exploring Random Tree (RRT) and A*.
We observed that GPT-3.5-turbo is able to provide real-time path planning
feedback to the robot and outperforms its counterparts. This paper establishes
the foundation for LLM-powered path planning for robotic systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.18760v2' target='_blank'>MLDT: Multi-Level Decomposition for Complex Long-Horizon Robotic Task
  Planning with Open-Source Large Language Model</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yike Wu, Jiatao Zhang, Nan Hu, LanLing Tang, Guilin Qi, Jun Shao, Jie Ren, Wei Song</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-27 16:58:20</h6>
<p class='card-text'>In the realm of data-driven AI technology, the application of open-source
large language models (LLMs) in robotic task planning represents a significant
milestone. Recent robotic task planning methods based on open-source LLMs
typically leverage vast task planning datasets to enhance models' planning
abilities. While these methods show promise, they struggle with complex
long-horizon tasks, which require comprehending more context and generating
longer action sequences. This paper addresses this limitation by proposing
MLDT, theMulti-Level Decomposition Task planning method. This method
innovatively decomposes tasks at the goal-level, task-level, and action-level
to mitigate the challenge of complex long-horizon tasks. In order to enhance
open-source LLMs' planning abilities, we introduce a goal-sensitive corpus
generation method to create high-quality training data and conduct instruction
tuning on the generated corpus. Since the complexity of the existing datasets
is not high enough, we construct a more challenging dataset, LongTasks, to
specifically evaluate planning ability on complex long-horizon tasks. We
evaluate our method using various LLMs on four datasets in VirtualHome. Our
results demonstrate a significant performance enhancement in robotic task
planning, showcasing MLDT's effectiveness in overcoming the limitations of
existing methods based on open-source LLMs as well as its practicality in
complex, real-world scenarios.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.18125v1' target='_blank'>For those who don't know (how) to ask: Building a dataset of technology
  questions for digital newcomers</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Evan Lucas, Kelly S. Steelman, Leo C. Ureel, Charles Wallace</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-26 22:08:33</h6>
<p class='card-text'>While the rise of large language models (LLMs) has created rich new
opportunities to learn about digital technology, many on the margins of this
technology struggle to gain and maintain competency due to lexical or
conceptual barriers that prevent them from asking appropriate questions.
Although there have been many efforts to understand factuality of LLM-created
content and ability of LLMs to answer questions, it is not well understood how
unclear or nonstandard language queries affect the model outputs. We propose
the creation of a dataset that captures questions of digital newcomers and
outsiders, utilizing data we have compiled from a decade's worth of one-on-one
tutoring. In this paper we lay out our planned efforts and some potential uses
of this dataset.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.17927v2' target='_blank'>MAGIS: LLM-Based Multi-Agent Framework for GitHub Issue Resolution</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wei Tao, Yucheng Zhou, Yanlin Wang, Wenqiang Zhang, Hongyu Zhang, Yu Cheng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-26 17:57:57</h6>
<p class='card-text'>In software development, resolving the emergent issues within GitHub
repositories is a complex challenge that involves not only the incorporation of
new code but also the maintenance of existing code. Large Language Models
(LLMs) have shown promise in code generation but face difficulties in resolving
Github issues, particularly at the repository level. To overcome this
challenge, we empirically study the reason why LLMs fail to resolve GitHub
issues and analyze the major factors. Motivated by the empirical findings, we
propose a novel LLM-based Multi-Agent framework for GitHub Issue reSolution,
MAGIS, consisting of four agents customized for software evolution: Manager,
Repository Custodian, Developer, and Quality Assurance Engineer agents. This
framework leverages the collaboration of various agents in the planning and
coding process to unlock the potential of LLMs to resolve GitHub issues. In
experiments, we employ the SWE-bench benchmark to compare MAGIS with popular
LLMs, including GPT-3.5, GPT-4, and Claude-2. MAGIS can resolve 13.94% GitHub
issues, significantly outperforming the baselines. Specifically, MAGIS achieves
an eight-fold increase in resolved ratio over the direct application of GPT-4,
the advanced LLM.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.17246v1' target='_blank'>TwoStep: Multi-agent Task Planning using Classical Planners and Large
  Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ishika Singh, David Traum, Jesse Thomason</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-25 22:47:13</h6>
<p class='card-text'>Classical planning formulations like the Planning Domain Definition Language
(PDDL) admit action sequences guaranteed to achieve a goal state given an
initial state if any are possible. However, reasoning problems defined in PDDL
do not capture temporal aspects of action taking, for example that two agents
in the domain can execute an action simultaneously if postconditions of each do
not interfere with preconditions of the other. A human expert can decompose a
goal into largely independent constituent parts and assign each agent to one of
these subgoals to take advantage of simultaneous actions for faster execution
of plan steps, each using only single agent planning. By contrast, large
language models (LLMs) used for directly inferring plan steps do not guarantee
execution success, but do leverage commonsense reasoning to assemble action
sequences. We combine the strengths of classical planning and LLMs by
approximating human intuitions for two-agent planning goal decomposition. We
demonstrate that LLM-based goal decomposition leads to faster planning times
than solving multi-agent PDDL problems directly while simultaneously achieving
fewer plan execution steps than a single agent plan alone and preserving
execution success. Additionally, we find that LLM-based approximations of
subgoals can achieve similar multi-agent execution steps than those specified
by human experts. Website and resources at https://glamor-usc.github.io/twostep</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.17238v1' target='_blank'>Temporal and Semantic Evaluation Metrics for Foundation Models in
  Post-Hoc Analysis of Robotic Sub-tasks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jonathan Salfity, Selma Wanna, Minkyu Choi, Mitch Pryor</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-25 22:39:20</h6>
<p class='card-text'>Recent works in Task and Motion Planning (TAMP) show that training control
policies on language-supervised robot trajectories with quality labeled data
markedly improves agent task success rates. However, the scarcity of such data
presents a significant hurdle to extending these methods to general use cases.
To address this concern, we present an automated framework to decompose
trajectory data into temporally bounded and natural language-based descriptive
sub-tasks by leveraging recent prompting strategies for Foundation Models (FMs)
including both Large Language Models (LLMs) and Vision Language Models (VLMs).
Our framework provides both time-based and language-based descriptions for
lower-level sub-tasks that comprise full trajectories. To rigorously evaluate
the quality of our automatic labeling framework, we contribute an algorithm
SIMILARITY to produce two novel metrics, temporal similarity and semantic
similarity. The metrics measure the temporal alignment and semantic fidelity of
language descriptions between two sub-task decompositions, namely an FM
sub-task decomposition prediction and a ground-truth sub-task decomposition. We
present scores for temporal similarity and semantic similarity above 90%,
compared to 30% of a randomized baseline, for multiple robotic environments,
demonstrating the effectiveness of our proposed framework. Our results enable
building diverse, large-scale, language-supervised datasets for improved
robotic TAMP.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.17134v2' target='_blank'>RepairAgent: An Autonomous, LLM-Based Agent for Program Repair</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Islem Bouzenia, Premkumar Devanbu, Michael Pradel</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-25 19:17:43</h6>
<p class='card-text'>Automated program repair has emerged as a powerful technique to mitigate the
impact of software bugs on system reliability and user experience. This paper
introduces RepairAgent, the first work to address the program repair challenge
through an autonomous agent based on a large language model (LLM). Unlike
existing deep learning-based approaches, which prompt a model with a fixed
prompt or in a fixed feedback loop, our work treats the LLM as an agent capable
of autonomously planning and executing actions to fix bugs by invoking suitable
tools. RepairAgent freely interleaves gathering information about the bug,
gathering repair ingredients, and validating fixes, while deciding which tools
to invoke based on the gathered information and feedback from previous fix
attempts. Key contributions that enable RepairAgent include a set of tools that
are useful for program repair, a dynamically updated prompt format that allows
the LLM to interact with these tools, and a finite state machine that guides
the agent in invoking the tools. Our evaluation on the popular Defects4J
dataset demonstrates RepairAgent's effectiveness in autonomously repairing 164
bugs, including 39 bugs not fixed by prior techniques. Interacting with the LLM
imposes an average cost of 270,000 tokens per bug, which, under the current
pricing of OpenAI's GPT-3.5 model, translates to 14 cents of USD per bug. To
the best of our knowledge, this work is the first to present an autonomous,
LLM-based agent for program repair, paving the way for future agent-based
techniques in software engineering.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.17124v2' target='_blank'>Grounding Language Plans in Demonstrations Through Counterfactual
  Perturbations</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yanwei Wang, Tsun-Hsuan Wang, Jiayuan Mao, Michael Hagenow, Julie Shah</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-25 19:04:59</h6>
<p class='card-text'>Grounding the common-sense reasoning of Large Language Models (LLMs) in
physical domains remains a pivotal yet unsolved problem for embodied AI.
Whereas prior works have focused on leveraging LLMs directly for planning in
symbolic spaces, this work uses LLMs to guide the search of task structures and
constraints implicit in multi-step demonstrations. Specifically, we borrow from
manipulation planning literature the concept of mode families, which group
robot configurations by specific motion constraints, to serve as an abstraction
layer between the high-level language representations of an LLM and the
low-level physical trajectories of a robot. By replaying a few human
demonstrations with synthetic perturbations, we generate coverage over the
demonstrations' state space with additional successful executions as well as
counterfactuals that fail the task. Our explanation-based learning framework
trains an end-to-end differentiable neural network to predict successful
trajectories from failures and as a by-product learns classifiers that ground
low-level states and images in mode families without dense labeling. The
learned grounding classifiers can further be used to translate language plans
into reactive policies in the physical domain in an interpretable manner. We
show our approach improves the interpretability and reactivity of imitation
learning through 2D navigation and simulated and real robot manipulation tasks.
Website: https://yanweiw.github.io/glide</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.17104v3' target='_blank'>Attribute First, then Generate: Locally-attributable Grounded Text
  Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Aviv Slobodkin, Eran Hirsch, Arie Cattan, Tal Schuster, Ido Dagan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-25 18:41:47</h6>
<p class='card-text'>Recent efforts to address hallucinations in Large Language Models (LLMs) have
focused on attributed text generation, which supplements generated texts with
citations of supporting sources for post-generation fact-checking and
corrections. Yet, these citations often point to entire documents or
paragraphs, burdening users with extensive verification work. In this paper, we
introduce a locally-attributable text generation approach, prioritizing concise
attributions. Our method, named "Attribute First, then Generate", breaks down
the conventional end-to-end generation process into three intuitive steps:
content selection, sentence planning, and sequential sentence generation. By
initially identifying relevant source segments ("select first") and then
conditioning the generation process on them ("then generate"), we ensure these
segments also act as the output's fine-grained attributions ("select" becomes
"attribute"). Tested on Multi-document Summarization and Long-form
Question-answering, our method not only yields more concise citations than the
baselines but also maintains - and in some cases enhances - both generation
quality and attribution accuracy. Furthermore, it significantly reduces the
time required for fact verification by human assessors.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.17089v2' target='_blank'>GOLF: Goal-Oriented Long-term liFe tasks supported by human-AI
  collaboration</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ben Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-25 18:25:10</h6>
<p class='card-text'>The advent of ChatGPT and similar large language models (LLMs) has
revolutionized the human-AI interaction and information-seeking process.
Leveraging LLMs as an alternative to search engines, users can now access
summarized information tailored to their queries, significantly reducing the
cognitive load associated with navigating vast information resources. This
shift underscores the potential of LLMs in redefining information access
paradigms. Drawing on the foundation of task-focused information retrieval and
LLMs' task planning ability, this research extends the scope of LLM
capabilities beyond routine task automation to support users in navigating
long-term and significant life tasks. It introduces the GOLF framework
(Goal-Oriented Long-term liFe tasks), which focuses on enhancing LLMs' ability
to assist in significant life decisions through goal orientation and long-term
planning. The methodology encompasses a comprehensive simulation study to test
the framework's efficacy, followed by model and human evaluations to develop a
dataset benchmark for long-term life tasks, and experiments across different
models and settings. By shifting the focus from short-term tasks to the broader
spectrum of long-term life goals, this research underscores the transformative
potential of LLMs in enhancing human decision-making processes and task
management, marking a significant step forward in the evolution of human-AI
collaboration.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.15648v2' target='_blank'>SRLM: Human-in-Loop Interactive Social Robot Navigation with Large
  Language Model and Deep Reinforcement Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Weizheng Wang, Ike Obi, Byung-Cheol Min</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-22 23:12:28</h6>
<p class='card-text'>An interactive social robotic assistant must provide services in complex and
crowded spaces while adapting its behavior based on real-time human language
commands or feedback. In this paper, we propose a novel hybrid approach called
Social Robot Planner (SRLM), which integrates Large Language Models (LLM) and
Deep Reinforcement Learning (DRL) to navigate through human-filled public
spaces and provide multiple social services. SRLM infers global planning from
human-in-loop commands in real-time, and encodes social information into a
LLM-based large navigation model (LNM) for low-level motion execution.
Moreover, a DRL-based planner is designed to maintain benchmarking performance,
which is blended with LNM by a large feedback model (LFM) to address the
instability of current text and LLM-driven LNM. Finally, SRLM demonstrates
outstanding performance in extensive experiments. More details about this work
are available at: https://sites.google.com/view/navi-srlm</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.15369v1' target='_blank'>OceanPlan: Hierarchical Planning and Replanning for Natural Language AUV
  Piloting in Large-scale Unexplored Ocean Environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ruochu Yang, Fumin Zhang, Mengxue Hou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-22 17:48:13</h6>
<p class='card-text'>We develop a hierarchical LLM-task-motion planning and replanning framework
to efficiently ground an abstracted human command into tangible Autonomous
Underwater Vehicle (AUV) control through enhanced representations of the world.
We also incorporate a holistic replanner to provide real-world feedback with
all planners for robust AUV operation. While there has been extensive research
in bridging the gap between LLMs and robotic missions, they are unable to
guarantee success of AUV applications in the vast and unknown ocean
environment. To tackle specific challenges in marine robotics, we design a
hierarchical planner to compose executable motion plans, which achieves
planning efficiency and solution quality by decomposing long-horizon missions
into sub-tasks. At the same time, real-time data stream is obtained by a
replanner to address environmental uncertainties during plan execution.
Experiments validate that our proposed framework delivers successful AUV
performance of long-duration missions through natural language piloting.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.15137v1' target='_blank'>CACA Agent: Capability Collaboration based AI Agent</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Peng Xu, Haoran Wang, Chuang Wang, Xu Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-22 11:42:47</h6>
<p class='card-text'>As AI Agents based on Large Language Models (LLMs) have shown potential in
practical applications across various fields, how to quickly deploy an AI agent
and how to conveniently expand the application scenario of AI agents has become
a challenge. Previous studies mainly focused on implementing all the reasoning
capabilities of AI agents within a single LLM, which often makes the model more
complex and also reduces the extensibility of AI agent functionality. In this
paper, we propose CACA Agent (Capability Collaboration based AI Agent), using
an open architecture inspired by service computing. CACA Agent integrates a set
of collaborative capabilities to implement AI Agents, not only reducing the
dependence on a single LLM, but also enhancing the extensibility of both the
planning abilities and the tools available to AI agents. Utilizing the proposed
system, we present a demo to illustrate the operation and the application
scenario extension of CACA Agent.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.13801v2' target='_blank'>Natural Language as Policies: Reasoning for Coordinate-Level Embodied
  Control with LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yusuke Mikami, Andrew Melnik, Jun Miura, Ville Hautamäki</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-20 17:58:12</h6>
<p class='card-text'>We demonstrate experimental results with LLMs that address robotics task
planning problems. Recently, LLMs have been applied in robotics task planning,
particularly using a code generation approach that converts complex high-level
instructions into mid-level policy codes. In contrast, our approach acquires
text descriptions of the task and scene objects, then formulates task planning
through natural language reasoning, and outputs coordinate level control
commands, thus reducing the necessity for intermediate representation code as
policies with pre-defined APIs. Our approach is evaluated on a multi-modal
prompt simulation benchmark, demonstrating that our prompt engineering
experiments with natural language reasoning significantly enhance success rates
compared to its absence. Furthermore, our approach illustrates the potential
for natural language descriptions to transfer robotics skills from known tasks
to previously unseen tasks. The project website:
https://natural-language-as-policies.github.io/</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.13597v2' target='_blank'>No more optimization rules: LLM-enabled policy-based multi-modal query
  optimizer</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yifan Wang, Haodi Ma, Daisy Zhe Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-20 13:44:30</h6>
<p class='card-text'>Large language model (LLM) has marked a pivotal moment in the field of
machine learning and deep learning. Recently its capability for query planning
has been investigated, including both single-modal and multi-modal queries.
However, there is no work on the query optimization capability of LLM. As a
critical (or could even be the most important) step that significantly impacts
the execution performance of the query plan, such analysis and attempts should
not be missed. From another aspect, existing query optimizers are usually
rule-based or rule-based + cost-based, i.e., they are dependent on manually
created rules to complete the query plan rewrite/transformation. Given the fact
that modern optimizers include hundreds to thousands of rules, designing a
multi-modal query optimizer following a similar way is significantly
time-consuming since we will have to enumerate as many multi-modal optimization
rules as possible, which has not been well addressed today. In this paper, we
investigate the query optimization ability of LLM and use LLM to design LaPuda,
a novel LLM and Policy based multi-modal query optimizer. Instead of
enumerating specific and detailed rules, LaPuda only needs a few abstract
policies to guide LLM in the optimization, by which much time and human effort
are saved. Furthermore, to prevent LLM from making mistakes or negative
optimization, we borrow the idea of gradient descent and propose a guided cost
descent (GCD) algorithm to perform the optimization, such that the optimization
can be kept in the correct direction. In our evaluation, our methods
consistently outperform the baselines in most cases. For example, the optimized
plans generated by our methods result in 1~3x higher execution speed than those
by the baselines.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.13583v3' target='_blank'>CoCoST: Automatic Complex Code Generation with Online Searching and
  Correctness Testing</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xinyi He, Jiaru Zou, Yun Lin, Mengyu Zhou, Shi Han, Zejian Yuan, Dongmei Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-20 13:33:55</h6>
<p class='card-text'>Large Language Models have revolutionized code generation ability by
converting natural language descriptions into executable code. However,
generating complex code within real-world scenarios remains challenging due to
intricate structures, subtle bugs, understanding of advanced data types, and
lack of supplementary contents. To address these challenges, we introduce the
CoCoST framework, which enhances complex code generation by online searching
for more information with planned queries and correctness testing for code
refinement. Moreover, CoCoST serializes the complex inputs and outputs to
improve comprehension and generates test cases to ensure the adaptability for
real-world applications. CoCoST is validated through rigorous experiments on
the DS-1000 and ClassEval datasets. Experimental results show that CoCoST
substantially improves the quality of complex code generation, highlighting its
potential to enhance the practicality of LLMs in generating complex code.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.13365v1' target='_blank'>ManiPose: A Comprehensive Benchmark for Pose-aware Object Manipulation
  in Robotics</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Qiaojun Yu, Ce Hao, Junbo Wang, Wenhai Liu, Liu Liu, Yao Mu, Yang You, Hengxu Yan, Cewu Lu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-20 07:48:32</h6>
<p class='card-text'>Robotic manipulation in everyday scenarios, especially in unstructured
environments, requires skills in pose-aware object manipulation (POM), which
adapts robots' grasping and handling according to an object's 6D pose.
Recognizing an object's position and orientation is crucial for effective
manipulation. For example, if a mug is lying on its side, it's more effective
to grasp it by the rim rather than the handle. Despite its importance, research
in POM skills remains limited, because learning manipulation skills requires
pose-varying simulation environments and datasets. This paper introduces
ManiPose, a pioneering benchmark designed to advance the study of pose-varying
manipulation tasks. ManiPose encompasses: 1) Simulation environments for POM
feature tasks ranging from 6D pose-specific pick-and-place of single objects to
cluttered scenes, further including interactions with articulated objects. 2) A
comprehensive dataset featuring geometrically consistent and
manipulation-oriented 6D pose labels for 2936 real-world scanned rigid objects
and 100 articulated objects across 59 categories. 3) A baseline for POM,
leveraging the inferencing abilities of LLM (e.g., ChatGPT) to analyze the
relationship between 6D pose and task-specific requirements, offers enhanced
pose-aware grasp prediction and motion planning capabilities. Our benchmark
demonstrates notable advancements in pose estimation, pose-aware manipulation,
and real-robot skill transfer, setting new standards for POM research. We will
open-source the ManiPose benchmark with the final version paper, inviting the
community to engage with our resources, available at our
website:https://sites.google.com/view/manipose.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.13313v1' target='_blank'>Polaris: A Safety-focused LLM Constellation Architecture for Healthcare</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Subhabrata Mukherjee, Paul Gamble, Markel Sanz Ausin, Neel Kant, Kriti Aggarwal, Neha Manjunath, Debajyoti Datta, Zhengliang Liu, Jiayuan Ding, Sophia Busacca, Cezanne Bianco, Swapnil Sharma, Rae Lasko, Michelle Voisard, Sanchay Harneja, Darya Filippova, Gerry Meixiong, Kevin Cha, Amir Youssefi, Meyhaa Buvanesh, Howard Weingram, Sebastian Bierman-Lytle, Harpreet Singh Mangat, Kim Parikh, Saad Godil, Alex Miller</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-20 05:34:03</h6>
<p class='card-text'>We develop Polaris, the first safety-focused LLM constellation for real-time
patient-AI healthcare conversations. Unlike prior LLM works in healthcare
focusing on tasks like question answering, our work specifically focuses on
long multi-turn voice conversations. Our one-trillion parameter constellation
system is composed of several multibillion parameter LLMs as co-operative
agents: a stateful primary agent that focuses on driving an engaging
conversation and several specialist support agents focused on healthcare tasks
performed by nurses to increase safety and reduce hallucinations. We develop a
sophisticated training protocol for iterative co-training of the agents that
optimize for diverse objectives. We train our models on proprietary data,
clinical care plans, healthcare regulatory documents, medical manuals, and
other medical reasoning documents. We align our models to speak like medical
professionals, using organic healthcare conversations and simulated ones
between patient actors and experienced nurses. This allows our system to
express unique capabilities such as rapport building, trust building, empathy
and bedside manner. Finally, we present the first comprehensive clinician
evaluation of an LLM system for healthcare. We recruited over 1100 U.S.
licensed nurses and over 130 U.S. licensed physicians to perform end-to-end
conversational evaluations of our system by posing as patients and rating the
system on several measures. We demonstrate Polaris performs on par with human
nurses on aggregate across dimensions such as medical safety, clinical
readiness, conversational quality, and bedside manner. Additionally, we conduct
a challenging task-based evaluation of the individual specialist support
agents, where we demonstrate our LLM agents significantly outperform a much
larger general-purpose LLM (GPT-4) as well as from its own medium-size class
(LLaMA-2 70B).</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.13271v1' target='_blank'>Enhancing Code Generation Performance of Smaller Models by Distilling
  the Reasoning Ability of LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhihong Sun, Chen Lyu, Bolun Li, Yao Wan, Hongyu Zhang, Ge Li, Zhi Jin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-20 03:09:54</h6>
<p class='card-text'>Large Language Models (LLMs) have recently made significant advances in code
generation through the 'Chain-of-Thought' prompting technique. This technique
empowers the model to autonomously devise "solution plans" to tackle intricate
programming challenges, thereby improving its performance in code generation.
Nevertheless, smaller models have been struggling to keep up with LLMs in
deducing these plans, adversely affecting their code generation capabilities.
Given the considerable size and associated deployment costs, along with
concerns about data security, many teams opt for deploying smaller models for
code generation. Consequently, there arises a compelling need for transferring
LLMs' code generation reasoning abilities to the smaller models. In this paper,
we propose the CodePLAN framework, which aims to transfer LLMs' reasoning
capabilities to smaller models through distillation. We adopt a multi-task
learning approach, jointly undertaking code generation and solution plan
generation tasks, to enhance the code generation capabilities of the smaller
model. To ensure the superior quality of the solution plans, we advocate for
the utilization of backward reasoning and plan sampling strategies. Our
experiments show that in comparison to the conventional fine-tuning approach,
our approach improves the smaller model's code generation performance (measured
in pass@1 metric) by over 130% on the challenging APPS benchmark.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.13198v2' target='_blank'>LAP, Using Action Feasibility for Improved Uncertainty Alignment of
  Large Language Model Planners</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:James F. Mullen Jr., Dinesh Manocha</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-19 23:18:40</h6>
<p class='card-text'>Large language models (LLMs) showcase many desirable traits for intelligent
and helpful robots. However, they are also known to hallucinate predictions.
This issue is exacerbated in robotics where LLM hallucinations may result in
robots confidently executing plans that are contrary to user goals, relying
more frequently on human assistance, or preventing the robot from asking for
help at all. In this work, we present LAP, a novel approach for utilizing
off-the-shelf LLMs, alongside a novel Action feasibility metric, in robotic
Planners that minimize harmful hallucinations and human intervention. Our key
finding is that calculating and leveraging a new metric, which we call
A-Feasibility, a measure of whether a given action is possible and safe in the
provided scene, helps to mitigate hallucinations in LLM predictions and better
align the LLM's confidence measure with the probability of success. We
specifically propose an A-Feasibility metric which both combines scene context
and prompting a LLM to determine if a given action is possible and safe in the
scene, using the LLM's response to compute the score. Through experiments in
both simulation and the real world on tasks with a variety of ambiguities, we
show that LAP significantly increases success rate and decreases the amount of
human intervention required relative to prior art. For example, in our
real-world testing paradigm, LAP decreases the human help rate of previous
methods by over 33% at a success rate of 70%.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.12884v2' target='_blank'>HYDRA: A Hyper Agent for Dynamic Compositional Visual Reasoning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Fucai Ke, Zhixi Cai, Simindokht Jahangard, Weiqing Wang, Pari Delir Haghighi, Hamid Rezatofighi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-19 16:31:30</h6>
<p class='card-text'>Recent advances in visual reasoning (VR), particularly with the aid of Large
Vision-Language Models (VLMs), show promise but require access to large-scale
datasets and face challenges such as high computational costs and limited
generalization capabilities. Compositional visual reasoning approaches have
emerged as effective strategies; however, they heavily rely on the commonsense
knowledge encoded in Large Language Models (LLMs) to perform planning,
reasoning, or both, without considering the effect of their decisions on the
visual reasoning process, which can lead to errors or failed procedures. To
address these challenges, we introduce HYDRA, a multi-stage dynamic
compositional visual reasoning framework designed for reliable and
incrementally progressive general reasoning. HYDRA integrates three essential
modules: a planner, a Reinforcement Learning (RL) agent serving as a cognitive
controller, and a reasoner. The planner and reasoner modules utilize an LLM to
generate instruction samples and executable code from the selected instruction,
respectively, while the RL agent dynamically interacts with these modules,
making high-level decisions on selection of the best instruction sample given
information from the historical state stored through a feedback loop. This
adaptable design enables HYDRA to adjust its actions based on previous feedback
received during the reasoning process, leading to more reliable reasoning
outputs and ultimately enhancing its overall effectiveness. Our framework
demonstrates state-of-the-art performance in various VR tasks on four different
widely-used datasets.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.12482v2' target='_blank'>Embodied LLM Agents Learn to Cooperate in Organized Teams</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xudong Guo, Kaixuan Huang, Jiale Liu, Wenhui Fan, Natalia Vélez, Qingyun Wu, Huazheng Wang, Thomas L. Griffiths, Mengdi Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-19 06:39:47</h6>
<p class='card-text'>Large Language Models (LLMs) have emerged as integral tools for reasoning,
planning, and decision-making, drawing upon their extensive world knowledge and
proficiency in language-related tasks. LLMs thus hold tremendous potential for
natural language interaction within multi-agent systems to foster cooperation.
However, LLM agents tend to over-report and comply with any instruction, which
may result in information redundancy and confusion in multi-agent cooperation.
Inspired by human organizations, this paper introduces a framework that imposes
prompt-based organization structures on LLM agents to mitigate these problems.
Through a series of experiments with embodied LLM agents and human-agent
collaboration, our results highlight the impact of designated leadership on
team efficiency, shedding light on the leadership qualities displayed by LLM
agents and their spontaneous cooperative behaviors. Further, we harness the
potential of LLMs to propose enhanced organizational prompts, via a
Criticize-Reflect process, resulting in novel organization structures that
reduce communication costs and enhance team efficiency.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.12393v1' target='_blank'>Dr3: Ask Large Language Models Not to Give Off-Topic Answers in Open
  Domain Multi-Hop Question Answering</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuan Gao, Yiheng Zhu, Yuanbin Cao, Yinzhi Zhou, Zhen Wu, Yujie Chen, Shenglan Wu, Haoyuan Hu, Xinyu Dai</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-19 03:00:03</h6>
<p class='card-text'>Open Domain Multi-Hop Question Answering (ODMHQA) plays a crucial role in
Natural Language Processing (NLP) by aiming to answer complex questions through
multi-step reasoning over retrieved information from external knowledge
sources. Recently, Large Language Models (LLMs) have demonstrated remarkable
performance in solving ODMHQA owing to their capabilities including planning,
reasoning, and utilizing tools. However, LLMs may generate off-topic answers
when attempting to solve ODMHQA, namely the generated answers are irrelevant to
the original questions. This issue of off-topic answers accounts for
approximately one-third of incorrect answers, yet remains underexplored despite
its significance. To alleviate this issue, we propose the
Discriminate->Re-Compose->Re- Solve->Re-Decompose (Dr3) mechanism.
Specifically, the Discriminator leverages the intrinsic capabilities of LLMs to
judge whether the generated answers are off-topic. In cases where an off-topic
answer is detected, the Corrector performs step-wise revisions along the
reversed reasoning chain (Re-Compose->Re-Solve->Re-Decompose) until the final
answer becomes on-topic. Experimental results on the HotpotQA and
2WikiMultiHopQA datasets demonstrate that our Dr3 mechanism considerably
reduces the occurrence of off-topic answers in ODMHQA by nearly 13%, improving
the performance in Exact Match (EM) by nearly 3% compared to the baseline
method without the Dr3 mechanism.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.12297v1' target='_blank'>Leveraging Large Language Models to Extract Information on Substance Use
  Disorder Severity from Clinical Notes: A Zero-shot Learning Approach</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Maria Mahbub, Gregory M. Dams, Sudarshan Srinivasan, Caitlin Rizy, Ioana Danciu, Jodie Trafton, Kathryn Knight</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-18 22:39:03</h6>
<p class='card-text'>Substance use disorder (SUD) poses a major concern due to its detrimental
effects on health and society. SUD identification and treatment depend on a
variety of factors such as severity, co-determinants (e.g., withdrawal
symptoms), and social determinants of health. Existing diagnostic coding
systems used by American insurance providers, like the International
Classification of Diseases (ICD-10), lack granularity for certain diagnoses,
but clinicians will add this granularity (as that found within the Diagnostic
and Statistical Manual of Mental Disorders classification or DSM-5) as
supplemental unstructured text in clinical notes. Traditional natural language
processing (NLP) methods face limitations in accurately parsing such diverse
clinical language. Large Language Models (LLMs) offer promise in overcoming
these challenges by adapting to diverse language patterns. This study
investigates the application of LLMs for extracting severity-related
information for various SUD diagnoses from clinical notes. We propose a
workflow employing zero-shot learning of LLMs with carefully crafted prompts
and post-processing techniques. Through experimentation with Flan-T5, an
open-source LLM, we demonstrate its superior recall compared to the rule-based
approach. Focusing on 11 categories of SUD diagnoses, we show the effectiveness
of LLMs in extracting severity information, contributing to improved risk
assessment and treatment planning for SUD patients.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.11552v3' target='_blank'>LLM3:Large Language Model-based Task and Motion Planning with Motion
  Failure Reasoning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shu Wang, Muzhi Han, Ziyuan Jiao, Zeyu Zhang, Ying Nian Wu, Song-Chun Zhu, Hangxin Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-18 08:03:47</h6>
<p class='card-text'>Conventional Task and Motion Planning (TAMP) approaches rely on manually
crafted interfaces connecting symbolic task planning with continuous motion
generation. These domain-specific and labor-intensive modules are limited in
addressing emerging tasks in real-world settings. Here, we present LLM^3, a
novel Large Language Model (LLM)-based TAMP framework featuring a
domain-independent interface. Specifically, we leverage the powerful reasoning
and planning capabilities of pre-trained LLMs to propose symbolic action
sequences and select continuous action parameters for motion planning.
Crucially, LLM^3 incorporates motion planning feedback through prompting,
allowing the LLM to iteratively refine its proposals by reasoning about motion
failure. Consequently, LLM^3 interfaces between task planning and motion
planning, alleviating the intricate design process of handling domain-specific
messages between them. Through a series of simulations in a box-packing domain,
we quantitatively demonstrate the effectiveness of LLM^3 in solving TAMP
problems and the efficiency in selecting action parameters. Ablation studies
underscore the significant contribution of motion failure reasoning to the
success of LLM^3. Furthermore, we conduct qualitative experiments on a physical
manipulator, demonstrating the practical applicability of our approach in
real-world settings.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.11401v2' target='_blank'>Scene-LLM: Extending Language Model for 3D Visual Understanding and
  Reasoning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Rao Fu, Jingyu Liu, Xilun Chen, Yixin Nie, Wenhan Xiong</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-18 01:18:48</h6>
<p class='card-text'>This paper introduces Scene-LLM, a 3D-visual-language model that enhances
embodied agents' abilities in interactive 3D indoor environments by integrating
the reasoning strengths of Large Language Models (LLMs). Scene-LLM adopts a
hybrid 3D visual feature representation, that incorporates dense spatial
information and supports scene state updates. The model employs a projection
layer to efficiently project these features in the pre-trained textual
embedding space, enabling effective interpretation of 3D visual information.
Unique to our approach is the integration of both scene-level and ego-centric
3D information. This combination is pivotal for interactive planning, where
scene-level data supports global planning and ego-centric data is important for
localization. Notably, we use ego-centric 3D frame features for feature
alignment, an efficient technique that enhances the model's ability to align
features of small objects within the scene. Our experiments with Scene-LLM
demonstrate its strong capabilities in dense captioning, question answering,
and interactive planning. We believe Scene-LLM advances the field of 3D visual
understanding and reasoning, offering new possibilities for sophisticated agent
interactions in indoor settings.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.11085v4' target='_blank'>m&m's: A Benchmark to Evaluate Tool-Use for multi-step multi-modal Tasks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zixian Ma, Weikai Huang, Jieyu Zhang, Tanmay Gupta, Ranjay Krishna</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-17 04:36:18</h6>
<p class='card-text'>Real-world multi-modal problems are rarely solved by a single machine
learning model, and often require multi-step computational plans that involve
stitching several models. Tool-augmented LLMs hold tremendous promise for
automating the generation of such computational plans. However, the lack of
standardized benchmarks for evaluating LLMs as planners for multi-step
multi-modal tasks has prevented a systematic study of planner design decisions.
Should LLMs generate a full plan in a single shot or step-by-step? Should they
invoke tools directly with Python code or through structured data formats like
JSON? Does feedback improve planning? To answer these questions and more, we
introduce m&m's: a benchmark containing 4K+ multi-step multi-modal tasks
involving 33 tools that include multi-modal models, (free) public APIs, and
image processing modules. For each of these task queries, we provide
automatically generated plans using this realistic toolset. We further provide
a high-quality subset of 1,565 task plans that are human-verified and correctly
executable. With m&m's, we evaluate 10 popular LLMs with 2 planning strategies
(multi-step vs. step-by-step planning), 2 plan formats (JSON vs. code), and 3
types of feedback (parsing/verification/execution). Finally, we summarize
takeaways from our extensive experiments. Our dataset and code are available on
HuggingFace (https://huggingface.co/datasets/zixianma/mnms) and Github
(https://github.com/RAIVNLab/mnms).</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.10482v2' target='_blank'>Can a GPT4-Powered AI Agent Be a Good Enough Performance Attribution
  Analyst?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Bruno de Melo, Jamiel Sheikh</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-15 17:12:57</h6>
<p class='card-text'>Performance attribution analysis, defined as the process of explaining the
drivers of the excess performance of an investment portfolio against a
benchmark, stands as a significant feature of portfolio management and plays a
crucial role in the investment decision-making process, particularly within the
fund management industry. Rooted in a solid financial and mathematical
framework, the importance and methodologies of this analytical technique are
extensively documented across numerous academic research papers and books. The
integration of large language models (LLMs) and AI agents marks a
groundbreaking development in this field. These agents are designed to automate
and enhance the performance attribution analysis by accurately calculating and
analyzing portfolio performances against benchmarks. In this study, we
introduce the application of an AI Agent for a variety of essential performance
attribution tasks, including the analysis of performance drivers and utilizing
LLMs as calculation engine for multi-level attribution analysis and
question-answering (QA) tasks. Leveraging advanced prompt engineering
techniques such as Chain-of-Thought (CoT) and Plan and Solve (PS), and
employing a standard agent framework from LangChain, the research achieves
promising results: it achieves accuracy rates exceeding 93% in analyzing
performance drivers, attains 100% in multi-level attribution calculations, and
surpasses 84% accuracy in QA exercises that simulate official examination
standards. These findings affirm the impactful role of AI agents, prompt
engineering and evaluation in advancing portfolio management processes,
highlighting a significant development in the practical application and
evaluation of Generative AI technologies within the domain.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.09631v1' target='_blank'>3D-VLA: A 3D Vision-Language-Action Generative World Model</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Haoyu Zhen, Xiaowen Qiu, Peihao Chen, Jincheng Yang, Xin Yan, Yilun Du, Yining Hong, Chuang Gan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-14 17:58:41</h6>
<p class='card-text'>Recent vision-language-action (VLA) models rely on 2D inputs, lacking
integration with the broader realm of the 3D physical world. Furthermore, they
perform action prediction by learning a direct mapping from perception to
action, neglecting the vast dynamics of the world and the relations between
actions and dynamics. In contrast, human beings are endowed with world models
that depict imagination about future scenarios to plan actions accordingly. To
this end, we propose 3D-VLA by introducing a new family of embodied foundation
models that seamlessly link 3D perception, reasoning, and action through a
generative world model. Specifically, 3D-VLA is built on top of a 3D-based
large language model (LLM), and a set of interaction tokens is introduced to
engage with the embodied environment. Furthermore, to inject generation
abilities into the model, we train a series of embodied diffusion models and
align them into the LLM for predicting the goal images and point clouds. To
train our 3D-VLA, we curate a large-scale 3D embodied instruction dataset by
extracting vast 3D-related information from existing robotics datasets. Our
experiments on held-in datasets demonstrate that 3D-VLA significantly improves
the reasoning, multimodal generation, and planning capabilities in embodied
environments, showcasing its potential in real-world applications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.09308v2' target='_blank'>Enabling Waypoint Generation for Collaborative Robots using LLMs and
  Mixed Reality</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Cathy Mengying Fang, Krzysztof Zieliński, Pattie Maes, Joe Paradiso, Bruce Blumberg, Mikkel Baun Kjærgaard</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-14 11:59:07</h6>
<p class='card-text'>Programming a robotic is a complex task, as it demands the user to have a
good command of specific programming languages and awareness of the robot's
physical constraints. We propose a framework that simplifies robot deployment
by allowing direct communication using natural language. It uses large language
models (LLM) for prompt processing, workspace understanding, and waypoint
generation. It also employs Augmented Reality (AR) to provide visual feedback
of the planned outcome. We showcase the effectiveness of our framework with a
simple pick-and-place task, which we implement on a real robot. Moreover, we
present an early concept of expressive robot behavior and skill generation that
can be used to communicate with the user and learn new skills (e.g., object
grasping).</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.09142v2' target='_blank'>USimAgent: Large Language Models for Simulating Search Users</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Erhan Zhang, Xingzhu Wang, Peiyuan Gong, Yankai Lin, Jiaxin Mao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-14 07:40:54</h6>
<p class='card-text'>Due to the advantages in the cost-efficiency and reproducibility, user
simulation has become a promising solution to the user-centric evaluation of
information retrieval systems. Nonetheless, accurately simulating user search
behaviors has long been a challenge, because users' actions in search are
highly complex and driven by intricate cognitive processes such as learning,
reasoning, and planning. Recently, Large Language Models (LLMs) have
demonstrated remarked potential in simulating human-level intelligence and have
been used in building autonomous agents for various tasks. However, the
potential of using LLMs in simulating search behaviors has not yet been fully
explored. In this paper, we introduce a LLM-based user search behavior
simulator, USimAgent. The proposed simulator can simulate users' querying,
clicking, and stopping behaviors during search, and thus, is capable of
generating complete search sessions for specific search tasks. Empirical
investigation on a real user behavior dataset shows that the proposed simulator
outperforms existing methods in query generation and is comparable to
traditional methods in predicting user clicks and stopping behaviors. These
results not only validate the effectiveness of using LLMs for user simulation
but also shed light on the development of a more robust and generic user
simulators. The code and data are accessible at
https://github.com/Meow-E/USimAgent.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.09059v2' target='_blank'>LAMP: A Language Model on the Map</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Pasquale Balsebre, Weiming Huang, Gao Cong</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-14 02:56:38</h6>
<p class='card-text'>Large Language Models (LLMs) are poised to play an increasingly important
role in our lives, providing assistance across a wide array of tasks. In the
geospatial domain, LLMs have demonstrated the ability to answer generic
questions, such as identifying a country's capital; nonetheless, their utility
is hindered when it comes to answering fine-grained questions about specific
places, such as grocery stores or restaurants, which constitute essential
aspects of people's everyday lives. This is mainly because the places in our
cities haven't been systematically fed into LLMs, so as to understand and
memorize them. This study introduces a novel framework for fine-tuning a
pre-trained model on city-specific data, to enable it to provide accurate
recommendations, while minimizing hallucinations. We share our model, LAMP, and
the data used to train it. We conduct experiments to analyze its ability to
correctly retrieving spatial objects, and compare it to well-known open- and
closed- source language models, such as GPT-4. Finally, we explore its emerging
capabilities through a case study on day planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.09740v1' target='_blank'>Teaching Machines to Code: Smart Contract Translation with LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Rabimba Karanjai, Lei Xu, Weidong Shi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-13 18:55:20</h6>
<p class='card-text'>The advent of large language models (LLMs) has marked a significant milestone
in the realm of artificial intelligence, with their capabilities often matching
or surpassing human expertise in various domains. Among these achievements,
their adeptness in translation tasks stands out, closely mimicking the
intricate and preliminary processes undertaken by human translators to ensure
the fidelity and quality of the translated content. Despite the advancements in
utilizing LLMs for translating programming code across different languages, the
domain of smart contract translation, particularly into languages not
previously encountered by the LLM, remains largely unexplored. In our research,
we present a pioneering approach, SolMover, which harnesses the synergy of two
distinct LLMs within a unified framework. This framework is designed to grasp
coding principles and apply this understanding to the translation of code into
an unfamiliar language. Our study delves into the capacity of LLMs to mimic
human learning processes, offering an in-depth evaluation of our methodology
for converting smart contracts written in Solidity to Move, a language with
limited resources. The framework employs one LLM to decipher coding conventions
for the new language, creating a blueprint for the second LLM, which, lacking
planning abilities, possesses coding expertise. The empirical evidence from our
experiments suggests that SolMover substantially enhances performance compared
to gpt-3.5-turbo-1106, and achieves superior results over competitors such as
Palm2 and Mixtral-8x7B-Instruct. Additionally, our analysis highlights the
efficacy of our bug mitigation strategy in elevating code quality across all
models, even outside the SolMover framework.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.08282v2' target='_blank'>Hierarchical Auto-Organizing System for Open-Ended Multi-Agent
  Navigation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhonghan Zhao, Kewei Chen, Dongxu Guo, Wenhao Chai, Tian Ye, Yanting Zhang, Gaoang Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-13 06:22:17</h6>
<p class='card-text'>Due to the dynamic and unpredictable open-world setting, navigating complex
environments in Minecraft poses significant challenges for multi-agent systems.
Agents must interact with the environment and coordinate their actions with
other agents to achieve common objectives. However, traditional approaches
often struggle to efficiently manage inter-agent communication and task
distribution, crucial for effective multi-agent navigation. Furthermore,
processing and integrating multi-modal information (such as visual, textual,
and auditory data) is essential for agents to comprehend their goals and
navigate the environment successfully and fully. To address this issue, we
design the HAS framework to auto-organize groups of LLM-based agents to
complete navigation tasks. In our approach, we devise a hierarchical
auto-organizing navigation system, which is characterized by 1) a hierarchical
system for multi-agent organization, ensuring centralized planning and
decentralized execution; 2) an auto-organizing and intra-communication
mechanism, enabling dynamic group adjustment under subtasks; 3) a multi-modal
information platform, facilitating multi-modal perception to perform the three
navigation tasks with one system. To assess organizational behavior, we design
a series of navigation tasks in the Minecraft environment, which includes
searching and exploring. We aim to develop embodied organizations that push the
boundaries of embodied AI, moving it towards a more human-like organizational
structure.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.08251v4' target='_blank'>Emergence of Social Norms in Generative Agent Societies: Principles and
  Architecture</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Siyue Ren, Zhiyao Cui, Ruiqi Song, Zhen Wang, Shuyue Hu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-13 05:08:10</h6>
<p class='card-text'>Social norms play a crucial role in guiding agents towards understanding and
adhering to standards of behavior, thus reducing social conflicts within
multi-agent systems (MASs). However, current LLM-based (or generative) MASs
lack the capability to be normative. In this paper, we propose a novel
architecture, named CRSEC, to empower the emergence of social norms within
generative MASs. Our architecture consists of four modules: Creation &
Representation, Spreading, Evaluation, and Compliance. This addresses several
important aspects of the emergent processes all in one: (i) where social norms
come from, (ii) how they are formally represented, (iii) how they spread
through agents' communications and observations, (iv) how they are examined
with a sanity check and synthesized in the long term, and (v) how they are
incorporated into agents' planning and actions. Our experiments deployed in the
Smallville sandbox game environment demonstrate the capability of our
architecture to establish social norms and reduce social conflicts within
generative MASs. The positive outcomes of our human evaluation, conducted with
30 evaluators, further affirm the effectiveness of our approach. Our project
can be accessed via the following link: https://github.com/sxswz213/CRSEC.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.08228v3' target='_blank'>Empowering Robot Path Planning with Large Language Models: osmAG Map
  Topology & Hierarchy Comprehension with LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Fujing Xie, Sören Schwertfeger</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-13 04:11:41</h6>
<p class='card-text'>Large Language Models (LLMs) have demonstrated great potential in robotic
applications by providing essential general knowledge. Mobile robots rely on
map comprehension for tasks like localization and navigation. In this paper, we
explore enabling LLMs to comprehend the topology and hierarchy of Area Graph, a
text-based hierarchical, topometric semantic map representation utilizing
polygons to demark areas such as rooms or buildings. Our experiments
demonstrate that with the right map representation, LLMs can effectively
comprehend Area Graph's topology and hierarchy. After straightforward
fine-tuning, the LLaMA2 models exceeded ChatGPT-3.5 in mastering these aspects.
Our dataset, dataset generation code, fine-tuned LoRA adapters can be accessed
at https://github.com/xiefujing/LLM-osmAG-Comprehension.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.06294v3' target='_blank'>ArgMed-Agents: Explainable Clinical Decision Reasoning with LLM
  Disscusion via Argumentation Schemes</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shengxin Hong, Liang Xiao, Xin Zhang, Jianxia Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-10 19:47:00</h6>
<p class='card-text'>There are two main barriers to using large language models (LLMs) in clinical
reasoning. Firstly, while LLMs exhibit significant promise in Natural Language
Processing (NLP) tasks, their performance in complex reasoning and planning
falls short of expectations. Secondly, LLMs use uninterpretable methods to make
clinical decisions that are fundamentally different from the clinician's
cognitive processes. This leads to user distrust. In this paper, we present a
multi-agent framework called ArgMed-Agents, which aims to enable LLM-based
agents to make explainable clinical decision reasoning through interaction.
ArgMed-Agents performs self-argumentation iterations via Argumentation Scheme
for Clinical Discussion (a reasoning mechanism for modeling cognitive processes
in clinical reasoning), and then constructs the argumentation process as a
directed graph representing conflicting relationships. Ultimately, use symbolic
solver to identify a series of rational and coherent arguments to support
decision. We construct a formal model of ArgMed-Agents and present conjectures
for theoretical guarantees. ArgMed-Agents enables LLMs to mimic the process of
clinical argumentative reasoning by generating explanations of reasoning in a
self-directed manner. The setup experiments show that ArgMed-Agents not only
improves accuracy in complex clinical decision reasoning problems compared to
other prompt methods, but more importantly, it provides users with decision
explanations that increase their confidence.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.06070v1' target='_blank'>Reframe Anything: LLM Agent for Open World Video Reframing</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiawang Cao, Yongliang Wu, Weiheng Chi, Wenbo Zhu, Ziyue Su, Jay Wu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-10 03:29:56</h6>
<p class='card-text'>The proliferation of mobile devices and social media has revolutionized
content dissemination, with short-form video becoming increasingly prevalent.
This shift has introduced the challenge of video reframing to fit various
screen aspect ratios, a process that highlights the most compelling parts of a
video. Traditionally, video reframing is a manual, time-consuming task
requiring professional expertise, which incurs high production costs. A
potential solution is to adopt some machine learning models, such as video
salient object detection, to automate the process. However, these methods often
lack generalizability due to their reliance on specific training data. The
advent of powerful large language models (LLMs) open new avenues for AI
capabilities. Building on this, we introduce Reframe Any Video Agent (RAVA), a
LLM-based agent that leverages visual foundation models and human instructions
to restructure visual content for video reframing. RAVA operates in three
stages: perception, where it interprets user instructions and video content;
planning, where it determines aspect ratios and reframing strategies; and
execution, where it invokes the editing tools to produce the final video. Our
experiments validate the effectiveness of RAVA in video salient object
detection and real-world reframing tasks, demonstrating its potential as a tool
for AI-powered video editing.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.05766v3' target='_blank'>FLAP: Flow-Adhering Planning with Constrained Decoding in LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shamik Roy, Sailik Sengupta, Daniele Bonadiman, Saab Mansour, Arshit Gupta</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-09 02:27:45</h6>
<p class='card-text'>Planning is a crucial task for agents in task oriented dialogs (TODs). Human
agents typically resolve user issues by following predefined workflows,
decomposing workflow steps into actionable items, and performing actions by
executing APIs in order; all of which require reasoning and planning. With the
recent advances in LLMs, there have been increasing attempts to use them for
task planning and API usage. However, the faithfulness of the plans to
predefined workflows and API dependencies, is not guaranteed with LLMs.
Moreover, workflows in real life are often custom-defined and prone to changes;
hence, adaptation is desirable. To study this, we propose the problem of
faithful planning in TODs that needs to resolve user intents by following
predefined flows and preserving API dependencies. To solve this problem, we
propose FLAP, a Flow-Adhering Planning algorithm based on constrained decoding
with lookahead heuristic for LLMs. Our algorithm alleviates the need for
finetuning LLMs using domain specific (plan/dependency) data, enables quick
adaptation to predefined flows, and outperforms other decoding and
prompting-based baselines. Further, our algorithm empowers smaller LLMs (7B) to
perform at par larger LLMs (30B-40B).</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.05701v2' target='_blank'>Are Large Language Models Aligned with People's Social Intuitions for
  Human-Robot Interactions?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lennart Wachowiak, Andrew Coles, Oya Celiktutan, Gerard Canal</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-08 22:23:23</h6>
<p class='card-text'>Large language models (LLMs) are increasingly used in robotics, especially
for high-level action planning. Meanwhile, many robotics applications involve
human supervisors or collaborators. Hence, it is crucial for LLMs to generate
socially acceptable actions that align with people's preferences and values. In
this work, we test whether LLMs capture people's intuitions about behavior
judgments and communication preferences in human-robot interaction (HRI)
scenarios. For evaluation, we reproduce three HRI user studies, comparing the
output of LLMs with that of real participants. We find that GPT-4 strongly
outperforms other models, generating answers that correlate strongly with
users' answers in two studies $\unicode{x2014}$ the first study dealing with
selecting the most appropriate communicative act for a robot in various
situations ($r_s$ = 0.82), and the second with judging the desirability,
intentionality, and surprisingness of behavior ($r_s$ = 0.83). However, for the
last study, testing whether people judge the behavior of robots and humans
differently, no model achieves strong correlations. Moreover, we show that
vision models fail to capture the essence of video stimuli and that LLMs tend
to rate different communicative acts and behavior desirability higher than
people.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.05680v2' target='_blank'>How Well Do Multi-modal LLMs Interpret CT Scans? An Auto-Evaluation
  Framework for Analyses</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Qingqing Zhu, Benjamin Hou, Tejas S. Mathai, Pritam Mukherjee, Qiao Jin, Xiuying Chen, Zhizheng Wang, Ruida Cheng, Ronald M. Summers, Zhiyong Lu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-08 21:16:28</h6>
<p class='card-text'>Automatically interpreting CT scans can ease the workload of radiologists.
However, this is challenging mainly due to the scarcity of adequate datasets
and reference standards for evaluation. This study aims to bridge this gap by
introducing a novel evaluation framework, named ``GPTRadScore''. This framework
assesses the capabilities of multi-modal LLMs, such as GPT-4 with Vision
(GPT-4V), Gemini Pro Vision, LLaVA-Med, and RadFM, in generating descriptions
for prospectively-identified findings. By employing a decomposition technique
based on GPT-4, GPTRadScore compares these generated descriptions with
gold-standard report sentences, analyzing their accuracy in terms of body part,
location, and type of finding. Evaluations demonstrated a high correlation with
clinician assessments and highlighted its potential over traditional metrics,
such as BLEU, METEOR, and ROUGE. Furthermore, to contribute to future studies,
we plan to release a benchmark dataset annotated by clinicians. Using
GPTRadScore, we found that while GPT-4V and Gemini Pro Vision fare better,
their performance revealed significant areas for improvement, primarily due to
limitations in the dataset used for training these models. To demonstrate this
potential, RadFM was fine-tuned and it resulted in significant accuracy
improvements: location accuracy rose from 3.41\% to 12.8\%, body part accuracy
from 29.12\% to 53\%, and type accuracy from 9.24\% to 30\%, thereby validating
our hypothesis.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.05468v1' target='_blank'>Will GPT-4 Run DOOM?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Adrian de Wynter</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-08 17:30:41</h6>
<p class='card-text'>We show that GPT-4's reasoning and planning capabilities extend to the 1993
first-person shooter Doom. This large language model (LLM) is able to run and
play the game with only a few instructions, plus a textual
description--generated by the model itself from screenshots--about the state of
the game being observed. We find that GPT-4 can play the game to a passable
degree: it is able to manipulate doors, combat enemies, and perform pathing.
More complex prompting strategies involving multiple model calls provide better
results. While further work is required to enable the LLM to play the game as
well as its classical, reinforcement learning-based counterparts, we note that
GPT-4 required no training, leaning instead on its own reasoning and
observational capabilities. We hope our work pushes the boundaries on
intelligent, LLM-based agents in video games. We conclude by discussing the
ethical implications of our work.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.04121v2' target='_blank'>Can Large Language Models Reason and Plan?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Subbarao Kambhampati</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-07 00:36:32</h6>
<p class='card-text'>While humans sometimes do show the capability of correcting their own
erroneous guesses with self-critiquing, there seems to be no basis for that
assumption in the case of LLMs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.03167v3' target='_blank'>PARADISE: Evaluating Implicit Planning Skills of Language Models with
  Procedural Warnings and Tips Dataset</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Arda Uzunoglu, Abdalfatah Rashid Safa, Gözde Gül Şahin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-05 18:01:59</h6>
<p class='card-text'>Recently, there has been growing interest within the community regarding
whether large language models are capable of planning or executing plans.
However, most prior studies use LLMs to generate high-level plans for
simplified scenarios lacking linguistic complexity and domain diversity,
limiting analysis of their planning abilities. These setups constrain
evaluation methods (e.g., predefined action space), architectural choices
(e.g., only generative models), and overlook the linguistic nuances essential
for realistic analysis. To tackle this, we present PARADISE, an abductive
reasoning task using Q\&A format on practical procedural text sourced from
wikiHow. It involves warning and tip inference tasks directly associated with
goals, excluding intermediary steps, with the aim of testing the ability of the
models to infer implicit knowledge of the plan solely from the given goal. Our
experiments, utilizing fine-tuned language models and zero-shot prompting,
reveal the effectiveness of task-specific small models over large language
models in most scenarios. Despite advancements, all models fall short of human
performance. Notably, our analysis uncovers intriguing insights, such as
variations in model behavior with dropped keywords, struggles of BERT-family
and GPT-4 with physical and abstract goals, and the proposed tasks offering
valuable prior knowledge for other unseen procedural tasks. The PARADISE
dataset and associated resources are publicly available for further research
exploration with https://github.com/GGLAB-KU/paradise.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.03101v3' target='_blank'>KnowAgent: Knowledge-Augmented Planning for LLM-Based Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuqi Zhu, Shuofei Qiao, Yixin Ou, Shumin Deng, Shiwei Lyu, Yue Shen, Lei Liang, Jinjie Gu, Huajun Chen, Ningyu Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-05 16:39:12</h6>
<p class='card-text'>Large Language Models (LLMs) have demonstrated great potential in complex
reasoning tasks, yet they fall short when tackling more sophisticated
challenges, especially when interacting with environments through generating
executable actions. This inadequacy primarily stems from the lack of built-in
action knowledge in language agents, which fails to effectively guide the
planning trajectories during task solving and results in planning
hallucination. To address this issue, we introduce KnowAgent, a novel approach
designed to enhance the planning capabilities of LLMs by incorporating explicit
action knowledge. Specifically, KnowAgent employs an action knowledge base and
a knowledgeable self-learning strategy to constrain the action path during
planning, enabling more reasonable trajectory synthesis, and thereby enhancing
the planning performance of language agents. Experimental results on HotpotQA
and ALFWorld based on various backbone models demonstrate that KnowAgent can
achieve comparable or superior performance to existing baselines. Further
analysis indicates the effectiveness of KnowAgent in terms of planning
hallucinations mitigation. Code is available in
https://github.com/zjunlp/KnowAgent.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.01599v1' target='_blank'>SCHEMA: State CHangEs MAtter for Procedure Planning in Instructional
  Videos</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yulei Niu, Wenliang Guo, Long Chen, Xudong Lin, Shih-Fu Chang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-03 19:53:06</h6>
<p class='card-text'>We study the problem of procedure planning in instructional videos, which
aims to make a goal-oriented sequence of action steps given partial visual
state observations. The motivation of this problem is to learn a structured and
plannable state and action space. Recent works succeeded in sequence modeling
of steps with only sequence-level annotations accessible during training, which
overlooked the roles of states in the procedures. In this work, we point out
that State CHangEs MAtter (SCHEMA) for procedure planning in instructional
videos. We aim to establish a more structured state space by investigating the
causal relations between steps and states in procedures. Specifically, we
explicitly represent each step as state changes and track the state changes in
procedures. For step representation, we leveraged the commonsense knowledge in
large language models (LLMs) to describe the state changes of steps via our
designed chain-of-thought prompting. For state change tracking, we align visual
state observations with language state descriptions via cross-modal contrastive
learning, and explicitly model the intermediate states of the procedure using
LLM-generated state descriptions. Experiments on CrossTask, COIN, and NIV
benchmark datasets demonstrate that our proposed SCHEMA model achieves
state-of-the-art performance and obtains explainable visualizations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.01271v1' target='_blank'>Employing LLMs for Incident Response Planning and Review</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sam Hays, Jules White</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-02 17:23:41</h6>
<p class='card-text'>Incident Response Planning (IRP) is essential for effective cybersecurity
management, requiring detailed documentation (or playbooks) to guide security
personnel during incidents. Yet, creating comprehensive IRPs is often hindered
by challenges such as complex systems, high turnover rates, and legacy
technologies lacking documentation. This paper argues that, despite these
obstacles, the development, review, and refinement of IRPs can be significantly
enhanced through the utilization of Large Language Models (LLMs) like ChatGPT.
By leveraging LLMs for tasks such as drafting initial plans, suggesting best
practices, and identifying documentation gaps, organizations can overcome
resource constraints and improve their readiness for cybersecurity incidents.
We discuss the potential of LLMs to streamline IRP processes, while also
considering the limitations and the need for human oversight in ensuring the
accuracy and relevance of generated content. Our findings contribute to the
cybersecurity field by demonstrating a novel approach to enhancing IRP with AI
technologies, offering practical insights for organizations seeking to bolster
their incident response capabilities.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.01248v1' target='_blank'>SceneCraft: An LLM Agent for Synthesizing 3D Scene as Blender Code</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ziniu Hu, Ahmet Iscen, Aashi Jain, Thomas Kipf, Yisong Yue, David A. Ross, Cordelia Schmid, Alireza Fathi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-02 16:16:26</h6>
<p class='card-text'>This paper introduces SceneCraft, a Large Language Model (LLM) Agent
converting text descriptions into Blender-executable Python scripts which
render complex scenes with up to a hundred 3D assets. This process requires
complex spatial planning and arrangement. We tackle these challenges through a
combination of advanced abstraction, strategic planning, and library learning.
SceneCraft first models a scene graph as a blueprint, detailing the spatial
relationships among assets in the scene. SceneCraft then writes Python scripts
based on this graph, translating relationships into numerical constraints for
asset layout. Next, SceneCraft leverages the perceptual strengths of
vision-language foundation models like GPT-V to analyze rendered images and
iteratively refine the scene. On top of this process, SceneCraft features a
library learning mechanism that compiles common script functions into a
reusable library, facilitating continuous self-improvement without expensive
LLM parameter tuning. Our evaluation demonstrates that SceneCraft surpasses
existing LLM-based agents in rendering complex scenes, as shown by its
adherence to constraints and favorable human assessments. We also showcase the
broader application potential of SceneCraft by reconstructing detailed 3D
scenes from the Sintel movie and guiding a video generative model with
generated scenes as intermediary control signal.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.00690v1' target='_blank'>Playing NetHack with LLMs: Potential & Limitations as Zero-Shot Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Dominik Jeurissen, Diego Perez-Liebana, Jeremy Gow, Duygu Cakmak, James Kwan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-03-01 17:22:16</h6>
<p class='card-text'>Large Language Models (LLMs) have shown great success as high-level planners
for zero-shot game-playing agents. However, these agents are primarily
evaluated on Minecraft, where long-term planning is relatively straightforward.
In contrast, agents tested in dynamic robot environments face limitations due
to simplistic environments with only a few objects and interactions. To fill
this gap in the literature, we present NetPlay, the first LLM-powered zero-shot
agent for the challenging roguelike NetHack. NetHack is a particularly
challenging environment due to its diverse set of items and monsters, complex
interactions, and many ways to die.
  NetPlay uses an architecture designed for dynamic robot environments,
modified for NetHack. Like previous approaches, it prompts the LLM to choose
from predefined skills and tracks past interactions to enhance decision-making.
Given NetHack's unpredictable nature, NetPlay detects important game events to
interrupt running skills, enabling it to react to unforeseen circumstances.
While NetPlay demonstrates considerable flexibility and proficiency in
interacting with NetHack's mechanics, it struggles with ambiguous task
descriptions and a lack of explicit feedback. Our findings demonstrate that
NetPlay performs best with detailed context information, indicating the
necessity for dynamic methods in supplying context information for complex
games such as NetHack.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.19348v2' target='_blank'>Deep Learning for Cross-Domain Data Fusion in Urban Computing: Taxonomy,
  Advances, and Outlook</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xingchen Zou, Yibo Yan, Xixuan Hao, Yuehong Hu, Haomin Wen, Erdong Liu, Junbo Zhang, Yong Li, Tianrui Li, Yu Zheng, Yuxuan Liang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-29 16:56:23</h6>
<p class='card-text'>As cities continue to burgeon, Urban Computing emerges as a pivotal
discipline for sustainable development by harnessing the power of cross-domain
data fusion from diverse sources (e.g., geographical, traffic, social media,
and environmental data) and modalities (e.g., spatio-temporal, visual, and
textual modalities). Recently, we are witnessing a rising trend that utilizes
various deep-learning methods to facilitate cross-domain data fusion in smart
cities. To this end, we propose the first survey that systematically reviews
the latest advancements in deep learning-based data fusion methods tailored for
urban computing. Specifically, we first delve into data perspective to
comprehend the role of each modality and data source. Secondly, we classify the
methodology into four primary categories: feature-based, alignment-based,
contrast-based, and generation-based fusion methods. Thirdly, we further
categorize multi-modal urban applications into seven types: urban planning,
transportation, economy, public safety, society, environment, and energy.
Compared with previous surveys, we focus more on the synergy of deep learning
methods with urban computing applications. Furthermore, we shed light on the
interplay between Large Language Models (LLMs) and urban computing, postulating
future research directions that could revolutionize the field. We firmly
believe that the taxonomy, progress, and prospects delineated in our survey
stand poised to significantly enrich the research community. The summary of the
comprehensive and up-to-date paper list can be found at
https://github.com/yoshall/Awesome-Multimodal-Urban-Computing.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.19299v1' target='_blank'>RL-GPT: Integrating Reinforcement Learning and Code-as-policy</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shaoteng Liu, Haoqi Yuan, Minda Hu, Yanwei Li, Yukang Chen, Shu Liu, Zongqing Lu, Jiaya Jia</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-29 16:07:22</h6>
<p class='card-text'>Large Language Models (LLMs) have demonstrated proficiency in utilizing
various tools by coding, yet they face limitations in handling intricate logic
and precise control. In embodied tasks, high-level planning is amenable to
direct coding, while low-level actions often necessitate task-specific
refinement, such as Reinforcement Learning (RL). To seamlessly integrate both
modalities, we introduce a two-level hierarchical framework, RL-GPT, comprising
a slow agent and a fast agent. The slow agent analyzes actions suitable for
coding, while the fast agent executes coding tasks. This decomposition
effectively focuses each agent on specific tasks, proving highly efficient
within our pipeline. Our approach outperforms traditional RL methods and
existing GPT agents, demonstrating superior efficiency. In the Minecraft game,
it rapidly obtains diamonds within a single day on an RTX3090. Additionally, it
achieves SOTA performance across all designated MineDojo tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.00843v2' target='_blank'>Large Language Models are Learnable Planners for Long-Term
  Recommendation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wentao Shi, Xiangnan He, Yang Zhang, Chongming Gao, Xinyue Li, Jizhi Zhang, Qifan Wang, Fuli Feng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-29 13:49:56</h6>
<p class='card-text'>Planning for both immediate and long-term benefits becomes increasingly
important in recommendation. Existing methods apply Reinforcement Learning (RL)
to learn planning capacity by maximizing cumulative reward for long-term
recommendation. However, the scarcity of recommendation data presents
challenges such as instability and susceptibility to overfitting when training
RL models from scratch, resulting in sub-optimal performance. In this light, we
propose to leverage the remarkable planning capabilities over sparse data of
Large Language Models (LLMs) for long-term recommendation. The key to achieving
the target lies in formulating a guidance plan following principles of
enhancing long-term engagement and grounding the plan to effective and
executable actions in a personalized manner. To this end, we propose a Bi-level
Learnable LLM Planner framework, which consists of a set of LLM instances and
breaks down the learning process into macro-learning and micro-learning to
learn macro-level guidance and micro-level personalized recommendation
policies, respectively. Extensive experiments validate that the framework
facilitates the planning ability of LLMs for long-term recommendation. Our code
and data can be found at https://github.com/jizhi-zhang/BiLLP.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.19052v1' target='_blank'>Exploring the Efficacy of Large Language Models in Summarizing Mental
  Health Counseling Sessions: A Benchmark Study</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Prottay Kumar Adhikary, Aseem Srivastava, Shivani Kumar, Salam Michael Singh, Puneet Manuja, Jini K Gopinath, Vijay Krishnan, Swati Kedia, Koushik Sinha Deb, Tanmoy Chakraborty</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-29 11:29:47</h6>
<p class='card-text'>Comprehensive summaries of sessions enable an effective continuity in mental
health counseling, facilitating informed therapy planning. Yet, manual
summarization presents a significant challenge, diverting experts' attention
from the core counseling process. This study evaluates the effectiveness of
state-of-the-art Large Language Models (LLMs) in selectively summarizing
various components of therapy sessions through aspect-based summarization,
aiming to benchmark their performance. We introduce MentalCLOUDS, a
counseling-component guided summarization dataset consisting of 191 counseling
sessions with summaries focused on three distinct counseling components (aka
counseling aspects). Additionally, we assess the capabilities of 11
state-of-the-art LLMs in addressing the task of component-guided summarization
in counseling. The generated summaries are evaluated quantitatively using
standard summarization metrics and verified qualitatively by mental health
professionals. Our findings demonstrate the superior performance of
task-specific LLMs such as MentalLlama, Mistral, and MentalBART in terms of
standard quantitative metrics such as Rouge-1, Rouge-2, Rouge-L, and BERTScore
across all aspects of counseling components. Further, expert evaluation reveals
that Mistral supersedes both MentalLlama and MentalBART based on six parameters
-- affective attitude, burden, ethicality, coherence, opportunity costs, and
perceived effectiveness. However, these models share the same weakness by
demonstrating a potential for improvement in the opportunity costs and
perceived effectiveness metrics.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.17930v1' target='_blank'>Pragmatic Instruction Following and Goal Assistance via Cooperative
  Language-Guided Inverse Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tan Zhi-Xuan, Lance Ying, Vikash Mansinghka, Joshua B. Tenenbaum</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-27 23:06:53</h6>
<p class='card-text'>People often give instructions whose meaning is ambiguous without further
context, expecting that their actions or goals will disambiguate their
intentions. How can we build assistive agents that follow such instructions in
a flexible, context-sensitive manner? This paper introduces cooperative
language-guided inverse plan search (CLIPS), a Bayesian agent architecture for
pragmatic instruction following and goal assistance. Our agent assists a human
by modeling them as a cooperative planner who communicates joint plans to the
assistant, then performs multimodal Bayesian inference over the human's goal
from actions and language, using large language models (LLMs) to evaluate the
likelihood of an instruction given a hypothesized plan. Given this posterior,
our assistant acts to minimize expected goal achievement cost, enabling it to
pragmatically follow ambiguous instructions and provide effective assistance
even when uncertain about the goal. We evaluate these capabilities in two
cooperative planning domains (Doors, Keys & Gems and VirtualHome), finding that
CLIPS significantly outperforms GPT-4V, LLM-based literal instruction following
and unimodal inverse planning in both accuracy and helpfulness, while closely
matching the inferences and assistive judgments provided by human raters.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.17531v2' target='_blank'>Nissist: An Incident Mitigation Copilot based on Troubleshooting Guides</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kaikai An, Fangkai Yang, Junting Lu, Liqun Li, Zhixing Ren, Hao Huang, Lu Wang, Pu Zhao, Yu Kang, Hua Ding, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-27 14:14:23</h6>
<p class='card-text'>Effective incident management is pivotal for the smooth operation of
enterprises-level cloud services. In order to expedite incident mitigation,
service teams compile troubleshooting knowledge into Troubleshooting Guides
(TSGs) accessible to on-call engineers (OCEs). While automated pipelines are
enabled to resolve the most frequent and easy incidents, there still exist
complex incidents that require OCEs' intervention. However, TSGs are often
unstructured and incomplete, which requires manual interpretation by OCEs,
leading to on-call fatigue and decreased productivity, especially among
new-hire OCEs. In this work, we propose Nissist which leverages TSGs and
incident mitigation histories to provide proactive suggestions, reducing human
intervention. Leveraging Large Language Models (LLM), Nissist extracts insights
from unstructured TSGs and historical incident mitigation discussions, forming
a comprehensive knowledge base. Its multi-agent system design enhances
proficiency in precisely discerning user queries, retrieving relevant
information, and delivering systematic plans consecutively. Through our user
case and experiment, we demonstrate that Nissist significant reduce Time to
Mitigate (TTM) in incident mitigation, alleviating operational burdens on OCEs
and improving service reliability. Our demo is available at
https://aka.ms/nissist_demo.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.17453v5' target='_blank'>DS-Agent: Automated Data Science by Empowering Large Language Models
  with Case-Based Reasoning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Siyuan Guo, Cheng Deng, Ying Wen, Hechang Chen, Yi Chang, Jun Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-27 12:26:07</h6>
<p class='card-text'>In this work, we investigate the potential of large language models (LLMs)
based agents to automate data science tasks, with the goal of comprehending
task requirements, then building and training the best-fit machine learning
models. Despite their widespread success, existing LLM agents are hindered by
generating unreasonable experiment plans within this scenario. To this end, we
present DS-Agent, a novel automatic framework that harnesses LLM agent and
case-based reasoning (CBR). In the development stage, DS-Agent follows the CBR
framework to structure an automatic iteration pipeline, which can flexibly
capitalize on the expert knowledge from Kaggle, and facilitate consistent
performance improvement through the feedback mechanism. Moreover, DS-Agent
implements a low-resource deployment stage with a simplified CBR paradigm to
adapt past successful solutions from the development stage for direct code
generation, significantly reducing the demand on foundational capabilities of
LLMs. Empirically, DS-Agent with GPT-4 achieves 100\% success rate in the
development stage, while attaining 36\% improvement on average one pass rate
across alternative LLMs in the deployment stage. In both stages, DS-Agent
achieves the best rank in performance, costing \$1.60 and \$0.13 per run with
GPT-4, respectively. Our data and code are open-sourced at
https://github.com/guosyjlu/DS-Agent.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.17161v1' target='_blank'>Large Language Model for Participatory Urban Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhilun Zhou, Yuming Lin, Depeng Jin, Yong Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-27 02:47:50</h6>
<p class='card-text'>Participatory urban planning is the mainstream of modern urban planning that
involves the active engagement of residents. However, the traditional
participatory paradigm requires experienced planning experts and is often
time-consuming and costly. Fortunately, the emerging Large Language Models
(LLMs) have shown considerable ability to simulate human-like agents, which can
be used to emulate the participatory process easily. In this work, we introduce
an LLM-based multi-agent collaboration framework for participatory urban
planning, which can generate land-use plans for urban regions considering the
diverse needs of residents. Specifically, we construct LLM agents to simulate a
planner and thousands of residents with diverse profiles and backgrounds. We
first ask the planner to carry out an initial land-use plan. To deal with the
different facilities needs of residents, we initiate a discussion among the
residents in each community about the plan, where residents provide feedback
based on their profiles. Furthermore, to improve the efficiency of discussion,
we adopt a fishbowl discussion mechanism, where part of the residents discuss
and the rest of them act as listeners in each round. Finally, we let the
planner modify the plan based on residents' feedback. We deploy our method on
two real-world regions in Beijing. Experiments show that our method achieves
state-of-the-art performance in residents satisfaction and inclusion metrics,
and also outperforms human experts in terms of service accessibility and
ecology metrics.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.17119v1' target='_blank'>Creating Suspenseful Stories: Iterative Planning with Large Language
  Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kaige Xie, Mark Riedl</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-27 01:25:52</h6>
<p class='card-text'>Automated story generation has been one of the long-standing challenges in
NLP. Among all dimensions of stories, suspense is very common in human-written
stories but relatively under-explored in AI-generated stories. While recent
advances in large language models (LLMs) have greatly promoted language
generation in general, state-of-the-art LLMs are still unreliable when it comes
to suspenseful story generation. We propose a novel iterative-prompting-based
planning method that is grounded in two theoretical foundations of story
suspense from cognitive psychology and narratology. This theory-grounded method
works in a fully zero-shot manner and does not rely on any supervised story
corpora. To the best of our knowledge, this paper is the first attempt at
suspenseful story generation with LLMs. Extensive human evaluations of the
generated suspenseful stories demonstrate the effectiveness of our method.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.16499v1' target='_blank'>LLMArena: Assessing Capabilities of Large Language Models in Dynamic
  Multi-Agent Environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Junzhe Chen, Xuming Hu, Shuodi Liu, Shiyu Huang, Wei-Wei Tu, Zhaofeng He, Lijie Wen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-26 11:31:48</h6>
<p class='card-text'>Recent advancements in large language models (LLMs) have revealed their
potential for achieving autonomous agents possessing human-level intelligence.
However, existing benchmarks for evaluating LLM Agents either use static
datasets, potentially leading to data leakage or focus only on single-agent
scenarios, overlooking the complexities of multi-agent interactions. There is a
lack of a benchmark that evaluates the diverse capabilities of LLM agents in
multi-agent, dynamic environments. To this end, we introduce LLMArena, a novel
and easily extensible framework for evaluating the diverse capabilities of LLM
in multi-agent dynamic environments. LLMArena encompasses seven distinct gaming
environments, employing Trueskill scoring to assess crucial abilities in LLM
agents, including spatial reasoning, strategic planning, numerical reasoning,
risk assessment, communication, opponent modeling, and team collaboration. We
conduct an extensive experiment and human evaluation among different sizes and
types of LLMs, showing that LLMs still have a significant journey ahead in
their development towards becoming fully autonomous agents, especially in
opponent modeling and team collaboration. We hope LLMArena could guide future
research towards enhancing these capabilities in LLMs, ultimately leading to
more sophisticated and practical applications in dynamic, multi-agent settings.
The code and data will be available.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.16181v1' target='_blank'>How Can LLM Guide RL? A Value-Based Approach</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shenao Zhang, Sirui Zheng, Shuqi Ke, Zhihan Liu, Wanxin Jin, Jianbo Yuan, Yingxiang Yang, Hongxia Yang, Zhaoran Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-25 20:07:13</h6>
<p class='card-text'>Reinforcement learning (RL) has become the de facto standard practice for
sequential decision-making problems by improving future acting policies with
feedback. However, RL algorithms may require extensive trial-and-error
interactions to collect useful feedback for improvement. On the other hand,
recent developments in large language models (LLMs) have showcased impressive
capabilities in language understanding and generation, yet they fall short in
exploration and self-improvement capabilities for planning tasks, lacking the
ability to autonomously refine their responses based on feedback. Therefore, in
this paper, we study how the policy prior provided by the LLM can enhance the
sample efficiency of RL algorithms. Specifically, we develop an algorithm named
LINVIT that incorporates LLM guidance as a regularization factor in value-based
RL, leading to significant reductions in the amount of data needed for
learning, particularly when the difference between the ideal policy and the
LLM-informed policy is small, which suggests that the initial policy is close
to optimal, reducing the need for further exploration. Additionally, we present
a practical algorithm SLINVIT that simplifies the construction of the value
function and employs subgoals to reduce the search complexity. Our experiments
across three interactive environments ALFWorld, InterCode, and BlocksWorld
demonstrate that our method achieves state-of-the-art success rates and also
surpasses previous RL and LLM approaches in terms of sample efficiency. Our
code is available at https://github.com/agentification/Language-Integrated-VI.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.16142v1' target='_blank'>From Text to Transformation: A Comprehensive Review of Large Language
  Models' Versatility</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Pravneet Kaur, Gautam Siddharth Kashyap, Ankit Kumar, Md Tabrez Nafis, Sandeep Kumar, Vikrant Shokeen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-25 16:47:59</h6>
<p class='card-text'>This groundbreaking study explores the expanse of Large Language Models
(LLMs), such as Generative Pre-Trained Transformer (GPT) and Bidirectional
Encoder Representations from Transformers (BERT) across varied domains ranging
from technology, finance, healthcare to education. Despite their established
prowess in Natural Language Processing (NLP), these LLMs have not been
systematically examined for their impact on domains such as fitness, and
holistic well-being, urban planning, climate modelling as well as disaster
management. This review paper, in addition to furnishing a comprehensive
analysis of the vast expanse and extent of LLMs' utility in diverse domains,
recognizes the research gaps and realms where the potential of LLMs is yet to
be harnessed. This study uncovers innovative ways in which LLMs can leave a
mark in the fields like fitness and wellbeing, urban planning, climate
modelling and disaster response which could inspire future researches and
applications in the said avenues.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.15809v2' target='_blank'>Empowering Large Language Model Agents through Action Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Haiteng Zhao, Chang Ma, Guoyin Wang, Jing Su, Lingpeng Kong, Jingjing Xu, Zhi-Hong Deng, Hongxia Yang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-24 13:13:04</h6>
<p class='card-text'>Large Language Model (LLM) Agents have recently garnered increasing interest
yet they are limited in their ability to learn from trial and error, a key
element of intelligent behavior. In this work, we argue that the capacity to
learn new actions from experience is fundamental to the advancement of learning
in LLM agents. While humans naturally expand their action spaces and develop
skills through experiential learning, LLM agents typically operate within fixed
action spaces, limiting their potential for growth. To address these
challenges, our study explores open-action learning for language agents. We
introduce a framework LearnAct with an iterative learning strategy to create
and improve actions in the form of Python functions. In each iteration, LLM
revises and updates the currently available actions based on the errors
identified in unsuccessful training tasks, thereby enhancing action
effectiveness. Our experimental evaluations across Robotic Planning and
Alfworld environments reveal that after learning on a few training task
instances, our approach to open-action learning markedly improves agent
performance for the type of task (by 32 percent in AlfWorld compared to
ReAct+Reflexion, for instance) highlighting the importance of experiential
action learning in the development of more intelligent LLM agents.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.15491v2' target='_blank'>API-BLEND: A Comprehensive Corpora for Training and Benchmarking API
  LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kinjal Basu, Ibrahim Abdelaziz, Subhajit Chaudhury, Soham Dan, Maxwell Crouse, Asim Munawar, Sadhana Kumaravel, Vinod Muthusamy, Pavan Kapanipathi, Luis A. Lastras</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-23 18:30:49</h6>
<p class='card-text'>There is a growing need for Large Language Models (LLMs) to effectively use
tools and external Application Programming Interfaces (APIs) to plan and
complete tasks. As such, there is tremendous interest in methods that can
acquire sufficient quantities of train and test data that involve calls to
tools / APIs. Two lines of research have emerged as the predominant strategies
for addressing this challenge. The first has focused on synthetic data
generation techniques, while the second has involved curating task-adjacent
datasets which can be transformed into API / Tool-based tasks. In this paper,
we focus on the task of identifying, curating, and transforming existing
datasets and, in turn, introduce API-BLEND, a large corpora for training and
systematic testing of tool-augmented LLMs. The datasets mimic real-world
scenarios involving API-tasks such as API / tool detection, slot filling, and
sequencing of the detected APIs. We demonstrate the utility of the API-BLEND
dataset for both training and benchmarking purposes.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.15368v4' target='_blank'>Probabilistically Correct Language-based Multi-Robot Planning using
  Conformal Prediction</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jun Wang, Guocheng He, Yiannis Kantaros</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-23 15:02:44</h6>
<p class='card-text'>This paper addresses task planning problems for language-instructed robot
teams. Tasks are expressed in natural language (NL), requiring the robots to
apply their capabilities at various locations and semantic objects. Several
recent works have addressed similar planning problems by leveraging pre-trained
Large Language Models (LLMs) to design effective multi-robot plans. However,
these approaches lack performance guarantees. To address this challenge, we
introduce a new distributed LLM-based planner, called S-ATLAS for Safe plAnning
for Teams of Language-instructed AgentS, that is capable of achieving
user-defined mission success rates. This is accomplished by leveraging
conformal prediction (CP), a distribution-free uncertainty quantification tool
in black-box models. CP allows the proposed multi-robot planner to reason about
its inherent uncertainty in a distributed fashion, enabling robots to make
individual decisions when they are sufficiently certain and seek help
otherwise. We show, both theoretically and empirically, that the proposed
planner can achieve user-specified task success rates, assuming successful plan
execution, while minimizing the overall number of help requests. We provide
comparative experiments against related works showing that our method is
significantly more computational efficient and achieves lower help rates. The
advantage of our algorithm over baselines becomes more pronounced with
increasing robot team size.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.15057v1' target='_blank'>On the Multi-turn Instruction Following for Conversational Web Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yang Deng, Xuan Zhang, Wenxuan Zhang, Yifei Yuan, See-Kiong Ng, Tat-Seng Chua</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-23 02:18:12</h6>
<p class='card-text'>Web agents powered by Large Language Models (LLMs) have demonstrated
remarkable abilities in planning and executing multi-step interactions within
complex web-based environments, fulfilling a wide range of web navigation
tasks. Despite these advancements, the potential for LLM-powered agents to
effectively engage with sequential user instructions in real-world scenarios
has not been fully explored. In this work, we introduce a new task of
Conversational Web Navigation, which necessitates sophisticated interactions
that span multiple turns with both the users and the environment, supported by
a specially developed dataset named Multi-Turn Mind2Web (MT-Mind2Web). To
tackle the limited context length of LLMs and the context-dependency issue of
the conversational tasks, we further propose a novel framework, named
self-reflective memory-augmented planning (Self-MAP), which employs memory
utilization and self-reflection techniques. Extensive experiments are conducted
to benchmark the MT-Mind2Web dataset, and validate the effectiveness of the
proposed method.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.14310v1' target='_blank'>Hint-before-Solving Prompting: Guiding LLMs to Effectively Utilize
  Encoded Knowledge</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jinlan Fu, Shenzhen Huangfu, Hang Yan, See-Kiong Ng, Xipeng Qiu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-22 05:58:03</h6>
<p class='card-text'>Large Language Models (LLMs) have recently showcased remarkable
generalizability in various domains. Despite their extensive knowledge, LLMs
still face challenges in efficiently utilizing encoded knowledge to develop
accurate and logical reasoning processes. To mitigate this problem, we
introduced Hint-before-Solving Prompting (HSP), which guides the model to
generate hints (e.g., specific knowledge or key ideas) for solving the problem
and then generate solutions containing intermediate reasoning steps. Since HSP
is orthogonal to prompting methods (e.g., Chain-of-Thought (CoT)), we applied
HSP to CoT, Least-to-Most, Plan-and-Solve, and Standard promptings. The results
of extensive experiments on 6 reasoning benchmarks and 4 open-source LLMs
demonstrate that HSP can effectively improve the accuracy of reasoning tasks:
(1) By applying high-quality hint-enhanced HSP to CoT prompting,
Llama2-70B-Chat shows an improvement of 9.7. (2) Beyond exploring training-free
LLM capabilities, we built the HSPMATH dataset based on HSP and fine-tuned
Llemma-7B, reaching 64.3 accuracy, surpassing GPT-3.5 and WizardMath-13B. We
make our code and dataset publicly available at
\url{https://github.com/jinlanfu/HSP}.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.13125v2' target='_blank'>TreeEval: Benchmark-Free Evaluation of Large Language Models through
  Tree Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xiang Li, Yunshi Lan, Chao Yang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-20 16:38:33</h6>
<p class='card-text'>Recently, numerous new benchmarks have been established to evaluate the
performance of large language models (LLMs) via either computing a holistic
score or employing another LLM as a judge. However, these approaches suffer
from data leakage due to the open access of the benchmark and inflexible
evaluation process. To address this issue, we introduce $\textbf{TreeEval}$, a
benchmark-free evaluation method for LLMs that let a high-performance LLM host
an irreproducible evaluation session and essentially avoids the data leakage.
Moreover, this LLM performs as an examiner to raise up a series of questions
under a topic with a tree planing strategy, which considers the current
evaluation status to decide the next question generation and ensures the
completeness and efficiency of the evaluation process. We evaluate $6$ models
of different parameter sizes, including $7$B, $13$B, and $33$B, and ultimately
achieved the highest correlation coefficient with AlpacaEval2.0 using only
around $45$ questions. We also conduct more analysis to show the robustness and
reliability of TreeEval. Our code can be accessed via the provided
https://github.com/Ashura5/TreeEval.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.12914v1' target='_blank'>Large Language Model-based Human-Agent Collaboration for Complex Task
  Solving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xueyang Feng, Zhi-Yuan Chen, Yujia Qin, Yankai Lin, Xu Chen, Zhiyuan Liu, Ji-Rong Wen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-20 11:03:36</h6>
<p class='card-text'>In recent developments within the research community, the integration of
Large Language Models (LLMs) in creating fully autonomous agents has garnered
significant interest. Despite this, LLM-based agents frequently demonstrate
notable shortcomings in adjusting to dynamic environments and fully grasping
human needs. In this work, we introduce the problem of LLM-based human-agent
collaboration for complex task-solving, exploring their synergistic potential.
In addition, we propose a Reinforcement Learning-based Human-Agent
Collaboration method, ReHAC. This approach includes a policy model designed to
determine the most opportune stages for human intervention within the
task-solving process. We construct a human-agent collaboration dataset to train
this policy model in an offline reinforcement learning environment. Our
validation tests confirm the model's effectiveness. The results demonstrate
that the synergistic efforts of humans and LLM-based agents significantly
improve performance in complex tasks, primarily through well-planned, limited
human intervention. Datasets and code are available at:
https://github.com/XueyangFeng/ReHAC.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.12741v2' target='_blank'>MuLan: Multimodal-LLM Agent for Progressive and Interactive Multi-Object
  Diffusion</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sen Li, Ruochen Wang, Cho-Jui Hsieh, Minhao Cheng, Tianyi Zhou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-20 06:14:30</h6>
<p class='card-text'>Existing text-to-image models still struggle to generate images of multiple
objects, especially in handling their spatial positions, relative sizes,
overlapping, and attribute bindings. To efficiently address these challenges,
we develop a training-free Multimodal-LLM agent (MuLan), as a human painter,
that can progressively generate multi-object with intricate planning and
feedback control. MuLan harnesses a large language model (LLM) to decompose a
prompt to a sequence of sub-tasks, each generating only one object by stable
diffusion, conditioned on previously generated objects. Unlike existing
LLM-grounded methods, MuLan only produces a high-level plan at the beginning
while the exact size and location of each object are determined upon each
sub-task by an LLM and attention guidance. Moreover, MuLan adopts a
vision-language model (VLM) to provide feedback to the image generated in each
sub-task and control the diffusion model to re-generate the image if it
violates the original prompt. Hence, each model in every step of MuLan only
needs to address an easy sub-task it is specialized for. The multi-step process
also allows human users to monitor the generation process and make preferred
changes at any intermediate step via text prompts, thereby improving the
human-AI collaboration experience. We collect 200 prompts containing
multi-objects with spatial relationships and attribute bindings from different
benchmarks to evaluate MuLan. The results demonstrate the superiority of MuLan
in generating multiple objects over baselines and its creativity when
collaborating with human users. The code is available at
https://github.com/measure-infinity/mulan-code.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.12275v3' target='_blank'>WorldCoder, a Model-Based LLM Agent: Building World Models by Writing
  Code and Interacting with the Environment</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hao Tang, Darren Key, Kevin Ellis</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-19 16:39:18</h6>
<p class='card-text'>We give a model-based agent that builds a Python program representing its
knowledge of the world based on its interactions with the environment. The
world model tries to explain its interactions, while also being optimistic
about what reward it can achieve. We define this optimism as a logical
constraint between a program and a planner. We study our agent on gridworlds,
and on task planning, finding our approach is more sample-efficient compared to
deep RL, more compute-efficient compared to ReAct-style agents, and that it can
transfer its knowledge across environments by editing its code.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.11903v3' target='_blank'>DiLA: Enhancing LLM Tool Learning with Differential Logic Layer</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yu Zhang, Hui-Ling Zhen, Zehua Pei, Yingzhao Lian, Lihao Yin, Mingxuan Yuan, Bei Yu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-19 07:38:57</h6>
<p class='card-text'>Considering the challenges faced by large language models (LLMs) in logical
reasoning and planning, prior efforts have sought to augment LLMs with access
to external solvers. While progress has been made on simple reasoning problems,
solving classical constraint satisfaction problems, such as the Boolean
Satisfiability Problem (SAT) and Graph Coloring Problem (GCP), remains
difficult for off-the-shelf solvers due to their intricate expressions and
exponential search spaces. In this paper, we propose a novel differential logic
layer-aided language modeling (DiLA) approach, where logical constraints are
integrated into the forward and backward passes of a network layer, to provide
another option for LLM tool learning. In DiLA, LLM aims to transform the
language description to logic constraints and identify initial solutions of the
highest quality, while the differential logic layer focuses on iteratively
refining the LLM-prompted solution. Leveraging the logic layer as a bridge,
DiLA enhances the logical reasoning ability of LLMs on a range of reasoning
problems encoded by Boolean variables, guaranteeing the efficiency and
correctness of the solution process. We evaluate the performance of DiLA on two
classic reasoning problems and empirically demonstrate its consistent
outperformance against existing prompt-based and solver-aided approaches.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.11882v1' target='_blank'>NOTE: Notable generation Of patient Text summaries through Efficient
  approach based on direct preference optimization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Imjin Ahn, Hansle Gwon, Young-Hak Kim, Tae Joon Jun, Sanghyun Park</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-19 06:43:25</h6>
<p class='card-text'>The discharge summary is a one of critical documents in the patient journey,
encompassing all events experienced during hospitalization, including multiple
visits, medications, tests, surgery/procedures, and admissions/discharge.
Providing a summary of the patient's progress is crucial, as it significantly
influences future care and planning. Consequently, clinicians face the
laborious and resource-intensive task of manually collecting, organizing, and
combining all the necessary data for a discharge summary. Therefore, we propose
"NOTE", which stands for "Notable generation Of patient Text summaries through
an Efficient approach based on direct preference optimization". NOTE is based
on Medical Information Mart for Intensive Care- III dataset and summarizes a
single hospitalization of a patient. Patient events are sequentially combined
and used to generate a discharge summary for each hospitalization. In the
present circumstances, large language models' application programming
interfaces (LLMs' APIs) are widely available, but importing and exporting
medical data presents significant challenges due to privacy protection policies
in healthcare institutions. Moreover, to ensure optimal performance, it is
essential to implement a lightweight model for internal server or program
within the hospital. Therefore, we utilized DPO and parameter efficient fine
tuning (PEFT) techniques to apply a fine-tuning method that guarantees superior
performance. To demonstrate the practical application of the developed NOTE, we
provide a webpage-based demonstration software. In the future, we will aim to
deploy the software available for actual use by clinicians in hospital. NOTE
can be utilized to generate various summaries not only discharge summaries but
also throughout a patient's journey, thereby alleviating the labor-intensive
workload of clinicians and aiming for increased efficiency.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2403.00783v2' target='_blank'>On the Roles of LLMs in Planning: Embedding LLMs into Planning Graphs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hankz Hankui Zhuo, Xin Chen, Rong Pan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-18 15:53:32</h6>
<p class='card-text'>Plan synthesis aims to generate a course of actions or policies to transit
given initial states to goal states, provided domain models that could be
designed by experts or learnt from training data or interactions with the
world. Intrigued by the claims of emergent planning capabilities in large
language models (LLMs), works have been proposed to investigate the planning
effectiveness of LLMs, without considering any utilization of off-the-shelf
planning techniques in LLMs. In this paper, we aim to further study the insight
of the planning capability of LLMs by investigating the roles of LLMs in
off-the-shelf planning frameworks. To do this, we investigate the effectiveness
of embedding LLMs into one of the well-known planning frameworks, graph-based
planning, proposing a novel LLMs-based planning framework with LLMs embedded in
two levels of planning graphs, i.e., mutual constraints generation level and
constraints solving level. We empirically exhibit the effectiveness of our
proposed framework in various planning domains.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.11534v2' target='_blank'>PreAct: Prediction Enhances Agent's Planning Ability</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Dayuan Fu, Jianzhao Huang, Siyuan Lu, Guanting Dong, Yejie Wang, Keqing He, Weiran Xu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-18 10:15:38</h6>
<p class='card-text'>Addressing the disparity between forecasts and actual results can enable
individuals to expand their thought processes and stimulate self-reflection,
thus promoting accurate planning. In this research, we present **PreAct**, an
agent framework that integrates **pre**diction, **rea**soning, and **act**ion.
By utilizing the information derived from predictions, the large language model
(LLM) agent can provide a wider range and more strategically focused reasoning.
This leads to more efficient actions that aid the agent in accomplishing
intricate tasks. Our experimental results show that PreAct surpasses the ReAct
method in completing complex tasks and that PreAct's performance can be further
improved when paired with other memory or selection strategy techniques. We
presented the model with varying quantities of historical predictions and
discovered that these predictions consistently enhance LLM planning.The
variances in single-step reasoning between PreAct and ReAct indicate that
PreAct indeed has benefits in terms of diversity and strategic orientation over
ReAct.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.11498v2' target='_blank'>Verifiably Following Complex Robot Instructions with Foundation Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Benedict Quartey, Eric Rosen, Stefanie Tellex, George Konidaris</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-18 08:05:54</h6>
<p class='card-text'>Enabling mobile robots to follow complex natural language instructions is an
important yet challenging problem. People want to flexibly express constraints,
refer to arbitrary landmarks and verify behavior when instructing robots.
Conversely, robots must disambiguate human instructions into specifications and
ground instruction referents in the real world. We propose Language Instruction
grounding for Motion Planning (LIMP), an approach that enables robots to
verifiably follow expressive and complex open-ended instructions in real-world
environments without prebuilt semantic maps. LIMP constructs a symbolic
instruction representation that reveals the robot's alignment with an
instructor's intended motives and affords the synthesis of robot behaviors that
are correct-by-construction. We perform a large scale evaluation and
demonstrate our approach on 150 instructions in five real-world environments
showing the generality of our approach and the ease of deployment in novel
unstructured domains. In our experiments, LIMP performs comparably with
state-of-the-art LLM task planners and LLM code-writing planners on standard
open vocabulary tasks and additionally achieves 79\% success rate on complex
spatiotemporal instructions while LLM and Code-writing planners both achieve
38\%. See supplementary materials and demo videos at
https://robotlimp.github.io</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.11489v2' target='_blank'>What's the Plan? Evaluating and Developing Planning-Aware Techniques for
  Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Eran Hirsch, Guy Uziel, Ateret Anaby-Tavor</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-18 07:42:49</h6>
<p class='card-text'>Planning is a fundamental task in artificial intelligence that involves
finding a sequence of actions that achieve a specified goal in a given
environment. Large language models (LLMs) are increasingly used for
applications that require planning capabilities, such as web or embodied
agents. In line with recent studies, we demonstrate through experimentation
that LLMs lack necessary skills required for planning. Based on these
observations, we advocate for the potential of a hybrid approach that combines
LLMs with classical planning methodology. Then, we introduce SimPlan, a novel
hybrid-method, and evaluate its performance in a new challenging setup. Our
extensive experiments across various planning domains demonstrate that SimPlan
significantly outperforms existing LLM-based planners.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.10890v2' target='_blank'>When is Tree Search Useful for LLM Planning? It Depends on the
  Discriminator</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ziru Chen, Michael White, Raymond Mooney, Ali Payani, Yu Su, Huan Sun</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-16 18:45:58</h6>
<p class='card-text'>In this paper, we examine how large language models (LLMs) solve multi-step
problems under a language agent framework with three components: a generator, a
discriminator, and a planning method. We investigate the practical utility of
two advanced planning methods, iterative correction and tree search. We present
a comprehensive analysis of how discrimination accuracy affects the overall
performance of agents when using these two methods or a simpler method,
re-ranking. Experiments on two tasks, text-to-SQL parsing and mathematical
reasoning, show that: (1) advanced planning methods demand discriminators with
at least 90% accuracy to achieve significant improvements over re-ranking; (2)
current LLMs' discrimination abilities have not met the needs of advanced
planning methods to achieve such improvements; (3) with LLM-based
discriminators, advanced planning methods may not adequately balance accuracy
and efficiency. For example, compared to the other two methods, tree search is
at least 10--20 times slower but leads to negligible performance gains, which
hinders its real-world applications. Code and data are available at
https://github.com/OSU-NLP-Group/llm-planning-eval.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.10778v2' target='_blank'>AutoGPT+P: Affordance-based Task Planning with Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Timo Birr, Christoph Pohl, Abdelrahman Younes, Tamim Asfour</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-16 16:00:50</h6>
<p class='card-text'>Recent advances in task planning leverage Large Language Models (LLMs) to
improve generalizability by combining such models with classical planning
algorithms to address their inherent limitations in reasoning capabilities.
However, these approaches face the challenge of dynamically capturing the
initial state of the task planning problem. To alleviate this issue, we propose
AutoGPT+P, a system that combines an affordance-based scene representation with
a planning system. Affordances encompass the action possibilities of an agent
on the environment and objects present in it. Thus, deriving the planning
domain from an affordance-based scene representation allows symbolic planning
with arbitrary objects. AutoGPT+P leverages this representation to derive and
execute a plan for a task specified by the user in natural language. In
addition to solving planning tasks under a closed-world assumption, AutoGPT+P
can also handle planning with incomplete information, e. g., tasks with missing
objects by exploring the scene, suggesting alternatives, or providing a partial
plan. The affordance-based scene representation combines object detection with
an automatically generated object-affordance-mapping using ChatGPT. The core
planning tool extends existing work by automatically correcting semantic and
syntactic errors. Our approach achieves a success rate of 98%, surpassing the
current 81% success rate of the current state-of-the-art LLM-based planning
method SayCan on the SayCan instruction set. Furthermore, we evaluated our
approach on our newly created dataset with 150 scenarios covering a wide range
of complex tasks with missing objects, achieving a success rate of 79% on our
dataset. The dataset and the code are publicly available at
https://git.h2t.iar.kit.edu/birr/autogpt-p-standalone.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.10534v1' target='_blank'>Using Left and Right Brains Together: Towards Vision and Language
  Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jun Cen, Chenfei Wu, Xiao Liu, Shengming Yin, Yixuan Pei, Jinglong Yang, Qifeng Chen, Nan Duan, Jianguo Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-16 09:46:20</h6>
<p class='card-text'>Large Language Models (LLMs) and Large Multi-modality Models (LMMs) have
demonstrated remarkable decision masking capabilities on a variety of tasks.
However, they inherently operate planning within the language space, lacking
the vision and spatial imagination ability. In contrast, humans utilize both
left and right hemispheres of the brain for language and visual planning during
the thinking process. Therefore, we introduce a novel vision-language planning
framework in this work to perform concurrent visual and language planning for
tasks with inputs of any form. Our framework incorporates visual planning to
capture intricate environmental details, while language planning enhances the
logical coherence of the overall system. We evaluate the effectiveness of our
framework across vision-language tasks, vision-only tasks, and language-only
tasks. The results demonstrate the superior performance of our approach,
indicating that the integration of visual and language planning yields better
contextually aware task execution.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.10980v5' target='_blank'>ChemReasoner: Heuristic Search over a Large Language Model's Knowledge
  Space using Quantum-Chemical Feedback</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Henry W. Sprueill, Carl Edwards, Khushbu Agarwal, Mariefel V. Olarte, Udishnu Sanyal, Conrad Johnston, Hongbin Liu, Heng Ji, Sutanay Choudhury</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-15 21:33:07</h6>
<p class='card-text'>The discovery of new catalysts is essential for the design of new and more
efficient chemical processes in order to transition to a sustainable future. We
introduce an AI-guided computational screening framework unifying linguistic
reasoning with quantum-chemistry based feedback from 3D atomistic
representations. Our approach formulates catalyst discovery as an uncertain
environment where an agent actively searches for highly effective catalysts via
the iterative combination of large language model (LLM)-derived hypotheses and
atomistic graph neural network (GNN)-derived feedback. Identified catalysts in
intermediate search steps undergo structural evaluation based on spatial
orientation, reaction pathways, and stability. Scoring functions based on
adsorption energies and reaction energy barriers steer the exploration in the
LLM's knowledge space toward energetically favorable, high-efficiency
catalysts. We introduce planning methods that automatically guide the
exploration without human input, providing competitive performance against
expert-enumerated chemical descriptor-based implementations. By integrating
language-guided reasoning with computational chemistry feedback, our work
pioneers AI-accelerated, trustworthy catalyst discovery.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.10979v2' target='_blank'>SportsMetrics: Blending Text and Numerical Data to Understand
  Information Fusion in LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yebowen Hu, Kaiqiang Song, Sangwoo Cho, Xiaoyang Wang, Hassan Foroosh, Dong Yu, Fei Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-15 20:26:07</h6>
<p class='card-text'>Large language models hold significant potential for integrating various data
types, such as text documents and database records, for advanced analytics.
However, blending text and numerical data presents substantial challenges. LLMs
need to process and cross-reference entities and numbers, handle data
inconsistencies and redundancies, and develop planning capabilities such as
building a working memory for managing complex data queries. In this paper, we
introduce four novel tasks centered around sports data analytics to evaluate
the numerical reasoning and information fusion capabilities of LLMs. These
tasks involve providing LLMs with detailed, play-by-play sports game
descriptions, then challenging them with adversarial scenarios such as new game
rules, longer durations, scrambled narratives, and analyzing key statistics in
game summaries. We conduct extensive experiments on NBA and NFL games to assess
the performance of LLMs on these tasks. Our benchmark, SportsMetrics,
introduces a new mechanism for assessing LLMs' numerical reasoning and fusion
skills.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.10294v1' target='_blank'>LAVE: LLM-Powered Agent Assistance and Language Augmentation for Video
  Editing</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Bryan Wang, Yuliang Li, Zhaoyang Lv, Haijun Xia, Yan Xu, Raj Sodhi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-15 19:53:11</h6>
<p class='card-text'>Video creation has become increasingly popular, yet the expertise and effort
required for editing often pose barriers to beginners. In this paper, we
explore the integration of large language models (LLMs) into the video editing
workflow to reduce these barriers. Our design vision is embodied in LAVE, a
novel system that provides LLM-powered agent assistance and language-augmented
editing features. LAVE automatically generates language descriptions for the
user's footage, serving as the foundation for enabling the LLM to process
videos and assist in editing tasks. When the user provides editing objectives,
the agent plans and executes relevant actions to fulfill them. Moreover, LAVE
allows users to edit videos through either the agent or direct UI manipulation,
providing flexibility and enabling manual refinement of agent actions. Our user
study, which included eight participants ranging from novices to proficient
editors, demonstrated LAVE's effectiveness. The results also shed light on user
perceptions of the proposed LLM-assisted editing paradigm and its impact on
users' creativity and sense of co-creation. Based on these findings, we propose
design implications to inform the future development of agent-assisted content
editing.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.10178v2' target='_blank'>TDAG: A Multi-Agent Framework based on Dynamic Task Decomposition and
  Agent Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yaoxiang Wang, Zhiyong Wu, Junfeng Yao, Jinsong Su</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-15 18:27:37</h6>
<p class='card-text'>The emergence of Large Language Models (LLMs) like ChatGPT has inspired the
development of LLM-based agents capable of addressing complex, real-world
tasks. However, these agents often struggle during task execution due to
methodological constraints, such as error propagation and limited adaptability.
To address this issue, we propose a multi-agent framework based on dynamic Task
Decomposition and Agent Generation (TDAG). This framework dynamically
decomposes complex tasks into smaller subtasks and assigns each to a
specifically generated subagent, thereby enhancing adaptability in diverse and
unpredictable real-world tasks. Simultaneously, existing benchmarks often lack
the granularity needed to evaluate incremental progress in complex, multi-step
tasks. In response, we introduce ItineraryBench in the context of travel
planning, featuring interconnected, progressively complex tasks with a
fine-grained evaluation system. ItineraryBench is designed to assess agents'
abilities in memory, planning, and tool usage across tasks of varying
complexity. Our experimental results reveal that TDAG significantly outperforms
established baselines, showcasing its superior adaptability and context
awareness in complex task scenarios.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.10051v1' target='_blank'>SwissNYF: Tool Grounded LLM Agents for Black Box Setting</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Somnath Sendhil Kumar, Dhruv Jain, Eshaan Agarwal, Raunak Pandey</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-15 16:15:38</h6>
<p class='card-text'>While Large Language Models (LLMs) have demonstrated enhanced capabilities in
function-calling, these advancements primarily rely on accessing the functions'
responses. This methodology is practical for simpler APIs but faces scalability
issues with irreversible APIs that significantly impact the system, such as a
database deletion API. Similarly, processes requiring extensive time for each
API call and those necessitating forward planning, like automated action
pipelines, present complex challenges. Furthermore, scenarios often arise where
a generalized approach is needed because algorithms lack direct access to the
specific implementations of these functions or secrets to use them. Traditional
tool planning methods are inadequate in these cases, compelling the need to
operate within black-box environments. Unlike their performance in tool
manipulation, LLMs excel in black-box tasks, such as program synthesis.
Therefore, we harness the program synthesis capabilities of LLMs to strategize
tool usage in black-box settings, ensuring solutions are verified prior to
implementation. We introduce TOPGUN, an ingeniously crafted approach leveraging
program synthesis for black box tool planning. Accompanied by SwissNYF, a
comprehensive suite that integrates black-box algorithms for planning and
verification tasks, addressing the aforementioned challenges and enhancing the
versatility and effectiveness of LLMs in complex API interactions. The public
code for SwissNYF is available at https://github.com/iclr-dummy-user/SwissNYF.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.09939v1' target='_blank'>Generative AI in the Construction Industry: A State-of-the-art Analysis</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ridwan Taiwo, Idris Temitope Bello, Sulemana Fatoama Abdulai, Abdul-Mugis Yussif, Babatunde Abiodun Salami, Abdullahi Saka, Tarek Zayed</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-15 13:39:55</h6>
<p class='card-text'>The construction industry is a vital sector of the global economy, but it
faces many productivity challenges in various processes, such as design,
planning, procurement, inspection, and maintenance. Generative artificial
intelligence (AI), which can create novel and realistic data or content, such
as text, image, video, or code, based on some input or prior knowledge, offers
innovative and disruptive solutions to address these challenges. However, there
is a gap in the literature on the current state, opportunities, and challenges
of generative AI in the construction industry. This study aims to fill this gap
by providing a state-of-the-art analysis of generative AI in construction, with
three objectives: (1) to review and categorize the existing and emerging
generative AI opportunities and challenges in the construction industry; (2) to
propose a framework for construction firms to build customized generative AI
solutions using their own data, comprising steps such as data collection,
dataset curation, training custom large language model (LLM), model evaluation,
and deployment; and (3) to demonstrate the framework via a case study of
developing a generative model for querying contract documents. The results show
that retrieval augmented generation (RAG) improves the baseline LLM by 5.2,
9.4, and 4.8% in terms of quality, relevance, and reproducibility. This study
provides academics and construction professionals with a comprehensive analysis
and practical framework to guide the adoption of generative AI techniques to
enhance productivity, quality, safety, and sustainability across the
construction industry.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.09836v2' target='_blank'>Chain-of-Planned-Behaviour Workflow Elicits Few-Shot Mobility Generation
  in LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chenyang Shao, Fengli Xu, Bingbing Fan, Jingtao Ding, Yuan Yuan, Meng Wang, Yong Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-15 09:58:23</h6>
<p class='card-text'>The powerful reasoning capabilities of large language models (LLMs) have
brought revolutionary changes to many fields, but their performance in human
behaviour generation has not yet been extensively explored. This gap likely
emerges because the internal processes governing behavioral intentions cannot
be solely explained by abstract reasoning. Instead, they are also influenced by
a multitude of factors, including social norms and personal preference.
Inspired by the Theory of Planned Behaviour (TPB), we develop a LLM workflow
named Chain-of-Planned Behaviour (CoPB) for mobility behaviour generation,
which reflects the important spatio-temporal dynamics of human activities.
Through exploiting the cognitive structures of attitude, subjective norms, and
perceived behaviour control in TPB, CoPB significantly enhance the ability of
LLMs to reason the intention of next movement. Specifically, CoPB substantially
reduces the error rate of mobility intention generation from 57.8% to 19.4%. To
improve the scalability of the proposed CoPB workflow, we further explore the
synergy between LLMs and mechanistic models. We find mechanistic mobility
models, such as gravity model, can effectively map mobility intentions to
physical mobility behaviours. The strategy of integrating CoPB with gravity
model can reduce the token cost by 97.7% and achieve better performance
simultaneously. Besides, the proposed CoPB workflow can facilitate GPT-4-turbo
to automatically generate high quality labels for mobility behavior reasoning.
We show such labels can be leveraged to fine-tune the smaller-scale, open
source LLaMA 3-8B, which significantly reduces usage costs without sacrificing
the quality of the generated behaviours.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.09390v2' target='_blank'>HGOT: Hierarchical Graph of Thoughts for Retrieval-Augmented In-Context
  Learning in Factuality Evaluation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yihao Fang, Stephen W. Thomas, Xiaodan Zhu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-14 18:41:19</h6>
<p class='card-text'>With the widespread adoption of large language models (LLMs) in numerous
applications, the challenge of factuality and the propensity for hallucinations
has emerged as a significant concern. To address this issue, particularly in
retrieval-augmented in-context learning, we introduce the hierarchical graph of
thoughts (HGOT), a structured, multi-layered graph approach designed to enhance
the retrieval of pertinent passages during in-context learning. The framework
utilizes the emergent planning capabilities of LLMs, employing the
divide-and-conquer strategy to break down complex queries into manageable
sub-queries. It refines self-consistency majority voting for answer selection,
which incorporates the recently proposed citation recall and precision metrics
to assess the quality of thoughts, linking an answer's credibility
intrinsically to the thought's quality. This methodology introduces a weighted
system in majority voting, prioritizing answers based on the citation quality
of their thoughts. Additionally, we propose a scoring mechanism for evaluating
retrieved passages, considering factors such as citation frequency and quality,
self-consistency confidence, and the retrieval module's ranking. Experiments
indicate that HGOT excels as a versatile approach, outperforming competing
models in FEVER by up to $7\%$ and matching leading models such as
Retrieve-then-Read in Open-SQuAD, and DSP in HotPotQA, demonstrating its
efficacy in enhancing LLMs' factuality.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.08546v2' target='_blank'>Grounding LLMs For Robot Task Planning Using Closed-loop State Feedback</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Vineet Bhat, Ali Umut Kaypak, Prashanth Krishnamurthy, Ramesh Karri, Farshad Khorrami</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-13 15:51:58</h6>
<p class='card-text'>Planning algorithms decompose complex problems into intermediate steps that
can be sequentially executed by robots to complete tasks. Recent works have
employed Large Language Models (LLMs) for task planning, using natural language
to generate robot policies in both simulation and real-world environments. LLMs
like GPT-4 have shown promising results in generalizing to unseen tasks, but
their applicability is limited due to hallucinations caused by insufficient
grounding in the robot environment. The robustness of LLMs in task planning can
be enhanced with environmental state information and feedback. In this paper,
we introduce a novel approach to task planning that utilizes two separate LLMs
for high-level planning and low-level control, improving task-related success
rates and goal condition recall. Our algorithm, \textit{BrainBody-LLM}, draws
inspiration from the human neural system, emulating its brain-body architecture
by dividing planning across two LLMs in a structured, hierarchical manner.
BrainBody-LLM implements a closed-loop feedback mechanism, enabling learning
from simulator errors to resolve execution errors in complex settings. We
demonstrate the successful application of BrainBody-LLM in the VirtualHome
simulation environment, achieving a 29\% improvement in task-oriented success
rates over competitive baselines with the GPT-4 backend. Additionally, we
evaluate our algorithm on seven complex tasks using a realistic physics
simulator and the Franka Research 3 robotic arm, comparing it with various
state-of-the-art LLMs. Our results show advancements in the reasoning
capabilities of recent LLMs, which enable them to learn from raw
simulator/controller errors to correct plans, making them highly effective in
robotic task planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.08189v2' target='_blank'>Simulating Human Strategic Behavior: Comparing Single and Multi-agent
  LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Karthik Sreedhar, Lydia Chilton</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-13 03:19:09</h6>
<p class='card-text'>When creating policies, plans, or designs for people, it is challenging for
designers to foresee all of the ways in which people may reason and behave.
Recently, Large Language Models (LLMs) have been shown to be able to simulate
human reasoning. We extend this work by measuring LLMs ability to simulate
strategic reasoning in the ultimatum game, a classic economics bargaining
experiment. Experimental evidence shows human strategic reasoning is complex;
people will often choose to punish other players to enforce social norms even
at personal expense. We test if LLMs can replicate this behavior in simulation,
comparing two structures: single LLMs and multi-agent systems. We compare their
abilities to (1) simulate human-like reasoning in the ultimatum game, (2)
simulate two player personalities, greedy and fair, and (3) create robust
strategies that are logically complete and consistent with personality. Our
evaluation shows that multi-agent systems are more accurate than single LLMs
(88 percent vs. 50 percent) in simulating human reasoning and actions for
personality pairs. Thus, there is potential to use LLMs to simulate human
strategic reasoning to help decision and policy-makers perform preliminary
explorations of how people behave in systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.08178v1' target='_blank'>LoTa-Bench: Benchmarking Language-oriented Task Planners for Embodied
  Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jae-Woo Choi, Youngwoo Yoon, Hyobin Ong, Jaehong Kim, Minsu Jang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-13 02:28:57</h6>
<p class='card-text'>Large language models (LLMs) have recently received considerable attention as
alternative solutions for task planning. However, comparing the performance of
language-oriented task planners becomes difficult, and there exists a dearth of
detailed exploration regarding the effects of various factors such as
pre-trained model selection and prompt construction. To address this, we
propose a benchmark system for automatically quantifying performance of task
planning for home-service embodied agents. Task planners are tested on two
pairs of datasets and simulators: 1) ALFRED and AI2-THOR, 2) an extension of
Watch-And-Help and VirtualHome. Using the proposed benchmark system, we perform
extensive experiments with LLMs and prompts, and explore several enhancements
of the baseline planner. We expect that the proposed benchmark tool would
accelerate the development of language-oriented task planners.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.08115v2' target='_blank'>On the Self-Verification Limitations of Large Language Models on
  Reasoning and Planning Tasks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kaya Stechly, Karthik Valmeekam, Subbarao Kambhampati</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-12 23:11:01</h6>
<p class='card-text'>There has been considerable divergence of opinion on the reasoning abilities
of Large Language Models (LLMs). While the initial optimism that reasoning
might emerge automatically with scale has been tempered thanks to a slew of
counterexamples--ranging from multiplication to simple planning--there persists
a wide spread belief that LLMs can self-critique and improve their own
solutions in an iterative fashion. This belief seemingly rests on the
assumption that verification of correctness should be easier than generation--a
rather classical argument from computational complexity--which should be
irrelevant to LLMs to the extent that what they are doing is approximate
retrieval. In this paper, we set out to systematically investigate the
effectiveness of iterative prompting in the context of reasoning and planning.
We present a principled empirical study of the performance of GPT-4 in three
domains: Game of 24, Graph Coloring, and STRIPS planning. We experiment both
with the model critiquing its own answers and with an external correct reasoner
verifying proposed solutions. In each case, we analyze whether the content of
criticisms actually affects bottom line performance, and whether we can ablate
elements of the augmented system without losing performance. We observe
significant performance collapse with self-critique and significant performance
gains with sound external verification. We also note that merely re-prompting
with a sound verifier maintains most of the benefits of more involved setups.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.07167v1' target='_blank'>Large-Language-Model Empowered Dose Volume Histogram Prediction for
  Intensity Modulated Radiotherapy</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zehao Dong, Yixin Chen, Hiram Gay, Yao Hao, Geoffrey D. Hugo, Pamela Samson, Tianyu Zhao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-11 11:24:09</h6>
<p class='card-text'>Treatment planning is currently a patient specific, time-consuming, and
resource demanding task in radiotherapy. Dose-volume histogram (DVH) prediction
plays a critical role in automating this process. The geometric relationship
between DVHs in radiotherapy plans and organs-at-risk (OAR) and planning target
volume (PTV) has been well established. This study explores the potential of
deep learning models for predicting DVHs using images and subsequent human
intervention facilitated by a large-language model (LLM) to enhance the
planning quality. We propose a pipeline to convert unstructured images to a
structured graph consisting of image-patch nodes and dose nodes. A novel Dose
Graph Neural Network (DoseGNN) model is developed for predicting DVHs from the
structured graph. The proposed DoseGNN is enhanced with the LLM to encode
massive knowledge from prescriptions and interactive instructions from
clinicians. In this study, we introduced an online human-AI collaboration
(OHAC) system as a practical implementation of the concept proposed for the
automation of intensity-modulated radiotherapy (IMRT) planning. In comparison
to the widely-employed DL models used in radiotherapy, DoseGNN achieved mean
square errors that were 80$\%$, 76$\%$ and 41.0$\%$ of those predicted by Swin
U-Net Transformer, 3D U-Net CNN and vanilla MLP, respectively. Moreover, the
LLM-empowered DoseGNN model facilitates seamless adjustment to treatment plans
through interaction with clinicians using natural language.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.07950v1' target='_blank'>Sentinels of the Stream: Unleashing Large Language Models for Dynamic
  Packet Classification in Software Defined Networks -- Position Paper</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shariq Murtuza</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-10 04:47:58</h6>
<p class='card-text'>With the release of OpenAI's ChatGPT, the field of large language models
(LLM) saw an increase of academic interest in GPT based chat assistants. In the
next few months multiple accesible large language models were released that
included Meta's LLama models and Mistral AI's Mistral and Mixtral MoE models.
These models are available openly for a wide array of purposes with a wide
spectrum of licenses. These LLMs have found their use in a different number of
fields like code development, SQL generation etc. In this work we propose our
plan to explore the applicability of large language model in the domain of
network security. We plan to create Sentinel, a LLM, to analyse network packet
contents and pass a judgment on it's threat level. This work is a preliminary
report that will lay our plan for our future endeavors.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.06608v2' target='_blank'>TIC: Translate-Infer-Compile for accurate "text to plan" using LLMs and
  Logical Representations</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sudhir Agarwal, Anu Sreepathy</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-09 18:39:13</h6>
<p class='card-text'>We study the problem of generating plans for given natural language planning
task requests. On one hand, LLMs excel at natural language processing but do
not perform well on planning. On the other hand, classical planning tools excel
at planning tasks but require input in a structured language such as the
Planning Domain Definition Language (PDDL). We leverage the strengths of both
the techniques by using an LLM for generating the PDDL representation (task
PDDL) of planning task requests followed by using a classical planner for
computing a plan. Unlike previous approaches that use LLMs for generating task
PDDLs directly, our approach comprises of (a) translate: using an LLM only for
generating a logically interpretable intermediate representation of natural
language task description, (b) infer: deriving additional logically dependent
information from the intermediate representation using a logic reasoner
(currently, Answer Set Programming solver), and (c) compile: generating the
target task PDDL from the base and inferred information. We observe that using
an LLM to only output the intermediate representation significantly reduces LLM
errors. Consequently, TIC approach achieves, for at least one LLM, high
accuracy on task PDDL generation for all seven domains of our evaluation
dataset.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.06596v1' target='_blank'>Understanding the Weakness of Large Language Model Agents within a
  Complex Android Environment</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mingzhe Xing, Rongkai Zhang, Hui Xue, Qi Chen, Fan Yang, Zhen Xiao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-09 18:19:25</h6>
<p class='card-text'>Large language models (LLMs) have empowered intelligent agents to execute
intricate tasks within domain-specific software such as browsers and games.
However, when applied to general-purpose software systems like operating
systems, LLM agents face three primary challenges. Firstly, the action space is
vast and dynamic, posing difficulties for LLM agents to maintain an up-to-date
understanding and deliver accurate responses. Secondly, real-world tasks often
require inter-application cooperation}, demanding farsighted planning from LLM
agents. Thirdly, agents need to identify optimal solutions aligning with user
constraints, such as security concerns and preferences. These challenges
motivate AndroidArena, an environment and benchmark designed to evaluate LLM
agents on a modern operating system. To address high-cost of manpower, we
design a scalable and semi-automated method to construct the benchmark. In the
task evaluation, AndroidArena incorporates accurate and adaptive metrics to
address the issue of non-unique solutions. Our findings reveal that even
state-of-the-art LLM agents struggle in cross-APP scenarios and adhering to
specific constraints. Additionally, we identify a lack of four key
capabilities, i.e., understanding, reasoning, exploration, and reflection, as
primary reasons for the failure of LLM agents. Furthermore, we provide
empirical analysis on the failure of reflection, and improve the success rate
by 27% with our proposed exploration strategy. This work is the first to
present valuable insights in understanding fine-grained weakness of LLM agents,
and offers a path forward for future research in this area. Environment,
benchmark, and evaluation code for AndroidArena are released at
https://github.com/AndroidArenaAgent/AndroidArena.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.06559v2' target='_blank'>Diffusion-ES: Gradient-free Planning with Diffusion for Autonomous
  Driving and Zero-Shot Instruction Following</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Brian Yang, Huangyuan Su, Nikolaos Gkanatsios, Tsung-Wei Ke, Ayush Jain, Jeff Schneider, Katerina Fragkiadaki</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-09 17:18:33</h6>
<p class='card-text'>Diffusion models excel at modeling complex and multimodal trajectory
distributions for decision-making and control. Reward-gradient guided denoising
has been recently proposed to generate trajectories that maximize both a
differentiable reward function and the likelihood under the data distribution
captured by a diffusion model. Reward-gradient guided denoising requires a
differentiable reward function fitted to both clean and noised samples,
limiting its applicability as a general trajectory optimizer. In this paper, we
propose DiffusionES, a method that combines gradient-free optimization with
trajectory denoising to optimize black-box non-differentiable objectives while
staying in the data manifold. Diffusion-ES samples trajectories during
evolutionary search from a diffusion model and scores them using a black-box
reward function. It mutates high-scoring trajectories using a truncated
diffusion process that applies a small number of noising and denoising steps,
allowing for much more efficient exploration of the solution space. We show
that DiffusionES achieves state-of-the-art performance on nuPlan, an
established closed-loop planning benchmark for autonomous driving. Diffusion-ES
outperforms existing sampling-based planners, reactive deterministic or
diffusion-based policies, and reward-gradient guidance. Additionally, we show
that unlike prior guidance methods, our method can optimize non-differentiable
language-shaped reward functions generated by few-shot LLM prompting. When
guided by a human teacher that issues instructions to follow, our method can
generate novel, highly complex behaviors, such as aggressive lane weaving,
which are not present in the training data. This allows us to solve the hardest
nuPlan scenarios which are beyond the capabilities of existing trajectory
optimization methods and driving policies.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.06529v4' target='_blank'>Introspective Planning: Aligning Robots' Uncertainty with Inherent Task
  Ambiguity</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kaiqu Liang, Zixu Zhang, Jaime Fernández Fisac</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-09 16:40:59</h6>
<p class='card-text'>Large language models (LLMs) exhibit advanced reasoning skills, enabling
robots to comprehend natural language instructions and strategically plan
high-level actions through proper grounding. However, LLM hallucination may
result in robots confidently executing plans that are misaligned with user
goals or even unsafe in critical scenarios. Additionally, inherent ambiguity in
natural language instructions can introduce uncertainty into the LLM's
reasoning and planning processes.We propose introspective planning, a
systematic approach that align LLM's uncertainty with the inherent ambiguity of
the task. Our approach constructs a knowledge base containing introspective
reasoning examples as post-hoc rationalizations of human-selected safe and
compliant plans, which are retrieved during deployment. Evaluations on three
tasks, including a newly introduced safe mobile manipulation benchmark,
demonstrate that introspection substantially improves both compliance and
safety over state-of-the-art LLM-based planning methods. Furthermore, we
empirically show that introspective planning, in combination with conformal
prediction, achieves tighter confidence bounds, maintaining statistical success
guarantees while minimizing unnecessary user clarification requests. The
webpage and code are accessible at https://introplan.github.io.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.07945v1' target='_blank'>ScreenAgent: A Vision Language Model-driven Computer Control Agent</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Runliang Niu, Jindong Li, Shiqi Wang, Yali Fu, Xiyu Hu, Xueyuan Leng, He Kong, Yi Chang, Qi Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-09 02:33:45</h6>
<p class='card-text'>Existing Large Language Models (LLM) can invoke a variety of tools and APIs
to complete complex tasks. The computer, as the most powerful and universal
tool, could potentially be controlled directly by a trained LLM agent. Powered
by the computer, we can hopefully build a more generalized agent to assist
humans in various daily digital works. In this paper, we construct an
environment for a Vision Language Model (VLM) agent to interact with a real
computer screen. Within this environment, the agent can observe screenshots and
manipulate the Graphics User Interface (GUI) by outputting mouse and keyboard
actions. We also design an automated control pipeline that includes planning,
acting, and reflecting phases, guiding the agent to continuously interact with
the environment and complete multi-step tasks. Additionally, we construct the
ScreenAgent Dataset, which collects screenshots and action sequences when
completing a variety of daily computer tasks. Finally, we trained a model,
ScreenAgent, which achieved computer control capabilities comparable to GPT-4V
and demonstrated more precise UI positioning capabilities. Our attempts could
inspire further research on building a generalist LLM agent. The code is
available at \url{https://github.com/niuzaisheng/ScreenAgent}.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.05932v2' target='_blank'>Driving Everywhere with Large Language Model Policy Adaptation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Boyi Li, Yue Wang, Jiageng Mao, Boris Ivanovic, Sushant Veer, Karen Leung, Marco Pavone</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-08 18:59:03</h6>
<p class='card-text'>Adapting driving behavior to new environments, customs, and laws is a
long-standing problem in autonomous driving, precluding the widespread
deployment of autonomous vehicles (AVs). In this paper, we present LLaDA, a
simple yet powerful tool that enables human drivers and autonomous vehicles
alike to drive everywhere by adapting their tasks and motion plans to traffic
rules in new locations. LLaDA achieves this by leveraging the impressive
zero-shot generalizability of large language models (LLMs) in interpreting the
traffic rules in the local driver handbook. Through an extensive user study, we
show that LLaDA's instructions are useful in disambiguating in-the-wild
unexpected situations. We also demonstrate LLaDA's ability to adapt AV motion
planning policies in real-world datasets; LLaDA outperforms baseline planning
approaches on all our metrics. Please check our website for more details:
https://boyiliee.github.io/llada.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.05741v2' target='_blank'>Real-World Robot Applications of Foundation Models: A Review</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kento Kawaharazuka, Tatsuya Matsushima, Andrew Gambardella, Jiaxian Guo, Chris Paxton, Andy Zeng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-08 15:19:50</h6>
<p class='card-text'>Recent developments in foundation models, like Large Language Models (LLMs)
and Vision-Language Models (VLMs), trained on extensive data, facilitate
flexible application across different tasks and modalities. Their impact spans
various fields, including healthcare, education, and robotics. This paper
provides an overview of the practical application of foundation models in
real-world robotics, with a primary emphasis on the replacement of specific
components within existing robot systems. The summary encompasses the
perspective of input-output relationships in foundation models, as well as
their role in perception, motion planning, and control within the field of
robotics. This paper concludes with a discussion of future challenges and
implications for practical robot applications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.05733v1' target='_blank'>TimeArena: Shaping Efficient Multitasking Language Agents in a
  Time-Aware Simulation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yikai Zhang, Siyu Yuan, Caiyu Hu, Kyle Richardson, Yanghua Xiao, Jiangjie Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-08 15:08:57</h6>
<p class='card-text'>Despite remarkable advancements in emulating human-like behavior through
Large Language Models (LLMs), current textual simulations do not adequately
address the notion of time. To this end, we introduce TimeArena, a novel
textual simulated environment that incorporates complex temporal dynamics and
constraints that better reflect real-life planning scenarios. In TimeArena,
agents are asked to complete multiple tasks as soon as possible, allowing for
parallel processing to save time. We implement the dependency between actions,
the time duration for each action, and the occupancy of the agent and the
objects in the environment. TimeArena grounds to 30 real-world tasks in
cooking, household activities, and laboratory work. We conduct extensive
experiments with various state-of-the-art LLMs using TimeArena. Our findings
reveal that even the most powerful models, e.g., GPT-4, still lag behind humans
in effective multitasking, underscoring the need for enhanced temporal
awareness in the development of language agents.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.05188v1' target='_blank'>InCoRo: In-Context Learning for Robotics Control with Feedback Loops</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiaqiang Ye Zhu, Carla Gomez Cano, David Vazquez Bermudez, Michal Drozdzal</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-07 19:01:11</h6>
<p class='card-text'>One of the challenges in robotics is to enable robotic units with the
reasoning capability that would be robust enough to execute complex tasks in
dynamic environments. Recent advances in LLMs have positioned them as go-to
tools for simple reasoning tasks, motivating the pioneering work of Liang et
al. [35] that uses an LLM to translate natural language commands into low-level
static execution plans for robotic units. Using LLMs inside robotics systems
brings their generalization to a new level, enabling zero-shot generalization
to new tasks. This paper extends this prior work to dynamic environments. We
propose InCoRo, a system that uses a classical robotic feedback loop composed
of an LLM controller, a scene understanding unit, and a robot. Our system
continuously analyzes the state of the environment and provides adapted
execution commands, enabling the robot to adjust to changing environmental
conditions and correcting for controller errors. Our system does not require
any iterative optimization to learn to accomplish a task as it leverages
in-context learning with an off-the-shelf LLM model. Through an extensive
validation process involving two standardized industrial robotic units -- SCARA
and DELTA types -- we contribute knowledge about these robots, not popular in
the community, thereby enriching it. We highlight the generalization
capabilities of our system and show that (1) in-context learning in combination
with the current state-of-the-art LLMs is an effective way to implement a
robotic controller; (2) in static environments, InCoRo surpasses the prior art
in terms of the success rate; (3) in dynamic environments, we establish new
state-of-the-art for the SCARA and DELTA units, respectively. This research
paves the way towards building reliable, efficient, intelligent autonomous
systems that adapt to dynamic environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.04975v1' target='_blank'>ChatScratch: An AI-Augmented System Toward Autonomous Visual Programming
  Learning for Children Aged 6-12</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Liuqing Chen, Shuhong Xiao, Yunnong Chen, Ruoyu Wu, Yaxuan Song, Lingyun Sun</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-07 15:55:51</h6>
<p class='card-text'>As Computational Thinking (CT) continues to permeate younger age groups in
K-12 education, established CT platforms such as Scratch face challenges in
catering to these younger learners, particularly those in the elementary school
(ages 6-12). Through formative investigation with Scratch experts, we uncover
three key obstacles to children's autonomous Scratch learning: artist's block
in project planning, bounded creativity in asset creation, and inadequate
coding guidance during implementation. To address these barriers, we introduce
ChatScratch, an AI-augmented system to facilitate autonomous programming
learning for young children. ChatScratch employs structured interactive
storyboards and visual cues to overcome artist's block, integrates digital
drawing and advanced image generation technologies to elevate creativity, and
leverages Scratch-specialized Large Language Models (LLMs) for professional
coding guidance. Our study shows that, compared to Scratch, ChatScratch
efficiently fosters autonomous programming learning, and contributes to the
creation of high-quality, personally meaningful Scratch projects for children.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.04631v1' target='_blank'>The Future of Cognitive Strategy-enhanced Persuasive Dialogue Agents:
  New Perspectives and Trends</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mengqi Chen, Bin Guo, Hao Wang, Haoyu Li, Qian Zhao, Jingqi Liu, Yasan Ding, Yan Pan, Zhiwen Yu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-07 07:28:34</h6>
<p class='card-text'>Persuasion, as one of the crucial abilities in human communication, has
garnered extensive attention from researchers within the field of intelligent
dialogue systems. We humans tend to persuade others to change their viewpoints,
attitudes or behaviors through conversations in various scenarios (e.g.,
persuasion for social good, arguing in online platforms). Developing dialogue
agents that can persuade others to accept certain standpoints is essential to
achieving truly intelligent and anthropomorphic dialogue system. Benefiting
from the substantial progress of Large Language Models (LLMs), dialogue agents
have acquired an exceptional capability in context understanding and response
generation. However, as a typical and complicated cognitive psychological
system, persuasive dialogue agents also require knowledge from the domain of
cognitive psychology to attain a level of human-like persuasion. Consequently,
the cognitive strategy-enhanced persuasive dialogue agent (defined as
CogAgent), which incorporates cognitive strategies to achieve persuasive
targets through conversation, has become a predominant research paradigm. To
depict the research trends of CogAgent, in this paper, we first present several
fundamental cognitive psychology theories and give the formalized definition of
three typical cognitive strategies, including the persuasion strategy, the
topic path planning strategy, and the argument structure prediction strategy.
Then we propose a new system architecture by incorporating the formalized
definition to lay the foundation of CogAgent. Representative works are detailed
and investigated according to the combined cognitive strategy, followed by the
summary of authoritative benchmarks and evaluation metrics. Finally, we
summarize our insights on open issues and future directions of CogAgent for
upcoming researchers.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.03755v1' target='_blank'>QuantAgent: Seeking Holy Grail in Trading by Self-Improving Large
  Language Model</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Saizhuo Wang, Hang Yuan, Lionel M. Ni, Jian Guo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-06 06:47:14</h6>
<p class='card-text'>Autonomous agents based on Large Language Models (LLMs) that devise plans and
tackle real-world challenges have gained prominence.However, tailoring these
agents for specialized domains like quantitative investment remains a
formidable task. The core challenge involves efficiently building and
integrating a domain-specific knowledge base for the agent's learning process.
This paper introduces a principled framework to address this challenge,
comprising a two-layer loop.In the inner loop, the agent refines its responses
by drawing from its knowledge base, while in the outer loop, these responses
are tested in real-world scenarios to automatically enhance the knowledge base
with new insights.We demonstrate that our approach enables the agent to
progressively approximate optimal behavior with provable
efficiency.Furthermore, we instantiate this framework through an autonomous
agent for mining trading signals named QuantAgent. Empirical results showcase
QuantAgent's capability in uncovering viable financial signals and enhancing
the accuracy of financial forecasts.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.03616v1' target='_blank'>Leveraging Large Language Models for Hybrid Workplace Decision Support</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yujin Kim, Chin-Chia Hsu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-06 01:05:14</h6>
<p class='card-text'>Large Language Models (LLMs) hold the potential to perform a variety of text
processing tasks and provide textual explanations for proposed actions or
decisions. In the era of hybrid work, LLMs can provide intelligent decision
support for workers who are designing their hybrid work plans. In particular,
they can offer suggestions and explanations to workers balancing numerous
decision factors, thereby enhancing their work experience. In this paper, we
present a decision support model for workspaces in hybrid work environments,
leveraging the reasoning skill of LLMs. We first examine LLM's capability of
making suitable workspace suggestions. We find that its reasoning extends
beyond the guidelines in the prompt and the LLM can manage the trade-off among
the available resources in the workspaces. We conduct an extensive user study
to understand workers' decision process for workspace choices and evaluate the
effectiveness of the system. We observe that a worker's decision could be
influenced by the LLM's suggestions and explanations. The participants in our
study find the system to be convenient, regardless of whether reasons are
provided or not. Our results show that employees can benefit from the
LLM-empowered system for their workspace selection in hybrid workplace.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.03610v1' target='_blank'>RAP: Retrieval-Augmented Planning with Contextual Memory for Multimodal
  LLM Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tomoyuki Kagaya, Thong Jing Yuan, Yuxuan Lou, Jayashree Karlekar, Sugiri Pranata, Akira Kinose, Koki Oguri, Felix Wick, Yang You</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-06 00:53:27</h6>
<p class='card-text'>Owing to recent advancements, Large Language Models (LLMs) can now be
deployed as agents for increasingly complex decision-making applications in
areas including robotics, gaming, and API integration. However, reflecting past
experiences in current decision-making processes, an innate human behavior,
continues to pose significant challenges. Addressing this, we propose
Retrieval-Augmented Planning (RAP) framework, designed to dynamically leverage
past experiences corresponding to the current situation and context, thereby
enhancing agents' planning capabilities. RAP distinguishes itself by being
versatile: it excels in both text-only and multimodal environments, making it
suitable for a wide range of tasks. Empirical evaluations demonstrate RAP's
effectiveness, where it achieves SOTA performance in textual scenarios and
notably enhances multimodal LLM agents' performance for embodied tasks. These
results highlight RAP's potential in advancing the functionality and
applicability of LLM agents in complex, real-world applications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.03271v3' target='_blank'>Uncertainty of Thoughts: Uncertainty-Aware Planning Enhances Information
  Seeking in Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhiyuan Hu, Chumin Liu, Xidong Feng, Yilun Zhao, See-Kiong Ng, Anh Tuan Luu, Junxian He, Pang Wei Koh, Bryan Hooi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-05 18:28:44</h6>
<p class='card-text'>In the face of uncertainty, the ability to *seek information* is of
fundamental importance. In many practical applications, such as medical
diagnosis and troubleshooting, the information needed to solve the task is not
initially given and has to be actively sought by asking follow-up questions
(for example, a doctor asking a patient for more details about their symptoms).
In this work, we introduce Uncertainty of Thoughts (UoT), an algorithm to
augment large language models with the ability to actively seek information by
asking effective questions. UoT combines 1) an *uncertainty-aware simulation
approach* which enables the model to simulate possible future scenarios and how
likely they are to occur, 2) *uncertainty-based rewards* motivated by
information gain which incentivizes the model to seek information, and 3) a
*reward propagation scheme* to select the optimal question to ask in a way that
maximizes the expected reward. In experiments on medical diagnosis,
troubleshooting, and the `20 Questions` game, UoT achieves an average
performance improvement of 38.1% in the rate of successful task completion
across multiple LLMs compared with direct prompting and also improves
efficiency (i.e., the number of questions needed to complete the task). Our
code has been released [here](https://github.com/zhiyuanhubj/UoT)</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.02805v2' target='_blank'>Graph-enhanced Large Language Models in Asynchronous Plan Reasoning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Fangru Lin, Emanuele La Malfa, Valentin Hofmann, Elle Michelle Yang, Anthony Cohn, Janet B. Pierrehumbert</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-05 08:26:33</h6>
<p class='card-text'>Planning is a fundamental property of human intelligence. Reasoning about
asynchronous plans is challenging since it requires sequential and parallel
planning to optimize time costs. Can large language models (LLMs) succeed at
this task? Here, we present the first large-scale study investigating this
question. We find that a representative set of closed and open-source LLMs,
including GPT-4 and LLaMA-2, behave poorly when not supplied with illustrations
about the task-solving process in our benchmark AsyncHow. We propose a novel
technique called Plan Like a Graph (PLaG) that combines graphs with natural
language prompts and achieves state-of-the-art results. We show that although
PLaG can boost model performance, LLMs still suffer from drastic degradation
when task complexity increases, highlighting the limits of utilizing LLMs for
simulating digital devices. We see our study as an exciting step towards using
LLMs as efficient autonomous agents. Our code and data are available at
https://github.com/fangru-lin/graph-llm-asynchow-plan.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.02716v1' target='_blank'>Understanding the planning of LLM agents: A survey</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xu Huang, Weiwen Liu, Xiaolong Chen, Xingmei Wang, Hao Wang, Defu Lian, Yasheng Wang, Ruiming Tang, Enhong Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-05 04:25:24</h6>
<p class='card-text'>As Large Language Models (LLMs) have shown significant intelligence, the
progress to leverage LLMs as planning modules of autonomous agents has
attracted more attention. This survey provides the first systematic view of
LLM-based agents planning, covering recent works aiming to improve planning
ability. We provide a taxonomy of existing works on LLM-Agent planning, which
can be categorized into Task Decomposition, Plan Selection, External Module,
Reflection and Memory. Comprehensive analyses are conducted for each direction,
and further challenges for the field of research are discussed.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.01874v1' target='_blank'>The RL/LLM Taxonomy Tree: Reviewing Synergies Between Reinforcement
  Learning and Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Moschoula Pternea, Prerna Singh, Abir Chakraborty, Yagna Oruganti, Mirco Milletari, Sayli Bapat, Kebei Jiang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-02 20:01:15</h6>
<p class='card-text'>In this work, we review research studies that combine Reinforcement Learning
(RL) and Large Language Models (LLMs), two areas that owe their momentum to the
development of deep neural networks. We propose a novel taxonomy of three main
classes based on the way that the two model types interact with each other. The
first class, RL4LLM, includes studies where RL is leveraged to improve the
performance of LLMs on tasks related to Natural Language Processing. L4LLM is
divided into two sub-categories depending on whether RL is used to directly
fine-tune an existing LLM or to improve the prompt of the LLM. In the second
class, LLM4RL, an LLM assists the training of an RL model that performs a task
that is not inherently related to natural language. We further break down
LLM4RL based on the component of the RL training framework that the LLM assists
or replaces, namely reward shaping, goal generation, and policy function.
Finally, in the third class, RL+LLM, an LLM and an RL agent are embedded in a
common planning framework without either of them contributing to training or
fine-tuning of the other. We further branch this class to distinguish between
studies with and without natural language feedback. We use this taxonomy to
explore the motivations behind the synergy of LLMs and RL and explain the
reasons for its success, while pinpointing potential shortcomings and areas
where further research is needed, as well as alternative methodologies that
serve the same goal.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.01622v4' target='_blank'>TravelPlanner: A Benchmark for Real-World Planning with Language Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jian Xie, Kai Zhang, Jiangjie Chen, Tinghui Zhu, Renze Lou, Yuandong Tian, Yanghua Xiao, Yu Su</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-02 18:39:51</h6>
<p class='card-text'>Planning has been part of the core pursuit for artificial intelligence since
its conception, but earlier AI agents mostly focused on constrained settings
because many of the cognitive substrates necessary for human-level planning
have been lacking. Recently, language agents powered by large language models
(LLMs) have shown interesting capabilities such as tool use and reasoning. Are
these language agents capable of planning in more complex settings that are out
of the reach of prior AI agents? To advance this investigation, we propose
TravelPlanner, a new planning benchmark that focuses on travel planning, a
common real-world planning scenario. It provides a rich sandbox environment,
various tools for accessing nearly four million data records, and 1,225
meticulously curated planning intents and reference plans. Comprehensive
evaluations show that the current language agents are not yet capable of
handling such complex planning tasks-even GPT-4 only achieves a success rate of
0.6%. Language agents struggle to stay on task, use the right tools to collect
information, or keep track of multiple constraints. However, we note that the
mere possibility for language agents to tackle such a complex problem is in
itself non-trivial progress. TravelPlanner provides a challenging yet
meaningful testbed for future language agents.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.01586v4' target='_blank'>TrustAgent: Towards Safe and Trustworthy LLM-based Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wenyue Hua, Xianjun Yang, Mingyu Jin, Zelong Li, Wei Cheng, Ruixiang Tang, Yongfeng Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-02 17:26:23</h6>
<p class='card-text'>The rise of LLM-based agents shows great potential to revolutionize task
planning, capturing significant attention. Given that these agents will be
integrated into high-stake domains, ensuring their reliability and safety is
crucial. This paper presents an Agent-Constitution-based agent framework,
TrustAgent, with a particular focus on improving the LLM-based agent safety.
The proposed framework ensures strict adherence to the Agent Constitution
through three strategic components: pre-planning strategy which injects safety
knowledge to the model before plan generation, in-planning strategy which
enhances safety during plan generation, and post-planning strategy which
ensures safety by post-planning inspection. Our experimental results
demonstrate that the proposed framework can effectively enhance an LLM agent's
safety across multiple domains by identifying and mitigating potential dangers
during the planning. Further analysis reveals that the framework not only
improves safety but also enhances the helpfulness of the agent. Additionally,
we highlight the importance of the LLM reasoning ability in adhering to the
Constitution. This paper sheds light on how to ensure the safe integration of
LLM-based agents into human-centric environments. Data and code are available
at https://github.com/agiresearch/TrustAgent.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.01817v3' target='_blank'>LLMs Can't Plan, But Can Help Planning in LLM-Modulo Frameworks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Subbarao Kambhampati, Karthik Valmeekam, Lin Guan, Mudit Verma, Kaya Stechly, Siddhant Bhambri, Lucas Saldyt, Anil Murthy</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-02 14:43:18</h6>
<p class='card-text'>There is considerable confusion about the role of Large Language Models
(LLMs) in planning and reasoning tasks. On one side are over-optimistic claims
that LLMs can indeed do these tasks with just the right prompting or
self-verification strategies. On the other side are perhaps over-pessimistic
claims that all that LLMs are good for in planning/reasoning tasks are as mere
translators of the problem specification from one syntactic format to another,
and ship the problem off to external symbolic solvers. In this position paper,
we take the view that both these extremes are misguided. We argue that
auto-regressive LLMs cannot, by themselves, do planning or self-verification
(which is after all a form of reasoning), and shed some light on the reasons
for misunderstandings in the literature. We will also argue that LLMs should be
viewed as universal approximate knowledge sources that have much more
meaningful roles to play in planning/reasoning tasks beyond simple
front-end/back-end format translators. We present a vision of {\bf LLM-Modulo
Frameworks} that combine the strengths of LLMs with external model-based
verifiers in a tighter bi-directional interaction regime. We will show how the
models driving the external verifiers themselves can be acquired with the help
of LLMs. We will also argue that rather than simply pipelining LLMs and
symbolic components, this LLM-Modulo Framework provides a better neuro-symbolic
approach that offers tighter integration between LLMs and symbolic components,
and allows extending the scope of model-based planning/reasoning regimes
towards more flexible knowledge, problem and preference specifications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.01135v1' target='_blank'>A Multi-Agent Conversational Recommender System</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiabao Fang, Shen Gao, Pengjie Ren, Xiuying Chen, Suzan Verberne, Zhaochun Ren</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-02 04:20:13</h6>
<p class='card-text'>Due to strong capabilities in conducting fluent, multi-turn conversations
with users, Large Language Models (LLMs) have the potential to further improve
the performance of Conversational Recommender System (CRS). Unlike the aimless
chit-chat that LLM excels at, CRS has a clear target. So it is imperative to
control the dialogue flow in the LLM to successfully recommend appropriate
items to the users. Furthermore, user feedback in CRS can assist the system in
better modeling user preferences, which has been ignored by existing studies.
However, simply prompting LLM to conduct conversational recommendation cannot
address the above two key challenges.
  In this paper, we propose Multi-Agent Conversational Recommender System
(MACRS) which contains two essential modules. First, we design a multi-agent
act planning framework, which can control the dialogue flow based on four
LLM-based agents. This cooperative multi-agent framework will generate various
candidate responses based on different dialogue acts and then choose the most
appropriate response as the system response, which can help MACRS plan suitable
dialogue acts. Second, we propose a user feedback-aware reflection mechanism
which leverages user feedback to reason errors made in previous turns to adjust
the dialogue act planning, and higher-level user information from implicit
semantics. We conduct extensive experiments based on user simulator to
demonstrate the effectiveness of MACRS in recommendation and user preferences
collection. Experimental results illustrate that MACRS demonstrates an
improvement in user interaction experience compared to directly using LLMs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.01053v1' target='_blank'>Plan-Grounded Large Language Models for Dual Goal Conversational
  Settings</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Diogo Glória-Silva, Rafael Ferreira, Diogo Tavares, David Semedo, João Magalhães</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-01 22:56:39</h6>
<p class='card-text'>Training Large Language Models (LLMs) to follow user instructions has been
shown to supply the LLM with ample capacity to converse fluently while being
aligned with humans. Yet, it is not completely clear how an LLM can lead a
plan-grounded conversation in mixed-initiative settings where instructions flow
in both directions of the conversation, i.e. both the LLM and the user provide
instructions to one another. In this paper, we tackle a dual goal
mixed-initiative conversational setting where the LLM not only grounds the
conversation on an arbitrary plan but also seeks to satisfy both a procedural
plan and user instructions. The LLM is then responsible for guiding the user
through the plan and, at the same time, adapting to new circumstances,
answering questions, and activating safety guardrails when needed. We propose a
novel LLM that grounds the dialogue on a procedural plan, can take the dialogue
initiative, and enforces guardrails on the system's behavior, while also
improving the LLM's responses to unexpected user behavior. Experiments in
controlled settings and with real users show that the best-performing model,
which we call PlanLLM, achieves a 2.1x improvement over a strong baseline.
Moreover, experiments also show good generalization to unseen domains.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.01786v2' target='_blank'>COA-GPT: Generative Pre-trained Transformers for Accelerated Course of
  Action Development in Military Operations</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Vinicius G. Goecks, Nicholas Waytowich</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-01 21:51:09</h6>
<p class='card-text'>The development of Courses of Action (COAs) in military operations is
traditionally a time-consuming and intricate process. Addressing this
challenge, this study introduces COA-GPT, a novel algorithm employing Large
Language Models (LLMs) for rapid and efficient generation of valid COAs.
COA-GPT incorporates military doctrine and domain expertise to LLMs through
in-context learning, allowing commanders to input mission information - in both
text and image formats - and receive strategically aligned COAs for review and
approval. Uniquely, COA-GPT not only accelerates COA development, producing
initial COAs within seconds, but also facilitates real-time refinement based on
commander feedback. This work evaluates COA-GPT in a military-relevant scenario
within a militarized version of the StarCraft II game, comparing its
performance against state-of-the-art reinforcement learning algorithms. Our
results demonstrate COA-GPT's superiority in generating strategically sound
COAs more swiftly, with added benefits of enhanced adaptability and alignment
with commander intentions. COA-GPT's capability to rapidly adapt and update
COAs during missions presents a transformative potential for military planning,
particularly in addressing planning discrepancies and capitalizing on emergent
windows of opportunities.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.00798v4' target='_blank'>Formal-LLM: Integrating Formal Language and Natural Language for
  Controllable LLM-based Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zelong Li, Wenyue Hua, Hao Wang, He Zhu, Yongfeng Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-01 17:30:50</h6>
<p class='card-text'>Recent advancements on Large Language Models (LLMs) enable AI Agents to
automatically generate and execute multi-step plans to solve complex tasks.
However, since LLM's content generation process is hardly controllable, current
LLM-based agents frequently generate invalid or non-executable plans, which
jeopardizes the performance of the generated plans and corrupts users' trust in
LLM-based agents. In response, this paper proposes a novel "Formal-LLM"
framework for LLM-based agents by integrating the expressiveness of natural
language and the precision of formal language. Specifically, the framework
allows agent developers to express their requirements or constraints for the
planning process as an automaton. A stack-based LLM plan generation process is
then conducted under the supervision of the automaton to ensure that the
generated plan satisfies the constraints, making the planning process
controllable. We conduct experiments on both benchmark tasks and practical
real-life tasks, and our framework achieves over 50% overall performance
increase, which validates the feasibility and effectiveness of employing
Formal-LLM to guide the plan generation of agents, preventing the agents from
generating invalid and unsuccessful plans. Further, more controllable LLM-based
agents can facilitate the broader utilization of LLM in application scenarios
where high validity of planning is essential. The source code of this work is
available at https://github.com/agiresearch/Formal-LLM.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.00658v3' target='_blank'>Learning Planning-based Reasoning by Trajectories Collection and Process
  Reward Synthesizing</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Fangkai Jiao, Chengwei Qin, Zhengyuan Liu, Nancy F. Chen, Shafiq Joty</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-01 15:18:33</h6>
<p class='card-text'>Large Language Models (LLMs) have demonstrated significant potential in
handling complex reasoning tasks through step-by-step rationale generation.
However, recent studies have raised concerns regarding the hallucination and
flaws in their reasoning process. Substantial efforts are being made to improve
the reliability and faithfulness of the generated rationales. Some approaches
model reasoning as planning, while others focus on annotating for process
supervision. Nevertheless, the planning-based search process often results in
high latency due to the frequent assessment of intermediate reasoning states
and the extensive exploration space. Additionally, supervising the reasoning
process with human annotation is costly and challenging to scale for LLM
training. To address these issues, in this paper, we propose a framework to
learn planning-based reasoning through Direct Preference Optimization (DPO) on
collected trajectories, which are ranked according to synthesized process
rewards. Our results on challenging logical reasoning benchmarks demonstrate
the effectiveness of our learning framework, showing that our 7B model can
surpass the strong counterparts like GPT-3.5-Turbo.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.00251v1' target='_blank'>Efficient Non-Parametric Uncertainty Quantification for Black-Box Large
  Language Models and Decision Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yao-Hung Hubert Tsai, Walter Talbott, Jian Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-02-01 00:23:31</h6>
<p class='card-text'>Step-by-step decision planning with large language models (LLMs) is gaining
attention in AI agent development. This paper focuses on decision planning with
uncertainty estimation to address the hallucination problem in language models.
Existing approaches are either white-box or computationally demanding, limiting
use of black-box proprietary LLMs within budgets. The paper's first
contribution is a non-parametric uncertainty quantification method for LLMs,
efficiently estimating point-wise dependencies between input-decision on the
fly with a single inference, without access to token logits. This estimator
informs the statistical interpretation of decision trustworthiness. The second
contribution outlines a systematic design for a decision-making agent,
generating actions like ``turn on the bathroom light'' based on user prompts
such as ``take a bath''. Users will be asked to provide preferences when more
than one action has high estimated point-wise dependencies. In conclusion, our
uncertainty estimation and decision-making agent design offer a cost-efficient
approach for AI agent development.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.18070v2' target='_blank'>Do Language Models Exhibit the Same Cognitive Biases in Problem Solving
  as Human Learners?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Andreas Opedal, Alessandro Stolfo, Haruki Shirakami, Ying Jiao, Ryan Cotterell, Bernhard Schölkopf, Abulhair Saparov, Mrinmaya Sachan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-31 18:48:20</h6>
<p class='card-text'>There is increasing interest in employing large language models (LLMs) as
cognitive models. For such purposes, it is central to understand which
properties of human cognition are well-modeled by LLMs, and which are not. In
this work, we study the biases of LLMs in relation to those known in children
when solving arithmetic word problems. Surveying the learning science
literature, we posit that the problem-solving process can be split into three
distinct steps: text comprehension, solution planning and solution execution.
We construct tests for each one in order to understand whether current LLMs
display the same cognitive biases as children in these steps. We generate a
novel set of word problems for each of these tests, using a neuro-symbolic
approach that enables fine-grained control over the problem features. We find
evidence that LLMs, with and without instruction-tuning, exhibit human-like
biases in both the text-comprehension and the solution-planning steps of the
solving process, but not in the final step, in which the arithmetic expressions
are executed to obtain the answer.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.17858v1' target='_blank'>Probing Language Models' Gesture Understanding for Enhanced Human-AI
  Interaction</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Philipp Wicke</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-31 14:19:03</h6>
<p class='card-text'>The rise of Large Language Models (LLMs) has affected various disciplines
that got beyond mere text generation. Going beyond their textual nature, this
project proposal aims to investigate the interaction between LLMs and
non-verbal communication, specifically focusing on gestures. The proposal sets
out a plan to examine the proficiency of LLMs in deciphering both explicit and
implicit non-verbal cues within textual prompts and their ability to associate
these gestures with various contextual factors. The research proposes to test
established psycholinguistic study designs to construct a comprehensive dataset
that pairs textual prompts with detailed gesture descriptions, encompassing
diverse regional variations, and semantic labels. To assess LLMs' comprehension
of gestures, experiments are planned, evaluating their ability to simulate
human behaviour in order to replicate psycholinguistic experiments. These
experiments consider cultural dimensions and measure the agreement between
LLM-identified gestures and the dataset, shedding light on the models'
contextual interpretation of non-verbal cues (e.g. gestures).</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.17464v3' target='_blank'>Efficient Tool Use with Chain-of-Abstraction Reasoning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Silin Gao, Jane Dwivedi-Yu, Ping Yu, Xiaoqing Ellen Tan, Ramakanth Pasunuru, Olga Golovneva, Koustuv Sinha, Asli Celikyilmaz, Antoine Bosselut, Tianlu Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-30 21:53:30</h6>
<p class='card-text'>To achieve faithful reasoning that aligns with human expectations, large
language models (LLMs) need to ground their reasoning to real-world knowledge
(e.g., web facts, math and physical rules). Tools help LLMs access this
external knowledge, but there remains challenges for fine-tuning LLM agents
(e.g., Toolformer) to invoke tools in multi-step reasoning problems, where
inter-connected tool calls require holistic and efficient tool usage planning.
  In this work, we propose a new method for LLMs to better leverage tools in
multi-step reasoning. Our method, Chain-of-Abstraction (CoA), trains LLMs to
first decode reasoning chains with abstract placeholders, and then call domain
tools to reify each reasoning chain by filling in specific knowledge. This
planning with abstract chains enables LLMs to learn more general reasoning
strategies, which are robust to shifts of domain knowledge (e.g., math results)
relevant to different reasoning questions. It also allows LLMs to perform
decoding and calling of external tools in parallel, which avoids the inference
delay caused by waiting for tool responses. In mathematical reasoning and Wiki
QA domains, we show that our method consistently outperforms previous
chain-of-thought and tool-augmented baselines on both in-distribution and
out-of-distribution test sets, with an average ~6% absolute QA accuracy
improvement. LLM agents trained with our method also show more efficient tool
use, with inference speed being on average ~1.4x faster than baseline
tool-augmented LLMs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.17167v3' target='_blank'>Planning, Creation, Usage: Benchmarking LLMs for Comprehensive Tool
  Utilization in Real-World Complex Scenarios</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shijue Huang, Wanjun Zhong, Jianqiao Lu, Qi Zhu, Jiahui Gao, Weiwen Liu, Yutai Hou, Xingshan Zeng, Yasheng Wang, Lifeng Shang, Xin Jiang, Ruifeng Xu, Qun Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-30 16:52:56</h6>
<p class='card-text'>The recent trend of using Large Language Models (LLMs) as tool agents in
real-world applications underscores the necessity for comprehensive evaluations
of their capabilities, particularly in complex scenarios involving planning,
creating, and using tools. However, existing benchmarks typically focus on
simple synthesized queries that do not reflect real-world complexity, thereby
offering limited perspectives in evaluating tool utilization. To address this
issue, we present UltraTool, a novel benchmark designed to improve and evaluate
LLMs' ability in tool utilization within real-world scenarios. UltraTool
focuses on the entire process of using tools - from planning and creating to
applying them in complex tasks. It emphasizes real-world complexities,
demanding accurate, multi-step planning for effective problem-solving. A key
feature of UltraTool is its independent evaluation of planning with natural
language, which happens before tool usage and simplifies the task solving by
mapping out the intermediate steps. Thus, unlike previous work, it eliminates
the restriction of pre-defined toolset. Through extensive experiments on
various LLMs, we offer novel insights into the evaluation of capabilities of
LLMs in tool utilization, thereby contributing a fresh perspective to this
rapidly evolving field. The benchmark is publicly available at
https://github.com/JoeYing1019/UltraTool.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.16578v3' target='_blank'>Leveraging Professional Radiologists' Expertise to Enhance LLMs'
  Evaluation for Radiology Reports</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Qingqing Zhu, Xiuying Chen, Qiao Jin, Benjamin Hou, Tejas Sudharshan Mathai, Pritam Mukherjee, Xin Gao, Ronald M Summers, Zhiyong Lu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-29 21:24:43</h6>
<p class='card-text'>In radiology, Artificial Intelligence (AI) has significantly advanced report
generation, but automatic evaluation of these AI-produced reports remains
challenging. Current metrics, such as Conventional Natural Language Generation
(NLG) and Clinical Efficacy (CE), often fall short in capturing the semantic
intricacies of clinical contexts or overemphasize clinical details, undermining
report clarity. To overcome these issues, our proposed method synergizes the
expertise of professional radiologists with Large Language Models (LLMs), like
GPT-3.5 and GPT-4 1. Utilizing In-Context Instruction Learning (ICIL) and Chain
of Thought (CoT) reasoning, our approach aligns LLM evaluations with
radiologist standards, enabling detailed comparisons between human and AI
generated reports. This is further enhanced by a Regression model that
aggregates sentence evaluation scores. Experimental results show that our
"Detailed GPT-4 (5-shot)" model achieves a 0.48 score, outperforming the METEOR
metric by 0.19, while our "Regressed GPT-4" model shows even greater alignment
with expert evaluations, exceeding the best existing metric by a 0.35 margin.
Moreover, the robustness of our explanations has been validated through a
thorough iterative strategy. We plan to publicly release annotations from
radiology experts, setting a new standard for accuracy in future assessments.
This underscores the potential of our approach in enhancing the quality
assessment of AI-driven medical reports.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.16158v2' target='_blank'>Mobile-Agent: Autonomous Multi-Modal Mobile Device Agent with Visual
  Perception</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Junyang Wang, Haiyang Xu, Jiabo Ye, Ming Yan, Weizhou Shen, Ji Zhang, Fei Huang, Jitao Sang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-29 13:46:37</h6>
<p class='card-text'>Mobile device agent based on Multimodal Large Language Models (MLLM) is
becoming a popular application. In this paper, we introduce Mobile-Agent, an
autonomous multi-modal mobile device agent. Mobile-Agent first leverages visual
perception tools to accurately identify and locate both the visual and textual
elements within the app's front-end interface. Based on the perceived vision
context, it then autonomously plans and decomposes the complex operation task,
and navigates the mobile Apps through operations step by step. Different from
previous solutions that rely on XML files of Apps or mobile system metadata,
Mobile-Agent allows for greater adaptability across diverse mobile operating
environments in a vision-centric way, thereby eliminating the necessity for
system-specific customizations. To assess the performance of Mobile-Agent, we
introduced Mobile-Eval, a benchmark for evaluating mobile device operations.
Based on Mobile-Eval, we conducted a comprehensive evaluation of Mobile-Agent.
The experimental results indicate that Mobile-Agent achieved remarkable
accuracy and completion rates. Even with challenging instructions, such as
multi-app operations, Mobile-Agent can still complete the requirements. Code
and model will be open-sourced at https://github.com/X-PLUG/MobileAgent.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.15940v3' target='_blank'>Knowledge-Aware Code Generation with Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tao Huang, Zhihong Sun, Zhi Jin, Ge Li, Chen Lyu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-29 08:01:22</h6>
<p class='card-text'>Large Language Models (LLMs) perform well on basic programming problems.
However, they encounter challenges when dealing with complex tasks involving
the use of diverse algorithmic and data structure skills, particularly
programming competition-level problems. Notably, ChatGPT exhibits proficient
performance on problems it has encountered during its pre-training phase, but
this performance deteriorates when faced with novel problems. Consequently,
enhancing the ability of LLMs to address unfamiliar problems has emerged as a
pivotal research focus. The problem-solving process of LLMs mirrors human
programmers' approach to a certain extent. When confronted with new programming
tasks, human programmers engage in task planning and code writing with the
previously acquired knowledge about algorithms and data structures. Despite
having learned such knowledge, LLMs struggle to effectively apply it when faced
with specific new problems. To address this issue, we constructed a novel
dataset, CodeF, which contains a portion of programming problems that ChatGPT
has not previously encountered. Furthermore, we developed a Knowledge Library
tailored for Python programming contest problems and introduced the concept of
Knowledge-Aware Code Generation (KareCoder). KareCoder bolsters the models'
understanding and problem-solving capabilities by integrating prompt and
knowledge from the library into the LLMs' code generation reasoning process,
especially on Pass@1 metrics. Upon testing on the CodeF and APPS datasets,
KareCoder demonstrated outstanding performance in handling novel problems
previously unencountered by LLMs. In contrast with the code directly generated
by ChatGPT, KareCoder achieved a relative improvement of 23.3% on the Pass@1
metric on the CodeF post2021-9 dataset. Additionally, it performs well compared
to other methods when dealing with problems that LLMs have previously
encountered.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.15688v2' target='_blank'>Divide and Conquer: Language Models can Plan and Self-Correct for
  Compositional Text-to-Image Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhenyu Wang, Enze Xie, Aoxue Li, Zhongdao Wang, Xihui Liu, Zhenguo Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-28 16:18:39</h6>
<p class='card-text'>Despite significant advancements in text-to-image models for generating
high-quality images, these methods still struggle to ensure the controllability
of text prompts over images in the context of complex text prompts, especially
when it comes to retaining object attributes and relationships. In this paper,
we propose CompAgent, a training-free approach for compositional text-to-image
generation, with a large language model (LLM) agent as its core. The
fundamental idea underlying CompAgent is premised on a divide-and-conquer
methodology. Given a complex text prompt containing multiple concepts including
objects, attributes, and relationships, the LLM agent initially decomposes it,
which entails the extraction of individual objects, their associated
attributes, and the prediction of a coherent scene layout. These individual
objects can then be independently conquered. Subsequently, the agent performs
reasoning by analyzing the text, plans and employs the tools to compose these
isolated objects. The verification and human feedback mechanism is finally
incorporated into our agent to further correct the potential attribute errors
and refine the generated images. Guided by the LLM agent, we propose a
tuning-free multi-concept customization model and a layout-to-image generation
model as the tools for concept composition, and a local image editing method as
the tool to interact with the agent for verification. The scene layout controls
the image generation process among these tools to prevent confusion among
multiple objects. Extensive experiments demonstrate the superiority of our
approach for compositional text-to-image generation: CompAgent achieves more
than 10\% improvement on T2I-CompBench, a comprehensive benchmark for
open-world compositional T2I generation. The extension to various related tasks
also illustrates the flexibility of our CompAgent for potential applications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.15006v2' target='_blank'>Airavata: Introducing Hindi Instruction-tuned LLM</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jay Gala, Thanmay Jayakumar, Jaavid Aktar Husain, Aswanth Kumar M, Mohammed Safi Ur Rahman Khan, Diptesh Kanojia, Ratish Puduppully, Mitesh M. Khapra, Raj Dabre, Rudra Murthy, Anoop Kunchukuttan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-26 17:07:08</h6>
<p class='card-text'>We announce the initial release of "Airavata," an instruction-tuned LLM for
Hindi. Airavata was created by fine-tuning OpenHathi with diverse,
instruction-tuning Hindi datasets to make it better suited for assistive tasks.
Along with the model, we also share the IndicInstruct dataset, which is a
collection of diverse instruction-tuning datasets to enable further research
for Indic LLMs. Additionally, we present evaluation benchmarks and a framework
for assessing LLM performance across tasks in Hindi. Currently, Airavata
supports Hindi, but we plan to expand this to all 22 scheduled Indic languages.
You can access all artifacts at https://ai4bharat.github.io/airavata.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.14295v4' target='_blank'>Demystifying Chains, Trees, and Graphs of Thoughts</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Maciej Besta, Florim Memedi, Zhenyu Zhang, Robert Gerstenberger, Guangyuan Piao, Nils Blach, Piotr Nyczyk, Marcin Copik, Grzegorz Kwaśniewski, Jürgen Müller, Lukas Gianinazzi, Ales Kubicek, Hubert Niewiadomski, Aidan O'Mahony, Onur Mutlu, Torsten Hoefler</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-25 16:34:00</h6>
<p class='card-text'>The field of natural language processing (NLP) has witnessed significant
progress in recent years, with a notable focus on improving large language
models' (LLM) performance through innovative prompting techniques. Among these,
prompt engineering coupled with structures has emerged as a promising paradigm,
with designs such as Chain-of-Thought, Tree of Thoughts, or Graph of Thoughts,
in which the overall LLM reasoning is guided by a structure such as a graph. As
illustrated with numerous examples, this paradigm significantly enhances the
LLM's capability to solve numerous tasks, ranging from logical or mathematical
reasoning to planning or creative writing. To facilitate the understanding of
this growing field and pave the way for future developments, we devise a
general blueprint for effective and efficient LLM reasoning schemes. For this,
we conduct an in-depth analysis of the prompt execution pipeline, clarifying
and clearly defining different concepts. We then build the first taxonomy of
structure-enhanced LLM reasoning schemes. We focus on identifying fundamental
classes of harnessed structures, and we analyze the representations of these
structures, algorithms executed with these structures, and many others. We
refer to these structures as reasoning topologies, because their representation
becomes to a degree spatial, as they are contained within the LLM context. Our
study compares existing prompting schemes using the proposed taxonomy,
discussing how certain design choices lead to different patterns in performance
and cost. We also outline theoretical underpinnings, relationships between
prompting and other parts of the LLM ecosystem such as knowledge bases, and the
associated research challenges. Our work will help to advance future prompt
engineering techniques.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.13649v2' target='_blank'>VisualWebArena: Evaluating Multimodal Agents on Realistic Visual Web
  Tasks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jing Yu Koh, Robert Lo, Lawrence Jang, Vikram Duvvur, Ming Chong Lim, Po-Yu Huang, Graham Neubig, Shuyan Zhou, Ruslan Salakhutdinov, Daniel Fried</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-24 18:35:21</h6>
<p class='card-text'>Autonomous agents capable of planning, reasoning, and executing actions on
the web offer a promising avenue for automating computer tasks. However, the
majority of existing benchmarks primarily focus on text-based agents,
neglecting many natural tasks that require visual information to effectively
solve. Given that most computer interfaces cater to human perception, visual
information often augments textual data in ways that text-only models struggle
to harness effectively. To bridge this gap, we introduce VisualWebArena, a
benchmark designed to assess the performance of multimodal web agents on
realistic \textit{visually grounded tasks}. VisualWebArena comprises of a set
of diverse and complex web-based tasks that evaluate various capabilities of
autonomous multimodal agents. To perform on this benchmark, agents need to
accurately process image-text inputs, interpret natural language instructions,
and execute actions on websites to accomplish user-defined objectives. We
conduct an extensive evaluation of state-of-the-art LLM-based autonomous
agents, including several multimodal models. Through extensive quantitative and
qualitative analysis, we identify several limitations of text-only LLM agents,
and reveal gaps in the capabilities of state-of-the-art multimodal language
agents. VisualWebArena provides a framework for evaluating multimodal
autonomous language agents, and offers insights towards building stronger
autonomous agents for the web. Our code, baseline models, and data is publicly
available at https://jykoh.com/vwa.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.01698v1' target='_blank'>Large language model empowered participatory urban planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhilun Zhou, Yuming Lin, Yong Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-24 10:50:01</h6>
<p class='card-text'>Participatory urban planning is the mainstream of modern urban planning and
involves the active engagement of different stakeholders. However, the
traditional participatory paradigm encounters challenges in time and manpower,
while the generative planning tools fail to provide adjustable and inclusive
solutions. This research introduces an innovative urban planning approach
integrating Large Language Models (LLMs) within the participatory process. The
framework, based on the crafted LLM agent, consists of role-play, collaborative
generation, and feedback iteration, solving a community-level land-use task
catering to 1000 distinct interests. Empirical experiments in diverse urban
communities exhibit LLM's adaptability and effectiveness across varied planning
scenarios. The results were evaluated on four metrics, surpassing human experts
in satisfaction and inclusion, and rivaling state-of-the-art reinforcement
learning methods in service and ecology. Further analysis shows the advantage
of LLM agents in providing adjustable and inclusive solutions with natural
language reasoning and strong scalability. While implementing the recent
advancements in emulating human behavior for planning, this work envisions both
planners and citizens benefiting from low-cost, efficient LLM agents, which is
crucial for enhancing participation and realizing participatory urban planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.13256v3' target='_blank'>UniMS-RAG: A Unified Multi-source Retrieval-Augmented Generation for
  Personalized Dialogue Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hongru Wang, Wenyu Huang, Yang Deng, Rui Wang, Zezhong Wang, Yufei Wang, Fei Mi, Jeff Z. Pan, Kam-Fai Wong</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-24 06:50:20</h6>
<p class='card-text'>Large Language Models (LLMs) has shown exceptional capabilities in many
natual language understanding and generation tasks. However, the
personalization issue still remains a much-coveted property, especially when it
comes to the multiple sources involved in the dialogue system. To better plan
and incorporate the use of multiple sources in generating personalized
response, we firstly decompose it into three sub-tasks: Knowledge Source
Selection, Knowledge Retrieval, and Response Generation. We then propose a
novel Unified Multi-Source Retrieval-Augmented Generation system (UniMS-RAG)
Specifically, we unify these three sub-tasks with different formulations into
the same sequence-to-sequence paradigm during the training, to adaptively
retrieve evidences and evaluate the relevance on-demand using special tokens,
called acting tokens and evaluation tokens. Enabling language models to
generate acting tokens facilitates interaction with various knowledge sources,
allowing them to adapt their behavior to diverse task requirements. Meanwhile,
evaluation tokens gauge the relevance score between the dialogue context and
the retrieved evidence. In addition, we carefully design a self-refinement
mechanism to iteratively refine the generated response considering 1) the
consistency scores between the generated response and retrieved evidence; and
2) the relevance scores. Experiments on two personalized datasets (DuLeMon and
KBP) show that UniMS-RAG achieves state-of-the-art performance on the knowledge
source selection and response generation task with itself as a retriever in a
unified manner. Extensive analyses and discussions are provided for shedding
some new perspectives for personalized dialogue systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.12459v2' target='_blank'>Towards Socially and Morally Aware RL agent: Reward Design With LLM</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhaoyue Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-23 03:00:03</h6>
<p class='card-text'>When we design and deploy an Reinforcement Learning (RL) agent, reward
functions motivates agents to achieve an objective. An incorrect or incomplete
specification of the objective can result in behavior that does not align with
human values - failing to adhere with social and moral norms that are ambiguous
and context dependent, and cause undesired outcomes such as negative side
effects and exploration that is unsafe. Previous work have manually defined
reward functions to avoid negative side effects, use human oversight for safe
exploration, or use foundation models as planning tools. This work studies the
ability of leveraging Large Language Models (LLM)' understanding of morality
and social norms on safe exploration augmented RL methods. This work evaluates
language model's result against human feedbacks and demonstrates language
model's capability as direct reward signals.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.10067v1' target='_blank'>LLM-based policy generation for intent-based management of applications</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kristina Dzeparoska, Jieyu Lin, Ali Tizghadam, Alberto Leon-Garcia</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-22 15:37:04</h6>
<p class='card-text'>Automated management requires decomposing high-level user requests, such as
intents, to an abstraction that the system can understand and execute. This is
challenging because even a simple intent requires performing a number of
ordered steps. And the task of identifying and adapting these steps (as
conditions change) requires a decomposition approach that cannot be exactly
pre-defined beforehand. To tackle these challenges and support automated intent
decomposition and execution, we explore the few-shot capability of Large
Language Models (LLMs). We propose a pipeline that progressively decomposes
intents by generating the required actions using a policy-based abstraction.
This allows us to automate the policy execution by creating a closed control
loop for the intent deployment. To do so, we generate and map the policies to
APIs and form application management loops that perform the necessary
monitoring, analysis, planning and execution. We evaluate our proposal with a
use-case to fulfill and assure an application service chain of virtual network
functions. Using our approach, we can generalize and generate the necessary
steps to realize intents, thereby enabling intent automation for application
management.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.11708v3' target='_blank'>Mastering Text-to-Image Diffusion: Recaptioning, Planning, and
  Generating with Multimodal LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ling Yang, Zhaochen Yu, Chenlin Meng, Minkai Xu, Stefano Ermon, Bin Cui</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-22 06:16:29</h6>
<p class='card-text'>Diffusion models have exhibit exceptional performance in text-to-image
generation and editing. However, existing methods often face challenges when
handling complex text prompts that involve multiple objects with multiple
attributes and relationships. In this paper, we propose a brand new
training-free text-to-image generation/editing framework, namely Recaption,
Plan and Generate (RPG), harnessing the powerful chain-of-thought reasoning
ability of multimodal LLMs to enhance the compositionality of text-to-image
diffusion models. Our approach employs the MLLM as a global planner to
decompose the process of generating complex images into multiple simpler
generation tasks within subregions. We propose complementary regional diffusion
to enable region-wise compositional generation. Furthermore, we integrate
text-guided image generation and editing within the proposed RPG in a
closed-loop fashion, thereby enhancing generalization ability. Extensive
experiments demonstrate our RPG outperforms state-of-the-art text-to-image
diffusion models, including DALL-E 3 and SDXL, particularly in multi-category
object composition and text-image semantic alignment. Notably, our RPG
framework exhibits wide compatibility with various MLLM architectures (e.g.,
MiniGPT-4) and diffusion backbones (e.g., ControlNet). Our code is available
at: https://github.com/YangLing0818/RPG-DiffusionMaster</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2402.01680v2' target='_blank'>Large Language Model based Multi-Agents: A Survey of Progress and
  Challenges</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Taicheng Guo, Xiuying Chen, Yaqi Wang, Ruidi Chang, Shichao Pei, Nitesh V. Chawla, Olaf Wiest, Xiangliang Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-21 23:36:14</h6>
<p class='card-text'>Large Language Models (LLMs) have achieved remarkable success across a wide
array of tasks. Due to the impressive planning and reasoning abilities of LLMs,
they have been used as autonomous agents to do many tasks automatically.
Recently, based on the development of using one LLM as a single planning or
decision-making agent, LLM-based multi-agent systems have achieved considerable
progress in complex problem-solving and world simulation. To provide the
community with an overview of this dynamic field, we present this survey to
offer an in-depth discussion on the essential aspects of multi-agent systems
based on LLMs, as well as the challenges. Our goal is for readers to gain
substantial insights on the following questions: What domains and environments
do LLM-based multi-agents simulate? How are these agents profiled and how do
they communicate? What mechanisms contribute to the growth of agents'
capacities? For those interested in delving into this field of study, we also
summarize the commonly used datasets or benchmarks for them to have convenient
access. To keep researchers updated on the latest studies, we maintain an
open-source GitHub repository, dedicated to outlining the research on LLM-based
multi-agent systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.09670v3' target='_blank'>DistServe: Disaggregating Prefill and Decoding for Goodput-optimized
  Large Language Model Serving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yinmin Zhong, Shengyu Liu, Junda Chen, Jianbo Hu, Yibo Zhu, Xuanzhe Liu, Xin Jin, Hao Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-18 01:03:38</h6>
<p class='card-text'>DistServe improves the performance of large language models (LLMs) serving by
disaggregating the prefill and decoding computation. Existing LLM serving
systems colocate the two phases and batch the computation of prefill and
decoding across all users and requests. We find that this strategy not only
leads to strong prefill-decoding interferences but also couples the resource
allocation and parallelism plans for both phases. LLM applications often
emphasize individual latency for each phase: time to first token (TTFT) for the
prefill phase and time per output token (TPOT) of each request for the decoding
phase. In the presence of stringent latency requirements, existing systems have
to prioritize one latency over the other, or over-provision compute resources
to meet both.
  DistServe assigns prefill and decoding computation to different GPUs, hence
eliminating prefill-decoding interferences. Given the application's TTFT and
TPOT requirements, DistServe co-optimizes the resource allocation and
parallelism strategy tailored for each phase. DistServe also places the two
phases according to the serving cluster's bandwidth to minimize the
communication caused by disaggregation. As a result, DistServe significantly
improves LLM serving performance in terms of the maximum rate that can be
served within both TTFT and TPOT constraints on each GPU. Our evaluations show
that on various popular LLMs, applications, and latency requirements, DistServe
can serve 7.4x more requests or 12.6x tighter SLO, compared to state-of-the-art
systems, while staying within latency constraints for > 90% of requests.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.09414v1' target='_blank'>Vlogger: Make Your Dream A Vlog</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shaobin Zhuang, Kunchang Li, Xinyuan Chen, Yaohui Wang, Ziwei Liu, Yu Qiao, Yali Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-17 18:55:12</h6>
<p class='card-text'>In this work, we present Vlogger, a generic AI system for generating a
minute-level video blog (i.e., vlog) of user descriptions. Different from short
videos with a few seconds, vlog often contains a complex storyline with
diversified scenes, which is challenging for most existing video generation
approaches. To break through this bottleneck, our Vlogger smartly leverages
Large Language Model (LLM) as Director and decomposes a long video generation
task of vlog into four key stages, where we invoke various foundation models to
play the critical roles of vlog professionals, including (1) Script, (2) Actor,
(3) ShowMaker, and (4) Voicer. With such a design of mimicking human beings,
our Vlogger can generate vlogs through explainable cooperation of top-down
planning and bottom-up shooting. Moreover, we introduce a novel video diffusion
model, ShowMaker, which serves as a videographer in our Vlogger for generating
the video snippet of each shooting scene. By incorporating Script and Actor
attentively as textual and visual prompts, it can effectively enhance
spatial-temporal coherence in the snippet. Besides, we design a concise mixed
training paradigm for ShowMaker, boosting its capacity for both T2V generation
and prediction. Finally, the extensive experiments show that our method
achieves state-of-the-art performance on zero-shot T2V generation and
prediction tasks. More importantly, Vlogger can generate over 5-minute vlogs
from open-world descriptions, without loss of video coherence on script and
actor. The code and model is all available at
https://github.com/zhuangshaobin/Vlogger.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.09083v1' target='_blank'>Remote Sensing ChatGPT: Solving Remote Sensing Tasks with ChatGPT and
  Visual Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Haonan Guo, Xin Su, Chen Wu, Bo Du, Liangpei Zhang, Deren Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-17 09:44:07</h6>
<p class='card-text'>Recently, the flourishing large language models(LLM), especially ChatGPT,
have shown exceptional performance in language understanding, reasoning, and
interaction, attracting users and researchers from multiple fields and domains.
Although LLMs have shown great capacity to perform human-like task
accomplishment in natural language and natural image, their potential in
handling remote sensing interpretation tasks has not yet been fully explored.
Moreover, the lack of automation in remote sensing task planning hinders the
accessibility of remote sensing interpretation techniques, especially to
non-remote sensing experts from multiple research fields. To this end, we
present Remote Sensing ChatGPT, an LLM-powered agent that utilizes ChatGPT to
connect various AI-based remote sensing models to solve complicated
interpretation tasks. More specifically, given a user request and a remote
sensing image, we utilized ChatGPT to understand user requests, perform task
planning according to the tasks' functions, execute each subtask iteratively,
and generate the final response according to the output of each subtask.
Considering that LLM is trained with natural language and is not capable of
directly perceiving visual concepts as contained in remote sensing images, we
designed visual cues that inject visual information into ChatGPT. With Remote
Sensing ChatGPT, users can simply send a remote sensing image with the
corresponding request, and get the interpretation results as well as language
feedback from Remote Sensing ChatGPT. Experiments and examples show that Remote
Sensing ChatGPT can tackle a wide range of remote sensing tasks and can be
extended to more tasks with more sophisticated models such as the remote
sensing foundation model. The code and demo of Remote Sensing ChatGPT is
publicly available at https://github.com/HaonanGuo/Remote-Sensing-ChatGPT .</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.09074v4' target='_blank'>Code Simulation Challenges for Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Emanuele La Malfa, Christoph Weinhuber, Orazio Torre, Fangru Lin, Samuele Marro, Anthony Cohn, Nigel Shadbolt, Michael Wooldridge</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-17 09:23:59</h6>
<p class='card-text'>Many reasoning, planning, and problem-solving tasks share an intrinsic
algorithmic nature: correctly simulating each step is a sufficient condition to
solve them correctly. This work studies to what extent Large Language Models
(LLMs) can simulate coding and algorithmic tasks to provide insights into
general capabilities in such algorithmic reasoning tasks. We introduce
benchmarks for straight-line programs, code that contains critical paths, and
approximate and redundant instructions. We further assess the simulation
capabilities of LLMs with sorting algorithms and nested loops and show that a
routine's computational complexity directly affects an LLM's ability to
simulate its execution. While the most powerful LLMs exhibit relatively strong
simulation capabilities, the process is fragile, seems to rely heavily on
pattern recognition, and is affected by memorisation. We propose a novel
off-the-shelf prompting method, Chain of Simulation (CoSm), which instructs
LLMs to simulate code execution line by line/follow the computation pattern of
compilers. CoSm efficiently helps LLMs reduce memorisation and shallow pattern
recognition while improving simulation performance. We consider the success of
CoSm in code simulation to be inspirational for other general routine
simulation reasoning tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.09042v1' target='_blank'>LLMs for Relational Reasoning: How Far are We?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhiming Li, Yushi Cao, Xiufeng Xu, Junzhe Jiang, Xu Liu, Yon Shin Teo, Shang-wei Lin, Yang Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-17 08:22:52</h6>
<p class='card-text'>Large language models (LLMs) have revolutionized many areas (e.g. natural
language processing, software engineering, etc.) by achieving state-of-the-art
performance on extensive downstream tasks. Aiming to achieve robust and general
artificial intelligence, there has been a surge of interest in investigating
the reasoning ability of the LLMs. Whereas the textual and numerical reasoning
benchmarks adopted by previous works are rather shallow and simple, it is hard
to conclude that the LLMs possess strong reasoning ability by merely achieving
positive results on these benchmarks. Recent efforts have demonstrated that the
LLMs are poor at solving sequential decision-making problems that require
common-sense planning by evaluating their performance on the reinforcement
learning benchmarks. In this work, we conduct an in-depth assessment of several
state-of-the-art LLMs' reasoning ability based on the inductive logic
programming (ILP) benchmark, which is broadly recognized as a representative
and challenging measurement for evaluating logic program induction/synthesis
systems as it requires inducing strict cause-effect logic to achieve robust
deduction on independent and identically distributed (IID) and
out-of-distribution (OOD) test samples. Our evaluations illustrate that
compared with the neural program induction systems which are much smaller in
model size, the state-of-the-art LLMs are much poorer in terms of reasoning
ability by achieving much lower performance and generalization using either
natural language prompting or truth-value matrix prompting.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.08392v3' target='_blank'>DoraemonGPT: Toward Understanding Dynamic Scenes with Large Language
  Models (Exemplified as A Video Agent)</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zongxin Yang, Guikun Chen, Xiaodi Li, Wenguan Wang, Yi Yang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-16 14:33:09</h6>
<p class='card-text'>Recent LLM-driven visual agents mainly focus on solving image-based tasks,
which limits their ability to understand dynamic scenes, making it far from
real-life applications like guiding students in laboratory experiments and
identifying their mistakes. Hence, this paper explores DoraemonGPT, a
comprehensive and conceptually elegant system driven by LLMs to understand
dynamic scenes. Considering the video modality better reflects the
ever-changing nature of real-world scenarios, we exemplify DoraemonGPT as a
video agent. Given a video with a question/task, DoraemonGPT begins by
converting the input video into a symbolic memory that stores task-related
attributes. This structured representation allows for spatial-temporal querying
and reasoning by well-designed sub-task tools, resulting in concise
intermediate results. Recognizing that LLMs have limited internal knowledge
when it comes to specialized domains (e.g., analyzing the scientific principles
underlying experiments), we incorporate plug-and-play tools to assess external
knowledge and address tasks across different domains. Moreover, a novel
LLM-driven planner based on Monte Carlo Tree Search is introduced to explore
the large planning space for scheduling various tools. The planner iteratively
finds feasible solutions by backpropagating the result's reward, and multiple
solutions can be summarized into an improved final answer. We extensively
evaluate DoraemonGPT's effectiveness on three benchmarks and several
in-the-wild scenarios. The code will be released at
https://github.com/z-x-yang/DoraemonGPT.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.07868v1' target='_blank'>Consolidating Trees of Robotic Plans Generated Using Large Language
  Models to Improve Reliability</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Md Sadman Sakib, Yu Sun</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-15 18:01:59</h6>
<p class='card-text'>The inherent probabilistic nature of Large Language Models (LLMs) introduces
an element of unpredictability, raising concerns about potential discrepancies
in their output. This paper introduces an innovative approach aims to generate
correct and optimal robotic task plans for diverse real-world demands and
scenarios. LLMs have been used to generate task plans, but they are unreliable
and may contain wrong, questionable, or high-cost steps. The proposed approach
uses LLM to generate a number of task plans as trees and amalgamates them into
a graph by removing questionable paths. Then an optimal task tree can be
retrieved to circumvent questionable and high-cost nodes, thereby improving
planning accuracy and execution efficiency. The approach is further improved by
incorporating a large knowledge network. Leveraging GPT-4 further, the
high-level task plan is converted into a low-level Planning Domain Definition
Language (PDDL) plan executable by a robot. Evaluation results highlight the
superior accuracy and efficiency of our approach compared to previous
methodologies in the field of task planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.07324v3' target='_blank'>Small LLMs Are Weak Tool Learners: A Multi-LLM Agent</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Weizhou Shen, Chenliang Li, Hongzhan Chen, Ming Yan, Xiaojun Quan, Hehong Chen, Ji Zhang, Fei Huang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-14 16:17:07</h6>
<p class='card-text'>Large Language Model (LLM) agents significantly extend the capabilities of
standalone LLMs, empowering them to interact with external tools (e.g., APIs,
functions) and complete various tasks in a self-directed fashion. The challenge
of tool use demands that LLMs not only understand user queries and generate
answers accurately but also excel in task planning, tool invocation, and result
summarization. While traditional works focus on training a single LLM with all
these capabilities, performance limitations become apparent, particularly with
smaller models. To overcome these challenges, we propose a novel approach that
decomposes the aforementioned capabilities into a planner, caller, and
summarizer. Each component is implemented by a single LLM that focuses on a
specific capability and collaborates with others to accomplish the task. This
modular framework facilitates individual updates and the potential use of
smaller LLMs for building each capability. To effectively train this framework,
we introduce a two-stage training paradigm. First, we fine-tune a backbone LLM
on the entire dataset without discriminating sub-tasks, providing the model
with a comprehensive understanding of the task. Second, the fine-tuned LLM is
used to instantiate the planner, caller, and summarizer respectively, which are
continually fine-tuned on respective sub-tasks. Evaluation across various
tool-use benchmarks illustrates that our proposed multi-LLM framework surpasses
the traditional single-LLM approach, highlighting its efficacy and advantages
in tool learning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.07314v3' target='_blank'>MapGPT: Map-Guided Prompting with Adaptive Path Planning for
  Vision-and-Language Navigation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiaqi Chen, Bingqian Lin, Ran Xu, Zhenhua Chai, Xiaodan Liang, Kwan-Yee K. Wong</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-14 15:34:48</h6>
<p class='card-text'>Embodied agents equipped with GPT as their brains have exhibited
extraordinary decision-making and generalization abilities across various
tasks. However, existing zero-shot agents for vision-and-language navigation
(VLN) only prompt GPT-4 to select potential locations within localized
environments, without constructing an effective "global-view" for the agent to
understand the overall environment. In this work, we present a novel map-guided
GPT-based agent, dubbed MapGPT, which introduces an online linguistic-formed
map to encourage global exploration. Specifically, we build an online map and
incorporate it into the prompts that include node information and topological
relationships, to help GPT understand the spatial environment. Benefiting from
this design, we further propose an adaptive planning mechanism to assist the
agent in performing multi-step path planning based on a map, systematically
exploring multiple candidate nodes or sub-goals step by step. Extensive
experiments demonstrate that our MapGPT is applicable to both GPT-4 and GPT-4V,
achieving state-of-the-art zero-shot performance on R2R and REVERIE
simultaneously (~10% and ~12% improvements in SR), and showcasing the newly
emergent global thinking and path planning abilities of the GPT.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.07128v3' target='_blank'>EHRAgent: Code Empowers Large Language Models for Few-shot Complex
  Tabular Reasoning on Electronic Health Records</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wenqi Shi, Ran Xu, Yuchen Zhuang, Yue Yu, Jieyu Zhang, Hang Wu, Yuanda Zhu, Joyce Ho, Carl Yang, May D. Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-13 18:09:05</h6>
<p class='card-text'>Large language models (LLMs) have demonstrated exceptional capabilities in
planning and tool utilization as autonomous agents, but few have been developed
for medical problem-solving. We propose EHRAgent, an LLM agent empowered with a
code interface, to autonomously generate and execute code for multi-tabular
reasoning within electronic health records (EHRs). First, we formulate an EHR
question-answering task into a tool-use planning process, efficiently
decomposing a complicated task into a sequence of manageable actions. By
integrating interactive coding and execution feedback, EHRAgent learns from
error messages and improves the originally generated code through iterations.
Furthermore, we enhance the LLM agent by incorporating long-term memory, which
allows EHRAgent to effectively select and build upon the most relevant
successful cases from past experiences. Experiments on three real-world
multi-tabular EHR datasets show that EHRAgent outperforms the strongest
baseline by up to 29.6% in success rate. EHRAgent leverages the emerging
few-shot learning capabilities of LLMs, enabling autonomous code generation and
execution to tackle complex clinical tasks with minimal demonstrations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.06949v2' target='_blank'>ORGANA: A Robotic Assistant for Automated Chemistry Experimentation and
  Characterization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kourosh Darvish, Marta Skreta, Yuchi Zhao, Naruki Yoshikawa, Sagnik Som, Miroslav Bogdanovic, Yang Cao, Han Hao, Haoping Xu, Alán Aspuru-Guzik, Animesh Garg, Florian Shkurti</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-13 02:03:28</h6>
<p class='card-text'>Chemistry experiments can be resource- and labor-intensive, often requiring
manual tasks like polishing electrodes in electrochemistry. Traditional lab
automation infrastructure faces challenges adapting to new experiments. To
address this, we introduce ORGANA, an assistive robotic system that automates
diverse chemistry experiments using decision-making and perception tools. It
makes decisions with chemists in the loop to control robots and lab devices.
ORGANA interacts with chemists using Large Language Models (LLMs) to derive
experiment goals, handle disambiguation, and provide experiment logs. ORGANA
plans and executes complex tasks with visual feedback, while supporting
scheduling and parallel task execution. We demonstrate ORGANA's capabilities in
solubility, pH measurement, recrystallization, and electrochemistry
experiments. In electrochemistry, it executes a 19-step plan in parallel to
characterize quinone derivatives for flow batteries. Our user study shows
ORGANA reduces frustration and physical demand by over 50%, with users saving
an average of 80.3% of their time when using it.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.06761v1' target='_blank'>APAR: LLMs Can Do Auto-Parallel Auto-Regressive Decoding</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mingdao Liu, Aohan Zeng, Bowen Wang, Peng Zhang, Jie Tang, Yuxiao Dong</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-12 18:50:36</h6>
<p class='card-text'>The massive adoption of large language models (LLMs) demands efficient
deployment strategies. However, the auto-regressive decoding process, which is
fundamental to how most LLMs generate text, poses challenges to achieve
efficient serving. In this work, we introduce a parallel auto-regressive
generation method. By instruct-tuning on general domain data that contains
hierarchical structures, we enable LLMs to independently plan their generation
process and perform auto-parallel auto-regressive (APAR) generation,
significantly reducing the number of generation steps. APAR alone can achieve
up to 2x speed-up, and when combined with speculative decoding, the speed-up
can reach up to 4x. In addition, APAR reduces the key-value cache consumption
and attention computation during generation. This leads to a throughput
increase of 20-70% and a latency reduce of 20-35% in high-throughput scenarios,
compared to state-of-the-art serving frameworks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.06603v1' target='_blank'>Mutual Enhancement of Large Language and Reinforcement Learning Models
  through Bi-Directional Feedback Mechanisms: A Case Study</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shangding Gu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-12 14:35:57</h6>
<p class='card-text'>Large Language Models (LLMs) have demonstrated remarkable capabilities for
reinforcement learning (RL) models, such as planning and reasoning
capabilities. However, the problems of LLMs and RL model collaboration still
need to be solved. In this study, we employ a teacher-student learning
framework to tackle these problems, specifically by offering feedback for LLMs
using RL models and providing high-level information for RL models with LLMs in
a cooperative multi-agent setting. Within this framework, the LLM acts as a
teacher, while the RL model acts as a student. The two agents cooperatively
assist each other through a process of recursive help, such as "I help you help
I help." The LLM agent supplies abstract information to the RL agent, enabling
efficient exploration and policy improvement. In turn, the RL agent offers
feedback to the LLM agent, providing valuable, real-time information that helps
generate more useful tokens. This bi-directional feedback loop promotes
optimization, exploration, and mutual improvement for both agents, enabling
them to accomplish increasingly challenging tasks. Remarkably, we propose a
practical algorithm to address the problem and conduct empirical experiments to
evaluate the effectiveness of our method.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.05302v2' target='_blank'>Theory of Mind abilities of Large Language Models in Human-Robot
  Interaction : An Illusion?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mudit Verma, Siddhant Bhambri, Subbarao Kambhampati</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-10 18:09:36</h6>
<p class='card-text'>Large Language Models have shown exceptional generative abilities in various
natural language and generation tasks. However, possible anthropomorphization
and leniency towards failure cases have propelled discussions on emergent
abilities of Large Language Models especially on Theory of Mind (ToM) abilities
in Large Language Models. While several false-belief tests exists to verify the
ability to infer and maintain mental models of another entity, we study a
special application of ToM abilities that has higher stakes and possibly
irreversible consequences : Human Robot Interaction. In this work, we explore
the task of Perceived Behavior Recognition, where a robot employs a Large
Language Model (LLM) to assess the robot's generated behavior in a manner
similar to human observer. We focus on four behavior types, namely -
explicable, legible, predictable, and obfuscatory behavior which have been
extensively used to synthesize interpretable robot behaviors. The LLMs goal is,
therefore to be a human proxy to the agent, and to answer how a certain agent
behavior would be perceived by the human in the loop, for example "Given a
robot's behavior X, would the human observer find it explicable?". We conduct a
human subject study to verify that the users are able to correctly answer such
a question in the curated situations (robot setting and plan) across five
domains. A first analysis of the belief test yields extremely positive results
inflating ones expectations of LLMs possessing ToM abilities. We then propose
and perform a suite of perturbation tests which breaks this illusion, i.e.
Inconsistent Belief, Uninformative Context and Conviction Test. We conclude
that, the high score of LLMs on vanilla prompts showcases its potential use in
HRI settings, however to possess ToM demands invariance to trivial or
irrelevant perturbations in the context which LLMs lack.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.05268v4' target='_blank'>AutoAct: Automatic Agent Learning from Scratch for QA via Self-Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shuofei Qiao, Ningyu Zhang, Runnan Fang, Yujie Luo, Wangchunshu Zhou, Yuchen Eleanor Jiang, Chengfei Lv, Huajun Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-10 16:57:24</h6>
<p class='card-text'>Language agents have achieved considerable performance on various complex
question-answering tasks by planning with external tools. Despite the incessant
exploration in this field, existing language agent systems still struggle with
costly, non-reproducible data reliance and face the challenge of compelling a
single model for multiple functions. To this end, we introduce AutoAct, an
automatic agent learning framework for QA that does not rely on large-scale
annotated data and synthetic planning trajectories from closed-source models
(e.g., GPT-4). Given limited data with a tool library, AutoAct first
automatically synthesizes planning trajectories without any assistance from
humans or strong closed-source models. Then, AutoAct leverages a
division-of-labor strategy to automatically differentiate based on the target
task information and synthesized trajectories, producing a sub-agent group to
complete the task. We conduct comprehensive experiments with different LLMs,
which demonstrates that AutoAct yields better or parallel performance compared
to various strong baselines. Further analysis demonstrates the effectiveness of
the division-of-labor strategy, with the trajectory quality generated by
AutoAct generally outperforming that of others. Code will be available at
https://github.com/zjunlp/AutoAct.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.05459v2' target='_blank'>Personal LLM Agents: Insights and Survey about the Capability,
  Efficiency and Security</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuanchun Li, Hao Wen, Weijun Wang, Xiangyu Li, Yizhen Yuan, Guohong Liu, Jiacheng Liu, Wenxing Xu, Xiang Wang, Yi Sun, Rui Kong, Yile Wang, Hanfei Geng, Jian Luan, Xuefeng Jin, Zilong Ye, Guanjing Xiong, Fan Zhang, Xiang Li, Mengwei Xu, Zhijun Li, Peng Li, Yang Liu, Ya-Qin Zhang, Yunxin Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-10 09:25:45</h6>
<p class='card-text'>Since the advent of personal computing devices, intelligent personal
assistants (IPAs) have been one of the key technologies that researchers and
engineers have focused on, aiming to help users efficiently obtain information
and execute tasks, and provide users with more intelligent, convenient, and
rich interaction experiences. With the development of smartphones and IoT,
computing and sensing devices have become ubiquitous, greatly expanding the
boundaries of IPAs. However, due to the lack of capabilities such as user
intent understanding, task planning, tool using, and personal data management
etc., existing IPAs still have limited practicality and scalability. Recently,
the emergence of foundation models, represented by large language models
(LLMs), brings new opportunities for the development of IPAs. With the powerful
semantic understanding and reasoning capabilities, LLM can enable intelligent
agents to solve complex problems autonomously. In this paper, we focus on
Personal LLM Agents, which are LLM-based agents that are deeply integrated with
personal data and personal devices and used for personal assistance. We
envision that Personal LLM Agents will become a major software paradigm for
end-users in the upcoming era. To realize this vision, we take the first step
to discuss several important questions about Personal LLM Agents, including
their architecture, capability, efficiency and security. We start by
summarizing the key components and design choices in the architecture of
Personal LLM Agents, followed by an in-depth analysis of the opinions collected
from domain experts. Next, we discuss several key challenges to achieve
intelligent, efficient and secure Personal LLM Agents, followed by a
comprehensive survey of representative solutions to address these challenges.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.04398v2' target='_blank'>Chain-of-Table: Evolving Tables in the Reasoning Chain for Table
  Understanding</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zilong Wang, Hao Zhang, Chun-Liang Li, Julian Martin Eisenschlos, Vincent Perot, Zifeng Wang, Lesly Miculicich, Yasuhisa Fujii, Jingbo Shang, Chen-Yu Lee, Tomas Pfister</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-09 07:46:26</h6>
<p class='card-text'>Table-based reasoning with large language models (LLMs) is a promising
direction to tackle many table understanding tasks, such as table-based
question answering and fact verification. Compared with generic reasoning,
table-based reasoning requires the extraction of underlying semantics from both
free-form questions and semi-structured tabular data. Chain-of-Thought and its
similar approaches incorporate the reasoning chain in the form of textual
context, but it is still an open question how to effectively leverage tabular
data in the reasoning chain. We propose the Chain-of-Table framework, where
tabular data is explicitly used in the reasoning chain as a proxy for
intermediate thoughts. Specifically, we guide LLMs using in-context learning to
iteratively generate operations and update the table to represent a tabular
reasoning chain. LLMs can therefore dynamically plan the next operation based
on the results of the previous ones. This continuous evolution of the table
forms a chain, showing the reasoning process for a given tabular problem. The
chain carries structured information of the intermediate results, enabling more
accurate and reliable predictions. Chain-of-Table achieves new state-of-the-art
performance on WikiTQ, FeTaQA, and TabFact benchmarks across multiple LLM
choices.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.04334v1' target='_blank'>Large Language Models for Robotics: Opportunities, Challenges, and
  Perspectives</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiaqi Wang, Zihao Wu, Yiwei Li, Hanqi Jiang, Peng Shu, Enze Shi, Huawen Hu, Chong Ma, Yiheng Liu, Xuhui Wang, Yincheng Yao, Xuan Liu, Huaqin Zhao, Zhengliang Liu, Haixing Dai, Lin Zhao, Bao Ge, Xiang Li, Tianming Liu, Shu Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-09 03:22:16</h6>
<p class='card-text'>Large language models (LLMs) have undergone significant expansion and have
been increasingly integrated across various domains. Notably, in the realm of
robot task planning, LLMs harness their advanced reasoning and language
comprehension capabilities to formulate precise and efficient action plans
based on natural language instructions. However, for embodied tasks, where
robots interact with complex environments, text-only LLMs often face challenges
due to a lack of compatibility with robotic visual perception. This study
provides a comprehensive overview of the emerging integration of LLMs and
multimodal LLMs into various robotic tasks. Additionally, we propose a
framework that utilizes multimodal GPT-4V to enhance embodied task planning
through the combination of natural language instructions and robot visual
perceptions. Our results, based on diverse datasets, indicate that GPT-4V
effectively enhances robot performance in embodied tasks. This extensive survey
and evaluation of LLMs and multimodal LLMs across a variety of robotic tasks
enriches the understanding of LLM-centric embodied intelligence and provides
forward-looking insights toward bridging the gap in Human-Robot-Environment
interaction.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.04157v2' target='_blank'>RePLan: Robotic Replanning with Perception and Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Marta Skreta, Zihan Zhou, Jia Lin Yuan, Kourosh Darvish, Alán Aspuru-Guzik, Animesh Garg</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-08 18:57:54</h6>
<p class='card-text'>Advancements in large language models (LLMs) have demonstrated their
potential in facilitating high-level reasoning, logical reasoning and robotics
planning. Recently, LLMs have also been able to generate reward functions for
low-level robot actions, effectively bridging the interface between high-level
planning and low-level robot control. However, the challenge remains that even
with syntactically correct plans, robots can still fail to achieve their
intended goals due to imperfect plans or unexpected environmental issues. To
overcome this, Vision Language Models (VLMs) have shown remarkable success in
tasks such as visual question answering. Leveraging the capabilities of VLMs,
we present a novel framework called Robotic Replanning with Perception and
Language Models (RePLan) that enables online replanning capabilities for
long-horizon tasks. This framework utilizes the physical grounding provided by
a VLM's understanding of the world's state to adapt robot actions when the
initial plan fails to achieve the desired goal. We developed a Reasoning and
Control (RC) benchmark with eight long-horizon tasks to test our approach. We
find that RePLan enables a robot to successfully adapt to unforeseen obstacles
while accomplishing open-ended, long-horizon goals, where baseline models
cannot, and can be readily applied to real robots. Find more information at
https://replan-lm.github.io/replan.github.io/</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.03630v2' target='_blank'>Why Solving Multi-agent Path Finding with Large Language Model has not
  Succeeded Yet</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Weizhe Chen, Sven Koenig, Bistra Dilkina</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-08 02:22:04</h6>
<p class='card-text'>With the explosive influence caused by the success of large language models
(LLM) like ChatGPT and GPT-4, there has been an extensive amount of recent work
showing that foundation models can be used to solve a large variety of tasks.
However, there is very limited work that shares insights on multi-agent
planning. Multi-agent planning is different from other domains by combining the
difficulty of multi-agent coordination and planning, and making it hard to
leverage external tools to facilitate the reasoning needed. In this paper, we
focus on the problem of multi-agent path finding (MAPF), which is also known as
multi-robot route planning, and study the performance of solving MAPF with
LLMs. We first show the motivating success on an empty room map without
obstacles, then the failure to plan on the harder room map and maze map of the
standard MAPF benchmark. We present our position on why directly solving MAPF
with LLMs has not been successful yet, and we use various experiments to
support our hypothesis. Based on our results, we discussed how researchers with
different backgrounds could help with this problem from different perspectives.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.03428v1' target='_blank'>Exploring Large Language Model based Intelligent Agents: Definitions,
  Methods, and Prospects</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuheng Cheng, Ceyao Zhang, Zhengwen Zhang, Xiangrui Meng, Sirui Hong, Wenhao Li, Zihao Wang, Zekai Wang, Feng Yin, Junhua Zhao, Xiuqiang He</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-07 09:08:24</h6>
<p class='card-text'>Intelligent agents stand out as a potential path toward artificial general
intelligence (AGI). Thus, researchers have dedicated significant effort to
diverse implementations for them. Benefiting from recent progress in large
language models (LLMs), LLM-based agents that use universal natural language as
an interface exhibit robust generalization capabilities across various
applications -- from serving as autonomous general-purpose task assistants to
applications in coding, social, and economic domains, LLM-based agents offer
extensive exploration opportunities. This paper surveys current research to
provide an in-depth overview of LLM-based intelligent agents within
single-agent and multi-agent systems. It covers their definitions, research
frameworks, and foundational components such as their composition, cognitive
and planning methods, tool utilization, and responses to environmental
feedback. We also delve into the mechanisms of deploying LLM-based agents in
multi-agent systems, including multi-role collaboration, message passing, and
strategies to alleviate communication issues between agents. The discussions
also shed light on popular datasets and application scenarios. We conclude by
envisioning prospects for LLM-based agents, considering the evolving landscape
of AI and natural language processing.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.02870v1' target='_blank'>AFSPP: Agent Framework for Shaping Preference and Personality with Large
  Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zihong He, Changwang Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-05 15:52:59</h6>
<p class='card-text'>The evolution of Large Language Models (LLMs) has introduced a new paradigm
for investigating human behavior emulation. Recent research has employed
LLM-based Agents to create a sociological research environment, in which agents
exhibit behavior based on the unfiltered characteristics of large language
models. However, these studies overlook the iterative development within a
human-like setting - Human preferences and personalities are complex, shaped by
various factors and subject to ongoing change as a result of environmental and
subjective influences. In light of this observation, we propose Agent Framework
for Shaping Preference and Personality (AFSPP), exploring the multifaceted
impact of social networks and subjective consciousness on LLM-based Agents'
preference and personality formation. With AFSPP, we have, for the first time,
successfully replicated several key findings from human personality
experiments. And other AFSPP-based experimental results indicate that plan
making, sensory perceptions and social networking with subjective information,
wield the most pronounced influence on preference shaping. AFSPP can
significantly enhance the efficiency and scope of psychological experiments,
while yielding valuable insights for Trustworthy Artificial Intelligence
research for strategies to prevent undesirable preference and personality
development.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.02705v2' target='_blank'>XUAT-Copilot: Multi-Agent Collaborative System for Automated User
  Acceptance Testing with Large Language Model</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhitao Wang, Wei Wang, Zirao Li, Long Wang, Can Yi, Xinjie Xu, Luyang Cao, Hanjing Su, Shouzhi Chen, Jun Zhou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-05 08:24:30</h6>
<p class='card-text'>In past years, we have been dedicated to automating user acceptance testing
(UAT) process of WeChat Pay, one of the most influential mobile payment
applications in China. A system titled XUAT has been developed for this
purpose. However, there is still a human-labor-intensive stage, i.e, test
scripts generation, in the current system. Therefore, in this paper, we
concentrate on methods of boosting the automation level of the current system,
particularly the stage of test scripts generation. With recent notable
successes, large language models (LLMs) demonstrate significant potential in
attaining human-like intelligence and there has been a growing research area
that employs LLMs as autonomous agents to obtain human-like decision-making
capabilities. Inspired by these works, we propose an LLM-powered multi-agent
collaborative system, named XUAT-Copilot, for automated UAT. The proposed
system mainly consists of three LLM-based agents responsible for action
planning, state checking and parameter selecting, respectively, and two
additional modules for state sensing and case rewriting. The agents interact
with testing device, make human-like decision and generate action command in a
collaborative way. The proposed multi-agent system achieves a close
effectiveness to human testers in our experimental studies and gains a
significant improvement of Pass@1 accuracy compared with single-agent
architecture. More importantly, the proposed system has launched in the formal
testing environment of WeChat Pay mobile app, which saves a considerable amount
of manpower in the daily development work.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.02695v2' target='_blank'>VoroNav: Voronoi-based Zero-shot Object Navigation with Large Language
  Model</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Pengying Wu, Yao Mu, Bingxian Wu, Yi Hou, Ji Ma, Shanghang Zhang, Chang Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-05 08:05:07</h6>
<p class='card-text'>In the realm of household robotics, the Zero-Shot Object Navigation (ZSON)
task empowers agents to adeptly traverse unfamiliar environments and locate
objects from novel categories without prior explicit training. This paper
introduces VoroNav, a novel semantic exploration framework that proposes the
Reduced Voronoi Graph to extract exploratory paths and planning nodes from a
semantic map constructed in real time. By harnessing topological and semantic
information, VoroNav designs text-based descriptions of paths and images that
are readily interpretable by a large language model (LLM). In particular, our
approach presents a synergy of path and farsight descriptions to represent the
environmental context, enabling LLM to apply commonsense reasoning to ascertain
waypoints for navigation. Extensive evaluation on HM3D and HSSD validates
VoroNav surpasses existing benchmarks in both success rate and exploration
efficiency (absolute improvement: +2.8% Success and +3.7% SPL on HM3D, +2.6%
Success and +3.8% SPL on HSSD). Additionally introduced metrics that evaluate
obstacle avoidance proficiency and perceptual efficiency further corroborate
the enhancements achieved by our method in ZSON planning. Project page:
https://voro-nav.github.io</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.02500v2' target='_blank'>On the Prospects of Incorporating Large Language Models (LLMs) in
  Automated Planning and Scheduling (APS)</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Vishal Pallagani, Kaushik Roy, Bharath Muppasani, Francesco Fabiano, Andrea Loreggia, Keerthiram Murugesan, Biplav Srivastava, Francesca Rossi, Lior Horesh, Amit Sheth</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-04 19:22:09</h6>
<p class='card-text'>Automated Planning and Scheduling is among the growing areas in Artificial
Intelligence (AI) where mention of LLMs has gained popularity. Based on a
comprehensive review of 126 papers, this paper investigates eight categories
based on the unique applications of LLMs in addressing various aspects of
planning problems: language translation, plan generation, model construction,
multi-agent planning, interactive planning, heuristics optimization, tool
integration, and brain-inspired planning. For each category, we articulate the
issues considered and existing gaps. A critical insight resulting from our
review is that the true potential of LLMs unfolds when they are integrated with
traditional symbolic planners, pointing towards a promising neuro-symbolic
approach. This approach effectively combines the generative aspects of LLMs
with the precision of classical planning methods. By synthesizing insights from
existing literature, we underline the potential of this integration to address
complex planning challenges. Our goal is to encourage the ICAPS community to
recognize the complementary strengths of LLMs and symbolic planners, advocating
for a direction in automated planning that leverages these synergistic
capabilities to develop more advanced and intelligent planning systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.02369v2' target='_blank'>SPEER: Sentence-Level Planning of Long Clinical Summaries via Embedded
  Entity Retrieval</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Griffin Adams, Jason Zucker, Noémie Elhadad</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-04 17:23:44</h6>
<p class='card-text'>Clinician must write a lengthy summary each time a patient is discharged from
the hospital. This task is time-consuming due to the sheer number of unique
clinical concepts covered in the admission. Identifying and covering salient
entities is vital for the summary to be clinically useful. We fine-tune
open-source LLMs (Mistral-7B-Instruct and Zephyr-7B-beta) on the task and find
that they generate incomplete and unfaithful summaries. To increase entity
coverage, we train a smaller, encoder-only model to predict salient entities,
which are treated as content-plans to guide the LLM. To encourage the LLM to
focus on specific mentions in the source notes, we propose SPEER:
Sentence-level Planning via Embedded Entity Retrieval. Specifically, we mark
each salient entity span with special "{{ }}" boundary tags and instruct the
LLM to retrieve marked spans before generating each sentence. Sentence-level
planning acts as a form of state tracking in that the model is explicitly
recording the entities it uses. We fine-tune Mistral and Zephyr variants on a
large-scale, diverse dataset of ~167k in-patient hospital admissions and
evaluate on 3 datasets. SPEER shows gains in both coverage and faithfulness
metrics over non-guided and guided baselines.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.01614v2' target='_blank'>GPT-4V(ision) is a Generalist Web Agent, if Grounded</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Boyuan Zheng, Boyu Gou, Jihyung Kil, Huan Sun, Yu Su</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-03 08:33:09</h6>
<p class='card-text'>The recent development on large multimodal models (LMMs), especially
GPT-4V(ision) and Gemini, has been quickly expanding the capability boundaries
of multimodal models beyond traditional tasks like image captioning and visual
question answering. In this work, we explore the potential of LMMs like GPT-4V
as a generalist web agent that can follow natural language instructions to
complete tasks on any given website. We propose SEEACT, a generalist web agent
that harnesses the power of LMMs for integrated visual understanding and acting
on the web. We evaluate on the recent MIND2WEB benchmark. In addition to
standard offline evaluation on cached websites, we enable a new online
evaluation setting by developing a tool that allows running web agents on live
websites. We show that GPT-4V presents a great potential for web agents -- it
can successfully complete 51.1 of the tasks on live websites if we manually
ground its textual plans into actions on the websites. This substantially
outperforms text-only LLMs like GPT-4 or smaller models (FLAN-T5 and BLIP-2)
specifically fine-tuned for web agents. However, grounding still remains a
major challenge. Existing LMM grounding strategies like set-of-mark prompting
turns out to be not effective for web agents, and the best grounding strategy
we develop in this paper leverages both the HTML structure and visuals. Yet,
there is still a substantial gap with oracle grounding, leaving ample room for
further improvement. All code, data, and evaluation tools are available at
https://github.com/OSU-NLP-Group/SeeAct.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.00812v2' target='_blank'>If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code
  Empowers Large Language Models to Serve as Intelligent Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ke Yang, Jiateng Liu, John Wu, Chaoqi Yang, Yi R. Fung, Sha Li, Zixuan Huang, Xu Cao, Xingyao Wang, Yiquan Wang, Heng Ji, Chengxiang Zhai</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-01 16:51:20</h6>
<p class='card-text'>The prominent large language models (LLMs) of today differ from past language
models not only in size, but also in the fact that they are trained on a
combination of natural language and formal language (code). As a medium between
humans and computers, code translates high-level goals into executable steps,
featuring standard syntax, logical consistency, abstraction, and modularity. In
this survey, we present an overview of the various benefits of integrating code
into LLMs' training data. Specifically, beyond enhancing LLMs in code
generation, we observe that these unique properties of code help (i) unlock the
reasoning ability of LLMs, enabling their applications to a range of more
complex natural language tasks; (ii) steer LLMs to produce structured and
precise intermediate steps, which can then be connected to external execution
ends through function calls; and (iii) take advantage of code compilation and
execution environment, which also provides diverse feedback for model
improvement. In addition, we trace how these profound capabilities of LLMs,
brought by code, have led to their emergence as intelligent agents (IAs) in
situations where the ability to understand instructions, decompose goals, plan
and execute actions, and refine from feedback are crucial to their success on
downstream tasks. Finally, we present several key challenges and future
directions of empowering LLMs with code.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.00741v3' target='_blank'>ToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of
  Large Language Models in Real-world Scenarios</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Junjie Ye, Guanyu Li, Songyang Gao, Caishuang Huang, Yilong Wu, Sixian Li, Xiaoran Fan, Shihan Dou, Tao Ji, Qi Zhang, Tao Gui, Xuanjing Huang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2024-01-01 12:49:36</h6>
<p class='card-text'>Existing evaluations of tool learning primarily focus on validating the
alignment of selected tools for large language models (LLMs) with expected
outcomes. However, these approaches rely on a limited set of scenarios where
answers can be pre-determined, diverging from genuine needs. Furthermore, a
sole emphasis on outcomes disregards the complex capabilities required for LLMs
to effectively use tools. To tackle this issue, we propose ToolEyes, a
fine-grained system tailored for the evaluation of the LLMs' tool learning
capabilities in authentic scenarios. The system meticulously examines seven
real-world scenarios, analyzing five dimensions crucial to LLMs in tool
learning: format alignment, intent comprehension, behavior planning, tool
selection, and answer organization. Additionally, ToolEyes incorporates a tool
library boasting approximately 600 tools, serving as an intermediary between
LLMs and the physical world. Evaluations involving ten LLMs across three
categories reveal a preference for specific scenarios and limited cognitive
abilities in tool learning. Intriguingly, expanding the model size even
exacerbates the hindrance to tool learning. The code and data are available at
https://github.com/Junjie-Ye/ToolEyes.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.00134v1' target='_blank'>Unicron: Economizing Self-Healing LLM Training at Scale</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tao He, Xue Li, Zhibin Wang, Kun Qian, Jingbo Xu, Wenyuan Yu, Jingren Zhou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-12-30 04:06:16</h6>
<p class='card-text'>Training large-scale language models is increasingly critical in various
domains, but it is hindered by frequent failures, leading to significant time
and economic costs. Current failure recovery methods in cloud-based settings
inadequately address the diverse and complex scenarios that arise, focusing
narrowly on erasing downtime for individual tasks without considering the
overall cost impact on a cluster. We introduce Unicron, a workload manager
designed for efficient self-healing in large-scale language model training.
Unicron optimizes the training process by minimizing failure-related costs
across multiple concurrent tasks within a cluster. Its key features include
in-band error detection for real-time error identification without extra
overhead, a dynamic cost-aware plan generation mechanism for optimal
reconfiguration, and an efficient transition strategy to reduce downtime during
state changes. Deployed on a 128-GPU distributed cluster, Unicron demonstrates
up to a 1.9x improvement in training efficiency over state-of-the-art methods,
significantly reducing failure recovery costs and enhancing the reliability of
large-scale language model training.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.00125v1' target='_blank'>LLM-Assist: Enhancing Closed-Loop Planning with Language-Based Reasoning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:S P Sharan, Francesco Pittaluga, Vijay Kumar B G, Manmohan Chandraker</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-12-30 02:53:45</h6>
<p class='card-text'>Although planning is a crucial component of the autonomous driving stack,
researchers have yet to develop robust planning algorithms that are capable of
safely handling the diverse range of possible driving scenarios. Learning-based
planners suffer from overfitting and poor long-tail performance. On the other
hand, rule-based planners generalize well, but might fail to handle scenarios
that require complex driving maneuvers. To address these limitations, we
investigate the possibility of leveraging the common-sense reasoning
capabilities of Large Language Models (LLMs) such as GPT4 and Llama2 to
generate plans for self-driving vehicles. In particular, we develop a novel
hybrid planner that leverages a conventional rule-based planner in conjunction
with an LLM-based planner. Guided by commonsense reasoning abilities of LLMs,
our approach navigates complex scenarios which existing planners struggle with,
produces well-reasoned outputs while also remaining grounded through working
alongside the rule-based approach. Through extensive evaluation on the nuPlan
benchmark, we achieve state-of-the-art performance, outperforming all existing
pure learning- and rule-based methods across most metrics. Our code will be
available at https://llmassist.github.io.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2312.17748v2' target='_blank'>K-PERM: Personalized Response Generation Using Dynamic Knowledge
  Retrieval and Persona-Adaptive Queries</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kanak Raj, Kaushik Roy, Vamshi Bonagiri, Priyanshul Govil, Krishnaprasad Thirunarayanan, Manas Gaur</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-12-29 18:59:58</h6>
<p class='card-text'>Personalizing conversational agents can enhance the quality of conversations
and increase user engagement. However, they often lack external knowledge to
appropriately tend to a user's persona. This is particularly crucial for
practical applications like mental health support, nutrition planning,
culturally sensitive conversations, or reducing toxic behavior in
conversational agents. To enhance the relevance and comprehensiveness of
personalized responses, we propose using a two-step approach that involves (1)
selectively integrating user personas and (2) contextualizing the response with
supplementing information from a background knowledge source. We develop K-PERM
(Knowledge-guided PErsonalization with Reward Modulation), a dynamic
conversational agent that combines these elements. K-PERM achieves
state-of-the-art performance on the popular FoCus dataset, containing
real-world personalized conversations concerning global landmarks. We show that
using responses from K-PERM can improve performance in state-of-the-art LLMs
(GPT 3.5) by 10.5%, highlighting the impact of K-PERM for personalizing
chatbots.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2312.16127v5' target='_blank'>LLM-SAP: Large Language Models Situational Awareness Based Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Liman Wang, Hanyang Zhong</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-12-26 17:19:09</h6>
<p class='card-text'>This study explores integrating large language models (LLMs) with situational
awareness-based planning (SAP) to enhance the decision-making capabilities of
AI agents in dynamic and uncertain environments. We employ a multi-agent
reasoning framework to develop a methodology that anticipates and actively
mitigates potential risks through iterative feedback and evaluation processes.
Our approach diverges from traditional automata theory by incorporating the
complexity of human-centric interactions into the planning process, thereby
expanding the planning scope of LLMs beyond structured and predictable
scenarios. The results demonstrate significant improvements in the model's
ability to provide comparative safe actions within hazard interactions,
offering a perspective on proactive and reactive planning strategies. This
research highlights the potential of LLMs to perform human-like action
planning, thereby paving the way for more sophisticated, reliable, and safe AI
systems in unpredictable real-world applications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2312.15838v1' target='_blank'>SecQA: A Concise Question-Answering Dataset for Evaluating Large
  Language Models in Computer Security</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zefang Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-12-26 00:59:30</h6>
<p class='card-text'>In this paper, we introduce SecQA, a novel dataset tailored for evaluating
the performance of Large Language Models (LLMs) in the domain of computer
security. Utilizing multiple-choice questions generated by GPT-4 based on the
"Computer Systems Security: Planning for Success" textbook, SecQA aims to
assess LLMs' understanding and application of security principles. We detail
the structure and intent of SecQA, which includes two versions of increasing
complexity, to provide a concise evaluation across various difficulty levels.
Additionally, we present an extensive evaluation of prominent LLMs, including
GPT-3.5-Turbo, GPT-4, Llama-2, Vicuna, Mistral, and Zephyr models, using both
0-shot and 5-shot learning settings. Our results, encapsulated in the SecQA v1
and v2 datasets, highlight the varying capabilities and limitations of these
models in the computer security context. This study not only offers insights
into the current state of LLMs in understanding security-related content but
also establishes SecQA as a benchmark for future advancements in this critical
research area.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2312.17016v1' target='_blank'>On the Promises and Challenges of Multimodal Foundation Models for
  Geographical, Environmental, Agricultural, and Urban Planning Applications</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chenjiao Tan, Qian Cao, Yiwei Li, Jielu Zhang, Xiao Yang, Huaqin Zhao, Zihao Wu, Zhengliang Liu, Hao Yang, Nemin Wu, Tao Tang, Xinyue Ye, Lilong Chai, Ninghao Liu, Changying Li, Lan Mu, Tianming Liu, Gengchen Mai</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-12-23 22:36:58</h6>
<p class='card-text'>The advent of large language models (LLMs) has heightened interest in their
potential for multimodal applications that integrate language and vision. This
paper explores the capabilities of GPT-4V in the realms of geography,
environmental science, agriculture, and urban planning by evaluating its
performance across a variety of tasks. Data sources comprise satellite imagery,
aerial photos, ground-level images, field images, and public datasets. The
model is evaluated on a series of tasks including geo-localization, textual
data extraction from maps, remote sensing image classification, visual question
answering, crop type identification, disease/pest/weed recognition, chicken
behavior analysis, agricultural object counting, urban planning knowledge
question answering, and plan generation. The results indicate the potential of
GPT-4V in geo-localization, land cover classification, visual question
answering, and basic image understanding. However, there are limitations in
several tasks requiring fine-grained recognition and precise counting. While
zero-shot learning shows promise, performance varies across problem domains and
image complexities. The work provides novel insights into GPT-4V's capabilities
and limitations for real-world geospatial, environmental, agricultural, and
urban planning challenges. Further research should focus on augmenting the
model's knowledge and reasoning for specialized domains through expanded
training. Overall, the analysis demonstrates foundational multimodal
intelligence, highlighting the potential of multimodal foundation models (FMs)
to advance interdisciplinary applications at the nexus of computer vision and
language.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2312.14828v1' target='_blank'>Plan, Posture and Go: Towards Open-World Text-to-Motion Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jinpeng Liu, Wenxun Dai, Chunyu Wang, Yiji Cheng, Yansong Tang, Xin Tong</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-12-22 17:02:45</h6>
<p class='card-text'>Conventional text-to-motion generation methods are usually trained on limited
text-motion pairs, making them hard to generalize to open-world scenarios. Some
works use the CLIP model to align the motion space and the text space, aiming
to enable motion generation from natural language motion descriptions. However,
they are still constrained to generate limited and unrealistic in-place
motions. To address these issues, we present a divide-and-conquer framework
named PRO-Motion, which consists of three modules as motion planner,
posture-diffuser and go-diffuser. The motion planner instructs Large Language
Models (LLMs) to generate a sequence of scripts describing the key postures in
the target motion. Differing from natural languages, the scripts can describe
all possible postures following very simple text templates. This significantly
reduces the complexity of posture-diffuser, which transforms a script to a
posture, paving the way for open-world generation. Finally, go-diffuser,
implemented as another diffusion model, estimates whole-body translations and
rotations for all postures, resulting in realistic motions. Experimental
results have shown the superiority of our method with other counterparts, and
demonstrated its capability of generating diverse and realistic motions from
complex open-world prompts such as "Experiencing a profound sense of joy". The
project page is available at https://moonsliu.github.io/Pro-Motion.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2312.14798v1' target='_blank'>Semantic Parsing for Complex Data Retrieval: Targeting Query Plans vs.
  SQL for No-Code Access to Relational Databases</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ben Eyal, Amir Bachar, Ophir Haroche, Michael Elhadad</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-12-22 16:16:15</h6>
<p class='card-text'>Large Language Models (LLMs) have spurred progress in text-to-SQL, the task
of generating SQL queries from natural language questions based on a given
database schema. Despite the declarative nature of SQL, it continues to be a
complex programming language. In this paper, we investigate the potential of an
alternative query language with simpler syntax and modular specification of
complex queries. The purpose is to create a query language that can be learned
more easily by modern neural semantic parsing architectures while also enabling
non-programmers to better assess the validity of the query plans produced by an
interactive query plan assistant.
  The proposed alternative query language is called Query Plan Language (QPL).
It is designed to be modular and can be translated into a restricted form of
SQL Common Table Expressions (CTEs). The aim of QPL is to make complex data
retrieval accessible to non-programmers by allowing users to express their
questions in natural language while also providing an easier-to-verify target
language. The paper demonstrates how neural LLMs can benefit from QPL's
modularity to generate complex query plans in a compositional manner. This
involves a question decomposition strategy and a planning stage.
  We conduct experiments on a version of the Spider text-to-SQL dataset that
has been converted to QPL. The hierarchical structure of QPL programs enables
us to measure query complexity naturally. Based on this assessment, we identify
the low accuracy of existing text-to-SQL systems on complex compositional
queries. We present ways to address the challenge of complex queries in an
iterative, user-controlled manner, using fine-tuned LLMs and a variety of
prompting strategies in a compositional manner.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2312.14033v3' target='_blank'>T-Eval: Evaluating the Tool Utilization Capability of Large Language
  Models Step by Step</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zehui Chen, Weihua Du, Wenwei Zhang, Kuikun Liu, Jiangning Liu, Miao Zheng, Jingming Zhuo, Songyang Zhang, Dahua Lin, Kai Chen, Feng Zhao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-12-21 17:02:06</h6>
<p class='card-text'>Large language models (LLM) have achieved remarkable performance on various
NLP tasks and are augmented by tools for broader applications. Yet, how to
evaluate and analyze the tool-utilization capability of LLMs is still
under-explored. In contrast to previous works that evaluate models
holistically, we comprehensively decompose the tool utilization into multiple
sub-processes, including instruction following, planning, reasoning, retrieval,
understanding, and review. Based on that, we further introduce T-Eval to
evaluate the tool utilization capability step by step. T-Eval disentangles the
tool utilization evaluation into several sub-domains along model capabilities,
facilitating the inner understanding of both holistic and isolated competency
of LLMs. We conduct extensive experiments on T-Eval and in-depth analysis of
various LLMs. T-Eval not only exhibits consistency with the outcome-oriented
evaluation but also provides a more fine-grained analysis of the capabilities
of LLMs, providing a new perspective in LLM evaluation on tool-utilization
ability. The benchmark will be available at
https://github.com/open-compass/T-Eval.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2312.13787v1' target='_blank'>User-adaptive Tourist Information Dialogue System with Yes/No Classifier
  and Sentiment Estimator</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ryo Yanagimoto, Yunosuke Kubo, Miki Oshio, Mikio Nakano, Kenta Yamamoto, Kazunori Komatani</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-12-21 12:23:14</h6>
<p class='card-text'>We introduce our system developed for Dialogue Robot Competition 2023
(DRC2023). First, rule-based utterance selection and utterance generation using
a large language model (LLM) are combined. We ensure the quality of system
utterances while also being able to respond to unexpected user utterances.
Second, dialogue flow is controlled by considering the results of the
BERT-based yes/no classifier and sentiment estimator. These allow the system to
adapt state transitions and sightseeing plans to the user.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2312.13545v2' target='_blank'>Developing Interactive Tourism Planning: A Dialogue Robot System Powered
  by a Large Language Model</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Katsumasa Yoshikawa, Takato Yamazaki, Masaya Ohagi, Tomoya Mizumoto, Keiya Sato</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-12-21 03:09:38</h6>
<p class='card-text'>In recent years, large language models (LLMs) have rapidly proliferated and
have been utilized in various tasks, including research in dialogue systems. We
aimed to construct a system that not only leverages the flexible conversational
abilities of LLMs but also their advanced planning capabilities to reduce the
speaking load on human interlocutors and efficiently plan trips. Furthermore,
we propose a method that divides the complex task of a travel agency into
multiple subtasks, managing each as a separate phase to effectively accomplish
the task. Our proposed system confirmed a certain level of success by achieving
fourth place in the Dialogue Robot Competition 2023 preliminaries rounds. We
report on the challenges identified through the competition.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2312.13126v1' target='_blank'>Generative agents in the streets: Exploring the use of Large Language
  Models (LLMs) in collecting urban perceptions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Deepank Verma, Olaf Mumm, Vanessa Miriam Carlow</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-12-20 15:45:54</h6>
<p class='card-text'>Evaluating the surroundings to gain understanding, frame perspectives, and
anticipate behavioral reactions is an inherent human trait. However, these
continuous encounters are diverse and complex, posing challenges to their study
and experimentation. Researchers have been able to isolate environmental
features and study their effect on human perception and behavior. However, the
research attempts to replicate and study human behaviors with proxies, such as
by integrating virtual mediums and interviews, have been inconsistent. Large
language models (LLMs) have recently been unveiled as capable of contextual
understanding and semantic reasoning. These models have been trained on large
amounts of text and have evolved to mimic believable human behavior. This study
explores the current advancements in Generative agents powered by LLMs with the
help of perceptual experiments. The experiment employs Generative agents to
interact with the urban environments using street view images to plan their
journey toward specific goals. The agents are given virtual personalities,
which make them distinguishable. They are also provided a memory database to
store their thoughts and essential visual information and retrieve it when
needed to plan their movement. Since LLMs do not possess embodiment, nor have
access to the visual realm, and lack a sense of motion or direction, we
designed movement and visual modules that help agents gain an overall
understanding of surroundings. The agents are further employed to rate the
surroundings they encounter based on their perceived sense of safety and
liveliness. As these agents store details in their memory, we query the
findings to get details regarding their thought processes. Overall, this study
experiments with current AI developments and their potential in simulated human
behavior in urban environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2312.12808v1' target='_blank'>Enhancing Consistency in Multimodal Dialogue System Using LLM with
  Dialogue Scenario</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hiroki Onozeki, Zhiyang Qi, Kazuma Akiyama, Ryutaro Asahara, Takumasa Kaneko, Michimasa Inaba</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-12-20 07:15:04</h6>
<p class='card-text'>This paper describes our dialogue system submitted to Dialogue Robot
Competition 2023. The system's task is to help a user at a travel agency decide
on a plan for visiting two sightseeing spots in Kyoto City that satisfy the
user. Our dialogue system is flexible and stable and responds to user
requirements by controlling dialogue flow according to dialogue scenarios. We
also improved user satisfaction by introducing motion and speech control based
on system utterances and user situations. In the preliminary round, our system
was ranked fifth in the impression evaluation and sixth in the plan evaluation
among all 12 teams.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2312.11865v3' target='_blank'>Large Language Models Play StarCraft II: Benchmarks and A Chain of
  Summarization Approach</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Weiyu Ma, Qirui Mi, Yongcheng Zeng, Xue Yan, Yuqiao Wu, Runji Lin, Haifeng Zhang, Jun Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-12-19 05:27:16</h6>
<p class='card-text'>StarCraft II is a challenging benchmark for AI agents due to the necessity of
both precise micro level operations and strategic macro awareness. Previous
works, such as Alphastar and SCC, achieve impressive performance on tackling
StarCraft II , however, still exhibit deficiencies in long term strategic
planning and strategy interpretability. Emerging large language model (LLM)
agents, such as Voyage and MetaGPT, presents the immense potential in solving
intricate tasks. Motivated by this, we aim to validate the capabilities of LLMs
on StarCraft II, a highly complex RTS game.To conveniently take full advantage
of LLMs` reasoning abilities, we first develop textual StratCraft II
environment, called TextStarCraft II, which LLM agent can interact. Secondly,
we propose a Chain of Summarization method, including single frame
summarization for processing raw observations and multi frame summarization for
analyzing game information, providing command recommendations, and generating
strategic decisions. Our experiment consists of two parts: first, an evaluation
by human experts, which includes assessing the LLMs`s mastery of StarCraft II
knowledge and the performance of LLM agents in the game; second, the in game
performance of LLM agents, encompassing aspects like win rate and the impact of
Chain of Summarization.Experiment results demonstrate that: 1. LLMs possess the
relevant knowledge and complex planning abilities needed to address StarCraft
II scenarios; 2. Human experts consider the performance of LLM agents to be
close to that of an average player who has played StarCraft II for eight years;
3. LLM agents are capable of defeating the built in AI at the Harder(Lv5)
difficulty level. We have open sourced the code and released demo videos of LLM
agent playing StarCraft II.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2312.11690v1' target='_blank'>Agent-based Learning of Materials Datasets from Scientific Literature</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mehrad Ansari, Seyed Mohamad Moosavi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-12-18 20:29:58</h6>
<p class='card-text'>Advancements in machine learning and artificial intelligence are transforming
materials discovery. Yet, the availability of structured experimental data
remains a bottleneck. The vast corpus of scientific literature presents a
valuable and rich resource of such data. However, manual dataset creation from
these resources is challenging due to issues in maintaining quality and
consistency, scalability limitations, and the risk of human error and bias.
Therefore, in this work, we develop a chemist AI agent, powered by large
language models (LLMs), to overcome these challenges by autonomously creating
structured datasets from natural language text, ranging from sentences and
paragraphs to extensive scientific research articles. Our chemist AI agent,
Eunomia, can plan and execute actions by leveraging the existing knowledge from
decades of scientific research articles, scientists, the Internet and other
tools altogether. We benchmark the performance of our approach in three
different information extraction tasks with various levels of complexity,
including solid-state impurity doping, metal-organic framework (MOF) chemical
formula, and property relations. Our results demonstrate that our zero-shot
agent, with the appropriate tools, is capable of attaining performance that is
either superior or comparable to the state-of-the-art fine-tuned materials
information extraction methods. This approach simplifies compilation of machine
learning-ready datasets for various materials discovery applications, and
significantly ease the accessibility of advanced natural language processing
tools for novice users in natural language. The methodology in this work is
developed as an open-source software on https://github.com/AI4ChemS/Eunomia.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2312.11190v2' target='_blank'>VisionTasker: Mobile Task Automation Using Vision Based UI Understanding
  and LLM Task Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yunpeng Song, Yiheng Bian, Yongtao Tang, Guiyu Ma, Zhongmin Cai</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-12-18 13:35:46</h6>
<p class='card-text'>Mobile task automation is an emerging field that leverages AI to streamline
and optimize the execution of routine tasks on mobile devices, thereby
enhancing efficiency and productivity. Traditional methods, such as Programming
By Demonstration (PBD), are limited due to their dependence on predefined tasks
and susceptibility to app updates. Recent advancements have utilized the view
hierarchy to collect UI information and employed Large Language Models (LLM) to
enhance task automation. However, view hierarchies have accessibility issues
and face potential problems like missing object descriptions or misaligned
structures. This paper introduces VisionTasker, a two-stage framework combining
vision-based UI understanding and LLM task planning, for mobile task automation
in a step-by-step manner. VisionTasker firstly converts a UI screenshot into
natural language interpretations using a vision-based UI understanding
approach, eliminating the need for view hierarchies. Secondly, it adopts a
step-by-step task planning method, presenting one interface at a time to the
LLM. The LLM then identifies relevant elements within the interface and
determines the next action, enhancing accuracy and practicality. Extensive
experiments show that VisionTasker outperforms previous methods, providing
effective UI representations across four datasets. Additionally, in automating
147 real-world tasks on an Android smartphone, VisionTasker demonstrates
advantages over humans in tasks where humans show unfamiliarity and shows
significant improvements when integrated with the PBD mechanism. VisionTasker
is open-source and available at https://github.com/AkimotoAyako/VisionTasker.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2312.10448v1' target='_blank'>Resolving Crash Bugs via Large Language Models: An Empirical Study</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xueying Du, Mingwei Liu, Juntao Li, Hanlin Wang, Xin Peng, Yiling Lou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-12-16 13:41:04</h6>
<p class='card-text'>Crash bugs cause unexpected program behaviors or even termination, requiring
high-priority resolution. However, manually resolving crash bugs is challenging
and labor-intensive, and researchers have proposed various techniques for their
automated localization and repair. ChatGPT, a recent large language model
(LLM), has garnered significant attention due to its exceptional performance
across various domains. This work performs the first investigation into
ChatGPT's capability in resolve real-world crash bugs, focusing on its
effectiveness in both localizing and repairing code-related and
environment-related crash bugs. Specifically, we initially assess ChatGPT's
fundamental ability to resolve crash bugs with basic prompts in a single
iteration. We observe that ChatGPT performs better at resolving code-related
crash bugs compared to environment-related ones, and its primary challenge in
resolution lies in inaccurate localization. Additionally, we explore ChatGPT's
potential with various advanced prompts. Furthermore, by stimulating ChatGPT's
self-planning, it methodically investigates each potential crash-causing
environmental factor through proactive inquiry, ultimately identifying the root
cause of the crash. Based on our findings, we propose IntDiagSolver, an
interaction methodology designed to facilitate precise crash bug resolution
through continuous interaction with LLMs. Evaluating IntDiagSolver on multiple
LLMs reveals consistent enhancement in the accuracy of crash bug resolution,
including ChatGPT, Claude, and CodeLlama.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2312.10332v1' target='_blank'>ProTIP: Progressive Tool Retrieval Improves Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Raviteja Anantha, Bortik Bandyopadhyay, Anirudh Kashi, Sayantan Mahinder, Andrew W Hill, Srinivas Chappidi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-12-16 05:43:11</h6>
<p class='card-text'>Large language models (LLMs) are increasingly employed for complex multi-step
planning tasks, where the tool retrieval (TR) step is crucial for achieving
successful outcomes. Two prevalent approaches for TR are single-step retrieval,
which utilizes the complete query, and sequential retrieval using task
decomposition (TD), where a full query is segmented into discrete atomic
subtasks. While single-step retrieval lacks the flexibility to handle
"inter-tool dependency," the TD approach necessitates maintaining "subtask-tool
atomicity alignment," as the toolbox can evolve dynamically. To address these
limitations, we introduce the Progressive Tool retrieval to Improve Planning
(ProTIP) framework. ProTIP is a lightweight, contrastive learning-based
framework that implicitly performs TD without the explicit requirement of
subtask labels, while simultaneously maintaining subtask-tool atomicity. On the
ToolBench dataset, ProTIP outperforms the ChatGPT task decomposition-based
approach by a remarkable margin, achieving a 24% improvement in Recall@K=10 for
TR and a 41% enhancement in tool accuracy for plan generation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2312.09245v2' target='_blank'>DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral
  Planning States for Autonomous Driving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wenhai Wang, Jiangwei Xie, ChuanYang Hu, Haoming Zou, Jianan Fan, Wenwen Tong, Yang Wen, Silei Wu, Hanming Deng, Zhiqi Li, Hao Tian, Lewei Lu, Xizhou Zhu, Xiaogang Wang, Yu Qiao, Jifeng Dai</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-12-14 18:59:05</h6>
<p class='card-text'>Large language models (LLMs) have opened up new possibilities for intelligent
agents, endowing them with human-like thinking and cognitive abilities. In this
work, we delve into the potential of large language models (LLMs) in autonomous
driving (AD). We introduce DriveMLM, an LLM-based AD framework that can perform
close-loop autonomous driving in realistic simulators. To this end, (1) we
bridge the gap between the language decisions and the vehicle control commands
by standardizing the decision states according to the off-the-shelf motion
planning module. (2) We employ a multi-modal LLM (MLLM) to model the behavior
planning module of a module AD system, which uses driving rules, user commands,
and inputs from various sensors (e.g., camera, lidar) as input and makes
driving decisions and provide explanations; This model can plug-and-play in
existing AD systems such as Apollo for close-loop driving. (3) We design an
effective data engine to collect a dataset that includes decision state and
corresponding explanation annotation for model training and evaluation. We
conduct extensive experiments and show that our model achieves 76.1 driving
score on the CARLA Town05 Long, and surpasses the Apollo baseline by 4.7 points
under the same settings, demonstrating the effectiveness of our model. We hope
this work can serve as a baseline for autonomous driving with LLMs. Code and
models shall be released at https://github.com/OpenGVLab/DriveMLM.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2312.08282v2' target='_blank'>Prompting LLMs with content plans to enhance the summarization of
  scientific articles</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Aldan Creo, Manuel Lama, Juan C. Vidal</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-12-13 16:57:31</h6>
<p class='card-text'>This paper presents novel prompting techniques to improve the performance of
automatic summarization systems for scientific articles. Scientific article
summarization is highly challenging due to the length and complexity of these
documents. We conceive, implement, and evaluate prompting techniques that
provide additional contextual information to guide summarization systems.
Specifically, we feed summarizers with lists of key terms extracted from
articles, such as author keywords or automatically generated keywords. Our
techniques are tested with various summarization models and input texts.
Results show performance gains, especially for smaller models summarizing
sections separately. This evidences that prompting is a promising approach to
overcoming the limitations of less powerful systems. Our findings introduce a
new research direction of using prompts to aid smaller models.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2312.11525v1' target='_blank'>Synocene, Beyond the Anthropocene: De-Anthropocentralising
  Human-Nature-AI Interaction</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Isabelle Hupont, Marina Wainer, Sam Nester, Sylvie Tissot, Lucía Iglesias-Blanco, Sandra Baldassarri</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-12-13 11:04:06</h6>
<p class='card-text'>Recent publications explore AI biases in detecting objects and people in the
environment. However, there is no research tackling how AI examines nature.
This case study presents a pioneering exploration into the AI attitudes
(ecocentric, anthropocentric and antipathetic) toward nature. Experiments with
a Large Language Model (LLM) and an image captioning algorithm demonstrate the
presence of anthropocentric biases in AI. Moreover, to delve deeper into these
biases and Human-Nature-AI interaction, we conducted a real-life experiment in
which participants underwent an immersive de-anthropocentric experience in a
forest and subsequently engaged with ChatGPT to co-create narratives. By
creating fictional AI chatbot characters with ecocentric attributes, emotions
and views, we successfully amplified ecocentric exchanges. We encountered some
difficulties, mainly that participants deviated from narrative co-creation to
short dialogues and questions and answers, possibly due to the novelty of
interacting with LLMs. To solve this problem, we recommend providing
preliminary guidelines on interacting with LLMs and allowing participants to
get familiar with the technology. We plan to repeat this experiment in various
countries and forests to expand our corpus of ecocentric materials.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2312.07850v1' target='_blank'>Large Language Model Enhanced Multi-Agent Systems for 6G Communications</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Feibo Jiang, Li Dong, Yubo Peng, Kezhi Wang, Kun Yang, Cunhua Pan, Dusit Niyato, Octavia A. Dobre</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-12-13 02:35:57</h6>
<p class='card-text'>The rapid development of the Large Language Model (LLM) presents huge
opportunities for 6G communications, e.g., network optimization and management
by allowing users to input task requirements to LLMs by nature language.
However, directly applying native LLMs in 6G encounters various challenges,
such as a lack of private communication data and knowledge, limited logical
reasoning, evaluation, and refinement abilities. Integrating LLMs with the
capabilities of retrieval, planning, memory, evaluation and reflection in
agents can greatly enhance the potential of LLMs for 6G communications. To this
end, we propose a multi-agent system with customized communication knowledge
and tools for solving communication related tasks using natural language,
comprising three components: (1) Multi-agent Data Retrieval (MDR), which
employs the condensate and inference agents to refine and summarize
communication knowledge from the knowledge base, expanding the knowledge
boundaries of LLMs in 6G communications; (2) Multi-agent Collaborative Planning
(MCP), which utilizes multiple planning agents to generate feasible solutions
for the communication related task from different perspectives based on the
retrieved knowledge; (3) Multi-agent Evaluation and Reflecxion (MER), which
utilizes the evaluation agent to assess the solutions, and applies the
reflexion agent and refinement agent to provide improvement suggestions for
current solutions. Finally, we validate the effectiveness of the proposed
multi-agent system by designing a semantic communication system, as a case
study of 6G communications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2312.07693v1' target='_blank'>Scaling Culture in Blockchain Gaming: Generative AI and Pseudonymous
  Engagement</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Henrik Axelsen, Sebastian Axelsen, Valdemar Licht, Jason Potts</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-12-12 19:38:43</h6>
<p class='card-text'>Managing rapidly growing decentralized gaming communities brings unique
challenges at the nexus of cultural economics and technology. This paper
introduces a streamlined analytical framework that utilizes Large Language
Models (LLMs), in this instance open-access generative pre-trained transformer
(GPT) models, offering an efficient solution with deeper insights into
community dynamics. The framework aids moderators in identifying pseudonymous
actor intent, moderating toxic behavior, rewarding desired actions to avoid
unintended consequences of blockchain-based gaming, and gauging community
sentiment as communities venture into metaverse platforms and plan for
hypergrowth. This framework strengthens community controls, eases onboarding,
and promotes a common moral mission across communities while reducing agency
costs by 95 pct. Highlighting the transformative role of generative AI, the
paper emphasizes its potential to redefine the cost of cultural production. It
showcases the utility of GPTs in digital community management, expanding their
implications in cultural economics and transmedia storytelling.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2312.07368v1' target='_blank'>Sequential Planning in Large Partially Observable Environments guided by
  LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Swarna Kamal Paul</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-12-12 15:36:59</h6>
<p class='card-text'>Sequential planning in large state space and action space quickly becomes
intractable due to combinatorial explosion of the search space. Heuristic
methods, like monte-carlo tree search, though effective for large state space,
but struggle if action space is large. Pure reinforcement learning methods,
relying only on reward signals, needs prohibitively large interactions with the
environment to device a viable plan. If the state space, observations and
actions can be represented in natural language then Large Language models (LLM)
can be used to generate action plans. Recently several such goal-directed
agents like Reflexion, CLIN, SayCan were able to surpass the performance of
other state-of-the-art methods with minimum or no task specific training. But
they still struggle with exploration and get stuck in local optima. Their
planning capabilities are limited by the limited reasoning capability of the
foundational LLMs on text data. We propose a hybrid agent "neoplanner", that
synergizes both state space search with queries to foundational LLM to get the
best action plan. The reward signals are quantitatively used to drive the
search. A balance of exploration and exploitation is maintained by maximizing
upper confidence bounds of values of states. In places where random exploration
is needed, the LLM is queried to generate an action plan. Learnings from each
trial are stored as entity relationships in text format. Those are used in
future queries to the LLM for continual improvement. Experiments in the
Scienceworld environment reveals a 124% improvement from the current best
method in terms of average reward gained across multiple tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2401.00006v3' target='_blank'>Building Open-Ended Embodied Agent via Language-Policy Bidirectional
  Adaptation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shaopeng Zhai, Jie Wang, Tianyi Zhang, Fuxian Huang, Qi Zhang, Ming Zhou, Jing Hou, Yu Qiao, Yu Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-12-12 11:06:07</h6>
<p class='card-text'>Building embodied agents on integrating Large Language Models (LLMs) and
Reinforcement Learning (RL) have revolutionized human-AI interaction:
researchers can now leverage language instructions to plan decision-making for
open-ended tasks. However, existing research faces challenges in meeting the
requirement of open-endedness. They typically either train LLM/RL models to
adapt to a fixed counterpart, limiting exploration of novel skills and
hindering the efficacy of human-AI interaction. To this end, we present
OpenPAL, a co-training framework comprising two stages: (1) fine-tuning a
pre-trained LLM to translate human instructions into goals for planning, and
goal-conditioned training a policy for decision-making; (2) co-training to
align the LLM and policy, achieving instruction open-endedness. We conducted
experiments using Contra, an open-ended FPS game, demonstrating that an agent
trained with OpenPAL not only comprehends arbitrary instructions but also
exhibits efficient execution. These results suggest that OpenPAL holds the
potential to construct open-ended embodied agents in practical scenarios.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2312.06876v1' target='_blank'>Interactive Planning Using Large Language Models for Partially
  Observable Robotics Tasks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lingfeng Sun, Devesh K. Jha, Chiori Hori, Siddarth Jain, Radu Corcodel, Xinghao Zhu, Masayoshi Tomizuka, Diego Romeres</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-12-11 22:54:44</h6>
<p class='card-text'>Designing robotic agents to perform open vocabulary tasks has been the
long-standing goal in robotics and AI. Recently, Large Language Models (LLMs)
have achieved impressive results in creating robotic agents for performing open
vocabulary tasks. However, planning for these tasks in the presence of
uncertainties is challenging as it requires \enquote{chain-of-thought}
reasoning, aggregating information from the environment, updating state
estimates, and generating actions based on the updated state estimates. In this
paper, we present an interactive planning technique for partially observable
tasks using LLMs. In the proposed method, an LLM is used to collect missing
information from the environment using a robot and infer the state of the
underlying problem from collected observations while guiding the robot to
perform the required actions. We also use a fine-tuned Llama 2 model via
self-instruct and compare its performance against a pre-trained LLM like GPT-4.
Results are demonstrated on several tasks in simulation as well as real-world
environments. A video describing our work along with some results could be
found here.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2312.06853v2' target='_blank'>LLF-Bench: Benchmark for Interactive Learning from Language Feedback</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ching-An Cheng, Andrey Kolobov, Dipendra Misra, Allen Nie, Adith Swaminathan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-12-11 21:49:04</h6>
<p class='card-text'>We introduce a new benchmark, LLF-Bench (Learning from Language Feedback
Benchmark; pronounced as "elf-bench"), to evaluate the ability of AI agents to
interactively learn from natural language feedback and instructions. Learning
from language feedback (LLF) is essential for people, largely because the rich
information this feedback provides can help a learner avoid much of trial and
error and thereby speed up the learning process. Large Language Models (LLMs)
have recently enabled AI agents to comprehend natural language -- and hence AI
agents can potentially benefit from language feedback during learning like
humans do. But existing interactive benchmarks do not assess this crucial
capability: they either use numeric reward feedback or require no learning at
all (only planning or information retrieval). LLF-Bench is designed to fill
this omission. LLF-Bench is a diverse collection of sequential decision-making
tasks that includes user recommendation, poem writing, navigation, and robot
control. The objective of an agent is to interactively solve these tasks based
on their natural-language instructions and the feedback received after taking
actions. Crucially, to ensure that the agent actually "learns" from the
feedback, LLF-Bench implements several randomization techniques (such as
paraphrasing and environment randomization) to ensure that the task isn't
familiar to the agent and that the agent is robust to various verbalizations.
In addition, LLF-Bench provides a unified OpenAI Gym interface for all its
tasks and allows the users to easily configure the information the feedback
conveys (among suggestion, explanation, and instantaneous performance) to study
how agents respond to different types of feedback. Together, these features
make LLF-Bench a unique research platform for developing and testing LLF
agents.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2312.06351v1' target='_blank'>Evaluation of Large Language Models for Decision Making in Autonomous
  Driving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kotaro Tanahashi, Yuichi Inoue, Yu Yamaguchi, Hidetatsu Yaginuma, Daiki Shiotsuka, Hiroyuki Shimatani, Kohei Iwamasa, Yoshiaki Inoue, Takafumi Yamaguchi, Koki Igari, Tsukasa Horinouchi, Kento Tokuhiro, Yugo Tokuchi, Shunsuke Aoki</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-12-11 12:56:40</h6>
<p class='card-text'>Various methods have been proposed for utilizing Large Language Models (LLMs)
in autonomous driving. One strategy of using LLMs for autonomous driving
involves inputting surrounding objects as text prompts to the LLMs, along with
their coordinate and velocity information, and then outputting the subsequent
movements of the vehicle. When using LLMs for such purposes, capabilities such
as spatial recognition and planning are essential. In particular, two
foundational capabilities are required: (1) spatial-aware decision making,
which is the ability to recognize space from coordinate information and make
decisions to avoid collisions, and (2) the ability to adhere to traffic rules.
However, quantitative research has not been conducted on how accurately
different types of LLMs can handle these problems. In this study, we
quantitatively evaluated these two abilities of LLMs in the context of
autonomous driving. Furthermore, to conduct a Proof of Concept (POC) for the
feasibility of implementing these abilities in actual vehicles, we developed a
system that uses LLMs to drive a vehicle.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2312.05708v1' target='_blank'>Context Tuning for Retrieval Augmented Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Raviteja Anantha, Tharun Bethi, Danil Vodianik, Srinivas Chappidi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-12-09 23:33:16</h6>
<p class='card-text'>Large language models (LLMs) have the remarkable ability to solve new tasks
with just a few examples, but they need access to the right tools. Retrieval
Augmented Generation (RAG) addresses this problem by retrieving a list of
relevant tools for a given task. However, RAG's tool retrieval step requires
all the required information to be explicitly present in the query. This is a
limitation, as semantic search, the widely adopted tool retrieval method, can
fail when the query is incomplete or lacks context. To address this limitation,
we propose Context Tuning for RAG, which employs a smart context retrieval
system to fetch relevant information that improves both tool retrieval and plan
generation. Our lightweight context retrieval model uses numerical,
categorical, and habitual usage signals to retrieve and rank context items. Our
empirical results demonstrate that context tuning significantly enhances
semantic search, achieving a 3.5-fold and 1.5-fold improvement in Recall@K for
context retrieval and tool retrieval tasks respectively, and resulting in an
11.6% increase in LLM-based planner accuracy. Additionally, we show that our
proposed lightweight model using Reciprocal Rank Fusion (RRF) with LambdaMART
outperforms GPT-4 based retrieval. Moreover, we observe context augmentation at
plan generation, even after tool retrieval, reduces hallucination.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2312.14950v2' target='_blank'>TypeFly: Flying Drones with Large Language Model</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Guojun Chen, Xiaojing Yu, Neiwen Ling, Lin Zhong</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-12-08 15:57:18</h6>
<p class='card-text'>Recent advancements in robot control using large language models (LLMs) have
demonstrated significant potential, primarily due to LLMs' capabilities to
understand natural language commands and generate executable plans in various
languages. However, in real-time and interactive applications involving mobile
robots, particularly drones, the sequential token generation process inherent
to LLMs introduces substantial latency, i.e. response time, in control plan
generation.
  In this paper, we present a system called ChatFly that tackles this problem
using a combination of a novel programming language called MiniSpec and its
runtime to reduce the plan generation time and drone response time. That is,
instead of asking an LLM to write a program (robotic plan) in the popular but
verbose Python, ChatFly gets it to do it in MiniSpec specially designed for
token efficiency and stream interpretation. Using a set of challenging drone
tasks, we show that design choices made by ChatFly can reduce up to 62%
response time and provide a more consistent user experience, enabling
responsive and intelligent LLM-based drone control with efficient completion.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2312.04889v3' target='_blank'>KwaiAgents: Generalized Information-seeking Agent System with Large
  Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Haojie Pan, Zepeng Zhai, Hao Yuan, Yaojia Lv, Ruiji Fu, Ming Liu, Zhongyuan Wang, Bing Qin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-12-08 08:11:11</h6>
<p class='card-text'>Driven by curiosity, humans have continually sought to explore and understand
the world around them, leading to the invention of various tools to satiate
this inquisitiveness. Despite not having the capacity to process and memorize
vast amounts of information in their brains, humans excel in critical thinking,
planning, reflection, and harnessing available tools to interact with and
interpret the world, enabling them to find answers efficiently. The recent
advancements in large language models (LLMs) suggest that machines might also
possess the aforementioned human-like capabilities, allowing them to exhibit
powerful abilities even with a constrained parameter count. In this paper, we
introduce KwaiAgents, a generalized information-seeking agent system based on
LLMs. Within KwaiAgents, we propose an agent system that employs LLMs as its
cognitive core, which is capable of understanding a user's query, behavior
guidelines, and referencing external documents. The agent can also update and
retrieve information from its internal memory, plan and execute actions using a
time-aware search-browse toolkit, and ultimately provide a comprehensive
response. We further investigate the system's performance when powered by LLMs
less advanced than GPT-4, and introduce the Meta-Agent Tuning (MAT) framework,
designed to ensure even an open-sourced 7B or 13B model performs well among
many agent systems. We exploit both benchmark and human evaluations to
systematically validate these capabilities. Extensive experiments show the
superiority of our agent system compared to other autonomous agents and
highlight the enhanced generalized agent-abilities of our fine-tuned LLMs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2312.04511v3' target='_blank'>An LLM Compiler for Parallel Function Calling</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sehoon Kim, Suhong Moon, Ryan Tabrizi, Nicholas Lee, Michael W. Mahoney, Kurt Keutzer, Amir Gholami</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-12-07 18:32:04</h6>
<p class='card-text'>The reasoning capabilities of the recent LLMs enable them to execute external
function calls to overcome their inherent limitations, such as knowledge
cutoffs, poor arithmetic skills, or lack of access to private data. This
development has allowed LLMs to select and coordinate multiple functions based
on the context to tackle more complex problems. However, current methods for
function calling often require sequential reasoning and acting for each
function which can result in high latency, cost, and sometimes inaccurate
behavior. To address this, we introduce LLMCompiler, which executes functions
in parallel to efficiently orchestrate multiple function calls. Drawing
inspiration from the principles of classical compilers, LLMCompiler enables
parallel function calling with three components: (i) a Function Calling
Planner, formulating execution plans for function calling; (ii) a Task Fetching
Unit, dispatching function calling tasks; and (iii) an Executor, executing
these tasks in parallel. LLMCompiler automatically generates an optimized
orchestration for the function calls and can be used with both open-source and
closed-source models. We have benchmarked LLMCompiler on a range of tasks with
different patterns of function calling. We observe consistent latency speedup
of up to 3.7x, cost savings of up to 6.7x, and accuracy improvement of up to
~9% compared to ReAct. Our code is available at
https://github.com/SqueezeAILab/LLMCompiler.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2312.03134v1' target='_blank'>A Hardware Evaluation Framework for Large Language Model Inference</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hengrui Zhang, August Ning, Rohan Prabhakar, David Wentzlaff</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-12-05 21:01:33</h6>
<p class='card-text'>The past year has witnessed the increasing popularity of Large Language
Models (LLMs). Their unprecedented scale and associated high hardware cost have
impeded their broader adoption, calling for efficient hardware designs. With
the large hardware needed to simply run LLM inference, evaluating different
hardware designs becomes a new bottleneck.
  This work introduces LLMCompass, a hardware evaluation framework for LLM
inference workloads. LLMCompass is fast, accurate, versatile, and able to
describe and evaluate different hardware designs. LLMCompass includes a mapper
to automatically find performance-optimal mapping and scheduling. It also
incorporates an area-based cost model to help architects reason about their
design choices. Compared to real-world hardware, LLMCompass' estimated latency
achieves an average 10.4% error rate across various operators with various
input sizes and an average 4.1% error rate for LLM inference. With LLMCompass,
simulating a 4-NVIDIA A100 GPU node running GPT-3 175B inference can be done
within 16 minutes on commodity hardware, including 26,400 rounds of the
mapper's parameter search.
  With the aid of LLMCompass, this work draws architectural implications and
explores new cost-effective hardware designs. By reducing the compute
capability or replacing High Bandwidth Memory (HBM) with traditional DRAM,
these new designs can achieve as much as 3.41x improvement in performance/cost
compared to an NVIDIA A100, making them promising choices for democratizing
LLMs.
  LLMCompass is planned to be fully open-source.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2312.03042v1' target='_blank'>Inherent limitations of LLMs regarding spatial information</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:He Yan, Xinyao Hu, Xiangpeng Wan, Chengyu Huang, Kai Zou, Shiqi Xu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-12-05 16:02:20</h6>
<p class='card-text'>Despite the significant advancements in natural language processing
capabilities demonstrated by large language models such as ChatGPT, their
proficiency in comprehending and processing spatial information, especially
within the domains of 2D and 3D route planning, remains notably underdeveloped.
This paper investigates the inherent limitations of ChatGPT and similar models
in spatial reasoning and navigation-related tasks, an area critical for
applications ranging from autonomous vehicle guidance to assistive technologies
for the visually impaired. In this paper, we introduce a novel evaluation
framework complemented by a baseline dataset, meticulously crafted for this
study. This dataset is structured around three key tasks: plotting spatial
points, planning routes in two-dimensional (2D) spaces, and devising pathways
in three-dimensional (3D) environments. We specifically developed this dataset
to assess the spatial reasoning abilities of ChatGPT. Our evaluation reveals
key insights into the model's capabilities and limitations in spatial
understanding.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2312.02419v2' target='_blank'>Human Demonstrations are Generalizable Knowledge for Robots</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Te Cui, Guangyan Chen, Tianxing Zhou, Zicai Peng, Mengxiao Hu, Haoyang Lu, Haizhou Li, Meiling Wang, Yi Yang, Yufeng Yue</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-12-05 01:35:39</h6>
<p class='card-text'>Learning from human demonstrations is an emerging trend for designing
intelligent robotic systems. However, previous methods typically regard videos
as instructions, simply dividing them into action sequences for robotic
repetition, which poses obstacles to generalization to diverse tasks or object
instances. In this paper, we propose a different perspective, considering human
demonstration videos not as mere instructions, but as a source of knowledge for
robots. Motivated by this perspective and the remarkable comprehension and
generalization capabilities exhibited by large language models (LLMs), we
propose DigKnow, a method that DIstills Generalizable KNOWledge with a
hierarchical structure. Specifically, DigKnow begins by converting human
demonstration video frames into observation knowledge. This knowledge is then
subjected to analysis to extract human action knowledge and further distilled
into pattern knowledge compassing task and object instances, resulting in the
acquisition of generalizable knowledge with a hierarchical structure. In
settings with different tasks or object instances, DigKnow retrieves relevant
knowledge for the current task and object instances. Subsequently, the
LLM-based planner conducts planning based on the retrieved knowledge, and the
policy executes actions in line with the plan to achieve the designated task.
Utilizing the retrieved knowledge, we validate and rectify planning and
execution outcomes, resulting in a substantial enhancement of the success rate.
Experimental results across a range of tasks and scenes demonstrate the
effectiveness of this approach in facilitating real-world robots to accomplish
tasks with the knowledge derived from human demonstrations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2312.01797v2' target='_blank'>LLM A*: Human in the Loop Large Language Models Enabled A* Search for
  Robotics</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hengjia Xiao, Peng Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-12-04 10:37:58</h6>
<p class='card-text'>This research focuses on how Large Language Models (LLMs) can help with
(path) planning for mobile embodied agents such as robots, in a
human-in-the-loop and interactive manner. A novel framework named LLM A*, aims
to leverage the commonsense of LLMs, and the utility-optimal A* is proposed to
facilitate few-shot near-optimal path planning. Prompts are used for two main
purposes: 1) to provide LLMs with essential information like environments,
costs, heuristics, etc.; 2) to communicate human feedback on intermediate
planning results to LLMs. This approach takes human feedback on board and
renders the entire planning process transparent (akin to a `white box') to
humans. Moreover, it facilitates code-free path planning, thereby fostering the
accessibility and inclusiveness of artificial intelligence techniques to
communities less proficient in coding. Comparative analysis against A* and RL
demonstrates that LLM A* exhibits greater efficiency in terms of search space
and achieves paths comparable to A* while outperforming RL. The interactive
nature of LLM A* also makes it a promising tool for deployment in collaborative
human-robot tasks. Codes and Supplemental Materials can be found at GitHub:
https://github.com/speedhawk/LLM-A-.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2312.01059v1' target='_blank'>Swarm-GPT: Combining Large Language Models with Safe Motion Planning for
  Robot Choreography Design</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Aoran Jiao, Tanmay P. Patel, Sanjmi Khurana, Anna-Mariya Korol, Lukas Brunke, Vivek K. Adajania, Utku Culha, Siqi Zhou, Angela P. Schoellig</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-12-02 08:04:57</h6>
<p class='card-text'>This paper presents Swarm-GPT, a system that integrates large language models
(LLMs) with safe swarm motion planning - offering an automated and novel
approach to deployable drone swarm choreography. Swarm-GPT enables users to
automatically generate synchronized drone performances through natural language
instructions. With an emphasis on safety and creativity, Swarm-GPT addresses a
critical gap in the field of drone choreography by integrating the creative
power of generative models with the effectiveness and safety of model-based
planning algorithms. This goal is achieved by prompting the LLM to generate a
unique set of waypoints based on extracted audio data. A trajectory planner
processes these waypoints to guarantee collision-free and feasible motion.
Results can be viewed in simulation prior to execution and modified through
dynamic re-prompting. Sim-to-real transfer experiments demonstrate Swarm-GPT's
ability to accurately replicate simulated drone trajectories, with a mean
sim-to-real root mean square error (RMSE) of 28.7 mm. To date, Swarm-GPT has
been successfully showcased at three live events, exemplifying safe real-world
deployment of pre-trained models.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2312.00763v1' target='_blank'>Beyond ChatBots: ExploreLLM for Structured Thoughts and Personalized
  Model Responses</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xiao Ma, Swaroop Mishra, Ariel Liu, Sophie Su, Jilin Chen, Chinmay Kulkarni, Heng-Tze Cheng, Quoc Le, Ed Chi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-12-01 18:31:28</h6>
<p class='card-text'>Large language model (LLM) powered chatbots are primarily text-based today,
and impose a large interactional cognitive load, especially for exploratory or
sensemaking tasks such as planning a trip or learning about a new city. Because
the interaction is textual, users have little scaffolding in the way of
structure, informational "scent", or ability to specify high-level preferences
or goals. We introduce ExploreLLM that allows users to structure thoughts, help
explore different options, navigate through the choices and recommendations,
and to more easily steer models to generate more personalized responses. We
conduct a user study and show that users find it helpful to use ExploreLLM for
exploratory or planning tasks, because it provides a useful schema-like
structure to the task, and guides users in planning. The study also suggests
that users can more easily personalize responses with high-level preferences
with ExploreLLM. Together, ExploreLLM points to a future where users interact
with LLMs beyond the form of chatbots, and instead designed to support complex
user tasks with a tighter integration between natural language and graphical
user interfaces.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.18440v1' target='_blank'>Autonomous Agents in Software Development: A Vision Paper</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zeeshan Rasheed, Muhammad Waseem, Kai-Kristian Kemell, Wang Xiaofeng, Anh Nguyen Duc, Kari Systä, Pekka Abrahamsson</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-30 10:42:43</h6>
<p class='card-text'>Large Language Models (LLM) and Generative Pre-trained Transformers (GPT),
are reshaping the field of Software Engineering (SE). They enable innovative
methods for executing many software engineering tasks, including automated code
generation, debugging, maintenance, etc. However, only a limited number of
existing works have thoroughly explored the potential of GPT agents in SE. This
vision paper inquires about the role of GPT-based agents in SE. Our vision is
to leverage the capabilities of multiple GPT agents to contribute to SE tasks
and to propose an initial road map for future work. We argue that multiple GPT
agents can perform creative and demanding tasks far beyond coding and
debugging. GPT agents can also do project planning, requirements engineering,
and software design. These can be done through high-level descriptions given by
the human developer. We have shown in our initial experimental analysis for
simple software (e.g., Snake Game, Tic-Tac-Toe, Notepad) that multiple GPT
agents can produce high-quality code and document it carefully. We argue that
it shows a promise of unforeseen efficiency and will dramatically reduce
lead-times. To this end, we intend to expand our efforts to understand how we
can scale these autonomous capabilities further.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.18307v1' target='_blank'>Categorical Traffic Transformer: Interpretable and Diverse Behavior
  Prediction with Tokenized Latent</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuxiao Chen, Sander Tonkens, Marco Pavone</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-30 07:25:24</h6>
<p class='card-text'>Adept traffic models are critical to both planning and closed-loop simulation
for autonomous vehicles (AV), and key design objectives include accuracy,
diverse multimodal behaviors, interpretability, and downstream compatibility.
Recently, with the advent of large language models (LLMs), an additional
desirable feature for traffic models is LLM compatibility. We present
Categorical Traffic Transformer (CTT), a traffic model that outputs both
continuous trajectory predictions and tokenized categorical predictions (lane
modes, homotopies, etc.). The most outstanding feature of CTT is its fully
interpretable latent space, which enables direct supervision of the latent
variable from the ground truth during training and avoids mode collapse
completely. As a result, CTT can generate diverse behaviors conditioned on
different latent modes with semantic meanings while beating SOTA on prediction
accuracy. In addition, CTT's ability to input and output tokens enables
integration with LLMs for common-sense reasoning and zero-shot generalization.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.17842v2' target='_blank'>Look Before You Leap: Unveiling the Power of GPT-4V in Robotic
  Vision-Language Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yingdong Hu, Fanqi Lin, Tong Zhang, Li Yi, Yang Gao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-29 17:46:25</h6>
<p class='card-text'>In this study, we are interested in imbuing robots with the capability of
physically-grounded task planning. Recent advancements have shown that large
language models (LLMs) possess extensive knowledge useful in robotic tasks,
especially in reasoning and planning. However, LLMs are constrained by their
lack of world grounding and dependence on external affordance models to
perceive environmental information, which cannot jointly reason with LLMs. We
argue that a task planner should be an inherently grounded, unified multimodal
system. To this end, we introduce Robotic Vision-Language Planning (ViLa), a
novel approach for long-horizon robotic planning that leverages vision-language
models (VLMs) to generate a sequence of actionable steps. ViLa directly
integrates perceptual data into its reasoning and planning process, enabling a
profound understanding of commonsense knowledge in the visual world, including
spatial layouts and object attributes. It also supports flexible multimodal
goal specification and naturally incorporates visual feedback. Our extensive
evaluation, conducted in both real-robot and simulated environments,
demonstrates ViLa's superiority over existing LLM-based planners, highlighting
its effectiveness in a wide array of open-world manipulation tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.17474v1' target='_blank'>Large Language Models for Networking: Applications, Enabling Techniques,
  and Challenges</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yudong Huang, Hongyang Du, Xinyuan Zhang, Dusit Niyato, Jiawen Kang, Zehui Xiong, Shuo Wang, Tao Huang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-29 09:31:13</h6>
<p class='card-text'>The rapid evolution of network technologies and the growing complexity of
network tasks necessitate a paradigm shift in how networks are designed,
configured, and managed. With a wealth of knowledge and expertise, large
language models (LLMs) are one of the most promising candidates. This paper
aims to pave the way for constructing domain-adapted LLMs for networking.
Firstly, we present potential LLM applications for vertical network fields and
showcase the mapping from natural language to network language. Then, several
enabling technologies are investigated, including parameter-efficient
finetuning and prompt engineering. The insight is that language understanding
and tool usage are both required for network LLMs. Driven by the idea of
embodied intelligence, we propose the ChatNet, a domain-adapted network LLM
framework with access to various external network tools. ChatNet can reduce the
time required for burdensome network planning tasks significantly, leading to a
substantial improvement in efficiency. Finally, key challenges and future
research directions are highlighted.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.17465v3' target='_blank'>AgentAvatar: Disentangling Planning, Driving and Rendering for
  Photorealistic Avatar Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Duomin Wang, Bin Dai, Yu Deng, Baoyuan Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-29 09:13:00</h6>
<p class='card-text'>In this study, our goal is to create interactive avatar agents that can
autonomously plan and animate nuanced facial movements realistically, from both
visual and behavioral perspectives. Given high-level inputs about the
environment and agent profile, our framework harnesses LLMs to produce a series
of detailed text descriptions of the avatar agents' facial motions. These
descriptions are then processed by our task-agnostic driving engine into motion
token sequences, which are subsequently converted into continuous motion
embeddings that are further consumed by our standalone neural-based renderer to
generate the final photorealistic avatar animations. These streamlined
processes allow our framework to adapt to a variety of non-verbal avatar
interactions, both monadic and dyadic. Our extensive study, which includes
experiments on both newly compiled and existing datasets featuring two types of
agents -- one capable of monadic interaction with the environment, and the
other designed for dyadic conversation -- validates the effectiveness and
versatility of our approach. To our knowledge, we advanced a leap step by
combining LLMs and neural rendering for generalized non-verbal prediction and
photo-realistic rendering of avatar agents.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.17406v2' target='_blank'>LLM-State: Open World State Representation for Long-horizon Task
  Planning with Large Language Model</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Siwei Chen, Anxing Xiao, David Hsu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-29 07:23:22</h6>
<p class='card-text'>This work addresses the problem of long-horizon task planning with the Large
Language Model (LLM) in an open-world household environment. Existing works
fail to explicitly track key objects and attributes, leading to erroneous
decisions in long-horizon tasks, or rely on highly engineered state features
and feedback, which is not generalizable. We propose an open state
representation that provides continuous expansion and updating of object
attributes from the LLM's inherent capabilities for context understanding and
historical action reasoning. Our proposed representation maintains a
comprehensive record of an object's attributes and changes, enabling robust
retrospective summary of the sequence of actions leading to the current state.
This allows continuously updating world model to enhance context understanding
for decision-making in task planning. We validate our model through experiments
across simulated and real-world task planning scenarios, demonstrating
significant improvements over baseline methods in a variety of tasks requiring
long-horizon state tracking and reasoning. (Video\footnote{Video demonstration:
\url{https://youtu.be/QkN-8pxV3Mo}.})</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.17351v1' target='_blank'>Exploring Large Language Models for Human Mobility Prediction under
  Public Events</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuebing Liang, Yichao Liu, Xiaohan Wang, Zhan Zhao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-29 04:25:15</h6>
<p class='card-text'>Public events, such as concerts and sports games, can be major attractors for
large crowds, leading to irregular surges in travel demand. Accurate human
mobility prediction for public events is thus crucial for event planning as
well as traffic or crowd management. While rich textual descriptions about
public events are commonly available from online sources, it is challenging to
encode such information in statistical or machine learning models. Existing
methods are generally limited in incorporating textual information, handling
data sparsity, or providing rationales for their predictions. To address these
challenges, we introduce a framework for human mobility prediction under public
events (LLM-MPE) based on Large Language Models (LLMs), leveraging their
unprecedented ability to process textual data, learn from minimal examples, and
generate human-readable explanations. Specifically, LLM-MPE first transforms
raw, unstructured event descriptions from online sources into a standardized
format, and then segments historical mobility data into regular and
event-related components. A prompting strategy is designed to direct LLMs in
making and rationalizing demand predictions considering historical mobility and
event features. A case study is conducted for Barclays Center in New York City,
based on publicly available event information and taxi trip data. Results show
that LLM-MPE surpasses traditional models, particularly on event days, with
textual data significantly enhancing its accuracy. Furthermore, LLM-MPE offers
interpretable insights into its predictions. Despite the great potential of
LLMs, we also identify key challenges including misinformation and high costs
that remain barriers to their broader adoption in large-scale human mobility
analysis.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.16974v2' target='_blank'>COLE: A Hierarchical Generation Framework for Multi-Layered and Editable
  Graphic Design</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Peidong Jia, Chenxuan Li, Yuhui Yuan, Zeyu Liu, Yichao Shen, Bohan Chen, Xingru Chen, Yinglin Zheng, Dong Chen, Ji Li, Xiaodong Xie, Shanghang Zhang, Baining Guo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-28 17:22:17</h6>
<p class='card-text'>Graphic design, which has been evolving since the 15th century, plays a
crucial role in advertising. The creation of high-quality designs demands
design-oriented planning, reasoning, and layer-wise generation. Unlike the
recent CanvaGPT, which integrates GPT-4 with existing design templates to build
a custom GPT, this paper introduces the COLE system - a hierarchical generation
framework designed to comprehensively address these challenges. This COLE
system can transform a vague intention prompt into a high-quality multi-layered
graphic design, while also supporting flexible editing based on user input.
Examples of such input might include directives like ``design a poster for
Hisaishi's concert.'' The key insight is to dissect the complex task of
text-to-design generation into a hierarchy of simpler sub-tasks, each addressed
by specialized models working collaboratively. The results from these models
are then consolidated to produce a cohesive final output. Our hierarchical task
decomposition can streamline the complex process and significantly enhance
generation reliability. Our COLE system comprises multiple fine-tuned Large
Language Models (LLMs), Large Multimodal Models (LMMs), and Diffusion Models
(DMs), each specifically tailored for design-aware layer-wise captioning,
layout planning, reasoning, and the task of generating images and text.
Furthermore, we construct the DESIGNINTENTION benchmark to demonstrate the
superiority of our COLE system over existing methods in generating high-quality
graphic designs from user intent. Last, we present a Canva-like multi-layered
image editing tool to support flexible editing of the generated multi-layered
graphic design images. We perceive our COLE system as an important step towards
addressing more complex and multi-layered graphic design generation tasks in
the future.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.16542v1' target='_blank'>Agents meet OKR: An Object and Key Results Driven Agent System with
  Hierarchical Self-Collaboration and Self-Evaluation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yi Zheng, Chongyang Ma, Kanle Shi, Haibin Huang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-28 06:16:30</h6>
<p class='card-text'>In this study, we introduce the concept of OKR-Agent designed to enhance the
capabilities of Large Language Models (LLMs) in task-solving. Our approach
utilizes both self-collaboration and self-correction mechanism, facilitated by
hierarchical agents, to address the inherent complexities in task-solving. Our
key observations are two-fold: first, effective task-solving demands in-depth
domain knowledge and intricate reasoning, for which deploying specialized
agents for individual sub-tasks can markedly enhance LLM performance. Second,
task-solving intrinsically adheres to a hierarchical execution structure,
comprising both high-level strategic planning and detailed task execution.
Towards this end, our OKR-Agent paradigm aligns closely with this hierarchical
structure, promising enhanced efficacy and adaptability across a range of
scenarios. Specifically, our framework includes two novel modules: hierarchical
Objects and Key Results generation and multi-level evaluation, each
contributing to more efficient and robust task-solving. In practical,
hierarchical OKR generation decomposes Objects into multiple sub-Objects and
assigns new agents based on key results and agent responsibilities. These
agents subsequently elaborate on their designated tasks and may further
decompose them as necessary. Such generation operates recursively and
hierarchically, culminating in a comprehensive set of detailed solutions. The
multi-level evaluation module of OKR-Agent refines solution by leveraging
feedback from all associated agents, optimizing each step of the process. This
ensures solution is accurate, practical, and effectively address intricate task
requirements, enhancing the overall reliability and quality of the outcome.
Experimental results also show our method outperforms the previous methods on
several tasks. Code and demo are available at https://okr-agent.github.io/</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.16468v1' target='_blank'>AvatarGPT: All-in-One Framework for Motion Understanding, Planning,
  Generation and Beyond</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zixiang Zhou, Yu Wan, Baoyuan Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-28 04:10:07</h6>
<p class='card-text'>Large Language Models(LLMs) have shown remarkable emergent abilities in
unifying almost all (if not every) NLP tasks. In the human motion-related
realm, however, researchers still develop siloed models for each task. Inspired
by InstuctGPT, and the generalist concept behind Gato, we introduce AvatarGPT,
an All-in-One framework for motion understanding, planning, generations as well
as other tasks such as motion in-between synthesis. AvatarGPT treats each task
as one type of instruction fine-tuned on the shared LLM. All the tasks are
seamlessly interconnected with language as the universal interface,
constituting a closed-loop within the framework. To achieve this, human motion
sequences are first encoded as discrete tokens, which serve as the extended
vocabulary of LLM. Then, an unsupervised pipeline to generate natural language
descriptions of human action sequences from in-the-wild videos is developed.
Finally, all tasks are jointly trained. Extensive experiments show that
AvatarGPT achieves SOTA on low-level tasks, and promising results on high-level
tasks, demonstrating the effectiveness of our proposed All-in-One framework.
Moreover, for the first time, AvatarGPT enables a principled approach by
iterative traversal of the tasks within the closed-loop for unlimited
long-motion synthesis.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2312.00812v4' target='_blank'>Empowering Autonomous Driving with Large Language Models: A Safety
  Perspective</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yixuan Wang, Ruochen Jiao, Sinong Simon Zhan, Chengtian Lang, Chao Huang, Zhaoran Wang, Zhuoran Yang, Qi Zhu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-28 03:13:09</h6>
<p class='card-text'>Autonomous Driving (AD) encounters significant safety hurdles in long-tail
unforeseen driving scenarios, largely stemming from the non-interpretability
and poor generalization of the deep neural networks within the AD system,
particularly in out-of-distribution and uncertain data. To this end, this paper
explores the integration of Large Language Models (LLMs) into AD systems,
leveraging their robust common-sense knowledge and reasoning abilities. The
proposed methodologies employ LLMs as intelligent decision-makers in behavioral
planning, augmented with a safety verifier shield for contextual safety
learning, for enhancing driving performance and safety. We present two key
studies in a simulated environment: an adaptive LLM-conditioned Model
Predictive Control (MPC) and an LLM-enabled interactive behavior planning
scheme with a state machine. Demonstrating superior performance and safety
metrics compared to state-of-the-art approaches, our approach shows the
promising potential for using LLMs for autonomous vehicles.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2312.12391v2' target='_blank'>vTrain: A Simulation Framework for Evaluating Cost-effective and
  Compute-optimal Large Language Model Training</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jehyeon Bang, Yujeong Choi, Myeongwoo Kim, Yongdeok Kim, Minsoo Rhu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-27 13:35:15</h6>
<p class='card-text'>As large language models (LLMs) become widespread in various application
domains, a critical challenge the AI community is facing is how to train these
large AI models in a cost-effective manner. Existing LLM training plans
typically employ a heuristic based parallel training strategy which is based on
empirical observations rather than grounded upon a thorough examination of the
search space of LLM parallelization. Such limitation renders existing systems
to leave significant performance left on the table, wasting millions of dollars
worth of training cost. This paper presents our profiling-driven simulator
called vTrain, providing AI practitioners a fast yet accurate software
framework to determine an efficient and cost-effective LLM training system
configuration. We demonstrate vTrain's practicality through several case
studies, e.g., effectively evaluating optimal training parallelization
strategies that balances training time and its associated training cost,
efficient multi-tenant GPU cluster schedulers targeting multiple LLM training
jobs, and determining a compute-optimal LLM model architecture given a fixed
compute budget.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.15649v3' target='_blank'>RoboGPT: an intelligent agent of making embodied long-term decisions for
  daily instruction tasks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yaran Chen, Wenbo Cui, Yuanwen Chen, Mining Tan, Xinyao Zhang, Dongbin Zhao, He Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-27 09:20:23</h6>
<p class='card-text'>Robotic agents must master common sense and long-term sequential decisions to
solve daily tasks through natural language instruction. The developments in
Large Language Models (LLMs) in natural language processing have inspired
efforts to use LLMs in complex robot planning. Despite LLMs' great
generalization and comprehension of instruction tasks, LLMs-generated task
plans sometimes lack feasibility and correctness. To address the problem, we
propose a RoboGPT agent\footnote{our code and dataset will be released soon}
for making embodied long-term decisions for daily tasks, with two modules: 1)
LLMs-based planning with re-plan to break the task into multiple sub-goals; 2)
RoboSkill individually designed for sub-goals to learn better navigation and
manipulation skills. The LLMs-based planning is enhanced with a new robotic
dataset and re-plan, called RoboGPT. The new robotic dataset of 67k daily
instruction tasks is gathered for fine-tuning the Llama model and obtaining
RoboGPT. RoboGPT planner with strong generalization can plan hundreds of daily
instruction tasks. Additionally, a low-computational Re-Plan module is designed
to allow plans to flexibly adapt to the environment, thereby addressing the
nomenclature diversity challenge. The proposed RoboGPT agent outperforms SOTA
methods on the ALFRED daily tasks. Moreover, RoboGPT planner exceeds SOTA
LLM-based planners like ChatGPT in task-planning rationality for hundreds of
unseen daily tasks, and even other domain tasks, while keeping the large
model's original broad application and generality.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.15566v1' target='_blank'>SpotServe: Serving Generative Large Language Models on Preemptible
  Instances</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xupeng Miao, Chunan Shi, Jiangfei Duan, Xiaoli Xi, Dahua Lin, Bin Cui, Zhihao Jia</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-27 06:31:17</h6>
<p class='card-text'>The high computational and memory requirements of generative large language
models (LLMs) make it challenging to serve them cheaply. This paper aims to
reduce the monetary cost for serving LLMs by leveraging preemptible GPU
instances on modern clouds, which offer accesses to spare GPUs at a much
cheaper price than regular instances but may be preempted by the cloud at any
time. Serving LLMs on preemptible instances requires addressing challenges
induced by frequent instance preemptions and the necessity of migrating
instances to handle these preemptions.
  This paper presents SpotServe, the first distributed LLM serving system on
preemptible instances. Several key techniques in SpotServe realize fast and
reliable serving of generative LLMs on cheap preemptible instances. First,
SpotServe dynamically adapts the LLM parallelization configuration for dynamic
instance availability and fluctuating workload, while balancing the trade-off
among the overall throughput, inference latency and monetary costs. Second, to
minimize the cost of migrating instances for dynamic reparallelization, the
task of migrating instances is formulated as a bipartite graph matching
problem, which uses the Kuhn-Munkres algorithm to identify an optimal migration
plan that minimizes communications. Finally, to take advantage of the grace
period offered by modern clouds, we introduce stateful inference recovery, a
new inference mechanism that commits inference progress at a much finer
granularity and allows SpotServe to cheaply resume inference upon preemption.
We evaluate on real spot instance preemption traces and various popular LLMs
and show that SpotServe can reduce the P99 tail latency by 2.4 - 9.1x compared
with the best existing LLM serving systems. We also show that SpotServe can
leverage the price advantage of preemptive instances, saving 54% monetary cost
compared with only using on-demand instances.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.14904v1' target='_blank'>LLM-Assisted Code Cleaning For Training Accurate Code Generators</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Naman Jain, Tianjun Zhang, Wei-Lin Chiang, Joseph E. Gonzalez, Koushik Sen, Ion Stoica</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-25 02:45:50</h6>
<p class='card-text'>Natural language to code generation is an important application area of LLMs
and has received wide attention from the community. The majority of relevant
studies have exclusively concentrated on increasing the quantity and functional
correctness of training sets while disregarding other stylistic elements of
programs. More recently, data quality has garnered a lot of interest and
multiple works have showcased its importance for improving performance. In this
work, we investigate data quality for code and find that making the code more
structured and readable leads to improved code generation performance of the
system. We build a novel data-cleaning pipeline that uses these principles to
transform existing programs by 1.) renaming variables, 2.) modularizing and
decomposing complex code into smaller helper sub-functions, and 3.) inserting
natural-language based plans via LLM based transformations. We evaluate our
approach on two challenging algorithmic code generation benchmarks and find
that fine-tuning CodeLLaMa-7B on our transformed modularized programs improves
the performance by up to 30% compared to fine-tuning on the original dataset.
Additionally, we demonstrate improved performance from using a smaller amount
of higher-quality data, finding that a model fine-tuned on the entire original
dataset is outperformed by a model trained on 15% of our cleaned dataset. Even
in comparison to closed-source models, our models outperform the much larger
AlphaCoder models.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.14379v1' target='_blank'>Robot Learning in the Era of Foundation Models: A Survey</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xuan Xiao, Jiahang Liu, Zhipeng Wang, Yanmin Zhou, Yong Qi, Qian Cheng, Bin He, Shuo Jiang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-24 09:56:21</h6>
<p class='card-text'>The proliferation of Large Language Models (LLMs) has s fueled a shift in
robot learning from automation towards general embodied Artificial Intelligence
(AI). Adopting foundation models together with traditional learning methods to
robot learning has increasingly gained recent interest research community and
showed potential for real-life application. However, there are few literatures
comprehensively reviewing the relatively new technologies combined with
robotics. The purpose of this review is to systematically assess the
state-of-the-art foundation model techniques in the robot learning and to
identify future potential areas. Specifically, we first summarized the
technical evolution of robot learning and identified the necessary preliminary
preparations for foundation models including the simulators, datasets,
foundation model framework. In addition, we focused on the following four
mainstream areas of robot learning including manipulation, navigation,
planning, and reasoning and demonstrated how the foundation model techniques
can be adopted in the above scenarios. Furthermore, critical issues which are
neglected in the current literatures including robot hardware and software
decoupling, dynamic data, generalization performance with the presence of
human, etc. were discussed. This review highlights the state-of-the-art
progress of foundation models in robot learning and future research should
focus on multimodal interaction especially dynamics data, exclusive foundation
models for robots, and AI alignment, etc.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.13884v3' target='_blank'>Controlling Large Language Model-based Agents for Large-Scale
  Decision-Making: An Actor-Critic Approach</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Bin Zhang, Hangyu Mao, Jingqing Ruan, Ying Wen, Yang Li, Shao Zhang, Zhiwei Xu, Dapeng Li, Ziyue Li, Rui Zhao, Lijuan Li, Guoliang Fan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-23 10:14:58</h6>
<p class='card-text'>The remarkable progress in Large Language Models (LLMs) opens up new avenues
for addressing planning and decision-making problems in Multi-Agent Systems
(MAS). However, as the number of agents increases, the issues of hallucination
in LLMs and coordination in MAS have become increasingly prominent.
Additionally, the efficient utilization of tokens emerges as a critical
consideration when employing LLMs to facilitate the interactions among a
substantial number of agents. In this paper, we develop a modular framework
called LLaMAC to mitigate these challenges. LLaMAC implements a value
distribution encoding similar to that found in the human brain, utilizing
internal and external feedback mechanisms to facilitate collaboration and
iterative reasoning among its modules. Through evaluations involving system
resource allocation and robot grid transportation, we demonstrate the
considerable advantages afforded by our proposed approach.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.13720v2' target='_blank'>Can LLMs Fix Issues with Reasoning Models? Towards More Likely Models
  for AI Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Turgay Caglar, Sirine Belhaj, Tathagata Chakraborti, Michael Katz, Sarath Sreedharan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-22 22:27:47</h6>
<p class='card-text'>This is the first work to look at the application of large language models
(LLMs) for the purpose of model space edits in automated planning tasks. To set
the stage for this union, we explore two different flavors of model space
problems that have been studied in the AI planning literature and explore the
effect of an LLM on those tasks. We empirically demonstrate how the performance
of an LLM contrasts with combinatorial search (CS) -- an approach that has been
traditionally used to solve model space tasks in planning, both with the LLM in
the role of a standalone model space reasoner as well as in the role of a
statistical signal in concert with the CS approach as part of a two-stage
process. Our experiments show promising results suggesting further forays of
LLMs into the exciting world of model space reasoning for planning tasks in the
future.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.13148v3' target='_blank'>Towards Responsible Generative AI: A Reference Architecture for
  Designing Foundation Model based Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Qinghua Lu, Liming Zhu, Xiwei Xu, Zhenchang Xing, Stefan Harrer, Jon Whittle</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-22 04:21:47</h6>
<p class='card-text'>Foundation models, such as large language models (LLMs), have been widely
recognised as transformative AI technologies due to their capabilities to
understand and generate content, including plans with reasoning capabilities.
Foundation model based agents derive their autonomy from the capabilities of
foundation models, which enable them to autonomously break down a given goal
into a set of manageable tasks and orchestrate task execution to meet the goal.
Despite the huge efforts put into building foundation model based agents, the
architecture design of the agents has not yet been systematically explored.
Also, while there are significant benefits of using agents for planning and
execution, there are serious considerations regarding responsible AI related
software quality attributes, such as security and accountability. Therefore,
this paper presents a pattern-oriented reference architecture that serves as
guidance when designing foundation model based agents. We evaluate the
completeness and utility of the proposed reference architecture by mapping it
to the architecture of two real-world agents.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.12893v2' target='_blank'>A Safer Vision-based Autonomous Planning System for Quadrotor UAVs with
  Dynamic Obstacle Trajectory Prediction and Its Application with LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiageng Zhong, Ming Li, Yinliang Chen, Zihang Wei, Fan Yang, Haoran Shen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-21 08:09:00</h6>
<p class='card-text'>For intelligent quadcopter UAVs, a robust and reliable autonomous planning
system is crucial. Most current trajectory planning methods for UAVs are
suitable for static environments but struggle to handle dynamic obstacles,
which can pose challenges and even dangers to flight. To address this issue,
this paper proposes a vision-based planning system that combines tracking and
trajectory prediction of dynamic obstacles to achieve efficient and reliable
autonomous flight. We use a lightweight object detection algorithm to identify
dynamic obstacles and then use Kalman Filtering to track and estimate their
motion states. During the planning phase, we not only consider static obstacles
but also account for the potential movements of dynamic obstacles. For
trajectory generation, we use a B-spline-based trajectory search algorithm,
which is further optimized with various constraints to enhance safety and
alignment with the UAV's motion characteristics. We conduct experiments in both
simulation and real-world environments, and the results indicate that our
approach can successfully detect and avoid obstacles in dynamic environments in
real-time, offering greater reliability compared to existing approaches.
Furthermore, with the advancements in Natural Language Processing (NLP)
technology demonstrating exceptional zero-shot generalization capabilities,
more user-friendly human-machine interactions have become feasible, and this
study also explores the integration of autonomous planning systems with Large
Language Models (LLMs).</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.12241v2' target='_blank'>InteraSSort: Interactive Assortment Planning Using Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Saketh Reddy Karra, Theja Tulabandhula</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-20 23:36:41</h6>
<p class='card-text'>Assortment planning, integral to multiple commercial offerings, is a key
problem studied in e-commerce and retail settings. Numerous variants of the
problem along with their integration into business solutions have been
thoroughly investigated in the existing literature. However, the nuanced
complexities of in-store planning and a lack of optimization proficiency among
store planners with strong domain expertise remain largely overlooked. These
challenges frequently necessitate collaborative efforts with multiple
stakeholders which often lead to prolonged decision-making processes and
significant delays. To mitigate these challenges and capitalize on the
advancements of Large Language Models (LLMs), we propose an interactive
assortment planning framework, InteraSSort that augments LLMs with optimization
tools to assist store planners in making decisions through interactive
conversations. Specifically, we develop a solution featuring a user-friendly
interface that enables users to express their optimization objectives as input
text prompts to InteraSSort and receive tailored optimized solutions as output.
Our framework extends beyond basic functionality by enabling the inclusion of
additional constraints through interactive conversation, facilitating precise
and highly customized decision-making. Extensive experiments demonstrate the
effectiveness of our framework and potential extensions to a broad range of
operations management challenges.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.12144v7' target='_blank'>Applications of Large Scale Foundation Models for Autonomous Driving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yu Huang, Yue Chen, Zhu Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-20 19:45:27</h6>
<p class='card-text'>Since DARPA Grand Challenges (rural) in 2004/05 and Urban Challenges in 2007,
autonomous driving has been the most active field of AI applications. Recently
powered by large language models (LLMs), chat systems, such as chatGPT and
PaLM, emerge and rapidly become a promising direction to achieve artificial
general intelligence (AGI) in natural language processing (NLP). There comes a
natural thinking that we could employ these abilities to reformulate autonomous
driving. By combining LLM with foundation models, it is possible to utilize the
human knowledge, commonsense and reasoning to rebuild autonomous driving
systems from the current long-tailed AI dilemma. In this paper, we investigate
the techniques of foundation models and LLMs applied for autonomous driving,
categorized as simulation, world model, data annotation and planning or E2E
solutions etc.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.11315v1' target='_blank'>TPTU-v2: Boosting Task Planning and Tool Usage of Large Language
  Model-based Agents in Real-world Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yilun Kong, Jingqing Ruan, Yihong Chen, Bin Zhang, Tianpeng Bao, Shiwei Shi, Guoqing Du, Xiaoru Hu, Hangyu Mao, Ziyue Li, Xingyu Zeng, Rui Zhao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-19 12:37:30</h6>
<p class='card-text'>Large Language Models (LLMs) have demonstrated proficiency in addressing
tasks that necessitate a combination of task planning and the usage of external
tools that require a blend of task planning and the utilization of external
tools, such as APIs. However, real-world complex systems present three
prevalent challenges concerning task planning and tool usage: (1) The real
system usually has a vast array of APIs, so it is impossible to feed the
descriptions of all APIs to the prompt of LLMs as the token length is limited;
(2) the real system is designed for handling complex tasks, and the base LLMs
can hardly plan a correct sub-task order and API-calling order for such tasks;
(3) Similar semantics and functionalities among APIs in real systems create
challenges for both LLMs and even humans in distinguishing between them. In
response, this paper introduces a comprehensive framework aimed at enhancing
the Task Planning and Tool Usage (TPTU) abilities of LLM-based agents operating
within real-world systems. Our framework comprises three key components
designed to address these challenges: (1) the API Retriever selects the most
pertinent APIs for the user task among the extensive array available; (2) LLM
Finetuner tunes a base LLM so that the finetuned LLM can be more capable for
task planning and API calling; (3) the Demo Selector adaptively retrieves
different demonstrations related to hard-to-distinguish APIs, which is further
used for in-context learning to boost the final performance. We validate our
methods using a real-world commercial system as well as an open-sourced
academic dataset, and the outcomes clearly showcase the efficacy of each
individual component as well as the integrated framework.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.12871v3' target='_blank'>An Embodied Generalist Agent in 3D World</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiangyong Huang, Silong Yong, Xiaojian Ma, Xiongkun Linghu, Puhao Li, Yan Wang, Qing Li, Song-Chun Zhu, Baoxiong Jia, Siyuan Huang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-18 01:21:38</h6>
<p class='card-text'>Leveraging massive knowledge from large language models (LLMs), recent
machine learning models show notable successes in general-purpose task solving
in diverse domains such as computer vision and robotics. However, several
significant challenges remain: (i) most of these models rely on 2D images yet
exhibit a limited capacity for 3D input; (ii) these models rarely explore the
tasks inherently defined in 3D world, e.g., 3D grounding, embodied reasoning
and acting. We argue these limitations significantly hinder current models from
performing real-world tasks and approaching general intelligence. To this end,
we introduce LEO, an embodied multi-modal generalist agent that excels in
perceiving, grounding, reasoning, planning, and acting in the 3D world. LEO is
trained with a unified task interface, model architecture, and objective in two
stages: (i) 3D vision-language (VL) alignment and (ii) 3D
vision-language-action (VLA) instruction tuning. We collect large-scale
datasets comprising diverse object-level and scene-level tasks, which require
considerable understanding of and interaction with the 3D world. Moreover, we
meticulously design an LLM-assisted pipeline to produce high-quality 3D VL
data. Through extensive experiments, we demonstrate LEO's remarkable
proficiency across a wide spectrum of tasks, including 3D captioning, question
answering, embodied reasoning, navigation and manipulation. Our ablative
studies and scaling analyses further provide valuable insights for developing
future embodied generalist agents. Code and data are available on project page.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.10813v4' target='_blank'>A Language Agent for Autonomous Driving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiageng Mao, Junjie Ye, Yuxi Qian, Marco Pavone, Yue Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-17 18:59:56</h6>
<p class='card-text'>Human-level driving is an ultimate goal of autonomous driving. Conventional
approaches formulate autonomous driving as a perception-prediction-planning
framework, yet their systems do not capitalize on the inherent reasoning
ability and experiential knowledge of humans. In this paper, we propose a
fundamental paradigm shift from current pipelines, exploiting Large Language
Models (LLMs) as a cognitive agent to integrate human-like intelligence into
autonomous driving systems. Our approach, termed Agent-Driver, transforms the
traditional autonomous driving pipeline by introducing a versatile tool library
accessible via function calls, a cognitive memory of common sense and
experiential knowledge for decision-making, and a reasoning engine capable of
chain-of-thought reasoning, task planning, motion planning, and
self-reflection. Powered by LLMs, our Agent-Driver is endowed with intuitive
common sense and robust reasoning capabilities, thus enabling a more nuanced,
human-like approach to autonomous driving. We evaluate our approach on the
large-scale nuScenes benchmark, and extensive experiments substantiate that our
Agent-Driver significantly outperforms the state-of-the-art driving methods by
a large margin. Our approach also demonstrates superior interpretability and
few-shot learning ability to these methods.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.10678v2' target='_blank'>Distilling and Retrieving Generalizable Knowledge for Robot Manipulation
  via Language Corrections</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lihan Zha, Yuchen Cui, Li-Heng Lin, Minae Kwon, Montserrat Gonzalez Arenas, Andy Zeng, Fei Xia, Dorsa Sadigh</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-17 18:00:20</h6>
<p class='card-text'>Today's robot policies exhibit subpar performance when faced with the
challenge of generalizing to novel environments. Human corrective feedback is a
crucial form of guidance to enable such generalization. However, adapting to
and learning from online human corrections is a non-trivial endeavor: not only
do robots need to remember human feedback over time to retrieve the right
information in new settings and reduce the intervention rate, but also they
would need to be able to respond to feedback that can be arbitrary corrections
about high-level human preferences to low-level adjustments to skill
parameters. In this work, we present Distillation and Retrieval of Online
Corrections (DROC), a large language model (LLM)-based system that can respond
to arbitrary forms of language feedback, distill generalizable knowledge from
corrections, and retrieve relevant past experiences based on textual and visual
similarity for improving performance in novel settings. DROC is able to respond
to a sequence of online language corrections that address failures in both
high-level task plans and low-level skill primitives. We demonstrate that DROC
effectively distills the relevant information from the sequence of online
corrections in a knowledge base and retrieves that knowledge in settings with
new task or object instances. DROC outperforms other techniques that directly
generate robot code via LLMs by using only half of the total number of
corrections needed in the first round and requires little to no corrections
after two iterations. We show further results, videos, prompts and code on
https://sites.google.com/stanford.edu/droc .</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.09868v5' target='_blank'>INTERVENOR: Prompting the Coding Ability of Large Language Models with
  the Interactive Chain of Repair</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hanbin Wang, Zhenghao Liu, Shuo Wang, Ganqu Cui, Ning Ding, Zhiyuan Liu, Ge Yu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-16 12:55:20</h6>
<p class='card-text'>This paper introduces INTERVENOR (INTERactiVE chaiN Of Repair), a system
designed to emulate the interactive code repair processes observed in humans,
encompassing both code diagnosis and code repair. INTERVENOR prompts Large
Language Models (LLMs) to play distinct roles during the code repair process,
functioning as both a Code Learner and a Code Teacher. Specifically, the Code
Learner is tasked with adhering to instructions to generate or repair code,
while the Code Teacher is responsible for crafting a Chain-of-Repair (CoR) to
serve as guidance for the Code Learner. During generating the CoR, the Code
Teacher needs to check the generated codes from Code Learner and reassess how
to address code bugs based on error feedback received from compilers.
Experimental results demonstrate that INTERVENOR surpasses baseline models,
exhibiting improvements of approximately 18% and 4.3% over GPT-3.5 in code
generation and code translation tasks, respectively. Our further analyses show
that CoR is effective to illuminate the reasons behind bugs and outline
solution plans in natural language. With the feedback of code compilers,
INTERVENOR can accurately identify syntax errors and assertion errors and
provide precise instructions to repair codes. All data and codes are available
at https://github.com/NEUIR/INTERVENOR</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.09830v3' target='_blank'>Automating the Generation of Prompts for LLM-based Action Choice in PDDL
  Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Katharina Stein, Daniel Fišer, Jörg Hoffmann, Alexander Koller</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-16 11:55:27</h6>
<p class='card-text'>Large language models (LLMs) have revolutionized a large variety of NLP
tasks. An active debate is to what extent they can do reasoning and planning.
Prior work has assessed the latter in the specific context of PDDL planning,
based on manually converting three PDDL domains into natural language (NL)
prompts. Here we automate this conversion step, showing how to leverage an LLM
to automatically generate NL prompts from PDDL input. Our automatically
generated NL prompts result in similar LLM-planning performance as the previous
manually generated ones. Beyond this, the automation enables us to run much
larger experiments, providing for the first time a broad evaluation of LLM
planning performance in PDDL.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.09724v2' target='_blank'>OVM, Outcome-supervised Value Models for Planning in Mathematical
  Reasoning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Fei Yu, Anningzhe Gao, Benyou Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-16 09:56:28</h6>
<p class='card-text'>Large language models (LLMs) often struggle with maintaining accuracy
throughout multiple multiple reasoning steps, especially in mathematical
reasoning where an error in earlier steps can propagate to subsequent ones and
it ultimately leading to an incorrect answer. To reduce error propagation,
guided decoding is employed to direct the LM decoding on a step-by-step basis.
We argue that in guided decoding, assessing the potential of an incomplete
reasoning path can be more advantageous than simply ensuring per-step
correctness, as the former approach leads towards a correct final answer. This
transforms the task into a $\textit{value estimation}$ problem in planning.
  Inspired by the findings that $\textit{outcome supervision for guided
decoding essentially acts as a value model}$, we propose Outcome-supervised
Value Model (OVM) that employs outcome supervision for training a value model,
which prioritizes steps that lead to accurate conclusions. Furthermore, the OVM
eliminates the need for labor-intensive annotations of step-level correctness,
thereby significantly enhancing its scalability. Our experiments on two
multi-step mathematical reasoning datasets, GSM8K and Game of 24, demonstrate
the superior performance of the OVM model. Notably, in GSM8K, our
$\textbf{OVM-7B model achieves state-of-the-art results among LLMs up to 13B
parameters}$; especially it does not utilize GPT-4 or code execution. These
findings offer a novel perspective on the role of outcome supervision in
training value models for multi-step reasoning tasks and provide theoretical
justification for its advantage in value estimation for guided decoding.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.09721v1' target='_blank'>On Evaluating the Integration of Reasoning and Action in LLM Agents with
  Database Question Answering</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Linyong Nan, Ellen Zhang, Weijin Zou, Yilun Zhao, Wenfei Zhou, Arman Cohan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-16 09:55:07</h6>
<p class='card-text'>This study introduces a new long-form database question answering dataset
designed to evaluate how Large Language Models (LLMs) interact with a SQL
interpreter. The task necessitates LLMs to strategically generate multiple SQL
queries to retrieve sufficient data from a database, to reason with the
acquired context, and to synthesize them into a comprehensive analytical
narrative. Our findings highlight that this task poses great challenges even
for the state-of-the-art GPT-4 model. We propose and evaluate two interaction
strategies, and provide a fine-grained analysis of the individual stages within
the interaction. A key discovery is the identification of two primary
bottlenecks hindering effective interaction: the capacity for planning and the
ability to generate multiple SQL queries. To address the challenge of
accurately assessing answer quality, we introduce a multi-agent evaluation
framework that simulates the academic peer-review process, enhancing the
precision and reliability of our evaluations. This framework allows for a more
nuanced understanding of the strengths and limitations of current LLMs in
complex retrieval and reasoning tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.09682v4' target='_blank'>MacGyver: Are Large Language Models Creative Problem Solvers?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yufei Tian, Abhilasha Ravichander, Lianhui Qin, Ronan Le Bras, Raja Marjieh, Nanyun Peng, Yejin Choi, Thomas L. Griffiths, Faeze Brahman</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-16 08:52:27</h6>
<p class='card-text'>We explore the creative problem-solving capabilities of modern LLMs in a
novel constrained setting. To this end, we create MACGYVER, an automatically
generated dataset consisting of over 1,600 real-world problems deliberately
designed to trigger innovative usage of objects and necessitate out-of-the-box
thinking. We then present our collection to both LLMs and humans to compare and
contrast their problem-solving abilities. MACGYVER is challenging for both
groups, but in unique and complementary ways. For instance, humans excel in
tasks they are familiar with but struggle with domain-specific knowledge,
leading to a higher variance. In contrast, LLMs, exposed to a variety of
specialized knowledge, attempt broader problems but fail by proposing
physically-infeasible actions. Finally, we provide a detailed error analysis of
LLMs, and demonstrate the potential of enhancing their problem-solving ability
with novel prompting techniques such as iterative step-wise reflection and
divergent-convergent thinking.
  This work (1) introduces a fresh arena for intelligent agents focusing on
intricate aspects of physical reasoning, planning, and unconventional thinking,
which supplements the existing spectrum of machine intelligence; and (2)
provides insight into the constrained problem-solving capabilities of both
humans and AI.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.08562v3' target='_blank'>MAgIC: Investigation of Large Language Model Powered Multi-Agent in
  Cognition, Adaptability, Rationality and Collaboration</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lin Xu, Zhiyuan Hu, Daquan Zhou, Hongyu Ren, Zhen Dong, Kurt Keutzer, See Kiong Ng, Jiashi Feng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-14 21:46:27</h6>
<p class='card-text'>Large Language Models (LLMs) have significantly advanced natural language
processing, demonstrating exceptional reasoning, tool usage, and memory
capabilities. As their applications expand into multi-agent environments, there
arises a need for a comprehensive evaluation framework that captures LLMs'
reasoning, planning, collaboration, and other social abilities. This work
introduces a novel competition-based benchmark framework specifically designed
to assess LLMs within multi-agent settings, providing quantitative metrics to
evaluate their judgment, reasoning, deception, self-awareness, cooperation,
coordination, and rationality. We utilize two social deduction games alongside
three game-theory scenarios to create diverse environments. Our frame is
fortified with the probabilistic graphic modeling (PGM) method, enhancing the
LLMs' capabilities in navigating complex social and cognitive dimensions. We
evaluate seven LLMs, quantitatively highlighting a significant capability gap
of over threefold between the strongest, GPT o1, and the weakest, Llama-2-70B.
It also confirms that our PGM enhancement boosts the abilities of all selected
models by an average of 37%. Our data and code can be found here
https://github.com/cathyxl/MAgIC.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.08244v2' target='_blank'>Language and Sketching: An LLM-driven Interactive Multimodal Multitask
  Robot Navigation Framework</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Weiqin Zu, Wenbin Song, Ruiqing Chen, Ze Guo, Fanglei Sun, Zheng Tian, Wei Pan, Jun Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-14 15:29:52</h6>
<p class='card-text'>The socially-aware navigation system has evolved to adeptly avoid various
obstacles while performing multiple tasks, such as point-to-point navigation,
human-following, and -guiding. However, a prominent gap persists: in
Human-Robot Interaction (HRI), the procedure of communicating commands to
robots demands intricate mathematical formulations. Furthermore, the transition
between tasks does not quite possess the intuitive control and user-centric
interactivity that one would desire. In this work, we propose an LLM-driven
interactive multimodal multitask robot navigation framework, termed LIM2N, to
solve the above new challenge in the navigation field. We achieve this by first
introducing a multimodal interaction framework where language and hand-drawn
inputs can serve as navigation constraints and control objectives. Next, a
reinforcement learning agent is built to handle multiple tasks with the
received information. Crucially, LIM2N creates smooth cooperation among the
reasoning of multimodal input, multitask planning, and adaptation and
processing of the intelligent sensing modules in the complicated system.
Extensive experiments are conducted in both simulation and the real world
demonstrating that LIM2N has superior user needs understanding, alongside an
enhanced interactive experience.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.08166v1' target='_blank'>MechAgents: Large language model multi-agent collaborations can solve
  mechanics problems, generate new data, and integrate knowledge</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Bo Ni, Markus J. Buehler</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-14 13:49:03</h6>
<p class='card-text'>Solving mechanics problems using numerical methods requires comprehensive
intelligent capability of retrieving relevant knowledge and theory,
constructing and executing codes, analyzing the results, a task that has thus
far mainly been reserved for humans. While emerging AI methods can provide
effective approaches to solve end-to-end problems, for instance via the use of
deep surrogate models or various data analytics strategies, they often lack
physical intuition since knowledge is baked into the parametric complement
through training, offering less flexibility when it comes to incorporating
mathematical or physical insights. By leveraging diverse capabilities of
multiple dynamically interacting large language models (LLMs), we can overcome
the limitations of conventional approaches and develop a new class of
physics-inspired generative machine learning platform, here referred to as
MechAgents. A set of AI agents can solve mechanics tasks, here demonstrated for
elasticity problems, via autonomous collaborations. A two-agent team can
effectively write, execute and self-correct code, in order to apply finite
element methods to solve classical elasticity problems in various flavors
(different boundary conditions, domain geometries, meshes, small/finite
deformation and linear/hyper-elastic constitutive laws, and others). For more
complex tasks, we construct a larger group of agents with enhanced division of
labor among planning, formulating, coding, executing and criticizing the
process and results. The agents mutually correct each other to improve the
overall team-work performance in understanding, formulating and validating the
solution. Our framework shows the potential of synergizing the intelligence of
language models, the reliability of physics-based modeling, and the dynamic
collaborations among diverse agents, opening novel avenues for automation of
solving engineering problems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.07387v2' target='_blank'>Assessing Logical Puzzle Solving in Large Language Models: Insights from
  a Minesweeper Case Study</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yinghao Li, Haorui Wang, Chao Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-13 15:11:26</h6>
<p class='card-text'>Large Language Models (LLMs) have shown remarkable proficiency in language
understanding and have been successfully applied to a variety of real-world
tasks through task-specific fine-tuning or prompt engineering. Despite these
advancements, it remains an open question whether LLMs are fundamentally
capable of reasoning and planning, or if they primarily rely on recalling and
synthesizing information from their training data. In our research, we
introduce a novel task -- Minesweeper -- specifically designed in a format
unfamiliar to LLMs and absent from their training datasets. This task
challenges LLMs to identify the locations of mines based on numerical clues
provided by adjacent opened cells. Successfully completing this task requires
an understanding of each cell's state, discerning spatial relationships between
the clues and mines, and strategizing actions based on logical deductions drawn
from the arrangement of the cells. Our experiments, including trials with the
advanced GPT-4 model, indicate that while LLMs possess the foundational
abilities required for this task, they struggle to integrate these into a
coherent, multi-step logical reasoning process needed to solve Minesweeper.
These findings highlight the need for further research to understand the nature
of reasoning capabilities in LLMs under similar circumstances, and to explore
pathways towards more sophisticated AI reasoning and planning models.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.07226v1' target='_blank'>Large Language Models for Robotics: A Survey</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Fanlong Zeng, Wensheng Gan, Yongheng Wang, Ning Liu, Philip S. Yu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-13 10:46:35</h6>
<p class='card-text'>The human ability to learn, generalize, and control complex manipulation
tasks through multi-modality feedback suggests a unique capability, which we
refer to as dexterity intelligence. Understanding and assessing this
intelligence is a complex task. Amidst the swift progress and extensive
proliferation of large language models (LLMs), their applications in the field
of robotics have garnered increasing attention. LLMs possess the ability to
process and generate natural language, facilitating efficient interaction and
collaboration with robots. Researchers and engineers in the field of robotics
have recognized the immense potential of LLMs in enhancing robot intelligence,
human-robot interaction, and autonomy. Therefore, this comprehensive review
aims to summarize the applications of LLMs in robotics, delving into their
impact and contributions to key areas such as robot control, perception,
decision-making, and path planning. We first provide an overview of the
background and development of LLMs for robotics, followed by a description of
the benefits of LLMs for robotics and recent advancements in robotics models
based on LLMs. We then delve into the various techniques used in the model,
including those employed in perception, decision-making, control, and
interaction. Finally, we explore the applications of LLMs in robotics and some
potential challenges they may face in the near future. Embodied intelligence is
the future of intelligent science, and LLMs-based robotics is one of the
promising but challenging paths to achieve this.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.07150v1' target='_blank'>Interaction is all You Need? A Study of Robots Ability to Understand and
  Execute</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kushal Koshti, Nidhir Bhavsar</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-13 08:39:06</h6>
<p class='card-text'>This paper aims to address a critical challenge in robotics, which is
enabling them to operate seamlessly in human environments through natural
language interactions. Our primary focus is to equip robots with the ability to
understand and execute complex instructions in coherent dialogs to facilitate
intricate task-solving scenarios. To explore this, we build upon the Execution
from Dialog History (EDH) task from the Teach benchmark. We employ a
multi-transformer model with BART LM. We observe that our best configuration
outperforms the baseline with a success rate score of 8.85 and a
goal-conditioned success rate score of 14.02. In addition, we suggest an
alternative methodology for completing this task. Moreover, we introduce a new
task by expanding the EDH task and making predictions about game plans instead
of individual actions. We have evaluated multiple BART models and an LLaMA2
LLM, which has achieved a ROGUE-L score of 46.77 for this task.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.06736v2' target='_blank'>Are LLMs Rigorous Logical Reasoner? Empowering Natural Language Proof
  Generation with Contrastive Stepwise Decoding</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ying Su, Xiaojin Fu, Mingwen Liu, Zhijiang Guo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-12 05:12:49</h6>
<p class='card-text'>Logical reasoning remains a pivotal component within the realm of artificial
intelligence. The recent evolution of large language models (LLMs) has marked
significant progress in this domain. The adoption of strategies like
chain-of-thought (CoT) has enhanced the performance of LLMs across diverse
reasoning tasks. Nonetheless, logical reasoning that involves proof planning,
specifically those that necessitate the validation of explanation accuracy,
continues to present stumbling blocks. In this study, we first evaluate the
efficacy of LLMs with advanced CoT strategies concerning such tasks. Our
analysis reveals that LLMs still struggle to navigate complex reasoning chains,
which demand the meticulous linkage of premises to derive a cogent conclusion.
To address this issue, we finetune a smaller-scale language model, equipping it
to decompose proof objectives into more manageable subgoals. We also introduce
contrastive decoding to stepwise proof generation, making use of negative
reasoning paths to strengthen the model's capacity for logical deduction.
Experiments on EntailmentBank underscore the success of our method in
augmenting the proof planning abilities of language models.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.06622v2' target='_blank'>TrainerAgent: Customizable and Efficient Model Training through
  LLM-Powered Multi-Agent System</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Haoyuan Li, Hao Jiang, Tianke Zhang, Zhelun Yu, Aoxiong Yin, Hao Cheng, Siming Fu, Yuhao Zhang, Wanggui He</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-11 17:39:24</h6>
<p class='card-text'>Training AI models has always been challenging, especially when there is a
need for custom models to provide personalized services. Algorithm engineers
often face a lengthy process to iteratively develop models tailored to specific
business requirements, making it even more difficult for non-experts. The quest
for high-quality and efficient model development, along with the emergence of
Large Language Model (LLM) Agents, has become a key focus in the industry.
Leveraging the powerful analytical, planning, and decision-making capabilities
of LLM, we propose a TrainerAgent system comprising a multi-agent framework
including Task, Data, Model and Server agents. These agents analyze
user-defined tasks, input data, and requirements (e.g., accuracy, speed),
optimizing them comprehensively from both data and model perspectives to obtain
satisfactory models, and finally deploy these models as online service.
Experimental evaluations on classical discriminative and generative tasks in
computer vision and natural language processing domains demonstrate that our
system consistently produces models that meet the desired criteria.
Furthermore, the system exhibits the ability to critically identify and reject
unattainable tasks, such as fantastical scenarios or unethical requests,
ensuring robustness and safety. This research presents a significant
advancement in achieving desired models with increased efficiency and quality
as compared to traditional model development, facilitated by the integration of
LLM-powered analysis, decision-making, and execution capabilities, as well as
the collaboration among four agents. We anticipate that our work will
contribute to the advancement of research on TrainerAgent in both academic and
industry communities, potentially establishing it as a new paradigm for model
development in the field of AI.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.05812v2' target='_blank'>CFBenchmark: Chinese Financial Assistant Benchmark for Large Language
  Model</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yang Lei, Jiangtong Li, Dawei Cheng, Zhijun Ding, Changjun Jiang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-10 01:12:03</h6>
<p class='card-text'>Large language models (LLMs) have demonstrated great potential in the
financial domain. Thus, it becomes important to assess the performance of LLMs
in the financial tasks. In this work, we introduce CFBenchmark, to evaluate the
performance of LLMs for Chinese financial assistant. The basic version of
CFBenchmark is designed to evaluate the basic ability in Chinese financial text
processing from three aspects~(\emph{i.e.} recognition, classification, and
generation) including eight tasks, and includes financial texts ranging in
length from 50 to over 1,800 characters. We conduct experiments on several LLMs
available in the literature with CFBenchmark-Basic, and the experimental
results indicate that while some LLMs show outstanding performance in specific
tasks, overall, there is still significant room for improvement in basic tasks
of financial text processing with existing models. In the future, we plan to
explore the advanced version of CFBenchmark, aiming to further explore the
extensive capabilities of language models in more profound dimensions as a
financial assistant in Chinese. Our codes are released at
https://github.com/TongjiFinLab/CFBenchmark.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.05596v1' target='_blank'>LLM Augmented Hierarchical Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Bharat Prakash, Tim Oates, Tinoosh Mohsenin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-09 18:54:28</h6>
<p class='card-text'>Solving long-horizon, temporally-extended tasks using Reinforcement Learning
(RL) is challenging, compounded by the common practice of learning without
prior knowledge (or tabula rasa learning). Humans can generate and execute
plans with temporally-extended actions and quickly learn to perform new tasks
because we almost never solve problems from scratch. We want autonomous agents
to have this same ability. Recently, LLMs have been shown to encode a
tremendous amount of knowledge about the world and to perform impressive
in-context learning and reasoning. However, using LLMs to solve real world
problems is hard because they are not grounded in the current task. In this
paper we exploit the planning capabilities of LLMs while using RL to provide
learning from the environment, resulting in a hierarchical agent that uses LLMs
to solve long-horizon tasks. Instead of completely relying on LLMs, they guide
a high-level policy, making learning significantly more sample efficient. This
approach is evaluated in simulation environments such as MiniGrid, SkillHack,
and Crafter, and on a real robot arm in block manipulation tasks. We show that
agents trained using our approach outperform other baselines methods and, once
trained, don't need access to LLMs during deployment.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.05657v3' target='_blank'>Agent Lumos: Unified and Modular Training for Open-Source Language
  Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Da Yin, Faeze Brahman, Abhilasha Ravichander, Khyathi Chandu, Kai-Wei Chang, Yejin Choi, Bill Yuchen Lin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-09 00:30:13</h6>
<p class='card-text'>Closed-source agents suffer from several issues such as a lack of
affordability, transparency, and reproducibility, particularly on complex
interactive tasks. This motivates the development of open-source alternatives.
We introduce LUMOS, one of the first frameworks for training open-source
LLM-based agents. LUMOS features a learnable, unified, and modular architecture
with a planning module that learns high-level subgoal generation, and a
grounding module trained to translate these into actions using various tools in
the execution module. The design allows for modular upgrades and wider
applicability to diverse interactive tasks. To foster generalizable agent
learning, we collect large-scale, unified, and high-quality training
annotations derived from diverse ground-truth reasoning rationales across
various complex interactive tasks. On 9 datasets, LUMOS exhibits several key
advantages: (1) LUMOS excels multiple larger open-source agents on the held-out
datasets (unused for training) for each task type. LUMOS even surpasses GPT
agents on QA and web tasks; (2) LUMOS outperforms open-source agents produced
by chain-of-thoughts and unmodularized integrated training; and (3) LUMOS
effectively generalizes to unseen tasks, outperforming 33B-scale agents and
domain-specific agents.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.05772v2' target='_blank'>ADaPT: As-Needed Decomposition and Planning with Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Archiki Prasad, Alexander Koller, Mareike Hartmann, Peter Clark, Ashish Sabharwal, Mohit Bansal, Tushar Khot</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-08 17:59:15</h6>
<p class='card-text'>Large Language Models (LLMs) are increasingly being used for interactive
decision-making tasks requiring planning and adapting to the environment.
Recent works employ LLMs-as-agents in broadly two ways: iteratively determining
the next action (iterative executors) or generating plans and executing
sub-tasks using LLMs (plan-and-execute). However, these methods struggle with
task complexity, as the inability to execute any sub-task may lead to task
failure. To address these shortcomings, we introduce As-Needed Decomposition
and Planning for complex Tasks (ADaPT), an approach that explicitly plans and
decomposes complex sub-tasks as-needed, i.e., when the LLM is unable to execute
them. ADaPT recursively decomposes sub-tasks to adapt to both task complexity
and LLM capability. Our results demonstrate that ADaPT substantially
outperforms established strong baselines, achieving success rates up to 28.3%
higher in ALFWorld, 27% in WebShop, and 33% in TextCraft -- a novel
compositional dataset that we introduce. Through extensive analysis, we
illustrate the importance of multilevel decomposition and establish that ADaPT
dynamically adjusts to the capabilities of the executor LLM as well as to task
complexity.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.04459v1' target='_blank'>Improving Pacing in Long-Form Story Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yichen Wang, Kevin Yang, Xiaoming Liu, Dan Klein</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-08 04:58:29</h6>
<p class='card-text'>Existing LLM-based systems for writing long-form stories or story outlines
frequently suffer from unnatural pacing, whether glossing over important events
or over-elaborating on insignificant details, resulting in a jarring experience
for the reader. We propose a CONCrete Outline ConTrol (CONCOCT) system to
improve pacing when automatically generating story outlines. We first train a
concreteness evaluator to judge which of two events is more concrete
(low-level-detailed). This evaluator can then be used to control pacing in
hierarchical outline generation; in this work, we explore a vaguest-first
expansion procedure that aims for uniform pacing. We further use the evaluator
to filter new outline items based on predicted concreteness. Compared to a
baseline hierarchical outline generator, humans judge CONCOCT's pacing to be
more consistent over 57% of the time across multiple outline lengths; the gains
also translate to downstream stories. All code, data, and models are
open-sourced.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.04403v1' target='_blank'>Human-Centered Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuliang Li, Nitin Kamra, Ruta Desai, Alon Halevy</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-08 00:14:05</h6>
<p class='card-text'>LLMs have recently made impressive inroads on tasks whose output is
structured, such as coding, robotic planning and querying databases. The vision
of creating AI-powered personal assistants also involves creating structured
outputs, such as a plan for one's day, or for an overseas trip. Here, since the
plan is executed by a human, the output doesn't have to satisfy strict
syntactic constraints. A useful assistant should also be able to incorporate
vague constraints specified by the user in natural language. This makes LLMs an
attractive option for planning.
  We consider the problem of planning one's day. We develop an LLM-based
planner (LLMPlan) extended with the ability to self-reflect on its output and a
symbolic planner (SymPlan) with the ability to translate text constraints into
a symbolic representation. Despite no formal specification of constraints, we
find that LLMPlan performs explicit constraint satisfaction akin to the
traditional symbolic planners on average (2% performance difference), while
retaining the reasoning of implicit requirements. Consequently, LLM-based
planners outperform their symbolic counterparts in user satisfaction (70.5% vs.
40.4%) during interactive evaluation with 40 users.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.14693v1' target='_blank'>Benefits and Harms of Large Language Models in Digital Mental Health</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Munmun De Choudhury, Sachin R. Pendse, Neha Kumar</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-07 14:11:10</h6>
<p class='card-text'>The past decade has been transformative for mental health research and
practice. The ability to harness large repositories of data, whether from
electronic health records (EHR), mobile devices, or social media, has revealed
a potential for valuable insights into patient experiences, promising early,
proactive interventions, as well as personalized treatment plans. Recent
developments in generative artificial intelligence, particularly large language
models (LLMs), show promise in leading digital mental health to uncharted
territory. Patients are arriving at doctors' appointments with information
sourced from chatbots, state-of-the-art LLMs are being incorporated in medical
software and EHR systems, and chatbots from an ever-increasing number of
startups promise to serve as AI companions, friends, and partners. This article
presents contemporary perspectives on the opportunities and risks posed by LLMs
in the design, development, and implementation of digital mental health tools.
We adopt an ecological framework and draw on the affordances offered by LLMs to
discuss four application areas -- care-seeking behaviors from individuals in
need of care, community care provision, institutional and medical care
provision, and larger care ecologies at the societal level. We engage in a
thoughtful consideration of whether and how LLM-based technologies could or
should be employed for enhancing mental health. The benefits and harms our
article surfaces could serve to help shape future research, advocacy, and
regulatory efforts focused on creating more responsible, user-friendly,
equitable, and secure LLM-based tools for mental health treatment and
intervention.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.02847v4' target='_blank'>Kinematic-aware Prompting for Generalizable Articulated Object
  Manipulation with LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wenke Xia, Dong Wang, Xincheng Pang, Zhigang Wang, Bin Zhao, Di Hu, Xuelong Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-06 03:26:41</h6>
<p class='card-text'>Generalizable articulated object manipulation is essential for home-assistant
robots. Recent efforts focus on imitation learning from demonstrations or
reinforcement learning in simulation, however, due to the prohibitive costs of
real-world data collection and precise object simulation, it still remains
challenging for these works to achieve broad adaptability across diverse
articulated objects. Recently, many works have tried to utilize the strong
in-context learning ability of Large Language Models (LLMs) to achieve
generalizable robotic manipulation, but most of these researches focus on
high-level task planning, sidelining low-level robotic control. In this work,
building on the idea that the kinematic structure of the object determines how
we can manipulate it, we propose a kinematic-aware prompting framework that
prompts LLMs with kinematic knowledge of objects to generate low-level motion
trajectory waypoints, supporting various object manipulation. To effectively
prompt LLMs with the kinematic structure of different objects, we design a
unified kinematic knowledge parser, which represents various articulated
objects as a unified textual description containing kinematic joints and
contact location. Building upon this unified description, a kinematic-aware
planner model is proposed to generate precise 3D manipulation waypoints via a
designed kinematic-aware chain-of-thoughts prompting method. Our evaluation
spanned 48 instances across 16 distinct categories, revealing that our
framework not only outperforms traditional methods on 8 seen categories but
also shows a powerful zero-shot capability for 8 unseen articulated object
categories. Moreover, the real-world experiments on 7 different object
categories prove our framework's adaptability in practical scenarios. Code is
released at
https://github.com/GeWu-Lab/LLM_articulated_object_manipulation/tree/main.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.02787v3' target='_blank'>Make a Donut: Hierarchical EMD-Space Planning for Zero-Shot Deformable
  Manipulation with Tools</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yang You, Bokui Shen, Congyue Deng, Haoran Geng, Songlin Wei, He Wang, Leonidas Guibas</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-05 22:43:29</h6>
<p class='card-text'>Deformable object manipulation stands as one of the most captivating yet
formidable challenges in robotics. While previous techniques have predominantly
relied on learning latent dynamics through demonstrations, typically
represented as either particles or images, there exists a pertinent limitation:
acquiring suitable demonstrations, especially for long-horizon tasks, can be
elusive. Moreover, basing learning entirely on demonstrations can hamper the
model's ability to generalize beyond the demonstrated tasks. In this work, we
introduce a demonstration-free hierarchical planning approach capable of
tackling intricate long-horizon tasks without necessitating any training. We
employ large language models (LLMs) to articulate a high-level, stage-by-stage
plan corresponding to a specified task. For every individual stage, the LLM
provides both the tool's name and the Python code to craft intermediate subgoal
point clouds. With the tool and subgoal for a particular stage at our disposal,
we present a granular closed-loop model predictive control strategy. This
leverages Differentiable Physics with Point-to-Point correspondence
(DiffPhysics-P2P) loss in the earth mover distance (EMD) space, applied
iteratively. Experimental findings affirm that our technique surpasses multiple
benchmarks in dough manipulation, spanning both short and long horizons.
Remarkably, our model demonstrates robust generalization capabilities to novel
and previously unencountered complex tasks without any preliminary
demonstrations. We further substantiate our approach with experimental trials
on real-world robotic platforms. Our project page:
https://qq456cvb.github.io/projects/donut.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.02597v1' target='_blank'>FloodBrain: Flood Disaster Reporting by Web-based Retrieval Augmented
  Generation with an LLM</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Grace Colverd, Paul Darm, Leonard Silverberg, Noah Kasmanoff</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-05 08:34:26</h6>
<p class='card-text'>Fast disaster impact reporting is crucial in planning humanitarian
assistance. Large Language Models (LLMs) are well known for their ability to
write coherent text and fulfill a variety of tasks relevant to impact
reporting, such as question answering or text summarization. However, LLMs are
constrained by the knowledge within their training data and are prone to
generating inaccurate, or "hallucinated", information. To address this, we
introduce a sophisticated pipeline embodied in our tool FloodBrain
(floodbrain.com), specialized in generating flood disaster impact reports by
extracting and curating information from the web. Our pipeline assimilates
information from web search results to produce detailed and accurate reports on
flood events. We test different LLMs as backbones in our tool and compare their
generated reports to human-written reports on different metrics. Similar to
other studies, we find a notable correlation between the scores assigned by
GPT-4 and the scores given by human evaluators when comparing our generated
reports to human-authored ones. Additionally, we conduct an ablation study to
test our single pipeline components and their relevancy for the final reports.
With our tool, we aim to advance the use of LLMs for disaster impact reporting
and reduce the time for coordination of humanitarian efforts in the wake of
flood disasters.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.04928v2' target='_blank'>Leveraging Large Language Models for Collective Decision-Making</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Marios Papachristou, Longqi Yang, Chin-Chia Hsu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-03 18:27:21</h6>
<p class='card-text'>In various work contexts, such as meeting scheduling, collaborating, and
project planning, collective decision-making is essential but often challenging
due to diverse individual preferences, varying work focuses, and power dynamics
among members. To address this, we propose a system leveraging Large Language
Models (LLMs) to facilitate group decision-making by managing conversations and
balancing preferences among individuals. Our system aims to extract individual
preferences from conversations and suggest options that satisfy the preferences
of the members. We specifically apply this system to corporate meeting
scheduling. We create synthetic employee profiles and simulate conversations at
scale, leveraging LLMs to evaluate the system performance as a novel approach
to conducting a user study. Our results indicate efficient coordination with
reduced interactions between the members and the LLM-based system. The system
refines and improves its proposed options over time, ensuring that many of the
members' individual preferences are satisfied in an equitable way. Finally, we
conduct a survey study involving human participants to assess our system's
ability to aggregate preferences and reasoning about them. Our findings show
that the system exhibits strong performance in both dimensions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.01403v1' target='_blank'>REAL: Resilience and Adaptation using Large Language Models on
  Autonomous Aerial Robots</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Andrea Tagliabue, Kota Kondo, Tong Zhao, Mason Peterson, Claudius T. Tewari, Jonathan P. How</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-02 17:16:21</h6>
<p class='card-text'>Large Language Models (LLMs) pre-trained on internet-scale datasets have
shown impressive capabilities in code understanding, synthesis, and general
purpose question-and-answering. Key to their performance is the substantial
prior knowledge acquired during training and their ability to reason over
extended sequences of symbols, often presented in natural language. In this
work, we aim to harness the extensive long-term reasoning, natural language
comprehension, and the available prior knowledge of LLMs for increased
resilience and adaptation in autonomous mobile robots. We introduce REAL, an
approach for REsilience and Adaptation using LLMs. REAL provides a strategy to
employ LLMs as a part of the mission planning and control framework of an
autonomous robot. The LLM employed by REAL provides (i) a source of prior
knowledge to increase resilience for challenging scenarios that the system had
not been explicitly designed for; (ii) a way to interpret natural-language and
other log/diagnostic information available in the autonomy stack, for mission
planning; (iii) a way to adapt the control inputs using minimal user-provided
prior knowledge about the dynamics/kinematics of the robot. We integrate REAL
in the autonomy stack of a real multirotor, querying onboard an offboard LLM at
0.1-1.0 Hz as part the robot's mission planning and control feedback loops. We
demonstrate in real-world experiments the ability of the LLM to reduce the
position tracking errors of a multirotor under the presence of (i) errors in
the parameters of the controller and (ii) unmodeled dynamics. We also show
(iii) decision making to avoid potentially dangerous scenarios (e.g., robot
oscillates) that had not been explicitly accounted for in the initial prompt
design.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.01049v1' target='_blank'>Multi-dimensional data refining strategy for effective fine-tuning LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Thanh Nguyen Ngoc, Quang Nhat Tran, Arthur Tang, Bao Nguyen, Thuy Nguyen, Thanh Pham</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-02 07:50:43</h6>
<p class='card-text'>Data is a cornerstone for fine-tuning large language models, yet acquiring
suitable data remains challenging. Challenges encompassed data scarcity,
linguistic diversity, and domain-specific content. This paper presents lessons
learned while crawling and refining data tailored for fine-tuning Vietnamese
language models. Crafting such a dataset, while accounting for linguistic
intricacies and striking a balance between inclusivity and accuracy, demands
meticulous planning. Our paper presents a multidimensional strategy including
leveraging existing datasets in the English language and developing customized
data-crawling scripts with the assistance of generative AI tools. A fine-tuned
LLM model for the Vietnamese language, which was produced using resultant
datasets, demonstrated good performance while generating Vietnamese news
articles from prompts. The study offers practical solutions and guidance for
future fine-tuning models in languages like Vietnamese.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.00967v2' target='_blank'>Vision-Language Interpreter for Robot Task Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Keisuke Shirai, Cristian C. Beltran-Hernandez, Masashi Hamaya, Atsushi Hashimoto, Shohei Tanaka, Kento Kawaharazuka, Kazutoshi Tanaka, Yoshitaka Ushiku, Shinsuke Mori</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-02 03:32:30</h6>
<p class='card-text'>Large language models (LLMs) are accelerating the development of
language-guided robot planners. Meanwhile, symbolic planners offer the
advantage of interpretability. This paper proposes a new task that bridges
these two trends, namely, multimodal planning problem specification. The aim is
to generate a problem description (PD), a machine-readable file used by the
planners to find a plan. By generating PDs from language instruction and scene
observation, we can drive symbolic planners in a language-guided framework. We
propose a Vision-Language Interpreter (ViLaIn), a new framework that generates
PDs using state-of-the-art LLM and vision-language models. ViLaIn can refine
generated PDs via error message feedback from the symbolic planner. Our aim is
to answer the question: How accurately can ViLaIn and the symbolic planner
generate valid robot plans? To evaluate ViLaIn, we introduce a novel dataset
called the problem description generation (ProDG) dataset. The framework is
evaluated with four new evaluation metrics. Experimental results show that
ViLaIn can generate syntactically correct problems with more than 99\% accuracy
and valid plans with more than 58\% accuracy. Our code and dataset are
available at https://github.com/omron-sinicx/ViLaIn.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.00416v1' target='_blank'>Efficient Human-AI Coordination via Preparatory Language-based
  Convention</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Cong Guan, Lichao Zhang, Chunpeng Fan, Yichen Li, Feng Chen, Lihe Li, Yunjia Tian, Lei Yuan, Yang Yu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-01 10:18:23</h6>
<p class='card-text'>Developing intelligent agents capable of seamless coordination with humans is
a critical step towards achieving artificial general intelligence. Existing
methods for human-AI coordination typically train an agent to coordinate with a
diverse set of policies or with human models fitted from real human data.
However, the massively diverse styles of human behavior present obstacles for
AI systems with constrained capacity, while high quality human data may not be
readily available in real-world scenarios. In this study, we observe that prior
to coordination, humans engage in communication to establish conventions that
specify individual roles and actions, making their coordination proceed in an
orderly manner. Building upon this observation, we propose employing the large
language model (LLM) to develop an action plan (or equivalently, a convention)
that effectively guides both human and AI. By inputting task requirements,
human preferences, the number of agents, and other pertinent information into
the LLM, it can generate a comprehensive convention that facilitates a clear
understanding of tasks and responsibilities for all parties involved.
Furthermore, we demonstrate that decomposing the convention formulation problem
into sub-problems with multiple new sessions being sequentially employed and
human feedback, will yield a more efficient coordination convention.
Experimental evaluations conducted in the Overcooked-AI environment, utilizing
a human proxy model, highlight the superior performance of our proposed method
compared to existing learning-based approaches. When coordinating with real
humans, our method achieves better alignment with human preferences and an
average performance improvement of 15% compared to the state-of-the-art.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.00262v2' target='_blank'>Plug-and-Play Policy Planner for Large Language Model Powered Dialogue
  Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yang Deng, Wenxuan Zhang, Wai Lam, See-Kiong Ng, Tat-Seng Chua</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-11-01 03:20:16</h6>
<p class='card-text'>Proactive dialogues serve as a practical yet challenging dialogue problem in
the era of large language models (LLMs), where the dialogue policy planning is
the key to improving the proactivity of LLMs. Most existing studies enable the
dialogue policy planning of LLMs using various prompting schemes or iteratively
enhance this capability in handling the given case with verbal AI feedback.
However, these approaches are either bounded by the policy planning capability
of the frozen LLMs or hard to be transferred to new cases. In this work, we
introduce a new dialogue policy planning paradigm to strategize LLMs for
proactive dialogue problems with a tunable language model plug-in as a
plug-and-play dialogue policy planner, named PPDPP. Specifically, we develop a
novel training framework to facilitate supervised fine-tuning over available
human-annotated data as well as reinforcement learning from goal-oriented AI
feedback with dynamic interaction data collected by the LLM-based self-play
simulation. In this manner, the LLM-powered dialogue agent can not only be
generalized to different cases after the training, but also be applicable to
different applications by just substituting the learned plug-in. In addition,
we propose to evaluate the policy planning capability of dialogue systems under
the interactive setting. Experimental results demonstrate that PPDPP
consistently and substantially outperforms existing approaches on three
different proactive dialogue applications, including negotiation, emotional
support, and tutoring dialogues.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.00153v2' target='_blank'>Towards A Natural Language Interface for Flexible Multi-Agent Task
  Assignment</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jake Brawer, Kayleigh Bishop, Bradley Hayes, Alessandro Roncone</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-31 20:56:05</h6>
<p class='card-text'>Task assignment and scheduling algorithms are powerful tools for autonomously
coordinating large teams of robotic or AI agents. However, the decisions these
system make often rely on components designed by domain experts, which can be
difficult for non-technical end-users to understand or modify to their own
ends. In this paper we propose a preliminary design for a flexible natural
language interface for a task assignment system. The goal of our approach is
both to grant users more control over a task assignment system's decision
process, as well as render these decisions more transparent. Users can direct
the task assignment system via natural language commands, which are applied as
constraints to a mixed-integer linear program (MILP) using a large language
model (LLM). Additionally, our proposed system can alert users to potential
issues with their commands, and engage them in a corrective dialogue in order
to find a viable solution. We conclude with a description of our planned
user-evaluation in the simulated environment Overcooked and describe next steps
towards developing a flexible and transparent task allocation system.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.20151v2' target='_blank'>Multi-Agent Consensus Seeking via Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Huaben Chen, Wenkang Ji, Lufeng Xu, Shiyu Zhao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-31 03:37:11</h6>
<p class='card-text'>Multi-agent systems driven by large language models (LLMs) have shown
promising abilities for solving complex tasks in a collaborative manner. This
work considers a fundamental problem in multi-agent collaboration: consensus
seeking. When multiple agents work together, we are interested in how they can
reach a consensus through inter-agent negotiation. To that end, this work
studies a consensus-seeking task where the state of each agent is a numerical
value and they negotiate with each other to reach a consensus value. It is
revealed that when not explicitly directed on which strategy should be adopted,
the LLM-driven agents primarily use the average strategy for consensus seeking
although they may occasionally use some other strategies. Moreover, this work
analyzes the impact of the agent number, agent personality, and network
topology on the negotiation process. The findings reported in this work can
potentially lay the foundations for understanding the behaviors of LLM-driven
multi-agent systems for solving more complex tasks. Furthermore, LLM-driven
consensus seeking is applied to a multi-robot aggregation task. This
application demonstrates the potential of LLM-driven agents to achieve
zero-shot autonomous planning for multi-robot collaboration tasks. Project
website: windylab.github.io/ConsensusLLM/.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.20034v1' target='_blank'>GG-LLM: Geometrically Grounding Large Language Models for Zero-shot
  Human Activity Forecasting in Human-Aware Task Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Moritz A. Graule, Volkan Isler</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-30 21:36:20</h6>
<p class='card-text'>A robot in a human-centric environment needs to account for the human's
intent and future motion in its task and motion planning to ensure safe and
effective operation. This requires symbolic reasoning about probable future
actions and the ability to tie these actions to specific locations in the
physical environment. While one can train behavioral models capable of
predicting human motion from past activities, this approach requires large
amounts of data to achieve acceptable long-horizon predictions. More
importantly, the resulting models are constrained to specific data formats and
modalities. Moreover, connecting predictions from such models to the
environment at hand to ensure the applicability of these predictions is an
unsolved problem. We present a system that utilizes a Large Language Model
(LLM) to infer a human's next actions from a range of modalities without
fine-tuning. A novel aspect of our system that is critical to robotics
applications is that it links the predicted actions to specific locations in a
semantic map of the environment. Our method leverages the fact that LLMs,
trained on a vast corpus of text describing typical human behaviors, encode
substantial world knowledge, including probable sequences of human actions and
activities. We demonstrate how these localized activity predictions can be
incorporated in a human-aware task planner for an assistive robot to reduce the
occurrences of undesirable human-robot interactions by 29.2% on average.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2311.01468v1' target='_blank'>Remember what you did so you know what to do next</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Manuel R. Ciosici, Alex Hedges, Yash Kankanampati, Justin Martin, Marjorie Freedman, Ralph Weischedel</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-30 19:29:00</h6>
<p class='card-text'>We explore using a moderately sized large language model (GPT-J 6B
parameters) to create a plan for a simulated robot to achieve 30 classes of
goals in ScienceWorld, a text game simulator for elementary science
experiments. Previously published empirical work claimed that large language
models (LLMs) are a poor fit (Wang et al., 2022) compared to reinforcement
learning. Using the Markov assumption (a single previous step), the LLM
outperforms the reinforcement learning-based approach by a factor of 1.4. When
we fill the LLM's input buffer with as many prior steps as possible,
improvement rises to 3.5x. Even when training on only 6.5% of the training
data, we observe a 2.2x improvement over the reinforcement-learning-based
approach. Our experiments show that performance varies widely across the 30
classes of actions, indicating that averaging over tasks can hide significant
performance issues. In work contemporaneous with ours, Lin et al. (2023)
demonstrated a two-part approach (SwiftSage) that uses a small LLM (T5-large)
complemented by OpenAI's massive LLMs to achieve outstanding results in
ScienceWorld. Our 6-B parameter, single-stage GPT-J matches the performance of
SwiftSage's two-stage architecture when it incorporates GPT-3.5 turbo which has
29-times more parameters than GPT-J.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.19212v1' target='_blank'>EHRTutor: Enhancing Patient Understanding of Discharge Instructions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zihao Zhang, Zonghai Yao, Huixue Zhou, Feiyun ouyang, Hong Yu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-30 00:46:03</h6>
<p class='card-text'>Large language models have shown success as a tutor in education in various
fields. Educating patients about their clinical visits plays a pivotal role in
patients' adherence to their treatment plans post-discharge. This paper
presents EHRTutor, an innovative multi-component framework leveraging the Large
Language Model (LLM) for patient education through conversational
question-answering. EHRTutor first formulates questions pertaining to the
electronic health record discharge instructions. It then educates the patient
through conversation by administering each question as a test. Finally, it
generates a summary at the end of the conversation. Evaluation results using
LLMs and domain experts have shown a clear preference for EHRTutor over the
baseline. Moreover, EHRTutor also offers a framework for generating synthetic
patient education dialogues that can be used for future in-house system
training.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.18075v4' target='_blank'>DUMA: a Dual-Mind Conversational Agent with Fast and Slow Thinking</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xiaoyu Tian, Liangyu Chen, Na Liu, Yaxuan Liu, Wei Zou, Kaijiang Chen, Ming Cui</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-27 11:43:46</h6>
<p class='card-text'>Inspired by the dual-process theory of human cognition, we introduce DUMA, a
novel conversational agent framework that embodies a dual-mind mechanism
through the utilization of two generative Large Language Models (LLMs)
dedicated to fast and slow thinking respectively. The fast thinking model
serves as the primary interface for external interactions and initial response
generation, evaluating the necessity for engaging the slow thinking model based
on the complexity of the complete response. When invoked, the slow thinking
model takes over the conversation, engaging in meticulous planning, reasoning,
and tool utilization to provide a well-analyzed response. This dual-mind
configuration allows for a seamless transition between intuitive responses and
deliberate problem-solving processes based on the situation. We have
constructed a conversational agent to handle online inquiries in the real
estate industry. The experiment proves that our method balances effectiveness
and efficiency, and has a significant improvement compared to the baseline.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.17512v2' target='_blank'>CompeteAI: Understanding the Competition Dynamics in Large Language
  Model-based Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Qinlin Zhao, Jindong Wang, Yixuan Zhang, Yiqiao Jin, Kaijie Zhu, Hao Chen, Xing Xie</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-26 16:06:20</h6>
<p class='card-text'>Large language models (LLMs) have been widely used as agents to complete
different tasks, such as personal assistance or event planning. While most of
the work has focused on cooperation and collaboration between agents, little
work explores competition, another important mechanism that promotes the
development of society and economy. In this paper, we seek to examine the
competition dynamics in LLM-based agents. We first propose a general framework
for studying the competition between agents. Then, we implement a practical
competitive environment using GPT-4 to simulate a virtual town with two types
of agents, restaurant agents and customer agents. Specifically, the restaurant
agents compete with each other to attract more customers, where competition
encourages them to transform, such as cultivating new operating strategies.
Simulation experiments reveal several interesting findings at the micro and
macro levels, which align well with existing market and sociological theories.
We hope that the framework and environment can be a promising testbed to study
competition that fosters understanding of society. Code is available at:
https://github.com/microsoft/competeai.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.17140v1' target='_blank'>Symbolic Planning and Code Generation for Grounded Dialogue</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Justin T. Chiu, Wenting Zhao, Derek Chen, Saujas Vaduguru, Alexander M. Rush, Daniel Fried</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-26 04:22:23</h6>
<p class='card-text'>Large language models (LLMs) excel at processing and generating both text and
code. However, LLMs have had limited applicability in grounded task-oriented
dialogue as they are difficult to steer toward task objectives and fail to
handle novel grounding. We present a modular and interpretable grounded
dialogue system that addresses these shortcomings by composing LLMs with a
symbolic planner and grounded code execution. Our system consists of a reader
and planner: the reader leverages an LLM to convert partner utterances into
executable code, calling functions that perform grounding. The translated
code's output is stored to track dialogue state, while a symbolic planner
determines the next appropriate response. We evaluate our system's performance
on the demanding OneCommon dialogue task, involving collaborative reference
resolution on abstract images of scattered dots. Our system substantially
outperforms the previous state-of-the-art, including improving task success in
human evaluations from 56% to 69% in the most challenging setting.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.17019v1' target='_blank'>Conditionally Combining Robot Skills using Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:K. R. Zentner, Ryan Julian, Brian Ichter, Gaurav S. Sukhatme</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-25 21:46:34</h6>
<p class='card-text'>This paper combines two contributions. First, we introduce an extension of
the Meta-World benchmark, which we call "Language-World," which allows a large
language model to operate in a simulated robotic environment using
semi-structured natural language queries and scripted skills described using
natural language. By using the same set of tasks as Meta-World, Language-World
results can be easily compared to Meta-World results, allowing for a point of
comparison between recent methods using Large Language Models (LLMs) and those
using Deep Reinforcement Learning. Second, we introduce a method we call Plan
Conditioned Behavioral Cloning (PCBC), that allows finetuning the behavior of
high-level plans using end-to-end demonstrations. Using Language-World, we show
that PCBC is able to achieve strong performance in a variety of few-shot
regimes, often achieving task generalization with as little as a single
demonstration. We have made Language-World available as open-source software at
https://github.com/krzentner/language-world/.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.16984v1' target='_blank'>Patterns of Student Help-Seeking When Using a Large Language
  Model-Powered Programming Assistant</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Brad Sheese, Mark Liffiton, Jaromir Savelka, Paul Denny</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-25 20:36:05</h6>
<p class='card-text'>Providing personalized assistance at scale is a long-standing challenge for
computing educators, but a new generation of tools powered by large language
models (LLMs) offers immense promise. Such tools can, in theory, provide
on-demand help in large class settings and be configured with appropriate
guardrails to prevent misuse and mitigate common concerns around learner
over-reliance. However, the deployment of LLM-powered tools in authentic
classroom settings is still rare, and very little is currently known about how
students will use them in practice and what type of help they will seek. To
address this, we examine students' use of an innovative LLM-powered tool that
provides on-demand programming assistance without revealing solutions directly.
We deployed the tool for 12 weeks in an introductory computer and data science
course ($n = 52$), collecting more than 2,500 queries submitted by students
throughout the term. We manually categorized all student queries based on the
type of assistance sought, and we automatically analyzed several additional
query characteristics. We found that most queries requested immediate help with
programming assignments, whereas fewer requests asked for help on related
concepts or for deepening conceptual understanding. Furthermore, students often
provided minimal information to the tool, suggesting this is an area in which
targeted instruction would be beneficial. We also found that students who
achieved more success in the course tended to have used the tool more
frequently overall. Lessons from this research can be leveraged by programming
educators and institutions who plan to augment their teaching with emerging
LLM-powered tools.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.16427v2' target='_blank'>PromptAgent: Strategic Planning with Language Models Enables
  Expert-level Prompt Optimization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xinyuan Wang, Chenxi Li, Zhen Wang, Fan Bai, Haotian Luo, Jiayou Zhang, Nebojsa Jojic, Eric P. Xing, Zhiting Hu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-25 07:47:01</h6>
<p class='card-text'>Highly effective, task-specific prompts are often heavily engineered by
experts to integrate detailed instructions and domain insights based on a deep
understanding of both instincts of large language models (LLMs) and the
intricacies of the target task. However, automating the generation of such
expert-level prompts remains elusive. Existing prompt optimization methods tend
to overlook the depth of domain knowledge and struggle to efficiently explore
the vast space of expert-level prompts. Addressing this, we present
PromptAgent, an optimization method that autonomously crafts prompts equivalent
in quality to those handcrafted by experts. At its core, PromptAgent views
prompt optimization as a strategic planning problem and employs a principled
planning algorithm, rooted in Monte Carlo tree search, to strategically
navigate the expert-level prompt space. Inspired by human-like trial-and-error
exploration, PromptAgent induces precise expert-level insights and in-depth
instructions by reflecting on model errors and generating constructive error
feedback. Such a novel framework allows the agent to iteratively examine
intermediate prompts (states), refine them based on error feedbacks (actions),
simulate future rewards, and search for high-reward paths leading to expert
prompts. We apply PromptAgent to 12 tasks spanning three practical domains:
BIG-Bench Hard (BBH), as well as domain-specific and general NLP tasks, showing
it significantly outperforms strong Chain-of-Thought and recent prompt
optimization baselines. Extensive analyses emphasize its capability to craft
expert-level, detailed, and domain-insightful prompts with great efficiency and
generalizability.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.15127v2' target='_blank'>Open-Ended Instructable Embodied Agents with Memory-Augmented Large
  Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Gabriel Sarch, Yue Wu, Michael J. Tarr, Katerina Fragkiadaki</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-23 17:31:55</h6>
<p class='card-text'>Pre-trained and frozen large language models (LLMs) can effectively map
simple scene rearrangement instructions to programs over a robot's visuomotor
functions through appropriate few-shot example prompting. To parse open-domain
natural language and adapt to a user's idiosyncratic procedures, not known
during prompt engineering time, fixed prompts fall short. In this paper, we
introduce HELPER, an embodied agent equipped with an external memory of
language-program pairs that parses free-form human-robot dialogue into action
programs through retrieval-augmented LLM prompting: relevant memories are
retrieved based on the current dialogue, instruction, correction, or VLM
description, and used as in-context prompt examples for LLM querying. The
memory is expanded during deployment to include pairs of user's language and
action plans, to assist future inferences and personalize them to the user's
language and routines. HELPER sets a new state-of-the-art in the TEACh
benchmark in both Execution from Dialog History (EDH) and Trajectory from
Dialogue (TfD), with a 1.7x improvement over the previous state-of-the-art for
TfD. Our models, code, and video results can be found in our project's website:
https://helper-agent-llm.github.io.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.15123v2' target='_blank'>Branch-Solve-Merge Improves Large Language Model Evaluation and
  Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Swarnadeep Saha, Omer Levy, Asli Celikyilmaz, Mohit Bansal, Jason Weston, Xian Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-23 17:29:48</h6>
<p class='card-text'>Large Language Models (LLMs) are frequently used for multi-faceted language
generation and evaluation tasks that involve satisfying intricate user
constraints or taking into account multiple aspects and criteria. However,
their performance can fall short, due to the model's lack of coherence and
inability to plan and decompose the problem. We propose Branch-Solve-Merge
(BSM), a Large Language Model program (Schlag et al., 2023) for tackling such
challenging natural language tasks. It consists of branch, solve, and merge
modules that are parameterized with specific prompts to the base LLM. These
three modules plan a decomposition of the task into multiple parallel
sub-tasks, independently solve them, and fuse the solutions to the sub-tasks.
We apply our method to the tasks of LLM response evaluation and constrained
text generation and evaluate its effectiveness with multiple LLMs, including
Vicuna, LLaMA-2-chat, and GPT-4. BSM improves the evaluation correctness and
consistency for each LLM by enhancing human-LLM agreement by up to 26%,
reducing length and pairwise position biases by up to 50%, and allowing
LLaMA2-chat to match or outperform GPT-4 on most domains. On a constraint story
generation task, BSM improves the coherence of stories while also improving
constraint satisfaction by 12%.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.14628v2' target='_blank'>Plan, Verify and Switch: Integrated Reasoning with Diverse X-of-Thoughts</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tengxiao Liu, Qipeng Guo, Yuqing Yang, Xiangkun Hu, Yue Zhang, Xipeng Qiu, Zheng Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-23 07:02:20</h6>
<p class='card-text'>As large language models (LLMs) have shown effectiveness with different
prompting methods, such as Chain of Thought, Program of Thought, we find that
these methods have formed a great complementarity to each other on math
reasoning tasks. In this work, we propose XoT, an integrated problem solving
framework by prompting LLMs with diverse reasoning thoughts. For each question,
XoT always begins with selecting the most suitable method then executes each
method iteratively. Within each iteration, XoT actively checks the validity of
the generated answer and incorporates the feedback from external executors,
allowing it to dynamically switch among different prompting methods. Through
extensive experiments on 10 popular math reasoning datasets, we demonstrate the
effectiveness of our proposed approach and thoroughly analyze the strengths of
each module. Moreover, empirical results suggest that our framework is
orthogonal to recent work that makes improvements on single reasoning methods
and can further generalise to logical reasoning domain. By allowing method
switching, XoT provides a fresh perspective on the collaborative integration of
diverse reasoning thoughts in a unified framework. The code is available at
https://github.com/tengxiaoliu/XoT.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.14414v2' target='_blank'>Vision Language Models in Autonomous Driving: A Survey and Outlook</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xingcheng Zhou, Mingyu Liu, Ekim Yurtsever, Bare Luka Zagar, Walter Zimmer, Hu Cao, Alois C. Knoll</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-22 21:06:10</h6>
<p class='card-text'>The applications of Vision-Language Models (VLMs) in the field of Autonomous
Driving (AD) have attracted widespread attention due to their outstanding
performance and the ability to leverage Large Language Models (LLMs). By
incorporating language data, driving systems can gain a better understanding of
real-world environments, thereby enhancing driving safety and efficiency. In
this work, we present a comprehensive and systematic survey of the advances in
vision language models in this domain, encompassing perception and
understanding, navigation and planning, decision-making and control, end-to-end
autonomous driving, and data generation. We introduce the mainstream VLM tasks
in AD and the commonly utilized metrics. Additionally, we review current
studies and applications in various areas and summarize the existing
language-enhanced autonomous driving datasets thoroughly. Lastly, we discuss
the benefits and challenges of VLMs in AD and provide researchers with the
current research gaps and future trends.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.18340v2' target='_blank'>UrbanCLIP: Learning Text-enhanced Urban Region Profiling with
  Contrastive Language-Image Pretraining from the Web</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yibo Yan, Haomin Wen, Siru Zhong, Wei Chen, Haodong Chen, Qingsong Wen, Roger Zimmermann, Yuxuan Liang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-22 02:32:53</h6>
<p class='card-text'>Urban region profiling from web-sourced data is of utmost importance for
urban planning and sustainable development. We are witnessing a rising trend of
LLMs for various fields, especially dealing with multi-modal data research such
as vision-language learning, where the text modality serves as a supplement
information for the image. Since textual modality has never been introduced
into modality combinations in urban region profiling, we aim to answer two
fundamental questions in this paper: i) Can textual modality enhance urban
region profiling? ii) and if so, in what ways and with regard to which aspects?
To answer the questions, we leverage the power of Large Language Models (LLMs)
and introduce the first-ever LLM-enhanced framework that integrates the
knowledge of textual modality into urban imagery profiling, named LLM-enhanced
Urban Region Profiling with Contrastive Language-Image Pretraining (UrbanCLIP).
Specifically, it first generates a detailed textual description for each
satellite image by an open-source Image-to-Text LLM. Then, the model is trained
on the image-text pairs, seamlessly unifying natural language supervision for
urban visual representation learning, jointly with contrastive loss and
language modeling loss. Results on predicting three urban indicators in four
major Chinese metropolises demonstrate its superior performance, with an
average improvement of 6.1% on R^2 compared to the state-of-the-art methods.
Our code and the image-language dataset will be released upon paper
notification.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.13659v1' target='_blank'>Benchmarking and Improving Text-to-SQL Generation under Ambiguity</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Adithya Bhaskar, Tushar Tomar, Ashutosh Sathe, Sunita Sarawagi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-20 17:00:53</h6>
<p class='card-text'>Research in Text-to-SQL conversion has been largely benchmarked against
datasets where each text query corresponds to one correct SQL. However, natural
language queries over real-life databases frequently involve significant
ambiguity about the intended SQL due to overlapping schema names and multiple
confusing relationship paths. To bridge this gap, we develop a novel benchmark
called AmbiQT with over 3000 examples where each text is interpretable as two
plausible SQLs due to lexical and/or structural ambiguity.
  When faced with ambiguity, an ideal top-$k$ decoder should generate all valid
interpretations for possible disambiguation by the user. We evaluate several
Text-to-SQL systems and decoding algorithms, including those employing
state-of-the-art LLMs, and find them to be far from this ideal. The primary
reason is that the prevalent beam search algorithm and its variants, treat SQL
queries as a string and produce unhelpful token-level diversity in the top-$k$.
  We propose LogicalBeam, a new decoding algorithm that navigates the SQL logic
space using a blend of plan-based template generation and constrained
infilling. Counterfactually generated plans diversify templates while
in-filling with a beam-search that branches solely on schema names provides
value diversity. LogicalBeam is up to $2.5$ times more effective than
state-of-the-art models at generating all candidate SQLs in the top-$k$ ranked
outputs. It also enhances the top-$5$ Exact and Execution Match Accuracies on
SPIDER and Kaggle DBQA.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.13255v2' target='_blank'>Steve-Eye: Equipping LLM-based Embodied Agents with Visual Perception in
  Open Worlds</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sipeng Zheng, Jiazheng Liu, Yicheng Feng, Zongqing Lu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-20 03:22:05</h6>
<p class='card-text'>Recent studies have presented compelling evidence that large language models
(LLMs) can equip embodied agents with the self-driven capability to interact
with the world, which marks an initial step toward versatile robotics. However,
these efforts tend to overlook the visual richness of open worlds, rendering
the entire interactive process akin to "a blindfolded text-based game."
Consequently, LLM-based agents frequently encounter challenges in intuitively
comprehending their surroundings and producing responses that are easy to
understand. In this paper, we propose Steve-Eye, an end-to-end trained large
multimodal model designed to address this limitation. Steve-Eye integrates the
LLM with a visual encoder which enables it to process visual-text inputs and
generate multimodal feedback. In addition, we use a semi-automatic strategy to
collect an extensive dataset comprising 850K open-world instruction pairs,
empowering our model to encompass three essential functions for an agent:
multimodal perception, foundational knowledge base, and skill prediction and
planning. Lastly, we develop three open-world evaluation benchmarks, then carry
out extensive experiments from a wide range of perspectives to validate our
model's capability to strategically act and plan. Codes and datasets will be
released.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.13227v1' target='_blank'>ToolChain*: Efficient Action Space Navigation in Large Language Models
  with A* Search</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuchen Zhuang, Xiang Chen, Tong Yu, Saayan Mitra, Victor Bursztyn, Ryan A. Rossi, Somdeb Sarkhel, Chao Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-20 02:24:35</h6>
<p class='card-text'>Large language models (LLMs) have demonstrated powerful decision-making and
planning capabilities in solving complicated real-world problems. LLM-based
autonomous agents can interact with diverse tools (e.g., functional APIs) and
generate solution plans that execute a series of API function calls in a
step-by-step manner. The multitude of candidate API function calls
significantly expands the action space, amplifying the critical need for
efficient action space navigation. However, existing methods either struggle
with unidirectional exploration in expansive action spaces, trapped into a
locally optimal solution, or suffer from exhaustively traversing all potential
actions, causing inefficient navigation. To address these issues, we propose
ToolChain*, an efficient tree search-based planning algorithm for LLM-based
agents. It formulates the entire action space as a decision tree, where each
node represents a possible API function call involved in a solution plan. By
incorporating the A* search algorithm with task-specific cost function design,
it efficiently prunes high-cost branches that may involve incorrect actions,
identifying the most low-cost valid path as the solution. Extensive experiments
on multiple tool-use and reasoning tasks demonstrate that ToolChain*
efficiently balances exploration and exploitation within an expansive action
space. It outperforms state-of-the-art baselines on planning and reasoning
tasks by 3.1% and 3.5% on average while requiring 7.35x and 2.31x less time,
respectively.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.13065v1' target='_blank'>Creative Robot Tool Use with Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mengdi Xu, Peide Huang, Wenhao Yu, Shiqi Liu, Xilun Zhang, Yaru Niu, Tingnan Zhang, Fei Xia, Jie Tan, Ding Zhao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-19 18:02:15</h6>
<p class='card-text'>Tool use is a hallmark of advanced intelligence, exemplified in both animal
behavior and robotic capabilities. This paper investigates the feasibility of
imbuing robots with the ability to creatively use tools in tasks that involve
implicit physical constraints and long-term planning. Leveraging Large Language
Models (LLMs), we develop RoboTool, a system that accepts natural language
instructions and outputs executable code for controlling robots in both
simulated and real-world environments. RoboTool incorporates four pivotal
components: (i) an "Analyzer" that interprets natural language to discern key
task-related concepts, (ii) a "Planner" that generates comprehensive strategies
based on the language input and key concepts, (iii) a "Calculator" that
computes parameters for each skill, and (iv) a "Coder" that translates these
plans into executable Python code. Our results show that RoboTool can not only
comprehend explicit or implicit physical constraints and environmental factors
but also demonstrate creative tool use. Unlike traditional Task and Motion
Planning (TAMP) methods that rely on explicit optimization, our LLM-based
system offers a more flexible, efficient, and user-friendly solution for
complex robotics tasks. Through extensive experiments, we validate that
RoboTool is proficient in handling tasks that would otherwise be infeasible
without the creative use of tools, thereby expanding the capabilities of
robotic systems. Demos are available on our project page:
https://creative-robotool.github.io/.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.12823v2' target='_blank'>AgentTuning: Enabling Generalized Agent Abilities for LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Aohan Zeng, Mingdao Liu, Rui Lu, Bowen Wang, Xiao Liu, Yuxiao Dong, Jie Tang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-19 15:19:53</h6>
<p class='card-text'>Open large language models (LLMs) with great performance in various tasks
have significantly advanced the development of LLMs. However, they are far
inferior to commercial models such as ChatGPT and GPT-4 when acting as agents
to tackle complex tasks in the real world. These agent tasks employ LLMs as the
central controller responsible for planning, memorization, and tool
utilization, necessitating both fine-grained prompting methods and robust LLMs
to achieve satisfactory performance. Though many prompting methods have been
proposed to complete particular agent tasks, there is lack of research focusing
on improving the agent capabilities of LLMs themselves without compromising
their general abilities. In this work, we present AgentTuning, a simple and
general method to enhance the agent abilities of LLMs while maintaining their
general LLM capabilities. We construct AgentInstruct, a lightweight
instruction-tuning dataset containing high-quality interaction trajectories. We
employ a hybrid instruction-tuning strategy by combining AgentInstruct with
open-source instructions from general domains. AgentTuning is used to
instruction-tune the Llama 2 series, resulting in AgentLM. Our evaluations show
that AgentTuning enables LLMs' agent capabilities without compromising general
abilities. The AgentLM-70B is comparable to GPT-3.5-turbo on unseen agent
tasks, demonstrating generalized agent capabilities. We open source the
AgentInstruct and AgentLM-7B, 13B, and 70B models at
https://github.com/THUDM/AgentTuning, serving open and powerful alternatives to
commercial LLMs for agent tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.12418v1' target='_blank'>The Shifted and The Overlooked: A Task-oriented Investigation of
  User-GPT Interactions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Siru Ouyang, Shuohang Wang, Yang Liu, Ming Zhong, Yizhu Jiao, Dan Iter, Reid Pryzant, Chenguang Zhu, Heng Ji, Jiawei Han</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-19 02:12:17</h6>
<p class='card-text'>Recent progress in Large Language Models (LLMs) has produced models that
exhibit remarkable performance across a variety of NLP tasks. However, it
remains unclear whether the existing focus of NLP research accurately captures
the genuine requirements of human users. This paper provides a comprehensive
analysis of the divergence between current NLP research and the needs of
real-world NLP applications via a large-scale collection of user-GPT
conversations. We analyze a large-scale collection of real user queries to GPT.
We compare these queries against existing NLP benchmark tasks and identify a
significant gap between the tasks that users frequently request from LLMs and
the tasks that are commonly studied in academic research. For example, we find
that tasks such as ``design'' and ``planning'' are prevalent in user
interactions but are largely neglected or different from traditional NLP
benchmarks. We investigate these overlooked tasks, dissect the practical
challenges they pose, and provide insights toward a roadmap to make LLMs better
aligned with user needs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.12342v2' target='_blank'>Eliminating Reasoning via Inferring with Planning: A New Framework to
  Guide LLMs' Non-linear Thinking</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yongqi Tong, Yifan Wang, Dawei Li, Sizhe Wang, Zi Lin, Simeng Han, Jingbo Shang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-18 21:42:16</h6>
<p class='card-text'>Chain-of-Thought(CoT) prompting and its variants explore equipping large
language models (LLMs) with high-level reasoning abilities by emulating
human-like linear cognition and logic. However, the human mind is complicated
and mixed with both linear and nonlinear thinking. In this work, we propose
\textbf{I}nferential \textbf{E}xclusion \textbf{P}rompting (IEP), a novel
prompting that combines the principles of elimination and inference in order to
guide LLMs to think non-linearly. IEP guides LLMs to plan and then utilize
Natural Language Inference (NLI) to deduce each possible solution's entailment
relation with context, commonsense, or facts, therefore yielding a broader
perspective by thinking back for inferring. This forward planning and backward
eliminating process allows IEP to better simulate the complex human thinking
processes compared to other CoT-based methods, which only reflect linear
cognitive processes. We conducted a series of empirical studies and have
corroborated that IEP consistently outperforms CoT across various tasks.
Additionally, we observe that integrating IEP and CoT further improves the
LLMs' performance on certain tasks, highlighting the necessity of equipping
LLMs with mixed logic processes. Moreover, to better evaluate comprehensive
features inherent in human logic, we introduce \textbf{M}ental-\textbf{A}bility
\textbf{R}easoning \textbf{B}enchmark (MARB). The benchmark comprises six novel
subtasks with a total of 9,115 questions, among which 1,685 are developed with
hand-crafted rationale references. We believe both \textsc{IEP} and
\textsc{MARB} can serve as a promising direction for unveiling LLMs' logic and
verbal reasoning abilities and drive further advancements. \textsc{MARB} will
be available at ~\texttt{anonymity link} soon.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.12128v2' target='_blank'>DiagrammerGPT: Generating Open-Domain, Open-Platform Diagrams via LLM
  Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Abhay Zala, Han Lin, Jaemin Cho, Mohit Bansal</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-18 17:37:10</h6>
<p class='card-text'>Text-to-image (T2I) generation has seen significant growth over the past few
years. Despite this, there has been little work on generating diagrams with T2I
models. A diagram is a symbolic/schematic representation that explains
information using structurally rich and spatially complex visualizations (e.g.,
a dense combination of related objects, text labels, directional arrows/lines,
etc.). Existing state-of-the-art T2I models often fail at diagram generation
because they lack fine-grained object layout control when many objects are
densely connected via complex relations such as arrows/lines, and also often
fail to render comprehensible text labels. To address this gap, we present
DiagrammerGPT, a novel two-stage text-to-diagram generation framework
leveraging the layout guidance capabilities of LLMs to generate more accurate
diagrams. In the first stage, we use LLMs to generate and iteratively refine
'diagram plans' (in a planner-auditor feedback loop). In the second stage, we
use a diagram generator, DiagramGLIGEN, and a text label rendering module to
generate diagrams (with clear text labels) following the diagram plans. To
benchmark the text-to-diagram generation task, we introduce AI2D-Caption, a
densely annotated diagram dataset built on top of the AI2D dataset. We show
that our DiagrammerGPT framework produces more accurate diagrams, outperforming
existing T2I models. We also provide comprehensive analysis, including
open-domain diagram generation, multi-platform vector graphic diagram
generation, human-in-the-loop editing, and multimodal planner/auditor LLMs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.12020v2' target='_blank'>LoHoRavens: A Long-Horizon Language-Conditioned Benchmark for Robotic
  Tabletop Manipulation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shengqiang Zhang, Philipp Wicke, Lütfi Kerem Şenel, Luis Figueredo, Abdeldjallil Naceri, Sami Haddadin, Barbara Plank, Hinrich Schütze</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-18 14:53:14</h6>
<p class='card-text'>The convergence of embodied agents and large language models (LLMs) has
brought significant advancements to embodied instruction following.
Particularly, the strong reasoning capabilities of LLMs make it possible for
robots to perform long-horizon tasks without expensive annotated
demonstrations. However, public benchmarks for testing the long-horizon
reasoning capabilities of language-conditioned robots in various scenarios are
still missing. To fill this gap, this work focuses on the tabletop manipulation
task and releases a simulation benchmark, \textit{LoHoRavens}, which covers
various long-horizon reasoning aspects spanning color, size, space, arithmetics
and reference. Furthermore, there is a key modality bridging problem for
long-horizon manipulation tasks with LLMs: how to incorporate the observation
feedback during robot execution for the LLM's closed-loop planning, which is
however less studied by prior work. We investigate two methods of bridging the
modality gap: caption generation and learnable interface for incorporating
explicit and implicit observation feedback to the LLM, respectively. These
methods serve as the two baselines for our proposed benchmark. Experiments show
that both methods struggle to solve some tasks, indicating long-horizon
manipulation tasks are still challenging for current popular models. We expect
the proposed public benchmark and baselines can help the community develop
better models for long-horizon tabletop manipulation tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.11604v2' target='_blank'>Language Models as Zero-Shot Trajectory Generators</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Teyun Kwon, Norman Di Palo, Edward Johns</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-17 21:57:36</h6>
<p class='card-text'>Large Language Models (LLMs) have recently shown promise as high-level
planners for robots when given access to a selection of low-level skills.
However, it is often assumed that LLMs do not possess sufficient knowledge to
be used for the low-level trajectories themselves. In this work, we address
this assumption thoroughly, and investigate if an LLM (GPT-4) can directly
predict a dense sequence of end-effector poses for manipulation tasks, when
given access to only object detection and segmentation vision models. We
designed a single, task-agnostic prompt, without any in-context examples,
motion primitives, or external trajectory optimisers. Then we studied how well
it can perform across 30 real-world language-based tasks, such as "open the
bottle cap" and "wipe the plate with the sponge", and we investigated which
design choices in this prompt are the most important. Our conclusions raise the
assumed limit of LLMs for robotics, and we reveal for the first time that LLMs
do indeed possess an understanding of low-level robot control sufficient for a
range of common tasks, and that they can additionally detect failures and then
re-plan trajectories accordingly. Videos, prompts, and code are available at:
https://www.robot-learning.uk/language-models-trajectory-generators.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.11249v1' target='_blank'>Leveraging Large Language Model for Automatic Evolving of Industrial
  Data-Centric R&D Cycle</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xu Yang, Xiao Yang, Weiqing Liu, Jinhui Li, Peng Yu, Zeqi Ye, Jiang Bian</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-17 13:18:02</h6>
<p class='card-text'>In the wake of relentless digital transformation, data-driven solutions are
emerging as powerful tools to address multifarious industrial tasks such as
forecasting, anomaly detection, planning, and even complex decision-making.
Although data-centric R&D has been pivotal in harnessing these solutions, it
often comes with significant costs in terms of human, computational, and time
resources. This paper delves into the potential of large language models (LLMs)
to expedite the evolution cycle of data-centric R&D. Assessing the foundational
elements of data-centric R&D, including heterogeneous task-related data,
multi-facet domain knowledge, and diverse computing-functional tools, we
explore how well LLMs can understand domain-specific requirements, generate
professional ideas, utilize domain-specific tools to conduct experiments,
interpret results, and incorporate knowledge from past endeavors to tackle new
challenges. We take quantitative investment research as a typical example of
industrial data-centric R&D scenario and verified our proposed framework upon
our full-stack open-sourced quantitative research platform Qlib and obtained
promising results which shed light on our vision of automatic evolving of
industrial data-centric R&D cycle.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.10632v1' target='_blank'>BioPlanner: Automatic Evaluation of LLMs on Protocol Planning in Biology</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Odhran O'Donoghue, Aleksandar Shtedritski, John Ginger, Ralph Abboud, Ali Essa Ghareeb, Justin Booth, Samuel G Rodriques</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-16 17:54:20</h6>
<p class='card-text'>The ability to automatically generate accurate protocols for scientific
experiments would represent a major step towards the automation of science.
Large Language Models (LLMs) have impressive capabilities on a wide range of
tasks, such as question answering and the generation of coherent text and code.
However, LLMs can struggle with multi-step problems and long-term planning,
which are crucial for designing scientific experiments. Moreover, evaluation of
the accuracy of scientific protocols is challenging, because experiments can be
described correctly in many different ways, require expert knowledge to
evaluate, and cannot usually be executed automatically. Here we present an
automatic evaluation framework for the task of planning experimental protocols,
and we introduce BioProt: a dataset of biology protocols with corresponding
pseudocode representations. To measure performance on generating scientific
protocols, we use an LLM to convert a natural language protocol into
pseudocode, and then evaluate an LLM's ability to reconstruct the pseudocode
from a high-level description and a list of admissible pseudocode functions. We
evaluate GPT-3 and GPT-4 on this task and explore their robustness. We
externally validate the utility of pseudocode representations of text by
generating accurate novel protocols using retrieved pseudocode, and we run a
generated protocol successfully in our biological laboratory. Our framework is
extensible to the evaluation and improvement of language model planning
abilities in other areas of science or other areas that lack automatic
evaluation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.10701v3' target='_blank'>Theory of Mind for Multi-Agent Collaboration via Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Huao Li, Yu Quan Chong, Simon Stepputtis, Joseph Campbell, Dana Hughes, Michael Lewis, Katia Sycara</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-16 07:51:19</h6>
<p class='card-text'>While Large Language Models (LLMs) have demonstrated impressive
accomplishments in both reasoning and planning, their abilities in multi-agent
collaborations remains largely unexplored. This study evaluates LLM-based
agents in a multi-agent cooperative text game with Theory of Mind (ToM)
inference tasks, comparing their performance with Multi-Agent Reinforcement
Learning (MARL) and planning-based baselines. We observed evidence of emergent
collaborative behaviors and high-order Theory of Mind capabilities among
LLM-based agents. Our results reveal limitations in LLM-based agents' planning
optimization due to systematic failures in managing long-horizon contexts and
hallucination about the task state. We explore the use of explicit belief state
representations to mitigate these issues, finding that it enhances task
performance and the accuracy of ToM inferences for LLM-based agents.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.09676v2' target='_blank'>Mastering Robot Manipulation with Multimodal Prompts through Pretraining
  and Multi-task Fine-tuning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiachen Li, Qiaozi Gao, Michael Johnston, Xiaofeng Gao, Xuehai He, Suhaila Shakiah, Hangjie Shi, Reza Ghanadan, William Yang Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-14 22:24:58</h6>
<p class='card-text'>Prompt-based learning has been demonstrated as a compelling paradigm
contributing to large language models' tremendous success (LLMs). Inspired by
their success in language tasks, existing research has leveraged LLMs in
embodied instruction following and task planning. In this work, we tackle the
problem of training a robot to understand multimodal prompts, interleaving
vision signals with text descriptions. This type of task poses a major
challenge to robots' capability to understand the interconnection and
complementarity between vision and language signals. In this work, we introduce
an effective framework that learns a policy to perform robot manipulation with
multimodal prompts from multi-task expert trajectories. Our methods consist of
a two-stage training pipeline that performs inverse dynamics pretraining and
multi-task finetuning. To facilitate multimodal understanding, we design our
multimodal prompt encoder by augmenting a pretrained LM with a residual
connection to the visual input and model the dependencies among action
dimensions. Empirically, we evaluate the efficacy of our method on the
VIMA-BENCH and establish a new state-of-the-art (10% improvement in success
rate). Moreover, we demonstrate that our model exhibits remarkable in-context
learning ability. Project page: \url{https://midas-icml.github.io/}.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.09454v1' target='_blank'>LgTS: Dynamic Task Sampling using LLM-generated sub-goals for
  Reinforcement Learning Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yash Shukla, Wenchang Gao, Vasanth Sarathy, Alvaro Velasquez, Robert Wright, Jivko Sinapov</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-14 00:07:03</h6>
<p class='card-text'>Recent advancements in reasoning abilities of Large Language Models (LLM) has
promoted their usage in problems that require high-level planning for robots
and artificial agents. However, current techniques that utilize LLMs for such
planning tasks make certain key assumptions such as, access to datasets that
permit finetuning, meticulously engineered prompts that only provide relevant
and essential information to the LLM, and most importantly, a deterministic
approach to allow execution of the LLM responses either in the form of existing
policies or plan operators. In this work, we propose LgTS (LLM-guided
Teacher-Student learning), a novel approach that explores the planning
abilities of LLMs to provide a graphical representation of the sub-goals to a
reinforcement learning (RL) agent that does not have access to the transition
dynamics of the environment. The RL agent uses Teacher-Student learning
algorithm to learn a set of successful policies for reaching the goal state
from the start state while simultaneously minimizing the number of
environmental interactions. Unlike previous methods that utilize LLMs, our
approach does not assume access to a propreitary or a fine-tuned LLM, nor does
it require pre-trained policies that achieve the sub-goals proposed by the LLM.
Through experiments on a gridworld based DoorKey domain and a search-and-rescue
inspired domain, we show that generating a graphical structure of sub-goals
helps in learning policies for the LLM proposed sub-goals and the
Teacher-Student learning algorithm minimizes the number of environment
interactions when the transition dynamics are unknown.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.08922v1' target='_blank'>LLaMA Rider: Spurring Large Language Models to Explore the Open World</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yicheng Feng, Yuxuan Wang, Jiazheng Liu, Sipeng Zheng, Zongqing Lu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-13 07:47:44</h6>
<p class='card-text'>Recently, various studies have leveraged Large Language Models (LLMs) to help
decision-making and planning in environments, and try to align the LLMs'
knowledge with the world conditions. Nonetheless, the capacity of LLMs to
continuously acquire environmental knowledge and adapt in an open world remains
uncertain. In this paper, we propose an approach to spur LLMs to explore the
open world, gather experiences, and learn to improve their task-solving
capabilities. In this approach, a multi-round feedback-revision mechanism is
utilized to encourage LLMs to actively select appropriate revision actions
guided by feedback information from the environment. This facilitates
exploration and enhances the model's performance. Besides, we integrate
sub-task relabeling to assist LLMs in maintaining consistency in sub-task
planning and help the model learn the combinatorial nature between tasks,
enabling it to complete a wider range of tasks through training based on the
acquired exploration experiences. By evaluation in Minecraft, an open-ended
sandbox world, we demonstrate that our approach LLaMA-Rider enhances the
efficiency of the LLM in exploring the environment, and effectively improves
the LLM's ability to accomplish more tasks through fine-tuning with merely 1.3k
instances of collected data, showing minimal training costs compared to the
baseline using reinforcement learning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.08840v1' target='_blank'>Large Language Models as Source Planner for Personalized
  Knowledge-grounded Dialogue</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hongru Wang, Minda Hu, Yang Deng, Rui Wang, Fei Mi, Weichao Wang, Yasheng Wang, Wai-Chung Kwan, Irwin King, Kam-Fai Wong</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-13 03:38:38</h6>
<p class='card-text'>Open-domain dialogue system usually requires different sources of knowledge
to generate more informative and evidential responses. However, existing
knowledge-grounded dialogue systems either focus on a single knowledge source
or overlook the dependency between multiple sources of knowledge, which may
result in generating inconsistent or even paradoxical responses. To incorporate
multiple knowledge sources and dependencies between them, we propose SAFARI, a
novel framework that leverages the exceptional capabilities of large language
models (LLMs) in planning, understanding, and incorporating under both
supervised and unsupervised settings. Specifically, SAFARI decouples the
knowledge grounding into multiple sources and response generation, which allows
easy extension to various knowledge sources including the possibility of not
using any sources. To study the problem, we construct a personalized
knowledge-grounded dialogue dataset \textit{\textbf{K}nowledge \textbf{B}ehind
\textbf{P}ersona}~(\textbf{KBP}), which is the first to consider the dependency
between persona and implicit knowledge. Experimental results on the KBP dataset
demonstrate that the SAFARI framework can effectively produce
persona-consistent and knowledge-enhanced responses.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.08796v1' target='_blank'>End-to-end Story Plot Generator</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hanlin Zhu, Andrew Cohen, Danqing Wang, Kevin Yang, Xiaomeng Yang, Jiantao Jiao, Yuandong Tian</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-13 00:49:59</h6>
<p class='card-text'>Story plots, while short, carry most of the essential information of a full
story that may contain tens of thousands of words. We study the problem of
automatic generation of story plots, which includes story premise, character
descriptions, plot outlines, etc. To generate a single engaging plot, existing
plot generators (e.g., DOC (Yang et al., 2022a)) require hundreds to thousands
of calls to LLMs (e.g., OpenAI API) in the planning stage of the story plot,
which is costly and takes at least several minutes. Moreover, the hard-wired
nature of the method makes the pipeline non-differentiable, blocking fast
specialization and personalization of the plot generator. In this paper, we
propose three models, $\texttt{OpenPlot}$, $\texttt{E2EPlot}$ and
$\texttt{RLPlot}$, to address these challenges. $\texttt{OpenPlot}$ replaces
expensive OpenAI API calls with LLaMA2 (Touvron et al., 2023) calls via careful
prompt designs, which leads to inexpensive generation of high-quality training
datasets of story plots. We then train an end-to-end story plot generator,
$\texttt{E2EPlot}$, by supervised fine-tuning (SFT) using approximately 13000
story plots generated by $\texttt{OpenPlot}$. $\texttt{E2EPlot}$ generates
story plots of comparable quality to $\texttt{OpenPlot}$, and is > 10$\times$
faster (1k tokens in only 30 seconds on average). Finally, we obtain
$\texttt{RLPlot}$ that is further fine-tuned with RLHF on several different
reward models for different aspects of story quality, which yields 60.0$\%$
winning rate against $\texttt{E2EPlot}$ along the aspect of suspense and
surprise.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.08740v3' target='_blank'>A Zero-Shot Language Agent for Computer Control with Structured
  Reflection</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tao Li, Gang Li, Zhiwei Deng, Bryan Wang, Yang Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-12 21:53:37</h6>
<p class='card-text'>Large language models (LLMs) have shown increasing capacity at planning and
executing a high-level goal in a live computer environment (e.g. MiniWoB++). To
perform a task, recent works often require a model to learn from trace examples
of the task via either supervised learning or few/many-shot prompting. Without
these trace examples, it remains a challenge how an agent can autonomously
learn and improve its control on a computer, which limits the ability of an
agent to perform a new task. We approach this problem with a zero-shot agent
that requires no given expert traces. Our agent plans for executable actions on
a partially observed environment, and iteratively progresses a task by
identifying and learning from its mistakes via self-reflection and structured
thought management. On the easy tasks of MiniWoB++, we show that our zero-shot
agent often outperforms recent SoTAs, with more efficient reasoning. For tasks
with more complexity, our reflective agent performs on par with prior best
models, even though previous works had the advantages of accessing expert
traces or additional screen information.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.08582v2' target='_blank'>Tree-Planner: Efficient Close-loop Task Planning with Large Language
  Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mengkang Hu, Yao Mu, Xinmiao Yu, Mingyu Ding, Shiguang Wu, Wenqi Shao, Qiguang Chen, Bin Wang, Yu Qiao, Ping Luo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-12 17:59:50</h6>
<p class='card-text'>This paper studies close-loop task planning, which refers to the process of
generating a sequence of skills (a plan) to accomplish a specific goal while
adapting the plan based on real-time observations. Recently, prompting Large
Language Models (LLMs) to generate actions iteratively has become a prevalent
paradigm due to its superior performance and user-friendliness. However, this
paradigm is plagued by two inefficiencies: high token consumption and redundant
error correction, both of which hinder its scalability for large-scale testing
and applications. To address these issues, we propose Tree-Planner, which
reframes task planning with LLMs into three distinct phases: plan sampling,
action tree construction, and grounded deciding. Tree-Planner starts by using
an LLM to sample a set of potential plans before execution, followed by the
aggregation of them to form an action tree. Finally, the LLM performs a
top-down decision-making process on the tree, taking into account real-time
environmental information. Experiments show that Tree-Planner achieves
state-of-the-art performance while maintaining high efficiency. By decomposing
LLM queries into a single plan-sampling call and multiple grounded-deciding
calls, a considerable part of the prompt are less likely to be repeatedly
consumed. As a result, token consumption is reduced by 92.2% compared to the
previously best-performing model. Additionally, by enabling backtracking on the
action tree as needed, the correction process becomes more flexible, leading to
a 40.5% decrease in error corrections.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.08535v3' target='_blank'>Formally Specifying the High-Level Behavior of LLM-Based Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Maxwell Crouse, Ibrahim Abdelaziz, Ramon Astudillo, Kinjal Basu, Soham Dan, Sadhana Kumaravel, Achille Fokoue, Pavan Kapanipathi, Salim Roukos, Luis Lastras</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-12 17:24:15</h6>
<p class='card-text'>Autonomous, goal-driven agents powered by LLMs have recently emerged as
promising tools for solving challenging problems without the need for
task-specific finetuned models that can be expensive to procure. Currently, the
design and implementation of such agents is ad hoc, as the wide variety of
tasks that LLM-based agents may be applied to naturally means there can be no
one-size-fits-all approach to agent design. In this work we aim to alleviate
the difficulty of designing and implementing new agents by proposing a
minimalistic generation framework that simplifies the process of building
agents. The framework we introduce allows the user to define desired agent
behaviors in a high-level, declarative specification that is then used to
construct a decoding monitor which guarantees the LLM will produce an output
exhibiting the desired behavior. Our declarative approach, in which the
behavior is described without concern for how it should be implemented or
enforced, enables rapid design, implementation, and experimentation with
different LLM-based agents. We demonstrate how the proposed framework can be
used to implement recent LLM-based agents (e.g., ReACT), and show how the
flexibility of our approach can be leveraged to define a new agent with more
complex behavior, the Plan-Act-Summarize-Solve (PASS) agent. Lastly, we
demonstrate that our method outperforms other agents on multiple popular
reasoning-centric question-answering benchmarks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.08446v2' target='_blank'>Towards Robust Multi-Modal Reasoning via Model Selection</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xiangyan Liu, Rongxue Li, Wei Ji, Tao Lin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-12 16:06:18</h6>
<p class='card-text'>The reasoning capabilities of LLM (Large Language Model) are widely
acknowledged in recent research, inspiring studies on tool learning and
autonomous agents. LLM serves as the "brain" of the agent, orchestrating
multiple tools for collaborative multi-step task solving. Unlike methods
invoking tools like calculators or weather APIs for straightforward tasks,
multi-modal agents excel by integrating diverse AI models for complex
challenges. However, current multi-modal agents neglect the significance of
model selection: they primarily focus on the planning and execution phases, and
will only invoke predefined task-specific models for each subtask, making the
execution fragile. Meanwhile, other traditional model selection methods are
either incompatible with or suboptimal for the multi-modal agent scenarios, due
to ignorance of dependencies among subtasks arising by multi-step reasoning. To
this end, we identify the key challenges therein and propose the $\textit{M}^3$
framework as a plug-in with negligible runtime overhead at test-time. This
framework improves model selection and bolsters the robustness of multi-modal
agents in multi-step reasoning. In the absence of suitable benchmarks, we
create MS-GQA, a new dataset specifically designed to investigate the model
selection challenge in multi-modal agents. Our experiments reveal that our
framework enables dynamic model selection, considering both user inputs and
subtask dependencies, thereby robustifying the overall reasoning process. Our
code and benchmark: https://github.com/LINs-lab/M3.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.08118v1' target='_blank'>Can Large Language Models Really Improve by Self-critiquing Their Own
  Plans?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Karthik Valmeekam, Matthew Marquez, Subbarao Kambhampati</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-12 08:22:37</h6>
<p class='card-text'>There have been widespread claims about Large Language Models (LLMs) being
able to successfully verify or self-critique their candidate solutions in
reasoning problems in an iterative mode. Intrigued by those claims, in this
paper we set out to investigate the verification/self-critiquing abilities of
large language models in the context of planning. We evaluate a planning system
that employs LLMs for both plan generation and verification. We assess the
verifier LLM's performance against ground-truth verification, the impact of
self-critiquing on plan generation, and the influence of varying feedback
levels on system performance. Using GPT-4, a state-of-the-art LLM, for both
generation and verification, our findings reveal that self-critiquing appears
to diminish plan generation performance, especially when compared to systems
with external, sound verifiers and the LLM verifiers in that system produce a
notable number of false positives, compromising the system's reliability.
Additionally, the nature of feedback, whether binary or detailed, showed
minimal impact on plan generation. Collectively, our results cast doubt on the
effectiveness of LLMs in a self-critiquing, iterative framework for planning
tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.08067v1' target='_blank'>GameGPT: Multi-agent Collaborative Framework for Game Development</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Dake Chen, Hanbin Wang, Yunhao Huo, Yuzhao Li, Haoyang Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-12 06:31:43</h6>
<p class='card-text'>The large language model (LLM) based agents have demonstrated their capacity
to automate and expedite software development processes. In this paper, we
focus on game development and propose a multi-agent collaborative framework,
dubbed GameGPT, to automate game development. While many studies have
pinpointed hallucination as a primary roadblock for deploying LLMs in
production, we identify another concern: redundancy. Our framework presents a
series of methods to mitigate both concerns. These methods include dual
collaboration and layered approaches with several in-house lexicons, to
mitigate the hallucination and redundancy in the planning, task identification,
and implementation phases. Furthermore, a decoupling approach is also
introduced to achieve code generation with better precision.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.07263v1' target='_blank'>CoPAL: Corrective Planning of Robot Actions with Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Frank Joublin, Antonello Ceravola, Pavel Smirnov, Felix Ocker, Joerg Deigmoeller, Anna Belardinelli, Chao Wang, Stephan Hasler, Daniel Tanneberg, Michael Gienger</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-11 07:39:42</h6>
<p class='card-text'>In the pursuit of fully autonomous robotic systems capable of taking over
tasks traditionally performed by humans, the complexity of open-world
environments poses a considerable challenge. Addressing this imperative, this
study contributes to the field of Large Language Models (LLMs) applied to task
and motion planning for robots. We propose a system architecture that
orchestrates a seamless interplay between multiple cognitive levels,
encompassing reasoning, planning, and motion generation. At its core lies a
novel replanning strategy that handles physically grounded, logical, and
semantic errors in the generated plans. We demonstrate the efficacy of the
proposed feedback architecture, particularly its impact on executability,
correctness, and time complexity via empirical evaluation in the context of a
simulation and two intricate real-world scenarios: blocks world, barman and
pizza preparation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.07088v2' target='_blank'>Diversity of Thought Improves Reasoning Abilities of LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ranjita Naik, Varun Chandrasekaran, Mert Yuksekgonul, Hamid Palangi, Besmira Nushi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-11 00:01:41</h6>
<p class='card-text'>Large language models (LLMs) are documented to struggle in settings that
require complex reasoning. Nevertheless, instructing the model to break down
the problem into smaller reasoning steps, or ensembling various generations
through modifying decoding steps boosts performance. However, these methods
assume that the input prompt is fixed and expect the decoding strategies to
introduce the diversity needed for ensembling. In this work, we discuss how one
can create and leverage variations of the input prompt as a means of diversity
of thought. We propose a method that automatically improves prompt diversity by
soliciting feedback from the LLM to ideate approaches that are apt for the
problem. We then ensemble the diverse prompts in our method DIVSE (DIVerse
reasoning path Self-Ensemble) across multiple inference calls, or use diverse
approaches within a single inference call; we call the latter IDIV-SE (In-call
DIVerse reasoning path Self-Ensemble). Apart from our approaches outperforming
prior work, DIV-SE(in particular) advances state-of-the-art performance on the
challenging planning and graph coloring benchmarks. Our results improve the
Pareto frontier of the accuracy-cost trade-off.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.06936v1' target='_blank'>LLMs Killed the Script Kiddie: How Agents Supported by Large Language
  Models Change the Landscape of Network Threat Testing</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Stephen Moskal, Sam Laney, Erik Hemberg, Una-May O'Reilly</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-10 18:49:20</h6>
<p class='card-text'>In this paper, we explore the potential of Large Language Models (LLMs) to
reason about threats, generate information about tools, and automate cyber
campaigns. We begin with a manual exploration of LLMs in supporting specific
threat-related actions and decisions. We proceed by automating the decision
process in a cyber campaign. We present prompt engineering approaches for a
plan-act-report loop for one action of a threat campaign and and a prompt
chaining design that directs the sequential decision process of a multi-action
campaign. We assess the extent of LLM's cyber-specific knowledge w.r.t the
short campaign we demonstrate and provide insights into prompt design for
eliciting actionable responses. We discuss the potential impact of LLMs on the
threat landscape and the ethical considerations of using LLMs for accelerating
threat actor capabilities. We report a promising, yet concerning, application
of generative AI to cyber threats. However, the LLM's capabilities to deal with
more complex networks, sophisticated vulnerabilities, and the sensitivity of
prompts are open questions. This research should spur deliberations over the
inevitable advancements in LLM-supported cyber adversarial landscape.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.06226v1' target='_blank'>Words into Action: Learning Diverse Humanoid Robot Behaviors using
  Language Guided Iterative Motion Refinement</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:K. Niranjan Kumar, Irfan Essa, Sehoon Ha</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-10 00:39:37</h6>
<p class='card-text'>Humanoid robots are well suited for human habitats due to their morphological
similarity, but developing controllers for them is a challenging task that
involves multiple sub-problems, such as control, planning and perception. In
this paper, we introduce a method to simplify controller design by enabling
users to train and fine-tune robot control policies using natural language
commands. We first learn a neural network policy that generates behaviors given
a natural language command, such as "walk forward", by combining Large Language
Models (LLMs), motion retargeting, and motion imitation. Based on the
synthesized motion, we iteratively fine-tune by updating the text prompt and
querying LLMs to find the best checkpoint associated with the closest motion in
history. We validate our approach using a simulated Digit humanoid robot and
demonstrate learning of diverse motions, such as walking, hopping, and kicking,
without the burden of complex reward engineering. In addition, we show that our
iterative refinement enables us to learn 3x times faster than a naive
formulation that learns from scratch.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.05853v1' target='_blank'>"Mango Mango, How to Let The Lettuce Dry Without A Spinner?'': Exploring
  User Perceptions of Using An LLM-Based Conversational Assistant Toward
  Cooking Partner</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Szeyi Chan, Jiachen Li, Bingsheng Yao, Amama Mahmood, Chien-Ming Huang, Holly Jimison, Elizabeth D Mynatt, Dakuo Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-09 16:49:59</h6>
<p class='card-text'>The rapid advancement of the Large Language Model (LLM) has created numerous
potentials for integration with conversational assistants (CAs) assisting
people in their daily tasks, particularly due to their extensive flexibility.
However, users' real-world experiences interacting with these assistants remain
unexplored. In this research, we chose cooking, a complex daily task, as a
scenario to investigate people's successful and unsatisfactory experiences
while receiving assistance from an LLM-based CA, Mango Mango. We discovered
that participants value the system's ability to provide extensive information
beyond the recipe, offer customized instructions based on context, and assist
them in dynamically planning the task. However, they expect the system to be
more adaptive to oral conversation and provide more suggestive responses to
keep users actively involved. Recognizing that users began treating our LLM-CA
as a personal assistant or even a partner rather than just a recipe-reading
tool, we propose several design considerations for future development.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.05746v4' target='_blank'>Put Your Money Where Your Mouth Is: Evaluating Strategic Planning and
  Execution of LLM Agents in an Auction Arena</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiangjie Chen, Siyu Yuan, Rong Ye, Bodhisattwa Prasad Majumder, Kyle Richardson</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-09 14:22:09</h6>
<p class='card-text'>Recent advancements in Large Language Models (LLMs) showcase advanced
reasoning, yet NLP evaluations often depend on static benchmarks. Evaluating
this necessitates environments that test strategic reasoning in dynamic,
competitive scenarios requiring long-term planning. We introduce AucArena, a
novel evaluation suite that simulates auctions, a setting chosen for being
highly unpredictable and involving many skills related to resource and risk
management, while also being easy to evaluate. We conduct controlled
experiments using state-of-the-art LLMs to power bidding agents to benchmark
their planning and execution skills. Our research demonstrates that LLMs, such
as GPT-4, possess key skills for auction participation, such as budget
management and goal adherence, which improve with adaptive strategies. This
highlights LLMs' potential in modeling complex social interactions in
competitive contexts. However, variability in LLM performance and occasional
outperformance by simpler methods indicate opportunities for further
advancements in LLM design and the value of our simulation environment for
ongoing testing and refinement.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.05707v4' target='_blank'>Guiding Language Model Reasoning with Planning Tokens</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xinyi Wang, Lucas Caccia, Oleksiy Ostapenko, Xingdi Yuan, William Yang Wang, Alessandro Sordoni</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-09 13:29:37</h6>
<p class='card-text'>Large language models (LLMs) have recently attracted considerable interest
for their ability to perform complex reasoning tasks, such as chain-of-thought
(CoT) reasoning. However, most of the existing approaches to enhance this
ability rely heavily on data-driven methods, while neglecting the structural
aspects of the model's reasoning capacity. To encourage a more structural
generation of CoT steps, we propose a hierarchical generation scheme: we let
the LM generate a planning token at the start of each reasoning step,
intuitively serving as a high-level plan of the current step, and add their
embeddings to the model parameters. Our approach requires a negligible increase
in trainable parameters (0.001%) and can be applied through either full
fine-tuning or a more parameter-efficient scheme. We demonstrate our method's
effectiveness by applying it to three different LLMs, showing notable accuracy
improvements across three math word problem datasets and one multihop QA
dataset with respect to standard fine-tuning baselines.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.05155v2' target='_blank'>Toolink: Linking Toolkit Creation and Using through Chain-of-Solving on
  Open-Source Model</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Cheng Qian, Chenyan Xiong, Zhenghao Liu, Zhiyuan Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-08 13:07:42</h6>
<p class='card-text'>Large Language Models (LLMs) have demonstrated remarkable progress in
utilizing tools, but their closed-source nature and high inference costs pose
limitations on their adaptability, necessitating a valid method that leverages
smaller, open-sourced models. In this paper, we introduce Toolink, a
comprehensive framework that performs task-solving by first creating a toolkit
and then integrating the planning and calling of tools through a
chain-of-solving (CoS) approach. We first validate the efficacy of Toolink in
harnessing the model's creativity and CoS ability on ChatGPT. Subsequently, we
curate CoS-GPT, a chain-of-solving dataset designed for tool-using, and
finetune the LLaMA-7B model. It results in LLaMA-CoS, a powerful open-source
model with advanced tool-planning and tool-calling capabilities. Evaluation of
diverse tasks from BIG-bench demonstrates its CoS ability matches that of
ChatGPT while its performance surpasses the chain-of-thought approach. Further
studies highlight the generalization of LLaMA-CoS to unseen tasks and showcase
its capability in using toolkits not explicitly tailored for the target task,
affirming its robustness in real-world scenarios.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.04981v1' target='_blank'>Compositional Semantics for Open Vocabulary Spatio-semantic
  Representations</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Robin Karlsson, Francisco Lepe-Salazar, Kazuya Takeda</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-08 03:07:14</h6>
<p class='card-text'>General-purpose mobile robots need to complete tasks without exact human
instructions. Large language models (LLMs) is a promising direction for
realizing commonsense world knowledge and reasoning-based planning.
Vision-language models (VLMs) transform environment percepts into
vision-language semantics interpretable by LLMs. However, completing complex
tasks often requires reasoning about information beyond what is currently
perceived. We propose latent compositional semantic embeddings z* as a
principled learning-based knowledge representation for queryable
spatio-semantic memories. We mathematically prove that z* can always be found,
and the optimal z* is the centroid for any set Z. We derive a probabilistic
bound for estimating separability of related and unrelated semantics. We prove
that z* is discoverable by iterative optimization by gradient descent from
visual appearance and singular descriptions. We experimentally verify our
findings on four embedding spaces incl. CLIP and SBERT. Our results show that
z* can represent up to 10 semantics encoded by SBERT, and up to 100 semantics
for ideal uniformly distributed high-dimensional embeddings. We demonstrate
that a simple dense VLM trained on the COCO-Stuff dataset can learn z* for 181
overlapping semantics by 42.23 mIoU, while improving conventional
non-overlapping open-vocabulary segmentation performance by +3.48 mIoU compared
with a popular SOTA model.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.04869v1' target='_blank'>ILuvUI: Instruction-tuned LangUage-Vision modeling of UIs from Machine
  Conversations</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yue Jiang, Eldon Schoop, Amanda Swearngin, Jeffrey Nichols</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-07 16:32:34</h6>
<p class='card-text'>Multimodal Vision-Language Models (VLMs) enable powerful applications from
their fused understanding of images and language, but many perform poorly on UI
tasks due to the lack of UI training data. In this paper, we adapt a recipe for
generating paired text-image training data for VLMs to the UI domain by
combining existing pixel-based methods with a Large Language Model (LLM).
Unlike prior art, our method requires no human-provided annotations, and it can
be applied to any dataset of UI screenshots. We generate a dataset of 335K
conversational examples paired with UIs that cover Q&A, UI descriptions, and
planning, and use it to fine-tune a conversational VLM for UI tasks. To assess
the performance of our model, we benchmark it on UI element detection tasks,
evaluate response quality, and showcase its applicability to multi-step UI
navigation and planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.04474v3' target='_blank'>Reverse Chain: A Generic-Rule for LLMs to Master Multi-API Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yinger Zhang, Hui Cai, Xeirui Song, Yicheng Chen, Rui Sun, Jing Zheng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-06 05:20:18</h6>
<p class='card-text'>While enabling large language models to implement function calling (known as
APIs) can greatly enhance the performance of Large Language Models (LLMs),
function calling is still a challenging task due to the complicated relations
between different APIs, especially in a context-learning setting without
fine-tuning. This paper introduces ``Reverse Chain'', a controllable,
target-driven approach designed to empower LLMs with the capability to operate
external APIs only via prompts. Recognizing that most LLMs have limited
tool-use capabilities, Reverse Chain limits LLMs to executing simple tasks,
e.g., API Selection and Argument Completion. Furthermore, to manage a
controllable multi-function calling, Reverse Chain adopts a generic rule based
on a backward reasoning process. This rule determines when to do API selection
or Argument completion. To evaluate the multi-tool-use capability of LLMs, we
have released a compositional multi-tool task dataset, available at
\url{https://anonymous.4open.science/r/reverse-chain-8681}. Extensive numerical
experiments validate the remarkable proficiency of Reverse Chain in managing
multiple API calls.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.03965v3' target='_blank'>Thought Propagation: An Analogical Approach to Complex Reasoning with
  Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Junchi Yu, Ran He, Rex Ying</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-06 01:40:09</h6>
<p class='card-text'>Large Language Models (LLMs) have achieved remarkable success in reasoning
tasks with the development of prompting methods. However, existing prompting
approaches cannot reuse insights of solving similar problems and suffer from
accumulated errors in multi-step reasoning, since they prompt LLMs to reason
\textit{from scratch}. To address these issues, we propose
\textbf{\textit{Thought Propagation} (TP)}, which explores the analogous
problems and leverages their solutions to enhance the complex reasoning ability
of LLMs. These analogous problems are related to the input one, with reusable
solutions and problem-solving strategies. Thus, it is promising to propagate
insights of solving previous analogous problems to inspire new problem-solving.
To achieve this, TP first prompts LLMs to propose and solve a set of analogous
problems that are related to the input one. Then, TP reuses the results of
analogous problems to directly yield a new solution or derive a
knowledge-intensive plan for execution to amend the initial solution obtained
from scratch. TP is compatible with existing prompting approaches, allowing
plug-and-play generalization and enhancement in a wide range of tasks without
much labor in task-specific prompt engineering. Experiments across three
challenging tasks demonstrate TP enjoys a substantial improvement over the
baselines by an average of 12\% absolute increase in finding the optimal
solutions in Shortest-path Reasoning, 13\% improvement of human preference in
Creative Writing, and 15\% enhancement in the task completion rate of LLM-Agent
Planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.03903v2' target='_blank'>LLM-Coordination: Evaluating and Analyzing Multi-agent Coordination
  Abilities in Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Saaket Agashe, Yue Fan, Anthony Reyna, Xin Eric Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-05 21:18:15</h6>
<p class='card-text'>The emergent reasoning and Theory of Mind (ToM) abilities demonstrated by
Large Language Models (LLMs) make them promising candidates for developing
coordination agents. In this study, we introduce a new LLM-Coordination
Benchmark aimed at a detailed analysis of LLMs within the context of Pure
Coordination Games, where participating agents need to cooperate for the most
gain. This benchmark evaluates LLMs through two distinct tasks: (1)
\emph{Agentic Coordination}, where LLMs act as proactive participants for
cooperation in 4 pure coordination games; (2) \emph{Coordination Question
Answering (QA)}, where LLMs are prompted to answer 198 multiple-choice
questions from the 4 games for evaluation of three key reasoning abilities:
Environment Comprehension, ToM Reasoning, and Joint Planning. Furthermore, to
enable LLMs for multi-agent coordination, we introduce a Cognitive Architecture
for Coordination (CAC) framework that can easily integrate different LLMs as
plug-and-play modules for pure coordination games. Our findings indicate that
LLM agents equipped with GPT-4-turbo achieve comparable performance to
state-of-the-art reinforcement learning methods in games that require
commonsense actions based on the environment. Besides, zero-shot coordination
experiments reveal that, unlike RL methods, LLM agents are robust to new unseen
partners. However, results on Coordination QA show a large room for improvement
in the Theory of Mind reasoning and joint planning abilities of LLMs. The
analysis also sheds light on how the ability of LLMs to understand their
environment and their partner's beliefs and intentions plays a part in their
ability to plan for coordination. Our code is available at
\url{https://github.com/eric-ai-lab/llm_coordination}.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.03249v3' target='_blank'>Can Large Language Models be Good Path Planners? A Benchmark and
  Investigation on Spatial-temporal Reasoning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mohamed Aghzal, Erion Plaku, Ziyu Yao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-05 01:42:16</h6>
<p class='card-text'>Large language models (LLMs) have achieved remarkable success across a wide
spectrum of tasks; however, they still face limitations in scenarios that
demand long-term planning and spatial reasoning. To facilitate this line of
research, in this work, we propose a new benchmark, termed $\textbf{P}$ath
$\textbf{P}$lanning from $\textbf{N}$atural $\textbf{L}$anguage
($\textbf{PPNL}$). Our benchmark evaluates LLMs' spatial-temporal reasoning by
formulating ''path planning'' tasks that require an LLM to navigate to target
locations while avoiding obstacles and adhering to constraints. Leveraging this
benchmark, we systematically investigate LLMs including GPT-4 via different
few-shot prompting methodologies as well as BART and T5 of various sizes via
fine-tuning. Our experimental results show the promise of few-shot GPT-4 in
spatial reasoning, when it is prompted to reason and act interleavedly,
although it still fails to perform long-term temporal reasoning. In contrast,
while fine-tuned LLMs achieved impressive results on in-distribution reasoning
tasks, they struggled to generalize to larger environments or environments with
more obstacles.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.02982v2' target='_blank'>Are LLMs Useful in the Poorest Schools? TheTeacher.AI in Sierra Leone</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jun Ho Choi, Oliver Garrod, Paul Atherton, Andrew Joyce-Gibbons, Miriam Mason-Sesay, Daniel Björkegren</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-04 17:18:47</h6>
<p class='card-text'>Education systems in developing countries have few resources to serve large,
poor populations. How might generative AI integrate into classrooms? This paper
introduces an AI chatbot designed to assist teachers in Sierra Leone with
professional development to improve their instruction. We describe initial
findings from early implementation across 122 schools and 193 teachers, and
analyze its use with qualitative observations and by analyzing queries.
Teachers use the system for lesson planning, classroom management, and subject
matter. Usage is sustained over the school year, and a subset of teachers use
the system more regularly. We draw conclusions from these findings about how
generative AI systems can be integrated into school systems in low income
countries.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.02567v2' target='_blank'>Improving Automatic VQA Evaluation Using Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Oscar Mañas, Benno Krojer, Aishwarya Agrawal</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-04 03:59:57</h6>
<p class='card-text'>8 years after the visual question answering (VQA) task was proposed, accuracy
remains the primary metric for automatic evaluation. VQA Accuracy has been
effective so far in the IID evaluation setting. However, our community is
undergoing a shift towards open-ended generative models and OOD evaluation. In
this new paradigm, the existing VQA Accuracy metric is overly stringent and
underestimates the performance of VQA systems. Thus, there is a need to develop
more robust automatic VQA metrics that serve as a proxy for human judgment. In
this work, we propose to leverage the in-context learning capabilities of
instruction-tuned large language models (LLMs) to build a better VQA metric. We
formulate VQA evaluation as an answer-rating task where the LLM is instructed
to score the accuracy of a candidate answer given a set of reference answers.
We demonstrate the proposed metric better correlates with human judgment
compared to existing metrics across several VQA models and benchmarks. We hope
wide adoption of our metric will contribute to better estimating the research
progress on the VQA task. We plan to release the evaluation code and collected
human judgments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.02374v5' target='_blank'>Conversational Health Agents: A Personalized LLM-Powered Agent Framework</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mahyar Abbasian, Iman Azimi, Amir M. Rahmani, Ramesh Jain</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-03 18:54:10</h6>
<p class='card-text'>Conversational Health Agents (CHAs) are interactive systems that provide
healthcare services, such as assistance and diagnosis. Current CHAs, especially
those utilizing Large Language Models (LLMs), primarily focus on conversation
aspects. However, they offer limited agent capabilities, specifically lacking
multi-step problem-solving, personalized conversations, and multimodal data
analysis. Our aim is to overcome these limitations. We propose openCHA, an
open-source LLM-powered framework, to empower conversational agents to generate
a personalized response for users' healthcare queries. This framework enables
developers to integrate external sources including data sources, knowledge
bases, and analysis models, into their LLM-based solutions. openCHA includes an
orchestrator to plan and execute actions for gathering information from
external sources, essential for formulating responses to user inquiries. It
facilitates knowledge acquisition, problem-solving capabilities, multilingual
and multimodal conversations, and fosters interaction with various AI
platforms. We illustrate the framework's proficiency in handling complex
healthcare tasks via two demonstrations and four use cases. Moreover, we
release openCHA as open source available to the community via GitHub.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.01727v3' target='_blank'>Can GPT-4 Replicate Empirical Software Engineering Research?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jenny T. Liang, Carmen Badea, Christian Bird, Robert DeLine, Denae Ford, Nicole Forsgren, Thomas Zimmermann</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-03 01:27:23</h6>
<p class='card-text'>Empirical software engineering research on production systems has brought
forth a better understanding of the software engineering process for
practitioners and researchers alike. However, only a small subset of production
systems is studied, limiting the impact of this research. While software
engineering practitioners could benefit from replicating research on their own
data, this poses its own set of challenges, since performing replications
requires a deep understanding of research methodologies and subtle nuances in
software engineering data. Given that large language models (LLMs), such as
GPT-4, show promise in tackling both software engineering- and science-related
tasks, these models could help replicate and thus democratize empirical
software engineering research.
  In this paper, we examine GPT-4's abilities to perform replications of
empirical software engineering research on new data. We study their ability to
surface assumptions made in empirical software engineering research
methodologies, as well as their ability to plan and generate code for analysis
pipelines on seven empirical software engineering papers. We perform a user
study with 14 participants with software engineering research expertise, who
evaluate GPT-4-generated assumptions and analysis plans (i.e., a list of module
specifications) from the papers. We find that GPT-4 is able to surface correct
assumptions, but struggles to generate ones that apply common knowledge about
software engineering data. In a manual analysis of the generated code, we find
that the GPT-4-generated code contains correct high-level logic, given a subset
of the methodology. However, the code contains many small implementation-level
errors, reflecting a lack of software engineering knowledge. Our findings have
implications for leveraging LLMs for software engineering research as well as
practitioner data scientists in software teams.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.01557v5' target='_blank'>SmartPlay: A Benchmark for LLMs as Intelligent Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yue Wu, Xuan Tang, Tom M. Mitchell, Yuanzhi Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-02 18:52:11</h6>
<p class='card-text'>Recent large language models (LLMs) have demonstrated great potential toward
intelligent agents and next-gen automation, but there currently lacks a
systematic benchmark for evaluating LLMs' abilities as agents. We introduce
SmartPlay: both a challenging benchmark and a methodology for evaluating LLMs
as agents. SmartPlay consists of 6 different games, including
Rock-Paper-Scissors, Tower of Hanoi, Minecraft. Each game features a unique
setting, providing up to 20 evaluation settings and infinite environment
variations. Each game in SmartPlay uniquely challenges a subset of 9 important
capabilities of an intelligent LLM agent, including reasoning with object
dependencies, planning ahead, spatial reasoning, learning from history, and
understanding randomness. The distinction between the set of capabilities each
game test allows us to analyze each capability separately. SmartPlay serves not
only as a rigorous testing ground for evaluating the overall performance of LLM
agents but also as a road-map for identifying gaps in current methodologies. We
release our benchmark at github.com/Microsoft/SmartPlay</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.01415v3' target='_blank'>GPT-Driver: Learning to Drive with GPT</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiageng Mao, Yuxi Qian, Junjie Ye, Hang Zhao, Yue Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-02 17:59:57</h6>
<p class='card-text'>We present a simple yet effective approach that can transform the OpenAI
GPT-3.5 model into a reliable motion planner for autonomous vehicles. Motion
planning is a core challenge in autonomous driving, aiming to plan a driving
trajectory that is safe and comfortable. Existing motion planners predominantly
leverage heuristic methods to forecast driving trajectories, yet these
approaches demonstrate insufficient generalization capabilities in the face of
novel and unseen driving scenarios. In this paper, we propose a novel approach
to motion planning that capitalizes on the strong reasoning capabilities and
generalization potential inherent to Large Language Models (LLMs). The
fundamental insight of our approach is the reformulation of motion planning as
a language modeling problem, a perspective not previously explored.
Specifically, we represent the planner inputs and outputs as language tokens,
and leverage the LLM to generate driving trajectories through a language
description of coordinate positions. Furthermore, we propose a novel
prompting-reasoning-finetuning strategy to stimulate the numerical reasoning
potential of the LLM. With this strategy, the LLM can describe highly precise
trajectory coordinates and also its internal decision-making process in natural
language. We evaluate our approach on the large-scale nuScenes dataset, and
extensive experiments substantiate the effectiveness, generalization ability,
and interpretability of our GPT-based motion planner. Code is now available at
https://github.com/PointsCoder/GPT-Driver.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.01468v3' target='_blank'>Probing the Multi-turn Planning Capabilities of LLMs via 20 Question
  Games</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yizhe Zhang, Jiarui Lu, Navdeep Jaitly</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-02 16:55:37</h6>
<p class='card-text'>Large language models (LLMs) are effective at answering questions that are
clearly asked. However, when faced with ambiguous queries they can act
unpredictably and produce incorrect outputs. This underscores the need for the
development of intelligent agents capable of asking clarification questions to
resolve ambiguities effectively. This capability requires complex
understanding, state tracking, reasoning and planning over multiple
conversational turns. However, directly measuring this can be challenging. In
this paper, we offer a surrogate problem which assesses an LLMs's capability to
deduce an entity unknown to itself, but revealed to a judge, by asking the
judge a series of queries. This \textit{entity-deducing game} can serve as an
evaluation framework to probe the conversational reasoning and planning
capabilities of language models. We systematically evaluate various LLMs and
discover significant differences in their performance on this task. We find
that strong LLMs like GPT-4 outperform human players by a large margin. We
further employ Behavior Cloning (BC) to examine whether a weaker model is
capable of imitating a stronger model and generalizing to data or domains,
using only the demonstrations from a stronger model. We finally propose to use
Reinforcement Learning to enhance reasoning and planning capacity of Vicuna
models through episodes of game playing, which lead to significant performance
improvement. We hope that this problem offers insights into how autonomous
agents could be trained to behave more intelligently in ambiguous
circumstances.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.01061v2' target='_blank'>Reasoning on Graphs: Faithful and Interpretable Large Language Model
  Reasoning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Linhao Luo, Yuan-Fang Li, Gholamreza Haffari, Shirui Pan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-10-02 10:14:43</h6>
<p class='card-text'>Large language models (LLMs) have demonstrated impressive reasoning abilities
in complex tasks. However, they lack up-to-date knowledge and experience
hallucinations during reasoning, which can lead to incorrect reasoning
processes and diminish their performance and trustworthiness. Knowledge graphs
(KGs), which capture vast amounts of facts in a structured format, offer a
reliable source of knowledge for reasoning. Nevertheless, existing KG-based LLM
reasoning methods only treat KGs as factual knowledge bases and overlook the
importance of their structural information for reasoning. In this paper, we
propose a novel method called reasoning on graphs (RoG) that synergizes LLMs
with KGs to enable faithful and interpretable reasoning. Specifically, we
present a planning-retrieval-reasoning framework, where RoG first generates
relation paths grounded by KGs as faithful plans. These plans are then used to
retrieve valid reasoning paths from the KGs for LLMs to conduct faithful
reasoning. Furthermore, RoG not only distills knowledge from KGs to improve the
reasoning ability of LLMs through training but also allows seamless integration
with any arbitrary LLMs during inference. Extensive experiments on two
benchmark KGQA datasets demonstrate that RoG achieves state-of-the-art
performance on KG reasoning tasks and generates faithful and interpretable
reasoning results.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.01441v2' target='_blank'>UPAR: A Kantian-Inspired Prompting Framework for Enhancing Large
  Language Model Capabilities</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hejia Geng, Boxun Xu, Peng Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-30 20:18:50</h6>
<p class='card-text'>Large Language Models (LLMs) have demonstrated impressive inferential
capabilities, with numerous research endeavors devoted to enhancing this
capacity through prompting. Despite these efforts, a unified epistemological
foundation is still conspicuously absent. Drawing inspiration from Kant's a
priori philosophy, we propose the UPAR prompting framework, designed to emulate
the structure of human cognition within LLMs. The UPAR framework is delineated
into four phases: "Understand", "Plan", "Act", and "Reflect", enabling the
extraction of structured information from complex contexts, prior planning of
solutions, execution according to plan, and self-reflection. This structure
significantly augments the explainability and accuracy of LLM inference,
producing a human-understandable and inspectable inferential trajectory.
Furthermore, our work offers an epistemological foundation for existing
prompting techniques, allowing for a possible systematic integration of these
methods. With GPT-4, our approach elevates the accuracy from COT baseline of
22.92% to 58.33% in a challenging subset of GSM8K, and from 67.91% to 75.40% in
the causal judgment task. Without using few-shot examples or external tools,
UPAR significantly outperforms existing prompting methods on SCIBENCH, a
challenging dataset containing collegiate-level mathematics, chemistry, and
physics scientific problems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.00194v4' target='_blank'>Improving Planning with Large Language Models: A Modular Agentic
  Architecture</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Taylor Webb, Shanka Subhra Mondal, Ida Momennejad</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-30 00:10:14</h6>
<p class='card-text'>Large language models (LLMs) demonstrate impressive performance on a wide
variety of tasks, but they often struggle with tasks that require multi-step
reasoning or goal-directed planning. Both cognitive neuroscience and
reinforcement learning (RL) have proposed a number of interacting functional
components that together implement search and evaluation in multi-step decision
making. These components include conflict monitoring, state prediction, state
evaluation, task decomposition, and orchestration. To improve planning with
LLMs, we propose an agentic architecture, the Modular Agentic Planner (MAP), in
which planning is accomplished via the recurrent interaction of the specialized
modules mentioned above, each implemented using an LLM. MAP improves planning
through the interaction of specialized modules that break down a larger problem
into multiple brief automated calls to the LLM. We evaluate MAP on three
challenging planning tasks -- graph traversal, Tower of Hanoi, and the
PlanBench benchmark -- as well as an NLP task requiring multi-step reasoning
(strategyQA). We find that MAP yields significant improvements over both
standard LLM methods (zero-shot prompting, in-context learning) and competitive
baselines (chain-of-thought, multi-agent debate, and tree-of-thought), can be
effectively combined with smaller and more cost-efficient LLMs (Llama3-70B),
and displays superior transfer across tasks. These results suggest the benefit
of a modular and multi-agent approach to planning with LLMs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2310.00163v2' target='_blank'>Cook2LTL: Translating Cooking Recipes to LTL Formulae using Large
  Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Angelos Mavrogiannis, Christoforos Mavrogiannis, Yiannis Aloimonos</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-29 21:59:13</h6>
<p class='card-text'>Cooking recipes are challenging to translate to robot plans as they feature
rich linguistic complexity, temporally-extended interconnected tasks, and an
almost infinite space of possible actions. Our key insight is that combining a
source of cooking domain knowledge with a formalism that captures the temporal
richness of cooking recipes could enable the extraction of unambiguous,
robot-executable plans. In this work, we use Linear Temporal Logic (LTL) as a
formal language expressive enough to model the temporal nature of cooking
recipes. Leveraging a pretrained Large Language Model (LLM), we present
Cook2LTL, a system that translates instruction steps from an arbitrary cooking
recipe found on the internet to a set of LTL formulae, grounding high-level
cooking actions to a set of primitive actions that are executable by a
manipulator in a kitchen environment. Cook2LTL makes use of a caching scheme
that dynamically builds a queryable action library at runtime. We instantiate
Cook2LTL in a realistic simulation environment (AI2-THOR), and evaluate its
performance across a series of cooking recipes. We demonstrate that our system
significantly decreases LLM API calls (-51%), latency (-59%), and cost (-42%)
compared to a baseline that queries the LLM for every newly encountered action
at runtime.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.17382v3' target='_blank'>Reason for Future, Act for Now: A Principled Framework for Autonomous
  LLM Agents with Provable Sample Efficiency</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhihan Liu, Hao Hu, Shenao Zhang, Hongyi Guo, Shuqi Ke, Boyi Liu, Zhaoran Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-29 16:36:39</h6>
<p class='card-text'>Large language models (LLMs) demonstrate impressive reasoning abilities, but
translating reasoning into actions in the real world remains challenging. In
particular, it remains unclear how to complete a given task provably within a
minimum number of interactions with the external environment, e.g., through an
internal mechanism of reasoning. To this end, we propose a principled framework
with provable regret guarantees to orchestrate reasoning and acting, which we
call "reason for future, act for now" (\texttt{RAFA}). Specifically, we design
a prompt template for reasoning that learns from the memory buffer and plans a
future trajectory over a long horizon ("reason for future"). At each step, the
LLM agent takes the initial action of the planned trajectory ("act for now"),
stores the collected feedback in the memory buffer, and reinvokes the reasoning
routine to replan the future trajectory from the new state.
  The key idea is to cast reasoning in LLMs as learning and planning in
Bayesian adaptive Markov decision processes (MDPs). Correspondingly, we prompt
LLMs to form an updated posterior of the unknown environment from the memory
buffer (learning) and generate an optimal trajectory for multiple future steps
that maximizes a value function (planning). The learning and planning
subroutines are performed in an "in-context" manner to emulate the actor-critic
update for MDPs. Our theoretical analysis proves that the novel combination of
long-term reasoning and short-term acting achieves a $\sqrt{T}$ regret. Here,
$T$ denotes the number of online interactions. In particular, the regret bound
highlights an intriguing interplay between the prior knowledge obtained through
pretraining and the uncertainty reduction achieved by reasoning and acting. Our
empirical validation shows that it outperforms various existing frameworks and
achieves nearly perfect scores on a few benchmarks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.17288v3' target='_blank'>AutoAgents: A Framework for Automatic Agent Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Guangyao Chen, Siwei Dong, Yu Shu, Ge Zhang, Jaward Sesay, Börje F. Karlsson, Jie Fu, Yemin Shi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-29 14:46:30</h6>
<p class='card-text'>Large language models (LLMs) have enabled remarkable advances in automated
task-solving with multi-agent systems. However, most existing LLM-based
multi-agent approaches rely on predefined agents to handle simple tasks,
limiting the adaptability of multi-agent collaboration to different scenarios.
Therefore, we introduce AutoAgents, an innovative framework that adaptively
generates and coordinates multiple specialized agents to build an AI team
according to different tasks. Specifically, AutoAgents couples the relationship
between tasks and roles by dynamically generating multiple required agents
based on task content and planning solutions for the current task based on the
generated expert agents. Multiple specialized agents collaborate with each
other to efficiently accomplish tasks. Concurrently, an observer role is
incorporated into the framework to reflect on the designated plans and agents'
responses and improve upon them. Our experiments on various benchmarks
demonstrate that AutoAgents generates more coherent and accurate solutions than
the existing multi-agent methods. This underscores the significance of
assigning different roles to different tasks and of team cooperation, offering
new perspectives for tackling complex tasks. The repository of this project is
available at https://github.com/Link-AGI/AutoAgents.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.17277v3' target='_blank'>Suspicion-Agent: Playing Imperfect Information Games with Theory of Mind
  Aware GPT-4</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiaxian Guo, Bo Yang, Paul Yoo, Bill Yuchen Lin, Yusuke Iwasawa, Yutaka Matsuo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-29 14:30:03</h6>
<p class='card-text'>Unlike perfect information games, where all elements are known to every
player, imperfect information games emulate the real-world complexities of
decision-making under uncertain or incomplete information. GPT-4, the recent
breakthrough in large language models (LLMs) trained on massive passive data,
is notable for its knowledge retrieval and reasoning abilities. This paper
delves into the applicability of GPT-4's learned knowledge for imperfect
information games. To achieve this, we introduce \textbf{Suspicion-Agent}, an
innovative agent that leverages GPT-4's capabilities for performing in
imperfect information games. With proper prompt engineering to achieve
different functions, Suspicion-Agent based on GPT-4 demonstrates remarkable
adaptability across a range of imperfect information card games. Importantly,
GPT-4 displays a strong high-order theory of mind (ToM) capacity, meaning it
can understand others and intentionally impact others' behavior. Leveraging
this, we design a planning strategy that enables GPT-4 to competently play
against different opponents, adapting its gameplay style as needed, while
requiring only the game rules and descriptions of observations as input. In the
experiments, we qualitatively showcase the capabilities of Suspicion-Agent
across three different imperfect information games and then quantitatively
evaluate it in Leduc Hold'em. The results show that Suspicion-Agent can
potentially outperform traditional algorithms designed for imperfect
information games, without any specialized training or examples. In order to
encourage and foster deeper insights within the community, we make our
game-related data publicly available.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.17234v2' target='_blank'>Cooperation, Competition, and Maliciousness: LLM-Stakeholders
  Interactive Negotiation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sahar Abdelnabi, Amr Gomaa, Sarath Sivaprasad, Lea Schönherr, Mario Fritz</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-29 13:33:06</h6>
<p class='card-text'>There is an growing interest in using Large Language Models (LLMs) in
multi-agent systems to tackle interactive real-world tasks that require
effective collaboration and assessing complex situations. Yet, we still have a
limited understanding of LLMs' communication and decision-making abilities in
multi-agent setups. The fundamental task of negotiation spans many key features
of communication, such as cooperation, competition, and manipulation
potentials. Thus, we propose using scorable negotiation to evaluate LLMs. We
create a testbed of complex multi-agent, multi-issue, and semantically rich
negotiation games. To reach an agreement, agents must have strong arithmetic,
inference, exploration, and planning capabilities while integrating them in a
dynamic and multi-turn setup. We propose multiple metrics to rigorously
quantify agents' performance and alignment with the assigned role. We provide
procedures to create new games and increase games' difficulty to have an
evolving benchmark. Importantly, we evaluate critical safety aspects such as
the interaction dynamics between agents influenced by greedy and adversarial
players. Our benchmark is highly challenging; GPT-3.5 and small models mostly
fail, and GPT-4 and SoTA large models (e.g., Llama-3 70b) still underperform.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.17179v2' target='_blank'>Alphazero-like Tree-Search can Guide Large Language Model Decoding and
  Training</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xidong Feng, Ziyu Wan, Muning Wen, Stephen Marcus McAleer, Ying Wen, Weinan Zhang, Jun Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-29 12:20:19</h6>
<p class='card-text'>Recent works like Tree-of-Thought (ToT) and Reasoning via Planning (RAP) aim
to augment the reasoning capabilities of LLMs by using tree-search algorithms
to guide multi-step reasoning. These methods rely on prompting a pre-trained
model to serve as a value function and focus on problems with low search depth.
As a result, these methods will not work in domains where the pre-trained LLM
does not have enough knowledge to serve as an effective value function or in
domains that require long-horizon planning. To address these limitations, we
present an AlphaZero-like tree-search learning framework for LLMs (termed
TS-LLM), systematically illustrating how tree-search with a learned value
function can guide LLM decoding. TS-LLM distinguishes itself in two key ways.
(1) Leveraging a learned value function and AlphaZero-like algorithms, our
approach can be generally adaptable to a wide range of tasks, language models
of any size, and tasks of varying search depths. (2) Our approach can guide
LLMs during both inference and training, iteratively improving the LLM.
Empirical results across reasoning, planning, alignment, and decision-making
tasks show that TS-LLM outperforms existing approaches and can handle trees
with a depth of 64.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.16797v1' target='_blank'>Promptbreeder: Self-Referential Self-Improvement Via Prompt Evolution</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chrisantha Fernando, Dylan Banarse, Henryk Michalewski, Simon Osindero, Tim Rocktäschel</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-28 19:01:07</h6>
<p class='card-text'>Popular prompt strategies like Chain-of-Thought Prompting can dramatically
improve the reasoning abilities of Large Language Models (LLMs) in various
domains. However, such hand-crafted prompt-strategies are often sub-optimal. In
this paper, we present Promptbreeder, a general-purpose self-referential
self-improvement mechanism that evolves and adapts prompts for a given domain.
Driven by an LLM, Promptbreeder mutates a population of task-prompts, and
subsequently evaluates them for fitness on a training set. Crucially, the
mutation of these task-prompts is governed by mutation-prompts that the LLM
generates and improves throughout evolution in a self-referential way. That is,
Promptbreeder is not just improving task-prompts, but it is also improving the
mutationprompts that improve these task-prompts. Promptbreeder outperforms
state-of-the-art prompt strategies such as Chain-of-Thought and Plan-and-Solve
Prompting on commonly used arithmetic and commonsense reasoning benchmarks.
Furthermore, Promptbreeder is able to evolve intricate task-prompts for the
challenging problem of hate speech classification.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.16609v1' target='_blank'>Qwen Technical Report</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei Huang, Binyuan Hui, Luo Ji, Mei Li, Junyang Lin, Runji Lin, Dayiheng Liu, Gao Liu, Chengqiang Lu, Keming Lu, Jianxin Ma, Rui Men, Xingzhang Ren, Xuancheng Ren, Chuanqi Tan, Sinan Tan, Jianhong Tu, Peng Wang, Shijie Wang, Wei Wang, Shengguang Wu, Benfeng Xu, Jin Xu, An Yang, Hao Yang, Jian Yang, Shusheng Yang, Yang Yao, Bowen Yu, Hongyi Yuan, Zheng Yuan, Jianwei Zhang, Xingxuan Zhang, Yichang Zhang, Zhenru Zhang, Chang Zhou, Jingren Zhou, Xiaohuan Zhou, Tianhang Zhu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-28 17:07:49</h6>
<p class='card-text'>Large language models (LLMs) have revolutionized the field of artificial
intelligence, enabling natural language processing tasks that were previously
thought to be exclusive to humans. In this work, we introduce Qwen, the first
installment of our large language model series. Qwen is a comprehensive
language model series that encompasses distinct models with varying parameter
counts. It includes Qwen, the base pretrained language models, and Qwen-Chat,
the chat models finetuned with human alignment techniques. The base language
models consistently demonstrate superior performance across a multitude of
downstream tasks, and the chat models, particularly those trained using
Reinforcement Learning from Human Feedback (RLHF), are highly competitive. The
chat models possess advanced tool-use and planning capabilities for creating
agent applications, showcasing impressive performance even when compared to
bigger models on complex tasks like utilizing a code interpreter. Furthermore,
we have developed coding-specialized models, Code-Qwen and Code-Qwen-Chat, as
well as mathematics-focused models, Math-Qwen-Chat, which are built upon base
language models. These models demonstrate significantly improved performance in
comparison with open-source models, and slightly fall behind the proprietary
models.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.16436v1' target='_blank'>Neuro Symbolic Reasoning for Planning: Counterexample Guided Inductive
  Synthesis using Large Language Models and Satisfiability Solving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sumit Kumar Jha, Susmit Jha, Patrick Lincoln, Nathaniel D. Bastian, Alvaro Velasquez, Rickard Ewetz, Sandeep Neema</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-28 13:40:50</h6>
<p class='card-text'>Generative large language models (LLMs) with instruct training such as GPT-4
can follow human-provided instruction prompts and generate human-like responses
to these prompts. Apart from natural language responses, they have also been
found to be effective at generating formal artifacts such as code, plans, and
logical specifications from natural language prompts. Despite their remarkably
improved accuracy, these models are still known to produce factually incorrect
or contextually inappropriate results despite their syntactic coherence - a
phenomenon often referred to as hallucination. This limitation makes it
difficult to use these models to synthesize formal artifacts that are used in
safety-critical applications. Unlike tasks such as text summarization and
question-answering, bugs in code, plan, and other formal artifacts produced by
LLMs can be catastrophic. We posit that we can use the satisfiability modulo
theory (SMT) solvers as deductive reasoning engines to analyze the generated
solutions from the LLMs, produce counterexamples when the solutions are
incorrect, and provide that feedback to the LLMs exploiting the dialog
capability of instruct-trained LLMs. This interaction between inductive LLMs
and deductive SMT solvers can iteratively steer the LLM to generate the correct
response. In our experiments, we use planning over the domain of blocks as our
synthesis task for evaluating our approach. We use GPT-4, GPT3.5 Turbo,
Davinci, Curie, Babbage, and Ada as the LLMs and Z3 as the SMT solver. Our
method allows the user to communicate the planning problem in natural language;
even the formulation of queries to SMT solvers is automatically generated from
natural language. Thus, the proposed technique can enable non-expert users to
describe their problems in natural language, and the combination of LLMs and
SMT solvers can produce provably correct solutions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.16090v1' target='_blank'>TPE: Towards Better Compositional Reasoning over Conceptual Tools with
  Multi-persona Collaboration</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hongru Wang, Huimin Wang, Lingzhi Wang, Minda Hu, Rui Wang, Boyang Xue, Hongyuan Lu, Fei Mi, Kam-Fai Wong</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-28 01:18:53</h6>
<p class='card-text'>Large language models (LLMs) have demonstrated exceptional performance in
planning the use of various functional tools, such as calculators and
retrievers, particularly in question-answering tasks. In this paper, we expand
the definition of these tools, centering on conceptual tools within the context
of dialogue systems. A conceptual tool specifies a cognitive concept that aids
systematic or investigative thought. These conceptual tools play important
roles in practice, such as multiple psychological or tutoring strategies being
dynamically applied in a single turn to compose helpful responses. To further
enhance the reasoning and planning capability of LLMs with these conceptual
tools, we introduce a multi-persona collaboration framework: Think-Plan-Execute
(TPE). This framework decouples the response generation process into three
distinct roles: Thinker, Planner, and Executor. Specifically, the Thinker
analyzes the internal status exhibited in the dialogue context, such as user
emotions and preferences, to formulate a global guideline. The Planner then
generates executable plans to call different conceptual tools (e.g., sources or
strategies), while the Executor compiles all intermediate results into a
coherent response. This structured approach not only enhances the
explainability and controllability of responses but also reduces token
redundancy. We demonstrate the effectiveness of TPE across various dialogue
response generation tasks, including multi-source (FoCus) and multi-strategy
interactions (CIMA and PsyQA). This reveals its potential to handle real-world
dialogue interactions that require more complicated tool learning beyond just
functional tools. The full code and data will be released for reproduction.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.16052v1' target='_blank'>OceanChat: Piloting Autonomous Underwater Vehicles in Natural Language</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ruochu Yang, Mengxue Hou, Junkai Wang, Fumin Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-27 22:16:56</h6>
<p class='card-text'>In the trending research of fusing Large Language Models (LLMs) and robotics,
we aim to pave the way for innovative development of AI systems that can enable
Autonomous Underwater Vehicles (AUVs) to seamlessly interact with humans in an
intuitive manner. We propose OceanChat, a system that leverages a closed-loop
LLM-guided task and motion planning framework to tackle AUV missions in the
wild. LLMs translate an abstract human command into a high-level goal, while a
task planner further grounds the goal into a task sequence with logical
constraints. To assist the AUV with understanding the task sequence, we utilize
a motion planner to incorporate real-time Lagrangian data streams received by
the AUV, thus mapping the task sequence into an executable motion plan.
Considering the highly dynamic and partially known nature of the underwater
environment, an event-triggered replanning scheme is developed to enhance the
system's robustness towards uncertainty. We also build a simulation platform
HoloEco that generates photo-realistic simulation for a wide range of AUV
applications. Experimental evaluation verifies that the proposed system can
achieve improved performance in terms of both success rate and computation
time. Project website: \url{https://sites.google.com/view/oceanchat}</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.16031v1' target='_blank'>DynaCon: Dynamic Robot Planner with Contextual Awareness via LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Gyeongmin Kim, Taehyeon Kim, Shyam Sundar Kannan, Vishnunandan L. N. Venkatesh, Donghan Kim, Byung-Cheol Min</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-27 21:21:40</h6>
<p class='card-text'>Mobile robots often rely on pre-existing maps for effective path planning and
navigation. However, when these maps are unavailable, particularly in
unfamiliar environments, a different approach become essential. This paper
introduces DynaCon, a novel system designed to provide mobile robots with
contextual awareness and dynamic adaptability during navigation, eliminating
the reliance of traditional maps. DynaCon integrates real-time feedback with an
object server, prompt engineering, and navigation modules. By harnessing the
capabilities of Large Language Models (LLMs), DynaCon not only understands
patterns within given numeric series but also excels at categorizing objects
into matched spaces. This facilitates dynamic path planner imbued with
contextual awareness. We validated the effectiveness of DynaCon through an
experiment where a robot successfully navigated to its goal using reasoning.
Source code and experiment videos for this work can be found at:
https://sites.google.com/view/dynacon.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.15943v2' target='_blank'>Scalable Multi-Robot Collaboration with Large Language Models:
  Centralized or Decentralized Systems?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yongchao Chen, Jacob Arkin, Yang Zhang, Nicholas Roy, Chuchu Fan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-27 18:40:36</h6>
<p class='card-text'>A flurry of recent work has demonstrated that pre-trained large language
models (LLMs) can be effective task planners for a variety of single-robot
tasks. The planning performance of LLMs is significantly improved via prompting
techniques, such as in-context learning or re-prompting with state feedback,
placing new importance on the token budget for the context window. An
under-explored but natural next direction is to investigate LLMs as multi-robot
task planners. However, long-horizon, heterogeneous multi-robot planning
introduces new challenges of coordination while also pushing up against the
limits of context window length. It is therefore critical to find
token-efficient LLM planning frameworks that are also able to reason about the
complexities of multi-robot coordination. In this work, we compare the task
success rate and token efficiency of four multi-agent communication frameworks
(centralized, decentralized, and two hybrid) as applied to four
coordination-dependent multi-agent 2D task scenarios for increasing numbers of
agents. We find that a hybrid framework achieves better task success rates
across all four tasks and scales better to more agents. We further demonstrate
the hybrid frameworks in 3D simulations where the vision-to-text problem and
dynamical errors are considered. See our project website
https://yongchao98.github.io/MIT-REALM-Multi-Robot/ for prompts, videos, and
code.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.15091v2' target='_blank'>VideoDirectorGPT: Consistent Multi-scene Video Generation via LLM-Guided
  Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Han Lin, Abhay Zala, Jaemin Cho, Mohit Bansal</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-26 17:36:26</h6>
<p class='card-text'>Recent text-to-video (T2V) generation methods have seen significant
advancements. However, the majority of these works focus on producing short
video clips of a single event (i.e., single-scene videos). Meanwhile, recent
large language models (LLMs) have demonstrated their capability in generating
layouts and programs to control downstream visual modules. This prompts an
important question: can we leverage the knowledge embedded in these LLMs for
temporally consistent long video generation? In this paper, we propose
VideoDirectorGPT, a novel framework for consistent multi-scene video generation
that uses the knowledge of LLMs for video content planning and grounded video
generation. Specifically, given a single text prompt, we first ask our video
planner LLM (GPT-4) to expand it into a 'video plan', which includes the scene
descriptions, the entities with their respective layouts, the background for
each scene, and consistency groupings of the entities. Next, guided by this
video plan, our video generator, named Layout2Vid, has explicit control over
spatial layouts and can maintain temporal consistency of entities across
multiple scenes, while being trained only with image-level annotations. Our
experiments demonstrate that our proposed VideoDirectorGPT framework
substantially improves layout and movement control in both single- and
multi-scene video generation and can generate multi-scene videos with
consistency, while achieving competitive performance with SOTAs in open-domain
single-scene T2V generation. Detailed ablation studies, including dynamic
adjustment of layout control strength with an LLM and video generation with
user-provided images, confirm the effectiveness of each component of our
framework and its future potential.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.15065v2' target='_blank'>Language-EXtended Indoor SLAM (LEXIS): A Versatile System for Real-time
  Visual Scene Understanding</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Christina Kassab, Matias Mattamala, Lintong Zhang, Maurice Fallon</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-26 16:50:20</h6>
<p class='card-text'>Versatile and adaptive semantic understanding would enable autonomous systems
to comprehend and interact with their surroundings. Existing fixed-class models
limit the adaptability of indoor mobile and assistive autonomous systems. In
this work, we introduce LEXIS, a real-time indoor Simultaneous Localization and
Mapping (SLAM) system that harnesses the open-vocabulary nature of Large
Language Models (LLMs) to create a unified approach to scene understanding and
place recognition. The approach first builds a topological SLAM graph of the
environment (using visual-inertial odometry) and embeds Contrastive
Language-Image Pretraining (CLIP) features in the graph nodes. We use this
representation for flexible room classification and segmentation, serving as a
basis for room-centric place recognition. This allows loop closure searches to
be directed towards semantically relevant places. Our proposed system is
evaluated using both public, simulated data and real-world data, covering
office and home environments. It successfully categorizes rooms with varying
layouts and dimensions and outperforms the state-of-the-art (SOTA). For place
recognition and trajectory estimation tasks we achieve equivalent performance
to the SOTA, all also utilizing the same pre-trained model. Lastly, we
demonstrate the system's potential for planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.14945v2' target='_blank'>Integration of Large Language Models within Cognitive Architectures for
  Autonomous Robots</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Miguel Á. González-Santamarta, Francisco J. Rodríguez-Lera, Ángel Manuel Guerrero-Higueras, Vicente Matellán-Olivera</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-26 14:00:25</h6>
<p class='card-text'>Symbolic reasoning systems have been used in cognitive architectures to
provide inference and planning capabilities. However, defining domains and
problems has proven difficult and prone to errors. Moreover, Large Language
Models (LLMs) have emerged as tools to process natural language for different
tasks. In this paper, we propose the use of LLMs to tackle these problems. This
way, this paper proposes the integration of LLMs in the ROS 2-integrated
cognitive architecture MERLIN2 for autonomous robots. Specifically, we present
the design, development and deployment of how to leverage the reasoning
capabilities of LLMs inside the deliberative processes of MERLIN2. As a result,
the deliberative system is updated from a PDDL-based planner system to a
natural language planning system. This proposal is evaluated quantitatively and
qualitatively, measuring the impact of incorporating the LLMs in the cognitive
architecture. Results show that a classical approach achieves better
performance but the proposed solution provides an enhanced interaction through
natural language.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.13879v2' target='_blank'>User Interaction Patterns and Breakdowns in Conversing with LLM-Powered
  Voice Assistants</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Amama Mahmood, Junxiang Wang, Bingsheng Yao, Dakuo Wang, Chien-Ming Huang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-25 05:10:50</h6>
<p class='card-text'>Conventional Voice Assistants (VAs) rely on traditional language models to
discern user intent and respond to their queries, leading to interactions that
often lack a broader contextual understanding, an area in which Large Language
Models (LLMs) excel. However, current LLMs are largely designed for text-based
interactions, thus making it unclear how user interactions will evolve if their
modality is changed to voice. In this work, we investigate whether LLMs can
enrich VA interactions via an exploratory study with participants (N=20) using
a ChatGPT-powered VA for three scenarios (medical self-diagnosis, creative
planning, and discussion) with varied constraints, stakes, and objectivity. We
observe that LLM-powered VA elicits richer interaction patterns that vary
across tasks, showing its versatility. Notably, LLMs absorb the majority of VA
intent recognition failures. We additionally discuss the potential of
harnessing LLMs for more resilient and fluid user-VA interactions and provide
design guidelines for tailoring LLMs for voice assistance.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.15129v1' target='_blank'>Evaluating Cognitive Maps and Planning in Large Language Models with
  CogEval</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ida Momennejad, Hosein Hasanbeig, Felipe Vieira, Hiteshi Sharma, Robert Osazuwa Ness, Nebojsa Jojic, Hamid Palangi, Jonathan Larson</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-25 01:20:13</h6>
<p class='card-text'>Recently an influx of studies claim emergent cognitive abilities in large
language models (LLMs). Yet, most rely on anecdotes, overlook contamination of
training sets, or lack systematic Evaluation involving multiple tasks, control
conditions, multiple iterations, and statistical robustness tests. Here we make
two major contributions. First, we propose CogEval, a cognitive
science-inspired protocol for the systematic evaluation of cognitive capacities
in Large Language Models. The CogEval protocol can be followed for the
evaluation of various abilities. Second, here we follow CogEval to
systematically evaluate cognitive maps and planning ability across eight LLMs
(OpenAI GPT-4, GPT-3.5-turbo-175B, davinci-003-175B, Google Bard,
Cohere-xlarge-52.4B, Anthropic Claude-1-52B, LLaMA-13B, and Alpaca-7B). We base
our task prompts on human experiments, which offer both established construct
validity for evaluating planning, and are absent from LLM training sets. We
find that, while LLMs show apparent competence in a few planning tasks with
simpler structures, systematic evaluation reveals striking failure modes in
planning tasks, including hallucinations of invalid trajectories and getting
trapped in loops. These findings do not support the idea of emergent
out-of-the-box planning ability in LLMs. This could be because LLMs do not
understand the latent relational structures underlying planning problems, known
as cognitive maps, and fail at unrolling goal-directed trajectories based on
the underlying structure. Implications for application and future directions
are discussed.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.15074v2' target='_blank'>Natural Language based Context Modeling and Reasoning for Ubiquitous
  Computing with Large Language Models: A Tutorial</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Haoyi Xiong, Jiang Bian, Sijia Yang, Xiaofei Zhang, Linghe Kong, Daqing Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-24 00:15:39</h6>
<p class='card-text'>Large language models (LLMs) have become phenomenally surging, since
2018--two decades after introducing context-awareness into computing systems.
Through taking into account the situations of ubiquitous devices, users and the
societies, context-aware computing has enabled a wide spectrum of innovative
applications, such as assisted living, location-based social network services
and so on. To recognize contexts and make decisions for actions accordingly,
various artificial intelligence technologies, such as Ontology and OWL, have
been adopted as representations for context modeling and reasoning. Recently,
with the rise of LLMs and their improved natural language understanding and
reasoning capabilities, it has become feasible to model contexts using natural
language and perform context reasoning by interacting with LLMs such as ChatGPT
and GPT-4. In this tutorial, we demonstrate the use of texts, prompts, and
autonomous agents (AutoAgents) that enable LLMs to perform context modeling and
reasoning without requiring fine-tuning of the model. We organize and introduce
works in the related field, and name this computing paradigm as the LLM-driven
Context-aware Computing (LCaC). In the LCaC paradigm, users' requests, sensors
reading data, and the command to actuators are supposed to be represented as
texts. Given the text of users' request and sensor data, the AutoAgent models
the context by prompting and sends to the LLM for context reasoning. LLM
generates a plan of actions and responds to the AutoAgent, which later follows
the action plan to foster context-awareness. To prove the concepts, we use two
showcases--(1) operating a mobile z-arm in an apartment for assisted living,
and (2) planning a trip and scheduling the itinerary in a context-aware and
personalized manner.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.14365v1' target='_blank'>An In-depth Survey of Large Language Model-based Artificial Intelligence
  Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Pengyu Zhao, Zijian Jin, Ning Cheng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-23 11:25:45</h6>
<p class='card-text'>Due to the powerful capabilities demonstrated by large language model (LLM),
there has been a recent surge in efforts to integrate them with AI agents to
enhance their performance. In this paper, we have explored the core differences
and characteristics between LLM-based AI agents and traditional AI agents.
Specifically, we first compare the fundamental characteristics of these two
types of agents, clarifying the significant advantages of LLM-based agents in
handling natural language, knowledge storage, and reasoning capabilities.
Subsequently, we conducted an in-depth analysis of the key components of AI
agents, including planning, memory, and tool use. Particularly, for the crucial
component of memory, this paper introduced an innovative classification scheme,
not only departing from traditional classification methods but also providing a
fresh perspective on the design of an AI agent's memory system. We firmly
believe that in-depth research and understanding of these core components will
lay a solid foundation for the future advancement of AI agent technology. At
the end of the paper, we provide directional suggestions for further research
in this field, with the hope of offering valuable insights to scholars and
researchers in the field.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.12767v1' target='_blank'>Furthest Reasoning with Plan Assessment: Stable Reasoning Path with
  Retrieval-Augmented Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yin Zhu, Zhiling Luo, Gong Cheng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-22 10:15:13</h6>
<p class='card-text'>Large Language Models (LLMs), acting as a powerful reasoner and generator,
exhibit extraordinary performance across various natural language tasks, such
as question answering (QA). Among these tasks, Multi-Hop Question Answering
(MHQA) stands as a widely discussed category, necessitating seamless
integration between LLMs and the retrieval of external knowledge. Existing
methods employ LLM to generate reasoning paths and plans, and utilize IR to
iteratively retrieve related knowledge, but these approaches have inherent
flaws. On one hand, Information Retriever (IR) is hindered by the low quality
of generated queries by LLM. On the other hand, LLM is easily misguided by the
irrelevant knowledge by IR. These inaccuracies, accumulated by the iterative
interaction between IR and LLM, lead to a disaster in effectiveness at the end.
To overcome above barriers, in this paper, we propose a novel pipeline for MHQA
called Furthest-Reasoning-with-Plan-Assessment (FuRePA), including an improved
framework (Furthest Reasoning) and an attached module (Plan Assessor). 1)
Furthest reasoning operates by masking previous reasoning path and generated
queries for LLM, encouraging LLM generating chain of thought from scratch in
each iteration. This approach enables LLM to break the shackle built by
previous misleading thoughts and queries (if any). 2) The Plan Assessor is a
trained evaluator that selects an appropriate plan from a group of candidate
plans proposed by LLM. Our methods are evaluated on three highly recognized
public multi-hop question answering datasets and outperform state-of-the-art on
most metrics (achieving a 10%-12% in answer accuracy).</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.12570v3' target='_blank'>Creativity Support in the Age of Large Language Models: An Empirical
  Study Involving Emerging Writers</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tuhin Chakrabarty, Vishakh Padmakumar, Faeze Brahman, Smaranda Muresan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-22 01:49:36</h6>
<p class='card-text'>The development of large language models (LLMs) capable of following
instructions and engaging in conversational interactions sparked increased
interest in their utilization across various support tools. We investigate the
utility of modern LLMs in assisting professional writers via an empirical user
study (n=30). The design of our collaborative writing interface is grounded in
the cognitive process model of writing that views writing as a goal-oriented
thinking process encompassing non-linear cognitive activities: planning,
translating, and reviewing. Participants are asked to submit a post-completion
survey to provide feedback on the potential and pitfalls of LLMs as writing
collaborators. Upon analyzing the writer-LLM interactions, we find that while
writers seek LLM's help across all three types of cognitive activities, they
find LLMs more helpful in translation and reviewing. Our findings from
analyzing both the interactions and the survey responses highlight future
research directions in creative writing assistance using LLMs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.12499v1' target='_blank'>CodePlan: Repository-level Coding using LLMs and Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ramakrishna Bairi, Atharv Sonwane, Aditya Kanade, Vageesh D C, Arun Iyer, Suresh Parthasarathy, Sriram Rajamani, B. Ashok, Shashank Shet</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-21 21:45:17</h6>
<p class='card-text'>Software engineering activities such as package migration, fixing errors
reports from static analysis or testing, and adding type annotations or other
specifications to a codebase, involve pervasively editing the entire repository
of code. We formulate these activities as repository-level coding tasks.
  Recent tools like GitHub Copilot, which are powered by Large Language Models
(LLMs), have succeeded in offering high-quality solutions to localized coding
problems. Repository-level coding tasks are more involved and cannot be solved
directly using LLMs, since code within a repository is inter-dependent and the
entire repository may be too large to fit into the prompt. We frame
repository-level coding as a planning problem and present a task-agnostic
framework, called CodePlan to solve it. CodePlan synthesizes a multi-step chain
of edits (plan), where each step results in a call to an LLM on a code location
with context derived from the entire repository, previous code changes and
task-specific instructions. CodePlan is based on a novel combination of an
incremental dependency analysis, a change may-impact analysis and an adaptive
planning algorithm.
  We evaluate the effectiveness of CodePlan on two repository-level tasks:
package migration (C#) and temporal code edits (Python). Each task is evaluated
on multiple code repositories, each of which requires inter-dependent changes
to many files (between 2-97 files). Coding tasks of this level of complexity
have not been automated using LLMs before. Our results show that CodePlan has
better match with the ground truth compared to baselines. CodePlan is able to
get 5/6 repositories to pass the validity checks (e.g., to build without errors
and make correct code edits) whereas the baselines (without planning but with
the same type of contextual information as CodePlan) cannot get any of the
repositories to pass them.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.12276v3' target='_blank'>LLMR: Real-time Prompting of Interactive Worlds using Large Language
  Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Fernanda De La Torre, Cathy Mengying Fang, Han Huang, Andrzej Banburski-Fahey, Judith Amores Fernandez, Jaron Lanier</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-21 17:37:01</h6>
<p class='card-text'>We present Large Language Model for Mixed Reality (LLMR), a framework for the
real-time creation and modification of interactive Mixed Reality experiences
using LLMs. LLMR leverages novel strategies to tackle difficult cases where
ideal training data is scarce, or where the design goal requires the synthesis
of internal dynamics, intuitive analysis, or advanced interactivity. Our
framework relies on text interaction and the Unity game engine. By
incorporating techniques for scene understanding, task planning,
self-debugging, and memory management, LLMR outperforms the standard GPT-4 by
4x in average error rate. We demonstrate LLMR's cross-platform interoperability
with several example worlds, and evaluate it on a variety of creation and
modification tasks to show that it can produce and edit diverse objects, tools,
and scenes. Finally, we conducted a usability study (N=11) with a diverse set
that revealed participants had positive experiences with the system and would
use it again.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.12089v2' target='_blank'>HiCRISP: An LLM-based Hierarchical Closed-Loop Robotic Intelligent
  Self-Correction Planner</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chenlin Ming, Jiacheng Lin, Pangkit Fong, Han Wang, Xiaoming Duan, Jianping He</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-21 13:58:26</h6>
<p class='card-text'>The integration of Large Language Models (LLMs) into robotics has
revolutionized human-robot interactions and autonomous task planning. However,
these systems are often unable to self-correct during the task execution, which
hinders their adaptability in dynamic real-world environments. To address this
issue, we present a Hierarchical Closed-loop Robotic Intelligent
Self-correction Planner (HiCRISP), an innovative framework that enables robots
to correct errors within individual steps during the task execution. HiCRISP
actively monitors and adapts the task execution process, addressing both
high-level planning and low-level action errors. Extensive benchmark
experiments, encompassing virtual and real-world scenarios, showcase HiCRISP's
exceptional performance, positioning it as a promising solution for robotic
task planning with LLMs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.11688v1' target='_blank'>LLM Guided Inductive Inference for Solving Compositional Problems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Abhigya Sodani, Lauren Moos, Matthew Mirman</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-20 23:44:16</h6>
<p class='card-text'>While large language models (LLMs) have demonstrated impressive performance
in question-answering tasks, their performance is limited when the questions
require knowledge that is not included in the model's training data and can
only be acquired through direct observation or interaction with the real world.
Existing methods decompose reasoning tasks through the use of modules invoked
sequentially, limiting their ability to answer deep reasoning tasks. We
introduce a method, Recursion based extensible LLM (REBEL), which handles
open-world, deep reasoning tasks by employing automated reasoning techniques
like dynamic planning and forward-chaining strategies. REBEL allows LLMs to
reason via recursive problem decomposition and utilization of external tools.
The tools that REBEL uses are specified only by natural language description.
We further demonstrate REBEL capabilities on a set of problems that require a
deeply nested use of external tools in a compositional and conversational
setting.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.11436v4' target='_blank'>You Only Look at Screens: Multimodal Chain-of-Action Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhuosheng Zhang, Aston Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-20 16:12:32</h6>
<p class='card-text'>Autonomous graphical user interface (GUI) agents aim to facilitate task
automation by interacting with the user interface without manual intervention.
Recent studies have investigated eliciting the capabilities of large language
models (LLMs) for effective engagement in diverse environments. To align with
the input-output requirement of LLMs, most existing approaches are developed
under a sandbox setting where they rely on external tools and
application-specific APIs to parse the environment into textual elements and
interpret the predicted actions. Consequently, those approaches often grapple
with inference inefficiency and error propagation risks. To mitigate the
challenges, we introduce Auto-GUI, a multimodal solution that directly
interacts with the interface, bypassing the need for environment parsing or
reliance on application-dependent APIs. Moreover, we propose a chain-of-action
technique -- leveraging a series of intermediate previous action histories and
future action plans -- to help the agent decide what action to execute. We
evaluate our approach on a new device-control benchmark AITW with 30$K$ unique
instructions, spanning multi-step tasks such as application operation, web
searching, and web shopping. Experimental results show that Auto-GUI achieves
state-of-the-art performance with an action type prediction accuracy of 90\%
and an overall action success rate of 74\%. Code is publicly available at
https://github.com/cooelf/Auto-GUI.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.11359v3' target='_blank'>Prompt, Plan, Perform: LLM-based Humanoid Control via Quantized
  Imitation Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jingkai Sun, Qiang Zhang, Yiqun Duan, Xiaoyang Jiang, Chong Cheng, Renjing Xu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-20 14:42:01</h6>
<p class='card-text'>In recent years, reinforcement learning and imitation learning have shown
great potential for controlling humanoid robots' motion. However, these methods
typically create simulation environments and rewards for specific tasks,
resulting in the requirements of multiple policies and limited capabilities for
tackling complex and unknown tasks. To overcome these issues, we present a
novel approach that combines adversarial imitation learning with large language
models (LLMs). This innovative method enables the agent to learn reusable
skills with a single policy and solve zero-shot tasks under the guidance of
LLMs. In particular, we utilize the LLM as a strategic planner for applying
previously learned skills to novel tasks through the comprehension of
task-specific prompts. This empowers the robot to perform the specified actions
in a sequence. To improve our model, we incorporate codebook-based vector
quantization, allowing the agent to generate suitable actions in response to
unseen textual commands from LLMs. Furthermore, we design general reward
functions that consider the distinct motion features of humanoid robots,
ensuring the agent imitates the motion data while maintaining goal orientation
without additional guiding direction approaches or policies. To the best of our
knowledge, this is the first framework that controls humanoid robots using a
single learning policy network and LLM as a planner. Extensive experiments
demonstrate that our method exhibits efficient and adaptive ability in
complicated motion tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.10982v1' target='_blank'>Is GPT4 a Good Trader?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Bingzhe Wu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-20 00:47:52</h6>
<p class='card-text'>Recently, large language models (LLMs), particularly GPT-4, have demonstrated
significant capabilities in various planning and reasoning tasks
\cite{cheng2023gpt4,bubeck2023sparks}. Motivated by these advancements, there
has been a surge of interest among researchers to harness the capabilities of
GPT-4 for the automated design of quantitative factors that do not overlap with
existing factor libraries, with an aspiration to achieve alpha returns
\cite{webpagequant}. In contrast to these work, this study aims to examine the
fidelity of GPT-4's comprehension of classic trading theories and its
proficiency in applying its code interpreter abilities to real-world trading
data analysis. Such an exploration is instrumental in discerning whether the
underlying logic GPT-4 employs for trading is intrinsically reliable.
Furthermore, given the acknowledged interpretative latitude inherent in most
trading theories, we seek to distill more precise methodologies of deploying
these theories from GPT-4's analytical process, potentially offering invaluable
insights to human traders.
  To achieve this objective, we selected daily candlestick (K-line) data from
specific periods for certain assets, such as the Shanghai Stock Index. Through
meticulous prompt engineering, we guided GPT-4 to analyze the technical
structures embedded within this data, based on specific theories like the
Elliott Wave Theory. We then subjected its analytical output to manual
evaluation, assessing its interpretative depth and accuracy vis-\`a-vis these
trading theories from multiple dimensions. The results and findings from this
study could pave the way for a synergistic amalgamation of human expertise and
AI-driven insights in the realm of trading.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.10309v2' target='_blank'>Bridging Zero-shot Object Navigation and Foundation Models through
  Pixel-Guided Navigation Skill</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wenzhe Cai, Siyuan Huang, Guangran Cheng, Yuxing Long, Peng Gao, Changyin Sun, Hao Dong</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-19 04:41:22</h6>
<p class='card-text'>Zero-shot object navigation is a challenging task for home-assistance robots.
This task emphasizes visual grounding, commonsense inference and locomotion
abilities, where the first two are inherent in foundation models. But for the
locomotion part, most works still depend on map-based planning approaches. The
gap between RGB space and map space makes it difficult to directly transfer the
knowledge from foundation models to navigation tasks. In this work, we propose
a Pixel-guided Navigation skill (PixNav), which bridges the gap between the
foundation models and the embodied navigation task. It is straightforward for
recent foundation models to indicate an object by pixels, and with pixels as
the goal specification, our method becomes a versatile navigation policy
towards all different kinds of objects. Besides, our PixNav is a pure RGB-based
policy that can reduce the cost of home-assistance robots. Experiments
demonstrate the robustness of the PixNav which achieves 80+% success rate in
the local path-planning task. To perform long-horizon object navigation, we
design an LLM-based planner to utilize the commonsense knowledge between
objects and rooms to select the best waypoint. Evaluations across both
photorealistic indoor simulators and real-world environments validate the
effectiveness of our proposed navigation strategy. Code and video demos are
available at https://github.com/wzcai99/Pixel-Navigator.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.10092v4' target='_blank'>Conformal Temporal Logic Planning using Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jun Wang, Jiaming Tong, Kaiyuan Tan, Yevgeniy Vorobeychik, Yiannis Kantaros</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-18 19:05:25</h6>
<p class='card-text'>This paper addresses planning problems for mobile robots. We consider
missions that require accomplishing multiple high-level sub-tasks, expressed in
natural language (NL), in a temporal and logical order. To formally define the
mission, we treat these sub-tasks as atomic predicates in a Linear Temporal
Logic (LTL) formula. We refer to this task specification framework as LTL-NL.
Our goal is to design plans, defined as sequences of robot actions,
accomplishing LTL-NL tasks. This action planning problem cannot be solved
directly by existing LTL planners because of the NL nature of atomic
predicates. To address it, we propose HERACLEs, a hierarchical neuro-symbolic
planner that relies on a novel integration of (i) existing symbolic planners
generating high-level task plans determining the order at which the NL
sub-tasks should be accomplished; (ii) pre-trained Large Language Models (LLMs)
to design sequences of robot actions based on these task plans; and (iii)
conformal prediction acting as a formal interface between (i) and (ii) and
managing uncertainties due to LLM imperfections. We show, both theoretically
and empirically, that HERACLEs can achieve user-defined mission success rates.
Finally, we provide comparative experiments demonstrating that HERACLEs
outperforms LLM-based planners that require the mission to be defined solely
using NL. Additionally, we present examples demonstrating that our approach
enhances user-friendliness compared to conventional symbolic approaches.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.10062v2' target='_blank'>SMART-LLM: Smart Multi-Agent Robot Task Planning using Large Language
  Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shyam Sundar Kannan, Vishnunandan L. N. Venkatesh, Byung-Cheol Min</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-18 18:17:56</h6>
<p class='card-text'>In this work, we introduce SMART-LLM, an innovative framework designed for
embodied multi-robot task planning. SMART-LLM: Smart Multi-Agent Robot Task
Planning using Large Language Models (LLMs), harnesses the power of LLMs to
convert high-level task instructions provided as input into a multi-robot task
plan. It accomplishes this by executing a series of stages, including task
decomposition, coalition formation, and task allocation, all guided by
programmatic LLM prompts within the few-shot prompting paradigm. We create a
benchmark dataset designed for validating the multi-robot task planning
problem, encompassing four distinct categories of high-level instructions that
vary in task complexity. Our evaluation experiments span both simulation and
real-world scenarios, demonstrating that the proposed model can achieve
promising results for generating multi-robot task plans. The experimental
videos, code, and datasets from the work can be found at
https://sites.google.com/view/smart-llm/.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.09971v2' target='_blank'>MindAgent: Emergent Gaming Interaction</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ran Gong, Qiuyuan Huang, Xiaojian Ma, Hoi Vo, Zane Durante, Yusuke Noda, Zilong Zheng, Song-Chun Zhu, Demetri Terzopoulos, Li Fei-Fei, Jianfeng Gao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-18 17:52:22</h6>
<p class='card-text'>Large Language Models (LLMs) have the capacity of performing complex
scheduling in a multi-agent system and can coordinate these agents into
completing sophisticated tasks that require extensive collaboration. However,
despite the introduction of numerous gaming frameworks, the community has
insufficient benchmarks towards building general multi-agents collaboration
infrastructure that encompass both LLM and human-NPCs collaborations. In this
work, we propose a novel infrastructure - MindAgent - to evaluate planning and
coordination emergent capabilities for gaming interaction. In particular, our
infrastructure leverages existing gaming framework, to i) require understanding
of the coordinator for a multi-agent system, ii) collaborate with human players
via un-finetuned proper instructions, and iii) establish an in-context learning
on few-shot prompt with feedback. Furthermore, we introduce CUISINEWORLD, a new
gaming scenario and related benchmark that dispatch a multi-agent collaboration
efficiency and supervise multiple agents playing the game simultaneously. We
conduct comprehensive evaluations with new auto-metric CoS for calculating the
collaboration efficiency. Finally, our infrastructure can be deployed into
real-world gaming scenarios in a customized VR version of CUISINEWORLD and
adapted in existing broader Minecraft gaming domain. We hope our findings on
LLMs and the new infrastructure for general-purpose scheduling and coordination
can help shed light on how such skills can be obtained by learning from large
language corpora.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.09919v3' target='_blank'>Plug in the Safety Chip: Enforcing Constraints for LLM-driven Robot
  Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ziyi Yang, Shreyas S. Raman, Ankit Shah, Stefanie Tellex</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-18 16:33:30</h6>
<p class='card-text'>Recent advancements in large language models (LLMs) have enabled a new
research domain, LLM agents, for solving robotics and planning tasks by
leveraging the world knowledge and general reasoning abilities of LLMs obtained
during pretraining. However, while considerable effort has been made to teach
the robot the "dos," the "don'ts" received relatively less attention. We argue
that, for any practical usage, it is as crucial to teach the robot the
"don'ts": conveying explicit instructions about prohibited actions, assessing
the robot's comprehension of these restrictions, and, most importantly,
ensuring compliance. Moreover, verifiable safe operation is essential for
deployments that satisfy worldwide standards such as ISO 61508, which defines
standards for safely deploying robots in industrial factory environments
worldwide. Aiming at deploying the LLM agents in a collaborative environment,
we propose a queryable safety constraint module based on linear temporal logic
(LTL) that simultaneously enables natural language (NL) to temporal constraints
encoding, safety violation reasoning and explaining, and unsafe action pruning.
To demonstrate the effectiveness of our system, we conducted experiments in
VirtualHome environment and on a real robot. The experimental results show that
our system strictly adheres to the safety constraints and scales well with
complex safety constraints, highlighting its potential for practical utility.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.09182v2' target='_blank'>Optimal Scene Graph Planning with Large Language Model Guidance</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhirui Dai, Arash Asgharivaskasi, Thai Duong, Shusen Lin, Maria-Elizabeth Tzes, George Pappas, Nikolay Atanasov</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-17 07:09:46</h6>
<p class='card-text'>Recent advances in metric, semantic, and topological mapping have equipped
autonomous robots with semantic concept grounding capabilities to interpret
natural language tasks. This work aims to leverage these new capabilities with
an efficient task planning algorithm for hierarchical metric-semantic models.
We consider a scene graph representation of the environment and utilize a large
language model (LLM) to convert a natural language task into a linear temporal
logic (LTL) automaton. Our main contribution is to enable optimal hierarchical
LTL planning with LLM guidance over scene graphs. To achieve efficiency, we
construct a hierarchical planning domain that captures the attributes and
connectivity of the scene graph and the task automaton, and provide semantic
guidance via an LLM heuristic function. To guarantee optimality, we design an
LTL heuristic function that is provably consistent and supplements the
potentially inadmissible LLM guidance in multi-heuristic planning. We
demonstrate efficient planning of complex natural language tasks in scene
graphs of virtualized real environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.09181v1' target='_blank'>From Cooking Recipes to Robot Task Trees -- Improving Planning
  Correctness and Task Efficiency by Leveraging LLMs with a Knowledge Network</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Md Sadman Sakib, Yu Sun</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-17 07:09:16</h6>
<p class='card-text'>Task planning for robotic cooking involves generating a sequence of actions
for a robot to prepare a meal successfully. This paper introduces a novel task
tree generation pipeline producing correct planning and efficient execution for
cooking tasks. Our method first uses a large language model (LLM) to retrieve
recipe instructions and then utilizes a fine-tuned GPT-3 to convert them into a
task tree, capturing sequential and parallel dependencies among subtasks. The
pipeline then mitigates the uncertainty and unreliable features of LLM outputs
using task tree retrieval. We combine multiple LLM task tree outputs into a
graph and perform a task tree retrieval to avoid questionable nodes and
high-cost nodes to improve planning correctness and improve execution
efficiency. Our evaluation results show its superior performance compared to
previous works in task planning accuracy and efficiency.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.08112v2' target='_blank'>Empowering Private Tutoring by Chaining Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yulin Chen, Ning Ding, Hai-Tao Zheng, Zhiyuan Liu, Maosong Sun, Bowen Zhou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-15 02:42:03</h6>
<p class='card-text'>Artificial intelligence has been applied in various aspects of online
education to facilitate teaching and learning. However, few approaches has been
made toward a complete AI-powered tutoring system. In this work, we explore the
development of a full-fledged intelligent tutoring system powered by
state-of-the-art large language models (LLMs), covering automatic course
planning and adjusting, tailored instruction, and flexible quiz evaluation. To
make the system robust to prolonged interaction and cater to individualized
education, the system is decomposed into three inter-connected core
processes-interaction, reflection, and reaction. Each process is implemented by
chaining LLM-powered tools along with dynamically updated memory modules. Tools
are LLMs prompted to execute one specific task at a time, while memories are
data storage that gets updated during education process. Statistical results
from learning logs demonstrate the effectiveness and mechanism of each tool
usage. Subjective feedback from human users reveal the usability of each
function, and comparison with ablation systems further testify the benefits of
the designed processes in long-term interaction.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.07918v5' target='_blank'>Unified Human-Scene Interaction via Prompted Chain-of-Contacts</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zeqi Xiao, Tai Wang, Jingbo Wang, Jinkun Cao, Wenwei Zhang, Bo Dai, Dahua Lin, Jiangmiao Pang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-14 17:59:49</h6>
<p class='card-text'>Human-Scene Interaction (HSI) is a vital component of fields like embodied AI
and virtual reality. Despite advancements in motion quality and physical
plausibility, two pivotal factors, versatile interaction control and the
development of a user-friendly interface, require further exploration before
the practical application of HSI. This paper presents a unified HSI framework,
UniHSI, which supports unified control of diverse interactions through language
commands. This framework is built upon the definition of interaction as Chain
of Contacts (CoC): steps of human joint-object part pairs, which is inspired by
the strong correlation between interaction types and human-object contact
regions. Based on the definition, UniHSI constitutes a Large Language Model
(LLM) Planner to translate language prompts into task plans in the form of CoC,
and a Unified Controller that turns CoC into uniform task execution. To
facilitate training and evaluation, we collect a new dataset named ScenePlan
that encompasses thousands of task plans generated by LLMs based on diverse
scenarios. Comprehensive experiments demonstrate the effectiveness of our
framework in versatile task execution and generalizability to real scanned
scenes. The project page is at https://github.com/OpenRobotLab/UniHSI .</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.07870v3' target='_blank'>Agents: An Open-source Framework for Autonomous Language Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wangchunshu Zhou, Yuchen Eleanor Jiang, Long Li, Jialong Wu, Tiannan Wang, Shi Qiu, Jintian Zhang, Jing Chen, Ruipu Wu, Shuai Wang, Shiding Zhu, Jiyu Chen, Wentao Zhang, Xiangru Tang, Ningyu Zhang, Huajun Chen, Peng Cui, Mrinmaya Sachan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-14 17:18:25</h6>
<p class='card-text'>Recent advances on large language models (LLMs) enable researchers and
developers to build autonomous language agents that can automatically solve
various tasks and interact with environments, humans, and other agents using
natural language interfaces. We consider language agents as a promising
direction towards artificial general intelligence and release Agents, an
open-source library with the goal of opening up these advances to a wider
non-specialist audience. Agents is carefully engineered to support important
features including planning, memory, tool usage, multi-agent communication, and
fine-grained symbolic control. Agents is user-friendly as it enables
non-specialists to build, customize, test, tune, and deploy state-of-the-art
autonomous language agents without much coding. The library is also
research-friendly as its modularized design makes it easily extensible for
researchers. Agents is available at https://github.com/aiwaves-cn/agents.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.07726v2' target='_blank'>GRID: Scene-Graph-based Instruction-driven Robotic Task Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhe Ni, Xiaoxin Deng, Cong Tai, Xinyue Zhu, Qinghongbing Xie, Weihang Huang, Xiang Wu, Long Zeng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-14 14:02:56</h6>
<p class='card-text'>Recent works have shown that Large Language Models (LLMs) can facilitate the
grounding of instructions for robotic task planning. Despite this progress,
most existing works have primarily focused on utilizing raw images to aid LLMs
in understanding environmental information. However, this approach not only
limits the scope of observation but also typically necessitates extensive
multimodal data collection and large-scale models. In this paper, we propose a
novel approach called Graph-based Robotic Instruction Decomposer (GRID), which
leverages scene graphs instead of images to perceive global scene information
and iteratively plan subtasks for a given instruction. Our method encodes
object attributes and relationships in graphs through an LLM and Graph
Attention Networks, integrating instruction features to predict subtasks
consisting of pre-defined robot actions and target objects in the scene graph.
This strategy enables robots to acquire semantic knowledge widely observed in
the environment from the scene graph. To train and evaluate GRID, we establish
a dataset construction pipeline to generate synthetic datasets for graph-based
robotic task planning. Experiments have shown that our method outperforms GPT-4
by over 25.4% in subtask accuracy and 43.6% in task accuracy. Moreover, our
method achieves a real-time speed of 0.11s per inference. Experiments conducted
on datasets of unseen scenes and scenes with varying numbers of objects
demonstrate that the task accuracy of GRID declined by at most 3.8%, showcasing
its robust cross-scene generalization ability. We validate our method in both
physical simulation and the real world. More details can be found on the
project page https://jackyzengl.github.io/GRID.github.io/.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.07694v1' target='_blank'>Tree of Uncertain Thoughts Reasoning for Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shentong Mo, Miao Xin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-14 13:14:51</h6>
<p class='card-text'>While the recently introduced Tree of Thoughts (ToT) has heralded
advancements in allowing Large Language Models (LLMs) to reason through
foresight and backtracking for global decision-making, it has overlooked the
inherent local uncertainties in intermediate decision points or "thoughts".
These local uncertainties, intrinsic to LLMs given their potential for diverse
responses, remain a significant concern in the reasoning process. Addressing
this pivotal gap, we introduce the Tree of Uncertain Thoughts (TouT) - a
reasoning framework tailored for LLMs. Our TouT effectively leverages Monte
Carlo Dropout to quantify uncertainty scores associated with LLMs' diverse
local responses at these intermediate steps. By marrying this local uncertainty
quantification with global search algorithms, TouT enhances the model's
precision in response generation. We substantiate our approach with rigorous
experiments on two demanding planning tasks: Game of 24 and Mini Crosswords.
The empirical evidence underscores TouT's superiority over both ToT and
chain-of-thought prompting methods.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.06719v1' target='_blank'>TrafficGPT: Viewing, Processing and Interacting with Traffic Foundation
  Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Siyao Zhang, Daocheng Fu, Zhao Zhang, Bin Yu, Pinlong Cai</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-13 04:47:43</h6>
<p class='card-text'>With the promotion of chatgpt to the public, Large language models indeed
showcase remarkable common sense, reasoning, and planning skills, frequently
providing insightful guidance. These capabilities hold significant promise for
their application in urban traffic management and control. However, LLMs
struggle with addressing traffic issues, especially processing numerical data
and interacting with simulations, limiting their potential in solving
traffic-related challenges. In parallel, specialized traffic foundation models
exist but are typically designed for specific tasks with limited input-output
interactions. Combining these models with LLMs presents an opportunity to
enhance their capacity for tackling complex traffic-related problems and
providing insightful suggestions. To bridge this gap, we present TrafficGPT, a
fusion of ChatGPT and traffic foundation models. This integration yields the
following key enhancements: 1) empowering ChatGPT with the capacity to view,
analyze, process traffic data, and provide insightful decision support for
urban transportation system management; 2) facilitating the intelligent
deconstruction of broad and complex tasks and sequential utilization of traffic
foundation models for their gradual completion; 3) aiding human decision-making
in traffic control through natural language dialogues; and 4) enabling
interactive feedback and solicitation of revised outcomes. By seamlessly
intertwining large language model and traffic expertise, TrafficGPT not only
advances traffic management but also offers a novel approach to leveraging AI
capabilities in this domain. The TrafficGPT demo can be found in
https://github.com/lijlansg/TrafficGPT.git.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.06687v2' target='_blank'>Self-Refined Large Language Model as Automated Reward Function Designer
  for Deep Reinforcement Learning in Robotics</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiayang Song, Zhehua Zhou, Jiawei Liu, Chunrong Fang, Zhan Shu, Lei Ma</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-13 02:56:56</h6>
<p class='card-text'>Although Deep Reinforcement Learning (DRL) has achieved notable success in
numerous robotic applications, designing a high-performing reward function
remains a challenging task that often requires substantial manual input.
Recently, Large Language Models (LLMs) have been extensively adopted to address
tasks demanding in-depth common-sense knowledge, such as reasoning and
planning. Recognizing that reward function design is also inherently linked to
such knowledge, LLM offers a promising potential in this context. Motivated by
this, we propose in this work a novel LLM framework with a self-refinement
mechanism for automated reward function design. The framework commences with
the LLM formulating an initial reward function based on natural language
inputs. Then, the performance of the reward function is assessed, and the
results are presented back to the LLM for guiding its self-refinement process.
We examine the performance of our proposed framework through a variety of
continuous robotic control tasks across three diverse robotic systems. The
results indicate that our LLM-designed reward functions are able to rival or
even surpass manually designed reward functions, highlighting the efficacy and
applicability of our approach.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.04077v4' target='_blank'>SayNav: Grounding Large Language Models for Dynamic Planning to
  Navigation in New Environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Abhinav Rajvanshi, Karan Sikka, Xiao Lin, Bhoram Lee, Han-Pang Chiu, Alvaro Velasquez</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-08 02:24:37</h6>
<p class='card-text'>Semantic reasoning and dynamic planning capabilities are crucial for an
autonomous agent to perform complex navigation tasks in unknown environments.
It requires a large amount of common-sense knowledge, that humans possess, to
succeed in these tasks. We present SayNav, a new approach that leverages human
knowledge from Large Language Models (LLMs) for efficient generalization to
complex navigation tasks in unknown large-scale environments. SayNav uses a
novel grounding mechanism, that incrementally builds a 3D scene graph of the
explored environment as inputs to LLMs, for generating feasible and
contextually appropriate high-level plans for navigation. The LLM-generated
plan is then executed by a pre-trained low-level planner, that treats each
planned step as a short-distance point-goal navigation sub-task. SayNav
dynamically generates step-by-step instructions during navigation and
continuously refines future steps based on newly perceived information. We
evaluate SayNav on multi-object navigation (MultiON) task, that requires the
agent to utilize a massive amount of human knowledge to efficiently search
multiple different objects in an unknown environment. We also introduce a
benchmark dataset for MultiON task employing ProcTHOR framework that provides
large photo-realistic indoor environments with variety of objects. SayNav
achieves state-of-the-art results and even outperforms an oracle based baseline
with strong ground-truth assumptions by more than 8% in terms of success rate,
highlighting its ability to generate dynamic plans for successfully locating
objects in large-scale new environments. The code, benchmark dataset and
demonstration videos are accessible at
https://www.sri.com/ics/computer-vision/saynav.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.02590v1' target='_blank'>Artificial General Intelligence for Radiation Oncology</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chenbin Liu, Zhengliang Liu, Jason Holmes, Lu Zhang, Lian Zhang, Yuzhen Ding, Peng Shu, Zihao Wu, Haixing Dai, Yiwei Li, Dinggang Shen, Ninghao Liu, Quanzheng Li, Xiang Li, Dajiang Zhu, Tianming Liu, Wei Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-05 21:26:37</h6>
<p class='card-text'>The emergence of artificial general intelligence (AGI) is transforming
radiation oncology. As prominent vanguards of AGI, large language models (LLMs)
such as GPT-4 and PaLM 2 can process extensive texts and large vision models
(LVMs) such as the Segment Anything Model (SAM) can process extensive imaging
data to enhance the efficiency and precision of radiation therapy. This paper
explores full-spectrum applications of AGI across radiation oncology including
initial consultation, simulation, treatment planning, treatment delivery,
treatment verification, and patient follow-up. The fusion of vision data with
LLMs also creates powerful multimodal models that elucidate nuanced clinical
patterns. Together, AGI promises to catalyze a shift towards data-driven,
personalized radiation therapy. However, these models should complement human
expertise and care. This paper provides an overview of how AGI can transform
radiation oncology to elevate the standard of patient care in radiation
oncology, with the key insight being AGI's ability to exploit multimodal
clinical data at scale.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.02427v3' target='_blank'>Cognitive Architectures for Language Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Theodore R. Sumers, Shunyu Yao, Karthik Narasimhan, Thomas L. Griffiths</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-05 17:56:20</h6>
<p class='card-text'>Recent efforts have augmented large language models (LLMs) with external
resources (e.g., the Internet) or internal control flows (e.g., prompt
chaining) for tasks requiring grounding or reasoning, leading to a new class of
language agents. While these agents have achieved substantial empirical
success, we lack a systematic framework to organize existing agents and plan
future developments. In this paper, we draw on the rich history of cognitive
science and symbolic artificial intelligence to propose Cognitive Architectures
for Language Agents (CoALA). CoALA describes a language agent with modular
memory components, a structured action space to interact with internal memory
and external environments, and a generalized decision-making process to choose
actions. We use CoALA to retrospectively survey and organize a large body of
recent work, and prospectively identify actionable directions towards more
capable agents. Taken together, CoALA contextualizes today's language agents
within the broader history of AI and outlines a path towards language-based
general intelligence.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.01352v1' target='_blank'>Self-driven Grounding: Large Language Model Agents with Automatical
  Language-aligned Skill Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shaohui Peng, Xing Hu, Qi Yi, Rui Zhang, Jiaming Guo, Di Huang, Zikang Tian, Ruizhi Chen, Zidong Du, Qi Guo, Yunji Chen, Ling Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-04 04:31:24</h6>
<p class='card-text'>Large language models (LLMs) show their powerful automatic reasoning and
planning capability with a wealth of semantic knowledge about the human world.
However, the grounding problem still hinders the applications of LLMs in the
real-world environment. Existing studies try to fine-tune the LLM or utilize
pre-defined behavior APIs to bridge the LLMs and the environment, which not
only costs huge human efforts to customize for every single task but also
weakens the generality strengths of LLMs. To autonomously ground the LLM onto
the environment, we proposed the Self-Driven Grounding (SDG) framework to
automatically and progressively ground the LLM with self-driven skill learning.
SDG first employs the LLM to propose the hypothesis of sub-goals to achieve
tasks and then verify the feasibility of the hypothesis via interacting with
the underlying environment. Once verified, SDG can then learn generalized
skills with the guidance of these successfully grounded subgoals. These skills
can be further utilized to accomplish more complex tasks which fail to pass the
verification phase. Verified in the famous instruction following task
set-BabyAI, SDG achieves comparable performance in the most challenging tasks
compared with imitation learning methods that cost millions of demonstrations,
proving the effectiveness of learned skills and showing the feasibility and
efficiency of our framework.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2309.00986v1' target='_blank'>ModelScope-Agent: Building Your Customizable Agent System with
  Open-source Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chenliang Li, Hehong Chen, Ming Yan, Weizhou Shen, Haiyang Xu, Zhikai Wu, Zhicheng Zhang, Wenmeng Zhou, Yingda Chen, Chen Cheng, Hongzhu Shi, Ji Zhang, Fei Huang, Jingren Zhou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-09-02 16:50:30</h6>
<p class='card-text'>Large language models (LLMs) have recently demonstrated remarkable
capabilities to comprehend human intentions, engage in reasoning, and design
planning-like behavior. To further unleash the power of LLMs to accomplish
complex tasks, there is a growing trend to build agent framework that equips
LLMs, such as ChatGPT, with tool-use abilities to connect with massive external
APIs. In this work, we introduce ModelScope-Agent, a general and customizable
agent framework for real-world applications, based on open-source LLMs as
controllers. It provides a user-friendly system library, with customizable
engine design to support model training on multiple open-source LLMs, while
also enabling seamless integration with both model APIs and common APIs in a
unified way. To equip the LLMs with tool-use abilities, a comprehensive
framework has been proposed spanning over tool-use data collection, tool
retrieval, tool registration, memory control, customized model training, and
evaluation for practical real-world applications. Finally, we showcase
ModelScopeGPT, a real-world intelligent assistant of ModelScope Community based
on the ModelScope-Agent framework, which is able to connect open-source LLMs
with more than 1000 public AI models and localized community knowledge in
ModelScope. The ModelScope-Agent
library\footnote{https://github.com/modelscope/modelscope-agent} and online
demo\footnote{https://modelscope.cn/studios/damo/ModelScopeGPT/summary} are now
publicly available.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2308.16505v3' target='_blank'>Recommender AI Agent: Integrating Large Language Models for Interactive
  Recommendations</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xu Huang, Jianxun Lian, Yuxuan Lei, Jing Yao, Defu Lian, Xing Xie</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-08-31 07:36:44</h6>
<p class='card-text'>Recommender models excel at providing domain-specific item recommendations by
leveraging extensive user behavior data. Despite their ability to act as
lightweight domain experts, they struggle to perform versatile tasks such as
providing explanations and engaging in conversations. On the other hand, large
language models (LLMs) represent a significant step towards artificial general
intelligence, showcasing remarkable capabilities in instruction comprehension,
commonsense reasoning, and human interaction. However, LLMs lack the knowledge
of domain-specific item catalogs and behavioral patterns, particularly in areas
that diverge from general world knowledge, such as online e-commerce.
Finetuning LLMs for each domain is neither economic nor efficient.
  In this paper, we bridge the gap between recommender models and LLMs,
combining their respective strengths to create a versatile and interactive
recommender system. We introduce an efficient framework called
\textbf{InteRecAgent}, which employs LLMs as the brain and recommender models
as tools. We first outline a minimal set of essential tools required to
transform LLMs into InteRecAgent. We then propose an efficient workflow within
InteRecAgent for task execution, incorporating key components such as memory
components, dynamic demonstration-augmented task planning, and reflection.
InteRecAgent enables traditional recommender systems, such as those ID-based
matrix factorization models, to become interactive systems with a natural
language interface through the integration of LLMs. Experimental results on
several public datasets show that InteRecAgent achieves satisfying performance
as a conversational recommender system, outperforming general-purpose LLMs. The
source code of InteRecAgent is released at https://aka.ms/recagent.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2308.15684v2' target='_blank'>Interactively Robot Action Planning with Uncertainty Analysis and Active
  Questioning by Large Language Model</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kazuki Hori, Kanata Suzuki, Tetsuya Ogata</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-08-30 00:54:44</h6>
<p class='card-text'>The application of the Large Language Model (LLM) to robot action planning
has been actively studied. The instructions given to the LLM by natural
language may include ambiguity and lack of information depending on the task
context. It is possible to adjust the output of LLM by making the instruction
input more detailed; however, the design cost is high. In this paper, we
propose the interactive robot action planning method that allows the LLM to
analyze and gather missing information by asking questions to humans. The
method can minimize the design cost of generating precise robot instructions.
We demonstrated the effectiveness of our method through concrete examples in
cooking tasks. However, our experiments also revealed challenges in robot
action planning with LLM, such as asking unimportant questions and assuming
crucial information without asking. Shedding light on these issues provides
valuable insights for future research on utilizing LLM for robotics.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2308.15299v1' target='_blank'>TaskLAMA: Probing the Complex Task Understanding of Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Quan Yuan, Mehran Kazemi, Xin Xu, Isaac Noble, Vaiva Imbrasaite, Deepak Ramachandran</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-08-29 13:36:45</h6>
<p class='card-text'>Structured Complex Task Decomposition (SCTD) is the problem of breaking down
a complex real-world task (such as planning a wedding) into a directed acyclic
graph over individual steps that contribute to achieving the task, with edges
specifying temporal dependencies between them. SCTD is an important component
of assistive planning tools, and a challenge for commonsense reasoning systems.
We probe how accurately SCTD can be done with the knowledge extracted from
Large Language Models (LLMs). We introduce a high-quality human-annotated
dataset for this problem and novel metrics to fairly assess performance of LLMs
against several baselines. Our experiments reveal that LLMs are able to
decompose complex tasks into individual steps effectively, with a relative
improvement of 15% to 280% over the best baseline. We also propose a number of
approaches to further improve their performance, with a relative improvement of
7% to 37% over the base model. However, we find that LLMs still struggle to
predict pairwise temporal dependencies, which reveals a gap in their
understanding of complex tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2308.15197v2' target='_blank'>Where Would I Go Next? Large Language Models as Human Mobility
  Predictors</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xinglei Wang, Meng Fang, Zichao Zeng, Tao Cheng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-08-29 10:24:23</h6>
<p class='card-text'>Accurate human mobility prediction underpins many important applications
across a variety of domains, including epidemic modelling, transport planning,
and emergency responses. Due to the sparsity of mobility data and the
stochastic nature of people's daily activities, achieving precise predictions
of people's locations remains a challenge. While recently developed large
language models (LLMs) have demonstrated superior performance across numerous
language-related tasks, their applicability to human mobility studies remains
unexplored. Addressing this gap, this article delves into the potential of LLMs
for human mobility prediction tasks. We introduce a novel method, LLM-Mob,
which leverages the language understanding and reasoning capabilities of LLMs
for analysing human mobility data. We present concepts of historical stays and
context stays to capture both long-term and short-term dependencies in human
movement and enable time-aware prediction by using time information of the
prediction target. Additionally, we design context-inclusive prompts that
enable LLMs to generate more accurate predictions. Comprehensive evaluations of
our method reveal that LLM-Mob excels in providing accurate and interpretable
predictions, highlighting the untapped potential of LLMs in advancing human
mobility prediction techniques. We posit that our research marks a significant
paradigm shift in human mobility modelling, transitioning from building complex
domain-specific models to harnessing general-purpose LLMs that yield accurate
predictions through language instructions. The code for this work is available
at https://github.com/xlwang233/LLM-Mob.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2308.14972v1' target='_blank'>LLM-Based Human-Robot Collaboration Framework for Manipulation Tasks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Haokun Liu, Yaonan Zhu, Kenji Kato, Izumi Kondo, Tadayoshi Aoyama, Yasuhisa Hasegawa</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-08-29 01:54:49</h6>
<p class='card-text'>This paper presents a novel approach to enhance autonomous robotic
manipulation using the Large Language Model (LLM) for logical inference,
converting high-level language commands into sequences of executable motion
functions. The proposed system combines the advantage of LLM with YOLO-based
environmental perception to enable robots to autonomously make reasonable
decisions and task planning based on the given commands. Additionally, to
address the potential inaccuracies or illogical actions arising from LLM, a
combination of teleoperation and Dynamic Movement Primitives (DMP) is employed
for action correction. This integration aims to improve the practicality and
generalizability of the LLM-based human-robot collaboration system.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2308.14296v3' target='_blank'>RecMind: Large Language Model Powered Agent For Recommendation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yancheng Wang, Ziyan Jiang, Zheng Chen, Fan Yang, Yingxue Zhou, Eunah Cho, Xing Fan, Xiaojiang Huang, Yanbin Lu, Yingzhen Yang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-08-28 04:31:04</h6>
<p class='card-text'>While the recommendation system (RS) has advanced significantly through deep
learning, current RS approaches usually train and fine-tune models on
task-specific datasets, limiting their generalizability to new recommendation
tasks and their ability to leverage external knowledge due to model scale and
data size constraints. Thus, we designed an LLM-powered autonomous recommender
agent, RecMind, which is capable of leveraging external knowledge, utilizing
tools with careful planning to provide zero-shot personalized recommendations.
We propose a Self-Inspiring algorithm to improve the planning ability. At each
intermediate step, the LLM self-inspires to consider all previously explored
states to plan for the next step. This mechanism greatly improves the model's
ability to comprehend and utilize historical information in planning for
recommendation. We evaluate RecMind's performance in various recommendation
scenarios. Our experiment shows that RecMind outperforms existing zero/few-shot
LLM-based recommendation baseline methods in various tasks and achieves
comparable performance to a fully trained recommendation model P5.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2308.13724v1' target='_blank'>ISR-LLM: Iterative Self-Refined Large Language Model for Long-Horizon
  Sequential Task Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhehua Zhou, Jiayang Song, Kunpeng Yao, Zhan Shu, Lei Ma</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-08-26 01:31:35</h6>
<p class='card-text'>Motivated by the substantial achievements observed in Large Language Models
(LLMs) in the field of natural language processing, recent research has
commenced investigations into the application of LLMs for complex, long-horizon
sequential task planning challenges in robotics. LLMs are advantageous in
offering the potential to enhance the generalizability as task-agnostic
planners and facilitate flexible interaction between human instructors and
planning systems. However, task plans generated by LLMs often lack feasibility
and correctness. To address this challenge, we introduce ISR-LLM, a novel
framework that improves LLM-based planning through an iterative self-refinement
process. The framework operates through three sequential steps: preprocessing,
planning, and iterative self-refinement. During preprocessing, an LLM
translator is employed to convert natural language input into a Planning Domain
Definition Language (PDDL) formulation. In the planning phase, an LLM planner
formulates an initial plan, which is then assessed and refined in the iterative
self-refinement step by using a validator. We examine the performance of
ISR-LLM across three distinct planning domains. The results show that ISR-LLM
is able to achieve markedly higher success rates in task accomplishments
compared to state-of-the-art LLM-based planners. Moreover, it also preserves
the broad applicability and generalizability of working with natural language
instructions.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2308.12908v1' target='_blank'>POLCA: Power Oversubscription in LLM Cloud Providers</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Pratyush Patel, Esha Choukse, Chaojie Zhang, Íñigo Goiri, Brijesh Warrier, Nithish Mahalingam, Ricardo Bianchini</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-08-24 16:32:34</h6>
<p class='card-text'>Recent innovation in large language models (LLMs), and their myriad use-cases
have rapidly driven up the compute capacity demand for datacenter GPUs. Several
cloud providers and other enterprises have made substantial plans of growth in
their datacenters to support these new workloads. One of the key bottleneck
resources in datacenters is power, and given the increasing model sizes of
LLMs, they are becoming increasingly power intensive. In this paper, we show
that there is a significant opportunity to oversubscribe power in LLM clusters.
Power oversubscription improves the power efficiency of these datacenters,
allowing more deployable servers per datacenter, and reduces the deployment
time, since building new datacenters is slow.
  We extensively characterize the power consumption patterns of a variety of
LLMs and their configurations. We identify the differences between the
inference and training power consumption patterns. Based on our analysis of
these LLMs, we claim that the average and peak power utilization in LLM
clusters for inference should not be very high. Our deductions align with the
data from production LLM clusters, revealing that inference workloads offer
substantial headroom for power oversubscription. However, the stringent set of
telemetry and controls that GPUs offer in a virtualized environment, makes it
challenging to have a reliable and robust power oversubscription mechanism.
  We propose POLCA, our framework for power oversubscription that is robust,
reliable, and readily deployable for GPU clusters. Using open-source models to
replicate the power patterns observed in production, we simulate POLCA and
demonstrate that we can deploy 30% more servers in the same GPU cluster for
inference, with minimal performance loss</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2308.12682v2' target='_blank'>SayCanPay: Heuristic Planning with Large Language Models using Learnable
  Domain Knowledge</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Rishi Hazra, Pedro Zuidberg Dos Martires, Luc De Raedt</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-08-24 09:47:28</h6>
<p class='card-text'>Large Language Models (LLMs) have demonstrated impressive planning abilities
due to their vast "world knowledge". Yet, obtaining plans that are both
feasible (grounded in affordances) and cost-effective (in plan length), remains
a challenge, despite recent progress. This contrasts with heuristic planning
methods that employ domain knowledge (formalized in action models such as PDDL)
and heuristic search to generate feasible, optimal plans. Inspired by this, we
propose to combine the power of LLMs and heuristic planning by leveraging the
world knowledge of LLMs and the principles of heuristic search. Our approach,
SayCanPay, employs LLMs to generate actions (Say) guided by learnable domain
knowledge, that evaluates actions' feasibility (Can) and long-term
reward/payoff (Pay), and heuristic search to select the best sequence of
actions. Our contributions are (1) a novel framing of the LLM planning problem
in the context of heuristic planning, (2) integrating grounding and
cost-effective elements into the generated plans, and (3) using heuristic
search over actions. Our extensive evaluations show that our model surpasses
other LLM planning approaches.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2308.12503v2' target='_blank'>CGMI: Configurable General Multi-Agent Interaction Framework</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shi Jinxin, Zhao Jiabao, Wang Yilei, Wu Xingjiao, Li Jiawen, He Liang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-08-24 02:03:29</h6>
<p class='card-text'>Benefiting from the powerful capabilities of large language models (LLMs),
agents based on LLMs have shown the potential to address domain-specific tasks
and emulate human behaviors. However, the content generated by these agents
remains somewhat superficial, owing to their limited domain expertise and the
absence of an effective cognitive architecture. To address this, we present the
Configurable General Multi-Agent Interaction (CGMI) framework, designed to
replicate human interactions in real-world scenarios. Specifically, we propose
a tree-structured methodology for the assignment, detection, and maintenance of
agent personality. Additionally, we designed a cognitive architecture equipped
with a skill library based on the ACT* model, which contains memory,
reflection, and planning modules. We have also integrated general agents to
augment the virtual environment's realism. Using the CGMI framework, we
simulated numerous classroom interactions between teacher and students. The
experiments indicate that aspects such as the teaching methodology, curriculum,
and student performance closely mirror real classroom settings. We will open
source our work.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2308.12086v2' target='_blank'>Out of the Cage: How Stochastic Parrots Win in Cyber Security
  Environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Maria Rigaki, Ondřej Lukáš, Carlos A. Catania, Sebastian Garcia</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-08-23 12:11:27</h6>
<p class='card-text'>Large Language Models (LLMs) have gained widespread popularity across diverse
domains involving text generation, summarization, and various natural language
processing tasks. Despite their inherent limitations, LLM-based designs have
shown promising capabilities in planning and navigating open-world scenarios.
This paper introduces a novel application of pre-trained LLMs as agents within
cybersecurity network environments, focusing on their utility for sequential
decision-making processes.
  We present an approach wherein pre-trained LLMs are leveraged as attacking
agents in two reinforcement learning environments. Our proposed agents
demonstrate similar or better performance against state-of-the-art agents
trained for thousands of episodes in most scenarios and configurations. In
addition, the best LLM agents perform similarly to human testers of the
environment without any additional training process. This design highlights the
potential of LLMs to efficiently address complex decision-making tasks within
cybersecurity.
  Furthermore, we introduce a new network security environment named
NetSecGame. The environment is designed to eventually support complex
multi-agent scenarios within the network security domain. The proposed
environment mimics real network attacks and is designed to be highly modular
and adaptable for various scenarios.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2308.11914v4' target='_blank'>Towards CausalGPT: A Multi-Agent Approach for Faithful Knowledge
  Reasoning via Promoting Causal Consistency in LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ziyi Tang, Ruilin Wang, Weixing Chen, Yongsen Zheng, Zechuan Chen, Yang Liu, Keze Wang, Tianshui Chen, Liang Lin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-08-23 04:59:21</h6>
<p class='card-text'>Despite the progress of foundation models, knowledge-based reasoning remains
a persistent challenge due to their limited capacity for knowledge recall and
inference. Existing methods primarily focus on encouraging these models to plan
and solve problems or extensively sample reasoning chains independently.
However, these methods often overlook conceptual errors and inferential
fallacies, inevitably leading to a series of notorious issues such as
misleading conclusions, cognitive biases, and reduced decision quality. While
explicit modeling of causality is argued to hold promise in addressing these
issues, contemporary research efforts have thus far fallen short in achieving
causality-based foundation models. Drawing inspiration from the orchestration
of diverse specialized agents collaborating to tackle intricate tasks, we
propose a framework named Causal-Consistency Chain-of-Thought (CaCo-CoT) that
harnesses multi-agent collaboration to bolster the faithfulness and causality
of foundation models, involving a set of reasoners and evaluators. These agents
collaboratively work within a reasoning-and-consensus paradigm to improve
faithfulness. The reasoners are tasked with generating reasoning chains for
knowledge-intensive problems by mimicking human causal reasoning. Meanwhile,
the evaluator scrutinizes the causal consistency of a reasoner's reasoning
chain from a non-causal and a counterfactual perspective. Our framework
demonstrates significant superiority over state-of-the-art methods through
extensive and comprehensive evaluations across text-based and multi-modal
knowledge reasoning tasks (e.g., science question answering and commonsense
reasoning).</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2308.10380v2' target='_blank'>A Human-on-the-Loop Optimization Autoformalism Approach for
  Sustainability</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ming Jin, Bilgehan Sel, Fnu Hardeep, Wotao Yin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-08-20 22:42:04</h6>
<p class='card-text'>This paper outlines a natural conversational approach to solving personalized
energy-related problems using large language models (LLMs). We focus on
customizable optimization problems that necessitate repeated solving with
slight variations in modeling and are user-specific, hence posing a challenge
to devising a one-size-fits-all model. We put forward a strategy that augments
an LLM with an optimization solver, enhancing its proficiency in understanding
and responding to user specifications and preferences while providing nonlinear
reasoning capabilities. Our approach pioneers the novel concept of human-guided
optimization autoformalism, translating a natural language task specification
automatically into an optimization instance. This enables LLMs to analyze,
explain, and tackle a variety of instance-specific energy-related problems,
pushing beyond the limits of current prompt-based techniques.
  Our research encompasses various commonplace tasks in the energy sector, from
electric vehicle charging and Heating, Ventilation, and Air Conditioning (HVAC)
control to long-term planning problems such as cost-benefit evaluations for
installing rooftop solar photovoltaics (PVs) or heat pumps. This pilot study
marks an essential stride towards the context-based formulation of optimization
using LLMs, with the potential to democratize optimization processes. As a
result, stakeholders are empowered to optimize their energy consumption,
promoting sustainable energy practices customized to personal needs and
preferences.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2308.10141v1' target='_blank'>March in Chat: Interactive Prompting for Remote Embodied Referring
  Expression</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yanyuan Qiao, Yuankai Qi, Zheng Yu, Jing Liu, Qi Wu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-08-20 03:00:20</h6>
<p class='card-text'>Many Vision-and-Language Navigation (VLN) tasks have been proposed in recent
years, from room-based to object-based and indoor to outdoor. The REVERIE
(Remote Embodied Referring Expression) is interesting since it only provides
high-level instructions to the agent, which are closer to human commands in
practice. Nevertheless, this poses more challenges than other VLN tasks since
it requires agents to infer a navigation plan only based on a short
instruction. Large Language Models (LLMs) show great potential in robot action
planning by providing proper prompts. Still, this strategy has not been
explored under the REVERIE settings. There are several new challenges. For
example, the LLM should be environment-aware so that the navigation plan can be
adjusted based on the current visual observation. Moreover, the LLM planned
actions should be adaptable to the much larger and more complex REVERIE
environment. This paper proposes a March-in-Chat (MiC) model that can talk to
the LLM on the fly and plan dynamically based on a newly proposed
Room-and-Object Aware Scene Perceiver (ROASP). Our MiC model outperforms the
previous state-of-the-art by large margins by SPL and RGSPL metrics on the
REVERIE benchmark.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2308.09884v2' target='_blank'>A Transformer-based Framework For Multi-variate Time Series: A Remaining
  Useful Life Prediction Use Case</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Oluwaseyi Ogunfowora, Homayoun Najjaran</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-08-19 02:30:35</h6>
<p class='card-text'>In recent times, Large Language Models (LLMs) have captured a global
spotlight and revolutionized the field of Natural Language Processing. One of
the factors attributed to the effectiveness of LLMs is the model architecture
used for training, transformers. Transformer models excel at capturing
contextual features in sequential data since time series data are sequential,
transformer models can be leveraged for more efficient time series data
prediction. The field of prognostics is vital to system health management and
proper maintenance planning. A reliable estimation of the remaining useful life
(RUL) of machines holds the potential for substantial cost savings. This
includes avoiding abrupt machine failures, maximizing equipment usage, and
serving as a decision support system (DSS). This work proposed an
encoder-transformer architecture-based framework for multivariate time series
prediction for a prognostics use case. We validated the effectiveness of the
proposed framework on all four sets of the C-MAPPS benchmark dataset for the
remaining useful life prediction task. To effectively transfer the knowledge
and application of transformers from the natural language domain to time
series, three model-specific experiments were conducted. Also, to enable the
model awareness of the initial stages of the machine life and its degradation
path, a novel expanding window method was proposed for the first time in this
work, it was compared with the sliding window method, and it led to a large
improvement in the performance of the encoder transformer model. Finally, the
performance of the proposed encoder-transformer model was evaluated on the test
dataset and compared with the results from 13 other state-of-the-art (SOTA)
models in the literature and it outperformed them all with an average
performance increase of 137.65% over the next best model across all the
datasets.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2308.09658v2' target='_blank'>Tree-of-Mixed-Thought: Combining Fast and Slow Thinking for Multi-hop
  Visual Reasoning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Pengbo Hu, Ji Qi, Xingyu Li, Hong Li, Xinqi Wang, Bing Quan, Ruiyu Wang, Yi Zhou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-08-18 16:21:40</h6>
<p class='card-text'>There emerges a promising trend of using large language models (LLMs) to
generate code-like plans for complex inference tasks such as visual reasoning.
This paradigm, known as LLM-based planning, provides flexibility in problem
solving and endows better interpretability. However, current research is mostly
limited to basic scenarios of simple questions that can be straightforward
answered in a few inference steps. Planning for the more challenging multi-hop
visual reasoning tasks remains under-explored. Specifically, under multi-hop
reasoning situations, the trade-off between accuracy and the complexity of
plan-searching becomes prominent. The prevailing algorithms either address the
efficiency issue by employing the fast one-stop generation or adopt a complex
iterative generation method to improve accuracy. Both fail to balance the need
for efficiency and performance. Drawing inspiration from the dual system of
cognition in the human brain, the fast and the slow think processes, we propose
a hierarchical plan-searching algorithm that integrates the one-stop reasoning
(fast) and the Tree-of-thought (slow). Our approach succeeds in performance
while significantly saving inference steps. Moreover, we repurpose the PTR and
the CLEVER datasets, developing a systematic framework for evaluating the
performance and efficiency of LLMs-based plan-search algorithms under reasoning
tasks at different levels of difficulty. Extensive experiments demonstrate the
superiority of our proposed algorithm in terms of performance and efficiency.
The dataset and code will be release soon.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2308.08469v6' target='_blank'>LLM4TS: Aligning Pre-Trained LLMs as Data-Efficient Time-Series
  Forecasters</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ching Chang, Wei-Yao Wang, Wen-Chih Peng, Tien-Fu Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-08-16 16:19:50</h6>
<p class='card-text'>Multivariate time-series forecasting is vital in various domains, e.g.,
economic planning and weather prediction. Deep train-from-scratch models have
exhibited effective performance yet require large amounts of data, which limits
real-world applicability. Recently, researchers have leveraged the
representation learning transferability of pre-trained Large Language Models
(LLMs) to handle limited non-linguistic datasets effectively. However,
incorporating LLMs with time-series data presents challenges of limited
adaptation due to different compositions between time-series and linguistic
data, and the inability to process multi-scale temporal information. To tackle
these challenges, we propose LLM4TS, a framework for time-series forecasting
with pre-trained LLMs. LLM4TS consists of a two-stage fine-tuning strategy: the
time-series alignment stage to align LLMs with the nuances of time-series data,
and the forecasting fine-tuning stage for downstream time-series forecasting
tasks. Furthermore, our framework features a novel two-level aggregation method
that integrates multi-scale temporal data within pre-trained LLMs, enhancing
their ability to interpret time-specific information. In experiments across 7
time-series forecasting datasets, LLM4TS is superior to existing
state-of-the-art methods compared with trained-from-scratch models in full-shot
scenarios, and also achieves the highest rank in few-shot scenarios. In
addition, evaluations compared with different unsupervised representation
learning approaches highlight LLM4TS's effectiveness with representation
learning in forecasting tasks. Ablation studies further validate each
component's contribution to LLM4TS and underscore the essential role of
utilizing LLM's pre-trained weights for optimal performance. The code is
available at https://github.com/blacksnail789521/LLM4TS.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2308.06810v2' target='_blank'>Ground Manipulator Primitive Tasks to Executable Actions using Large
  Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yue Cao, C. S. George Lee</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-08-13 16:52:36</h6>
<p class='card-text'>Layered architectures have been widely used in robot systems. The majority of
them implement planning and execution functions in separate layers. However,
there still lacks a straightforward way to transit high-level tasks in the
planning layer to the low-level motor commands in the execution layer. In order
to tackle this challenge, we propose a novel approach to ground the manipulator
primitive tasks to robot low-level actions using large language models (LLMs).
We designed a program-function-like prompt based on the task frame formalism.
In this way, we enable LLMs to generate position/force set-points for hybrid
control. Evaluations over several state-of-the-art LLMs are provided.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2308.06391v1' target='_blank'>Dynamic Planning with a LLM</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Gautier Dagan, Frank Keller, Alex Lascarides</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-08-11 21:17:13</h6>
<p class='card-text'>While Large Language Models (LLMs) can solve many NLP tasks in zero-shot
settings, applications involving embodied agents remain problematic. In
particular, complex plans that require multi-step reasoning become difficult
and too costly as the context window grows. Planning requires understanding the
likely effects of one's actions and identifying whether the current environment
satisfies the goal state. While symbolic planners find optimal solutions
quickly, they require a complete and accurate representation of the planning
problem, severely limiting their use in practical scenarios. In contrast,
modern LLMs cope with noisy observations and high levels of uncertainty when
reasoning about a task. Our work presents LLM Dynamic Planner (LLM-DP): a
neuro-symbolic framework where an LLM works hand-in-hand with a traditional
planner to solve an embodied task. Given action-descriptions, LLM-DP solves
Alfworld faster and more efficiently than a naive LLM ReAct baseline.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2308.05345v3' target='_blank'>RTLLM: An Open-Source Benchmark for Design RTL Generation with Large
  Language Model</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yao Lu, Shang Liu, Qijun Zhang, Zhiyao Xie</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-08-10 05:24:41</h6>
<p class='card-text'>Inspired by the recent success of large language models (LLMs) like ChatGPT,
researchers start to explore the adoption of LLMs for agile hardware design,
such as generating design RTL based on natural-language instructions. However,
in existing works, their target designs are all relatively simple and in a
small scale, and proposed by the authors themselves, making a fair comparison
among different LLM solutions challenging. In addition, many prior works only
focus on the design correctness, without evaluating the design qualities of
generated design RTL. In this work, we propose an open-source benchmark named
RTLLM, for generating design RTL with natural language instructions. To
systematically evaluate the auto-generated design RTL, we summarized three
progressive goals, named syntax goal, functionality goal, and design quality
goal. This benchmark can automatically provide a quantitative evaluation of any
given LLM-based solution. Furthermore, we propose an easy-to-use yet
surprisingly effective prompt engineering technique named self-planning, which
proves to significantly boost the performance of GPT-3.5 in our proposed
benchmark.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2308.05177v1' target='_blank'>Fixing Rust Compilation Errors using LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Pantazis Deligiannis, Akash Lal, Nikita Mehrotra, Aseem Rastogi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-08-09 18:30:27</h6>
<p class='card-text'>The Rust programming language, with its safety guarantees, has established
itself as a viable choice for low-level systems programming language over the
traditional, unsafe alternatives like C/C++. These guarantees come from a
strong ownership-based type system, as well as primitive support for features
like closures, pattern matching, etc., that make the code more concise and
amenable to reasoning. These unique Rust features also pose a steep learning
curve for programmers.
  This paper presents a tool called RustAssistant that leverages the emergent
capabilities of Large Language Models (LLMs) to automatically suggest fixes for
Rust compilation errors. RustAssistant uses a careful combination of prompting
techniques as well as iteration with an LLM to deliver high accuracy of fixes.
RustAssistant is able to achieve an impressive peak accuracy of roughly 74% on
real-world compilation errors in popular open-source Rust repositories. We plan
to release our dataset of Rust compilation errors to enable further research.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2308.05095v2' target='_blank'>LayoutLLM-T2I: Eliciting Layout Guidance from LLM for Text-to-Image
  Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Leigang Qu, Shengqiong Wu, Hao Fei, Liqiang Nie, Tat-Seng Chua</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-08-09 17:45:04</h6>
<p class='card-text'>In the text-to-image generation field, recent remarkable progress in Stable
Diffusion makes it possible to generate rich kinds of novel photorealistic
images. However, current models still face misalignment issues (e.g.,
problematic spatial relation understanding and numeration failure) in complex
natural scenes, which impedes the high-faithfulness text-to-image generation.
Although recent efforts have been made to improve controllability by giving
fine-grained guidance (e.g., sketch and scribbles), this issue has not been
fundamentally tackled since users have to provide such guidance information
manually. In this work, we strive to synthesize high-fidelity images that are
semantically aligned with a given textual prompt without any guidance. Toward
this end, we propose a coarse-to-fine paradigm to achieve layout planning and
image generation. Concretely, we first generate the coarse-grained layout
conditioned on a given textual prompt via in-context learning based on Large
Language Models. Afterward, we propose a fine-grained object-interaction
diffusion method to synthesize high-faithfulness images conditioned on the
prompt and the automatically generated layout. Extensive experiments
demonstrate that our proposed method outperforms the state-of-the-art models in
terms of layout and image generation. Our code and settings are available at
https://layoutllm-t2i.github.io.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2308.04026v1' target='_blank'>AgentSims: An Open-Source Sandbox for Large Language Model Evaluation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiaju Lin, Haoran Zhao, Aochi Zhang, Yiting Wu, Huqiuyue Ping, Qin Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-08-08 03:59:28</h6>
<p class='card-text'>With ChatGPT-like large language models (LLM) prevailing in the community,
how to evaluate the ability of LLMs is an open question. Existing evaluation
methods suffer from following shortcomings: (1) constrained evaluation
abilities, (2) vulnerable benchmarks, (3) unobjective metrics. We suggest that
task-based evaluation, where LLM agents complete tasks in a simulated
environment, is a one-for-all solution to solve above problems. We present
AgentSims, an easy-to-use infrastructure for researchers from all disciplines
to test the specific capacities they are interested in. Researchers can build
their evaluation tasks by adding agents and buildings on an interactive GUI or
deploy and test new support mechanisms, i.e. memory, planning and tool-use
systems, by a few lines of codes. Our demo is available at
https://agentsims.com .</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2308.03427v3' target='_blank'>TPTU: Large Language Model-based AI Agents for Task Planning and Tool
  Usage</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jingqing Ruan, Yihong Chen, Bin Zhang, Zhiwei Xu, Tianpeng Bao, Guoqing Du, Shiwei Shi, Hangyu Mao, Ziyue Li, Xingyu Zeng, Rui Zhao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-08-07 09:22:03</h6>
<p class='card-text'>With recent advancements in natural language processing, Large Language
Models (LLMs) have emerged as powerful tools for various real-world
applications. Despite their prowess, the intrinsic generative abilities of LLMs
may prove insufficient for handling complex tasks which necessitate a
combination of task planning and the usage of external tools. In this paper, we
first propose a structured framework tailored for LLM-based AI Agents and
discuss the crucial capabilities necessary for tackling intricate problems.
Within this framework, we design two distinct types of agents (i.e., one-step
agent and sequential agent) to execute the inference process. Subsequently, we
instantiate the framework using various LLMs and evaluate their Task Planning
and Tool Usage (TPTU) abilities on typical tasks. By highlighting key findings
and challenges, our goal is to provide a helpful resource for researchers and
practitioners to leverage the power of LLMs in their AI applications. Our study
emphasizes the substantial potential of these models, while also identifying
areas that need more investigation and improvement.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2308.02151v3' target='_blank'>Retroformer: Retrospective Large Language Agents with Policy Gradient
  Optimization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Weiran Yao, Shelby Heinecke, Juan Carlos Niebles, Zhiwei Liu, Yihao Feng, Le Xue, Rithesh Murthy, Zeyuan Chen, Jianguo Zhang, Devansh Arpit, Ran Xu, Phil Mui, Huan Wang, Caiming Xiong, Silvio Savarese</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-08-04 06:14:23</h6>
<p class='card-text'>Recent months have seen the emergence of a powerful new trend in which large
language models (LLMs) are augmented to become autonomous language agents
capable of performing objective oriented multi-step tasks on their own, rather
than merely responding to queries from human users. Most existing language
agents, however, are not optimized using environment-specific rewards. Although
some agents enable iterative refinement through verbal feedback, they do not
reason and plan in ways that are compatible with gradient-based learning from
rewards. This paper introduces a principled framework for reinforcing large
language agents by learning a retrospective model, which automatically tunes
the language agent prompts from environment feedback through policy gradient.
Specifically, our proposed agent architecture learns from rewards across
multiple environments and tasks, for fine-tuning a pre-trained language model
which refines the language agent prompt by summarizing the root cause of prior
failed attempts and proposing action plans. Experimental results on various
tasks demonstrate that the language agents improve over time and that our
approach considerably outperforms baselines that do not properly leverage
gradients from the environment. This demonstrates that using policy gradient
optimization to improve language agents, for which we believe our work is one
of the first, seems promising and can be applied to optimize other models in
the agent architecture to enhance agent performances over time.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2307.16376v1' target='_blank'>When Large Language Models Meet Personalization: Perspectives of
  Challenges and Opportunities</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jin Chen, Zheng Liu, Xu Huang, Chenwang Wu, Qi Liu, Gangwei Jiang, Yuanhao Pu, Yuxuan Lei, Xiaolong Chen, Xingmei Wang, Defu Lian, Enhong Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-07-31 02:48:56</h6>
<p class='card-text'>The advent of large language models marks a revolutionary breakthrough in
artificial intelligence. With the unprecedented scale of training and model
parameters, the capability of large language models has been dramatically
improved, leading to human-like performances in understanding, language
synthesizing, and common-sense reasoning, etc. Such a major leap-forward in
general AI capacity will change the pattern of how personalization is
conducted. For one thing, it will reform the way of interaction between humans
and personalization systems. Instead of being a passive medium of information
filtering, large language models present the foundation for active user
engagement. On top of such a new foundation, user requests can be proactively
explored, and user's required information can be delivered in a natural and
explainable way. For another thing, it will also considerably expand the scope
of personalization, making it grow from the sole function of collecting
personalized information to the compound function of providing personalized
services. By leveraging large language models as general-purpose interface, the
personalization systems may compile user requests into plans, calls the
functions of external tools to execute the plans, and integrate the tools'
outputs to complete the end-to-end personalization tasks. Today, large language
models are still being developed, whereas the application in personalization is
largely unexplored. Therefore, we consider it to be the right time to review
the challenges in personalization and the opportunities to address them with
LLMs. In particular, we dedicate this perspective paper to the discussion of
the following aspects: the development and challenges for the existing
personalization system, the newly emerged capabilities of large language
models, and the potential ways of making use of large language models for
personalization.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2307.16368v3' target='_blank'>AntGPT: Can Large Language Models Help Long-term Action Anticipation
  from Videos?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Qi Zhao, Shijie Wang, Ce Zhang, Changcheng Fu, Minh Quan Do, Nakul Agarwal, Kwonjoon Lee, Chen Sun</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-07-31 02:14:19</h6>
<p class='card-text'>Can we better anticipate an actor's future actions (e.g. mix eggs) by knowing
what commonly happens after his/her current action (e.g. crack eggs)? What if
we also know the longer-term goal of the actor (e.g. making egg fried rice)?
The long-term action anticipation (LTA) task aims to predict an actor's future
behavior from video observations in the form of verb and noun sequences, and it
is crucial for human-machine interaction. We propose to formulate the LTA task
from two perspectives: a bottom-up approach that predicts the next actions
autoregressively by modeling temporal dynamics; and a top-down approach that
infers the goal of the actor and plans the needed procedure to accomplish the
goal. We hypothesize that large language models (LLMs), which have been
pretrained on procedure text data (e.g. recipes, how-tos), have the potential
to help LTA from both perspectives. It can help provide the prior knowledge on
the possible next actions, and infer the goal given the observed part of a
procedure, respectively. To leverage the LLMs, we propose a two-stage
framework, AntGPT. It first recognizes the actions already performed in the
observed videos and then asks an LLM to predict the future actions via
conditioned generation, or to infer the goal and plan the whole procedure by
chain-of-thought prompting. Empirical results on the Ego4D LTA v1 and v2
benchmarks, EPIC-Kitchens-55, as well as EGTEA GAZE+ demonstrate the
effectiveness of our proposed approach. AntGPT achieves state-of-the-art
performance on all above benchmarks, and can successfully infer the goal and
thus perform goal-conditioned "counterfactual" prediction via qualitative
analysis. Code and model will be released at
https://brown-palm.github.io/AntGPT</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2307.15337v3' target='_blank'>Skeleton-of-Thought: Prompting LLMs for Efficient Parallel Generation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xuefei Ning, Zinan Lin, Zixuan Zhou, Zifu Wang, Huazhong Yang, Yu Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-07-28 06:31:34</h6>
<p class='card-text'>This work aims at decreasing the end-to-end generation latency of large
language models (LLMs). One of the major causes of the high generation latency
is the sequential decoding approach adopted by almost all state-of-the-art
LLMs. In this work, motivated by the thinking and writing process of humans, we
propose Skeleton-of-Thought (SoT), which first guides LLMs to generate the
skeleton of the answer, and then conducts parallel API calls or batched
decoding to complete the contents of each skeleton point in parallel. Not only
does SoT provide considerable speed-ups across 12 LLMs, but it can also
potentially improve the answer quality on several question categories. SoT is
an initial attempt at data-centric optimization for inference efficiency, and
showcases the potential of eliciting high-quality answers by explicitly
planning the answer structure in language.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2307.14535v2' target='_blank'>Scaling Up and Distilling Down: Language-Guided Robot Skill Acquisition</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Huy Ha, Pete Florence, Shuran Song</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-07-26 22:52:43</h6>
<p class='card-text'>We present a framework for robot skill acquisition, which 1) efficiently
scale up data generation of language-labelled robot data and 2) effectively
distills this data down into a robust multi-task language-conditioned
visuo-motor policy. For (1), we use a large language model (LLM) to guide
high-level planning, and sampling-based robot planners (e.g. motion or grasp
samplers) for generating diverse and rich manipulation trajectories. To
robustify this data-collection process, the LLM also infers a code-snippet for
the success condition of each task, simultaneously enabling the data-collection
process to detect failure and retry as well as the automatic labeling of
trajectories with success/failure. For (2), we extend the diffusion policy
single-task behavior-cloning approach to multi-task settings with language
conditioning. Finally, we propose a new multi-task benchmark with 18 tasks
across five domains to test long-horizon behavior, common-sense reasoning,
tool-use, and intuitive physics. We find that our distilled policy successfully
learned the robust retrying behavior in its data collection procedure, while
improving absolute success rates by 33.2% on average across five domains. Code,
data, and additional qualitative results are available on
https://www.cs.columbia.edu/~huy/scalingup/.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2308.00121v3' target='_blank'>Getting pwn'd by AI: Penetration Testing with Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Andreas Happe, Jürgen Cito</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-07-24 19:59:22</h6>
<p class='card-text'>The field of software security testing, more specifically penetration
testing, is an activity that requires high levels of expertise and involves
many manual testing and analysis steps. This paper explores the potential usage
of large-language models, such as GPT3.5, to augment penetration testers with
AI sparring partners. We explore the feasibility of supplementing penetration
testers with AI models for two distinct use cases: high-level task planning for
security testing assignments and low-level vulnerability hunting within a
vulnerable virtual machine. For the latter, we implemented a closed-feedback
loop between LLM-generated low-level actions with a vulnerable virtual machine
(connected through SSH) and allowed the LLM to analyze the machine state for
vulnerabilities and suggest concrete attack vectors which were automatically
executed within the virtual machine. We discuss promising initial results,
detail avenues for improvement, and close deliberating on the ethics of
providing AI-based sparring partners.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2307.12856v4' target='_blank'>A Real-World WebAgent with Planning, Long Context Understanding, and
  Program Synthesis</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Izzeddin Gur, Hiroki Furuta, Austin Huang, Mustafa Safdari, Yutaka Matsuo, Douglas Eck, Aleksandra Faust</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-07-24 14:56:30</h6>
<p class='card-text'>Pre-trained large language models (LLMs) have recently achieved better
generalization and sample efficiency in autonomous web automation. However, the
performance on real-world websites has still suffered from (1) open domainness,
(2) limited context length, and (3) lack of inductive bias on HTML. We
introduce WebAgent, an LLM-driven agent that learns from self-experience to
complete tasks on real websites following natural language instructions.
WebAgent plans ahead by decomposing instructions into canonical
sub-instructions, summarizes long HTML documents into task-relevant snippets,
and acts on websites via Python programs generated from those. We design
WebAgent with Flan-U-PaLM, for grounded code generation, and HTML-T5, new
pre-trained LLMs for long HTML documents using local and global attention
mechanisms and a mixture of long-span denoising objectives, for planning and
summarization. We empirically demonstrate that our modular recipe improves the
success on real websites by over 50%, and that HTML-T5 is the best model to
solve various HTML understanding tasks; achieving 18.7% higher success rate
than the prior method on MiniWoB web automation benchmark, and SoTA performance
on Mind2Web, an offline task planning evaluation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2307.11922v1' target='_blank'>Selective Perception: Optimizing State Descriptions with Reinforcement
  Learning for Language Model Actors</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kolby Nottingham, Yasaman Razeghi, Kyungmin Kim, JB Lanier, Pierre Baldi, Roy Fox, Sameer Singh</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-07-21 22:02:50</h6>
<p class='card-text'>Large language models (LLMs) are being applied as actors for sequential
decision making tasks in domains such as robotics and games, utilizing their
general world knowledge and planning abilities. However, previous work does
little to explore what environment state information is provided to LLM actors
via language. Exhaustively describing high-dimensional states can impair
performance and raise inference costs for LLM actors. Previous LLM actors avoid
the issue by relying on hand-engineered, task-specific protocols to determine
which features to communicate about a state and which to leave out. In this
work, we propose Brief Language INputs for DEcision-making Responses (BLINDER),
a method for automatically selecting concise state descriptions by learning a
value function for task-conditioned state descriptions. We evaluate BLINDER on
the challenging video game NetHack and a robotic manipulation task. Our method
improves task success rate, reduces input size and compute costs, and
generalizes between LLM actors.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2307.11865v3' target='_blank'>CARTIER: Cartographic lAnguage Reasoning Targeted at Instruction
  Execution for Robots</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Dmitriy Rivkin, Nikhil Kakodkar, Francois Hogan, Bobak H. Baghi, Gregory Dudek</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-07-21 19:09:37</h6>
<p class='card-text'>This work explores the capacity of large language models (LLMs) to address
problems at the intersection of spatial planning and natural language
interfaces for navigation. We focus on following complex instructions that are
more akin to natural conversation than traditional explicit procedural
directives typically seen in robotics. Unlike most prior work where navigation
directives are provided as simple imperative commands (e.g., "go to the
fridge"), we examine implicit directives obtained through conversational
interactions.We leverage the 3D simulator AI2Thor to create household query
scenarios at scale, and augment it by adding complex language queries for 40
object types. We demonstrate that a robot using our method CARTIER
(Cartographic lAnguage Reasoning Targeted at Instruction Execution for Robots)
can parse descriptive language queries up to 42% more reliably than existing
LLM-enabled methods by exploiting the ability of LLMs to interpret the user
interaction in the context of the objects in the scenario.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2307.10432v3' target='_blank'>PharmacyGPT: The AI Pharmacist</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhengliang Liu, Zihao Wu, Mengxuan Hu, Bokai Zhao, Lin Zhao, Tianyi Zhang, Haixing Dai, Xianyan Chen, Ye Shen, Sheng Li, Quanzheng Li, Xiang Li, Brian Murray, Tianming Liu, Andrea Sikora</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-07-19 19:40:34</h6>
<p class='card-text'>In this study, we introduce PharmacyGPT, a novel framework to assess the
capabilities of large language models (LLMs) such as ChatGPT and GPT-4 in
emulating the role of clinical pharmacists. Our methodology encompasses the
utilization of LLMs to generate comprehensible patient clusters, formulate
medication plans, and forecast patient outcomes. We conduct our investigation
using real data acquired from the intensive care unit (ICU) at the University
of North Carolina Chapel Hill (UNC) Hospital. Our analysis offers valuable
insights into the potential applications and limitations of LLMs in the field
of clinical pharmacy, with implications for both patient care and the
development of future AI-driven healthcare solutions. By evaluating the
performance of PharmacyGPT, we aim to contribute to the ongoing discourse
surrounding the integration of artificial intelligence in healthcare settings,
ultimately promoting the responsible and efficacious use of such technologies.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2307.08985v1' target='_blank'>PromptCrafter: Crafting Text-to-Image Prompt through Mixed-Initiative
  Dialogue with LLM</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Seungho Baek, Hyerin Im, Jiseung Ryu, Juhyeong Park, Takyeon Lee</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-07-18 05:51:00</h6>
<p class='card-text'>Text-to-image generation model is able to generate images across a diverse
range of subjects and styles based on a single prompt. Recent works have
proposed a variety of interaction methods that help users understand the
capabilities of models and utilize them. However, how to support users to
efficiently explore the model's capability and to create effective prompts are
still open-ended research questions. In this paper, we present PromptCrafter, a
novel mixed-initiative system that allows step-by-step crafting of
text-to-image prompt. Through the iterative process, users can efficiently
explore the model's capability, and clarify their intent. PromptCrafter also
supports users to refine prompts by answering various responses to clarifying
questions generated by a Large Language Model. Lastly, users can revert to a
desired step by reviewing the work history. In this workshop paper, we discuss
the design process of PromptCrafter and our plans for follow-up studies.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2307.07930v1' target='_blank'>GeoGPT: Understanding and Processing Geospatial Tasks through An
  Autonomous GPT</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yifan Zhang, Cheng Wei, Shangyou Wu, Zhengting He, Wenhao Yu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-07-16 03:03:59</h6>
<p class='card-text'>Decision-makers in GIS need to combine a series of spatial algorithms and
operations to solve geospatial tasks. For example, in the task of facility
siting, the Buffer tool is usually first used to locate areas close or away
from some specific entities; then, the Intersect or Erase tool is used to
select candidate areas satisfied multiple requirements. Though professionals
can easily understand and solve these geospatial tasks by sequentially
utilizing relevant tools, it is difficult for non-professionals to handle these
problems. Recently, Generative Pre-trained Transformer (e.g., ChatGPT) presents
strong performance in semantic understanding and reasoning. Especially, AutoGPT
can further extend the capabilities of large language models (LLMs) by
automatically reasoning and calling externally defined tools. Inspired by these
studies, we attempt to lower the threshold of non-professional users to solve
geospatial tasks by integrating the semantic understanding ability inherent in
LLMs with mature tools within the GIS community. Specifically, we develop a new
framework called GeoGPT that can conduct geospatial data collection,
processing, and analysis in an autonomous manner with the instruction of only
natural language. In other words, GeoGPT is used to understand the demands of
non-professional users merely based on input natural language descriptions, and
then think, plan, and execute defined GIS tools to output final effective
results. Several cases including geospatial data crawling, spatial query,
facility siting, and mapping validate the effectiveness of our framework.
Though limited cases are presented in this paper, GeoGPT can be further
extended to various tasks by equipping with more GIS tools, and we think the
paradigm of "foundational plus professional" implied in GeoGPT provides an
effective way to develop next-generation GIS in this era of large foundation
models.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2307.07696v1' target='_blank'>Coupling Large Language Models with Logic Programming for Robust and
  General Reasoning from Text</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhun Yang, Adam Ishay, Joohyung Lee</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-07-15 03:29:59</h6>
<p class='card-text'>While large language models (LLMs), such as GPT-3, appear to be robust and
general, their reasoning ability is not at a level to compete with the best
models trained for specific natural language reasoning problems. In this study,
we observe that a large language model can serve as a highly effective few-shot
semantic parser. It can convert natural language sentences into a logical form
that serves as input for answer set programs, a logic-based declarative
knowledge representation formalism. The combination results in a robust and
general system that can handle multiple question-answering tasks without
requiring retraining for each new task. It only needs a few examples to guide
the LLM's adaptation to a specific task, along with reusable ASP knowledge
modules that can be applied to multiple tasks. We demonstrate that this method
achieves state-of-the-art performance on several NLP benchmarks, including
bAbI, StepGame, CLUTRR, and gSCAN. Additionally, it successfully tackles robot
planning tasks that an LLM alone fails to solve.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2307.06187v1' target='_blank'>Self-Adaptive Large Language Model (LLM)-Based Multiagent Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Nathalia Nascimento, Paulo Alencar, Donald Cowan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-07-12 14:26:46</h6>
<p class='card-text'>In autonomic computing, self-adaptation has been proposed as a fundamental
paradigm to manage the complexity of multiagent systems (MASs). This achieved
by extending a system with support to monitor and adapt itself to achieve
specific concerns of interest. Communication in these systems is key given that
in scenarios involving agent interaction, it enhances cooperation and reduces
coordination challenges by enabling direct, clear information exchange.
However, improving the expressiveness of the interaction communication with
MASs is not without challenges. In this sense, the interplay between
self-adaptive systems and effective communication is crucial for future MAS
advancements. In this paper, we propose the integration of large language
models (LLMs) such as GPT-based technologies into multiagent systems. We anchor
our methodology on the MAPE-K model, which is renowned for its robust support
in monitoring, analyzing, planning, and executing system adaptations in
response to dynamic environments. We also present a practical illustration of
the proposed approach, in which we implement and assess a basic MAS-based
application. The approach significantly advances the state-of-the-art of
self-adaptive systems by proposing a new paradigm for MAS self-adaptation of
autonomous systems based on LLM capabilities.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2307.06135v2' target='_blank'>SayPlan: Grounding Large Language Models using 3D Scene Graphs for
  Scalable Robot Task Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Krishan Rana, Jesse Haviland, Sourav Garg, Jad Abou-Chakra, Ian Reid, Niko Suenderhauf</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-07-12 12:37:55</h6>
<p class='card-text'>Large language models (LLMs) have demonstrated impressive results in
developing generalist planning agents for diverse tasks. However, grounding
these plans in expansive, multi-floor, and multi-room environments presents a
significant challenge for robotics. We introduce SayPlan, a scalable approach
to LLM-based, large-scale task planning for robotics using 3D scene graph
(3DSG) representations. To ensure the scalability of our approach, we: (1)
exploit the hierarchical nature of 3DSGs to allow LLMs to conduct a 'semantic
search' for task-relevant subgraphs from a smaller, collapsed representation of
the full graph; (2) reduce the planning horizon for the LLM by integrating a
classical path planner and (3) introduce an 'iterative replanning' pipeline
that refines the initial plan using feedback from a scene graph simulator,
correcting infeasible actions and avoiding planning failures. We evaluate our
approach on two large-scale environments spanning up to 3 floors and 36 rooms
with 140 assets and objects and show that our approach is capable of grounding
large-scale, long-horizon task plans from abstract, and natural language
instruction for a mobile manipulator robot to execute. We provide real robot
video demonstrations on our project page https://sayplan.github.io.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2307.05973v2' target='_blank'>VoxPoser: Composable 3D Value Maps for Robotic Manipulation with
  Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wenlong Huang, Chen Wang, Ruohan Zhang, Yunzhu Li, Jiajun Wu, Li Fei-Fei</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-07-12 07:40:48</h6>
<p class='card-text'>Large language models (LLMs) are shown to possess a wealth of actionable
knowledge that can be extracted for robot manipulation in the form of reasoning
and planning. Despite the progress, most still rely on pre-defined motion
primitives to carry out the physical interactions with the environment, which
remains a major bottleneck. In this work, we aim to synthesize robot
trajectories, i.e., a dense sequence of 6-DoF end-effector waypoints, for a
large variety of manipulation tasks given an open-set of instructions and an
open-set of objects. We achieve this by first observing that LLMs excel at
inferring affordances and constraints given a free-form language instruction.
More importantly, by leveraging their code-writing capabilities, they can
interact with a vision-language model (VLM) to compose 3D value maps to ground
the knowledge into the observation space of the agent. The composed value maps
are then used in a model-based planning framework to zero-shot synthesize
closed-loop robot trajectories with robustness to dynamic perturbations. We
further demonstrate how the proposed framework can benefit from online
experiences by efficiently learning a dynamics model for scenes that involve
contact-rich interactions. We present a large-scale study of the proposed
method in both simulated and real-robot environments, showcasing the ability to
perform a large variety of everyday manipulation tasks specified in free-form
natural language. Videos and code at https://voxposer.github.io</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2307.04738v1' target='_blank'>RoCo: Dialectic Multi-Robot Collaboration with Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhao Mandi, Shreeya Jain, Shuran Song</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-07-10 17:52:01</h6>
<p class='card-text'>We propose a novel approach to multi-robot collaboration that harnesses the
power of pre-trained large language models (LLMs) for both high-level
communication and low-level path planning. Robots are equipped with LLMs to
discuss and collectively reason task strategies. They then generate sub-task
plans and task space waypoint paths, which are used by a multi-arm motion
planner to accelerate trajectory planning. We also provide feedback from the
environment, such as collision checking, and prompt the LLM agents to improve
their plan and waypoints in-context. For evaluation, we introduce RoCoBench, a
6-task benchmark covering a wide range of multi-robot collaboration scenarios,
accompanied by a text-only dataset for agent representation and reasoning. We
experimentally demonstrate the effectiveness of our approach -- it achieves
high success rates across all tasks in RoCoBench and adapts to variations in
task semantics. Our dialog setup offers high interpretability and flexibility
-- in real world experiments, we show RoCo easily incorporates
human-in-the-loop, where a user can communicate and collaborate with a robot
agent to complete tasks together. See project website
https://project-roco.github.io for videos and code.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2307.02779v3' target='_blank'>Large Language Models Empowered Autonomous Edge AI for Connected
  Intelligence</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yifei Shen, Jiawei Shao, Xinjie Zhang, Zehong Lin, Hao Pan, Dongsheng Li, Jun Zhang, Khaled B. Letaief</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-07-06 05:16:55</h6>
<p class='card-text'>The evolution of wireless networks gravitates towards connected intelligence,
a concept that envisions seamless interconnectivity among humans, objects, and
intelligence in a hyper-connected cyber-physical world. Edge artificial
intelligence (Edge AI) is a promising solution to achieve connected
intelligence by delivering high-quality, low-latency, and privacy-preserving AI
services at the network edge. This article presents a vision of autonomous edge
AI systems that automatically organize, adapt, and optimize themselves to meet
users' diverse requirements, leveraging the power of large language models
(LLMs), i.e., Generative Pretrained Transformer (GPT). By exploiting the
powerful abilities of GPT in language understanding, planning, and code
generation, as well as incorporating classic wisdom such as task-oriented
communication and edge federated learning, we present a versatile framework
that efficiently coordinates edge AI models to cater to users' personal demands
while automatically generating code to train new models in a privacy-preserving
manner. Experimental results demonstrate the system's remarkable ability to
accurately comprehend user demands, efficiently execute AI models with minimal
cost, and effectively create high-performance AI models at edge servers.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2307.02757v1' target='_blank'>Wireless Multi-Agent Generative AI: From Connected Intelligence to
  Collective Intelligence</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hang Zou, Qiyang Zhao, Lina Bariah, Mehdi Bennis, Merouane Debbah</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-07-06 03:41:15</h6>
<p class='card-text'>The convergence of generative large language models (LLMs), edge networks,
and multi-agent systems represents a groundbreaking synergy that holds immense
promise for future wireless generations, harnessing the power of collective
intelligence and paving the way for self-governed networks where intelligent
decision-making happens right at the edge. This article puts the stepping-stone
for incorporating multi-agent generative artificial intelligence (AI) in
wireless networks, and sets the scene for realizing on-device LLMs, where
multi-agent LLMs are collaboratively planning and solving tasks to achieve a
number of network goals. We further investigate the profound limitations of
cloud-based LLMs, and explore multi-agent LLMs from a game theoretic
perspective, where agents collaboratively solve tasks in competitive
environments. Moreover, we establish the underpinnings for the architecture
design of wireless multi-agent generative AI systems at the network level and
the agent level, and we identify the wireless technologies that are envisioned
to play a key role in enabling on-device LLM. To demonstrate the promising
potentials of wireless multi-agent generative AI networks, we highlight the
benefits that can be achieved when implementing wireless generative agents in
intent-based networking, and we provide a case study to showcase how on-device
LLMs can contribute to solving network intents in a collaborative fashion. We
finally shed lights on potential challenges and sketch a research roadmap
towards realizing the vision of wireless collective intelligence.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2307.02485v2' target='_blank'>Building Cooperative Embodied Agents Modularly with Large Language
  Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hongxin Zhang, Weihua Du, Jiaming Shan, Qinhong Zhou, Yilun Du, Joshua B. Tenenbaum, Tianmin Shu, Chuang Gan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-07-05 17:59:27</h6>
<p class='card-text'>In this work, we address challenging multi-agent cooperation problems with
decentralized control, raw sensory observations, costly communication, and
multi-objective tasks instantiated in various embodied environments. While
previous research either presupposes a cost-free communication channel or
relies on a centralized controller with shared observations, we harness the
commonsense knowledge, reasoning ability, language comprehension, and text
generation prowess of LLMs and seamlessly incorporate them into a
cognitive-inspired modular framework that integrates with perception, memory,
and execution. Thus building a Cooperative Embodied Language Agent CoELA, who
can plan, communicate, and cooperate with others to accomplish long-horizon
tasks efficiently. Our experiments on C-WAH and TDW-MAT demonstrate that CoELA
driven by GPT-4 can surpass strong planning-based methods and exhibit emergent
effective communication. Though current Open LMs like LLAMA-2 still
underperform, we fine-tune a CoELA with data collected with our agents and show
how they can achieve promising performance. We also conducted a user study for
human-agent interaction and discovered that CoELA communicating in natural
language can earn more trust and cooperate more effectively with humans. Our
research underscores the potential of LLMs for future research in multi-agent
cooperation. Videos can be found on the project website
https://vis-www.cs.umass.edu/Co-LLM-Agents/.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2307.01928v2' target='_blank'>Robots That Ask For Help: Uncertainty Alignment for Large Language Model
  Planners</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Allen Z. Ren, Anushri Dixit, Alexandra Bodrova, Sumeet Singh, Stephen Tu, Noah Brown, Peng Xu, Leila Takayama, Fei Xia, Jake Varley, Zhenjia Xu, Dorsa Sadigh, Andy Zeng, Anirudha Majumdar</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-07-04 21:25:12</h6>
<p class='card-text'>Large language models (LLMs) exhibit a wide range of promising capabilities
-- from step-by-step planning to commonsense reasoning -- that may provide
utility for robots, but remain prone to confidently hallucinated predictions.
In this work, we present KnowNo, which is a framework for measuring and
aligning the uncertainty of LLM-based planners such that they know when they
don't know and ask for help when needed. KnowNo builds on the theory of
conformal prediction to provide statistical guarantees on task completion while
minimizing human help in complex multi-step planning settings. Experiments
across a variety of simulated and real robot setups that involve tasks with
different modes of ambiguity (e.g., from spatial to numeric uncertainties, from
human preferences to Winograd schemas) show that KnowNo performs favorably over
modern baselines (which may involve ensembles or extensive prompt tuning) in
terms of improving efficiency and autonomy, while providing formal assurances.
KnowNo can be used with LLMs out of the box without model-finetuning, and
suggests a promising lightweight approach to modeling uncertainty that can
complement and scale with the growing capabilities of foundation models.
Website: https://robot-help.github.io</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2307.01848v1' target='_blank'>Embodied Task Planning with Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhenyu Wu, Ziwei Wang, Xiuwei Xu, Jiwen Lu, Haibin Yan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-07-04 17:58:25</h6>
<p class='card-text'>Equipping embodied agents with commonsense is important for robots to
successfully complete complex human instructions in general environments.
Recent large language models (LLM) can embed rich semantic knowledge for agents
in plan generation of complex tasks, while they lack the information about the
realistic world and usually yield infeasible action sequences. In this paper,
we propose a TAsk Planing Agent (TaPA) in embodied tasks for grounded planning
with physical scene constraint, where the agent generates executable plans
according to the existed objects in the scene by aligning LLMs with the visual
perception models. Specifically, we first construct a multimodal dataset
containing triplets of indoor scenes, instructions and action plans, where we
provide the designed prompts and the list of existing objects in the scene for
GPT-3.5 to generate a large number of instructions and corresponding planned
actions. The generated data is leveraged for grounded plan tuning of
pre-trained LLMs. During inference, we discover the objects in the scene by
extending open-vocabulary object detectors to multi-view RGB images collected
in different achievable locations. Experimental results show that the generated
plan from our TaPA framework can achieve higher success rate than LLaVA and
GPT-3.5 by a sizable margin, which indicates the practicality of embodied task
planning in general and complex environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2307.00329v4' target='_blank'>DoReMi: Grounding Language Model by Detecting and Recovering from
  Plan-Execution Misalignment</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yanjiang Guo, Yen-Jen Wang, Lihan Zha, Jianyu Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-07-01 12:51:02</h6>
<p class='card-text'>Large language models (LLMs) encode a vast amount of semantic knowledge and
possess remarkable understanding and reasoning capabilities. Previous work has
explored how to ground LLMs in robotic tasks to generate feasible and
executable textual plans. However, low-level execution in the physical world
may deviate from the high-level textual plan due to environmental perturbations
or imperfect controller design. In this paper, we propose \textbf{DoReMi}, a
novel language model grounding framework that enables immediate Detection and
Recovery from Misalignments between plan and execution. Specifically, we
leverage LLMs to play a dual role, aiding not only in high-level planning but
also generating constraints that can indicate misalignment during execution.
Then vision language models (VLMs) are utilized to detect constraint violations
continuously. Our pipeline can monitor the low-level execution and enable
timely recovery if certain plan-execution misalignment occurs. Experiments on
various complex tasks including robot arms and humanoid robots demonstrate that
our method can lead to higher task success rates and shorter task completion
times. Videos of DoReMi are available at
\url{https://sites.google.com/view/doremi-paper}.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2306.17271v1' target='_blank'>DisasterResponseGPT: Large Language Models for Accelerated Plan of
  Action Development in Disaster Response Scenarios</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Vinicius G. Goecks, Nicholas R. Waytowich</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-06-29 19:24:19</h6>
<p class='card-text'>The development of plans of action in disaster response scenarios is a
time-consuming process. Large Language Models (LLMs) offer a powerful solution
to expedite this process through in-context learning. This study presents
DisasterResponseGPT, an algorithm that leverages LLMs to generate valid plans
of action quickly by incorporating disaster response and planning guidelines in
the initial prompt. In DisasterResponseGPT, users input the scenario
description and receive a plan of action as output. The proposed method
generates multiple plans within seconds, which can be further refined following
the user's feedback. Preliminary results indicate that the plans of action
developed by DisasterResponseGPT are comparable to human-generated ones while
offering greater ease of modification in real-time. This approach has the
potential to revolutionize disaster response operations by enabling rapid
updates and adjustments during the plan's execution.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2306.15724v4' target='_blank'>REFLECT: Summarizing Robot Experiences for Failure Explanation and
  Correction</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zeyi Liu, Arpit Bahety, Shuran Song</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-06-27 18:03:15</h6>
<p class='card-text'>The ability to detect and analyze failed executions automatically is crucial
for an explainable and robust robotic system. Recently, Large Language Models
(LLMs) have demonstrated strong reasoning abilities on textual inputs. To
leverage the power of LLMs for robot failure explanation, we introduce REFLECT,
a framework which queries LLM for failure reasoning based on a hierarchical
summary of robot past experiences generated from multisensory observations. The
failure explanation can further guide a language-based planner to correct the
failure and complete the task. To systematically evaluate the framework, we
create the RoboFail dataset with a variety of tasks and failure scenarios. We
demonstrate that the LLM-based framework is able to generate informative
failure explanations that assist successful correction planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2306.14898v3' target='_blank'>InterCode: Standardizing and Benchmarking Interactive Coding with
  Execution Feedback</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:John Yang, Akshara Prabhakar, Karthik Narasimhan, Shunyu Yao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-06-26 17:59:50</h6>
<p class='card-text'>Humans write code in a fundamentally interactive manner and rely on constant
execution feedback to correct errors, resolve ambiguities, and decompose tasks.
While LLMs have recently exhibited promising coding capabilities, current
coding benchmarks mostly consider a static instruction-to-code sequence
transduction process, which has the potential for error propagation and a
disconnect between the generated code and its final execution environment. To
address this gap, we introduce InterCode, a lightweight, flexible, and
easy-to-use framework of interactive coding as a standard reinforcement
learning (RL) environment, with code as actions and execution feedback as
observations. Our framework is language and platform agnostic, uses
self-contained Docker environments to provide safe and reproducible execution,
and is compatible out-of-the-box with traditional seq2seq coding methods, while
enabling the development of new methods for interactive code generation. We use
InterCode to create three interactive code environments with Bash, SQL, and
Python as action spaces, leveraging data from the static NL2Bash, Spider, and
MBPP datasets. We demonstrate InterCode's viability as a testbed by evaluating
multiple state-of-the-art LLMs configured with different prompting strategies
such as ReAct and Plan & Solve. Our results showcase the benefits of
interactive code generation and demonstrate that InterCode can serve as a
challenging benchmark for advancing code understanding and generation
capabilities. InterCode is designed to be easily extensible and can even be
used to create new tasks such as Capture the Flag, a popular coding puzzle that
is inherently multi-step and involves multiple programming languages. Project
site with code and data: https://intercode-benchmark.github.io</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2306.14325v2' target='_blank'>The Neuro-Symbolic Inverse Planning Engine (NIPE): Modeling
  Probabilistic Social Inferences from Linguistic Inputs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lance Ying, Katherine M. Collins, Megan Wei, Cedegao E. Zhang, Tan Zhi-Xuan, Adrian Weller, Joshua B. Tenenbaum, Lionel Wong</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-06-25 19:38:01</h6>
<p class='card-text'>Human beings are social creatures. We routinely reason about other agents,
and a crucial component of this social reasoning is inferring people's goals as
we learn about their actions. In many settings, we can perform intuitive but
reliable goal inference from language descriptions of agents, actions, and the
background environments. In this paper, we study this process of language
driving and influencing social reasoning in a probabilistic goal inference
domain. We propose a neuro-symbolic model that carries out goal inference from
linguistic inputs of agent scenarios. The "neuro" part is a large language
model (LLM) that translates language descriptions to code representations, and
the "symbolic" part is a Bayesian inverse planning engine. To test our model,
we design and run a human experiment on a linguistic goal inference task. Our
model closely matches human response patterns and better predicts human
judgements than using an LLM alone.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2306.12672v2' target='_blank'>From Word Models to World Models: Translating from Natural Language to
  the Probabilistic Language of Thought</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lionel Wong, Gabriel Grand, Alexander K. Lew, Noah D. Goodman, Vikash K. Mansinghka, Jacob Andreas, Joshua B. Tenenbaum</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-06-22 05:14:00</h6>
<p class='card-text'>How does language inform our downstream thinking? In particular, how do
humans make meaning from language--and how can we leverage a theory of
linguistic meaning to build machines that think in more human-like ways? In
this paper, we propose rational meaning construction, a computational framework
for language-informed thinking that combines neural language models with
probabilistic models for rational inference. We frame linguistic meaning as a
context-sensitive mapping from natural language into a probabilistic language
of thought (PLoT)--a general-purpose symbolic substrate for generative world
modeling. Our architecture integrates two computational tools that have not
previously come together: we model thinking with probabilistic programs, an
expressive representation for commonsense reasoning; and we model meaning
construction with large language models (LLMs), which support broad-coverage
translation from natural language utterances to code expressions in a
probabilistic programming language. We illustrate our framework through
examples covering four core domains from cognitive science: probabilistic
reasoning, logical and relational reasoning, visual and physical reasoning, and
social reasoning. In each, we show that LLMs can generate context-sensitive
translations that capture pragmatically-appropriate linguistic meanings, while
Bayesian inference with the generated programs supports coherent and robust
commonsense reasoning. We extend our framework to integrate
cognitively-motivated symbolic modules (physics simulators, graphics engines,
and planning algorithms) to provide a unified commonsense thinking interface
from language. Finally, we explore how language can drive the construction of
world models themselves. We hope this work will provide a roadmap towards
cognitive models and AI systems that synthesize the insights of both modern and
classical computational perspectives.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2306.08640v2' target='_blank'>AssistGPT: A General Multi-modal Assistant that can Plan, Execute,
  Inspect, and Learn</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Difei Gao, Lei Ji, Luowei Zhou, Kevin Qinghong Lin, Joya Chen, Zihan Fan, Mike Zheng Shou</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-06-14 17:12:56</h6>
<p class='card-text'>Recent research on Large Language Models (LLMs) has led to remarkable
advancements in general NLP AI assistants. Some studies have further explored
the use of LLMs for planning and invoking models or APIs to address more
general multi-modal user queries. Despite this progress, complex visual-based
tasks still remain challenging due to the diverse nature of visual tasks. This
diversity is reflected in two aspects: 1) Reasoning paths. For many real-life
applications, it is hard to accurately decompose a query simply by examining
the query itself. Planning based on the specific visual content and the results
of each step is usually required. 2) Flexible inputs and intermediate results.
Input forms could be flexible for in-the-wild cases, and involves not only a
single image or video but a mixture of videos and images, e.g., a user-view
image with some reference videos. Besides, a complex reasoning process will
also generate diverse multimodal intermediate results, e.g., video narrations,
segmented video clips, etc. To address such general cases, we propose a
multi-modal AI assistant, AssistGPT, with an interleaved code and language
reasoning approach called Plan, Execute, Inspect, and Learn (PEIL) to integrate
LLMs with various tools. Specifically, the Planner is capable of using natural
language to plan which tool in Executor should do next based on the current
reasoning progress. Inspector is an efficient memory manager to assist the
Planner to feed proper visual information into a specific tool. Finally, since
the entire reasoning process is complex and flexible, a Learner is designed to
enable the model to autonomously explore and discover the optimal solution. We
conducted experiments on A-OKVQA and NExT-QA benchmarks, achieving
state-of-the-art results. Moreover, showcases demonstrate the ability of our
system to handle questions far more complex than those found in the benchmarks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2306.07863v3' target='_blank'>Synapse: Trajectory-as-Exemplar Prompting with Memory for Computer
  Control</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Longtao Zheng, Rundong Wang, Xinrun Wang, Bo An</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-06-13 15:49:41</h6>
<p class='card-text'>Building agents with large language models (LLMs) for computer control is a
burgeoning research area, where the agent receives computer states and performs
actions to complete complex tasks. Previous computer agents have demonstrated
the benefits of in-context learning (ICL); however, their performance is
hindered by several issues. First, the limited context length of LLMs and
complex computer states restrict the number of exemplars, as a single webpage
can consume the entire context. Second, the exemplars in current methods, such
as high-level plans and multi-choice questions, cannot represent complete
trajectories, leading to suboptimal performance in long-horizon tasks. Third,
existing computer agents rely on task-specific exemplars and overlook the
similarity among tasks, resulting in poor generalization to novel tasks. To
address these challenges, we introduce Synapse, a computer agent featuring
three key components: i) state abstraction, which filters out task-irrelevant
information from raw states, allowing more exemplars within the limited
context, ii) trajectory-as-exemplar prompting, which prompts the LLM with
complete trajectories of the abstracted states and actions to improve
multi-step decision-making, and iii) exemplar memory, which stores the
embeddings of exemplars and retrieves them via similarity search for
generalization to novel tasks. We evaluate Synapse on MiniWoB++, a standard
task suite, and Mind2Web, a real-world website benchmark. In MiniWoB++, Synapse
achieves a 99.2% average success rate (a 10% relative improvement) across 64
tasks using demonstrations from only 48 tasks. Notably, Synapse is the first
ICL method to solve the book-flight task in MiniWoB++. Synapse also exhibits a
56% relative improvement in average step success rate over the previous
state-of-the-art prompting scheme in Mind2Web.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2306.07580v3' target='_blank'>SayTap: Language to Quadrupedal Locomotion</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yujin Tang, Wenhao Yu, Jie Tan, Heiga Zen, Aleksandra Faust, Tatsuya Harada</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-06-13 07:09:11</h6>
<p class='card-text'>Large language models (LLMs) have demonstrated the potential to perform
high-level planning. Yet, it remains a challenge for LLMs to comprehend
low-level commands, such as joint angle targets or motor torques. This paper
proposes an approach to use foot contact patterns as an interface that bridges
human commands in natural language and a locomotion controller that outputs
these low-level commands. This results in an interactive system for quadrupedal
robots that allows the users to craft diverse locomotion behaviors flexibly. We
contribute an LLM prompt design, a reward function, and a method to expose the
controller to the feasible distribution of contact patterns. The results are a
controller capable of achieving diverse locomotion patterns that can be
transferred to real robot hardware. Compared with other design choices, the
proposed approach enjoys more than 50% success rate in predicting the correct
contact patterns and can solve 10 more tasks out of a total of 30 tasks. Our
project site is: https://saytap.github.io.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2306.06767v2' target='_blank'>The Impact of ChatGPT and LLMs on Medical Imaging Stakeholders:
  Perspectives and Use Cases</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiancheng Yang, Hongwei Bran Li, Donglai Wei</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-06-11 20:39:13</h6>
<p class='card-text'>This study investigates the transformative potential of Large Language Models
(LLMs), such as OpenAI ChatGPT, in medical imaging. With the aid of public
data, these models, which possess remarkable language understanding and
generation capabilities, are augmenting the interpretive skills of
radiologists, enhancing patient-physician communication, and streamlining
clinical workflows. The paper introduces an analytic framework for presenting
the complex interactions between LLMs and the broader ecosystem of medical
imaging stakeholders, including businesses, insurance entities, governments,
research institutions, and hospitals (nicknamed BIGR-H). Through detailed
analyses, illustrative use cases, and discussions on the broader implications
and future directions, this perspective seeks to raise discussion in strategic
planning and decision-making in the era of AI-enabled healthcare.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2306.06624v2' target='_blank'>RestGPT: Connecting Large Language Models with Real-World RESTful APIs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yifan Song, Weimin Xiong, Dawei Zhu, Wenhao Wu, Han Qian, Mingbo Song, Hailiang Huang, Cheng Li, Ke Wang, Rong Yao, Ye Tian, Sujian Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-06-11 08:53:12</h6>
<p class='card-text'>Tool-augmented large language models (LLMs) have achieved remarkable progress
in tackling a broad range of tasks. However, existing methods are mainly
restricted to specifically designed tools and fail to fulfill complex
instructions, having great limitations when confronted with real-world
scenarios. In this paper, we explore a more realistic scenario by connecting
LLMs with RESTful APIs, which adhere to the widely adopted REST software
architectural style for web service development. To address the practical
challenges of tackling complex instructions, we propose RestGPT, which exploits
the power of LLMs and conducts a coarse-to-fine online planning mechanism to
enhance the abilities of task decomposition and API selection. RestGPT also
contains an API executor tailored for calling RESTful APIs, which can
meticulously formulate parameters and parse API responses. To fully evaluate
the performance of RestGPT, we propose RestBench, a high-quality benchmark
which consists of two real-world scenarios and human-annotated instructions
with gold solution paths. Experiments show that RestGPT is able to achieve
impressive results in complex tasks and has strong robustness, which paves a
new way towards AGI. RestGPT and RestBench is publicly available at
https://restgpt.github.io/.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2306.06531v3' target='_blank'>AutoTAMP: Autoregressive Task and Motion Planning with LLMs as
  Translators and Checkers</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yongchao Chen, Jacob Arkin, Charles Dawson, Yang Zhang, Nicholas Roy, Chuchu Fan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-06-10 21:58:29</h6>
<p class='card-text'>For effective human-robot interaction, robots need to understand, plan, and
execute complex, long-horizon tasks described by natural language. Recent
advances in large language models (LLMs) have shown promise for translating
natural language into robot action sequences for complex tasks. However,
existing approaches either translate the natural language directly into robot
trajectories or factor the inference process by decomposing language into task
sub-goals and relying on a motion planner to execute each sub-goal. When
complex environmental and temporal constraints are involved, inference over
planning tasks must be performed jointly with motion plans using traditional
task-and-motion planning (TAMP) algorithms, making factorization into subgoals
untenable. Rather than using LLMs to directly plan task sub-goals, we instead
perform few-shot translation from natural language task descriptions to an
intermediate task representation that can then be consumed by a TAMP algorithm
to jointly solve the task and motion plan. To improve translation, we
automatically detect and correct both syntactic and semantic errors via
autoregressive re-prompting, resulting in significant improvements in task
completion. We show that our approach outperforms several methods using LLMs as
planners in complex task domains. See our project website
https://yongchao98.github.io/MIT-REALM-AutoTAMP/ for prompts, videos, and code.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2306.05696v1' target='_blank'>Embodied Executable Policy Learning with Language-based Scene
  Summarization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jielin Qiu, Mengdi Xu, William Han, Seungwhan Moon, Ding Zhao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-06-09 06:34:09</h6>
<p class='card-text'>Large Language models (LLMs) have shown remarkable success in assisting robot
learning tasks, i.e., complex household planning. However, the performance of
pretrained LLMs heavily relies on domain-specific templated text data, which
may be infeasible in real-world robot learning tasks with image-based
observations. Moreover, existing LLMs with text inputs lack the capability to
evolve with non-expert interactions with environments. In this work, we
introduce a novel learning paradigm that generates robots' executable actions
in the form of text, derived solely from visual observations, using
language-based summarization of these observations as the connecting bridge
between both domains. Our proposed paradigm stands apart from previous works,
which utilized either language instructions or a combination of language and
visual data as inputs. Moreover, our method does not require oracle text
summarization of the scene, eliminating the need for human involvement in the
learning loop, which makes it more practical for real-world robot learning
tasks. Our proposed paradigm consists of two modules: the SUM module, which
interprets the environment using visual observations and produces a text
summary of the scene, and the APM module, which generates executable action
policies based on the natural language descriptions provided by the SUM module.
We demonstrate that our proposed method can employ two fine-tuning strategies,
including imitation learning and reinforcement learning approaches, to adapt to
the target test tasks effectively. We conduct extensive experiments involving
various SUM/APM model selections, environments, and tasks across 7 house
layouts in the VirtualHome environment. Our experimental results demonstrate
that our method surpasses existing baselines, confirming the effectiveness of
this novel learning paradigm.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2306.05171v1' target='_blank'>Robot Task Planning Based on Large Language Model Representing Knowledge
  with Directed Graph Structures</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yue Zhen, Sheng Bi, Lu Xing-tong, Pan Wei-qin, Shi Hai-peng, Chen Zi-rui, Fang Yi-shu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-06-08 13:10:00</h6>
<p class='card-text'>Traditional robot task planning methods face challenges when dealing with
highly unstructured environments and complex tasks. We propose a task planning
method that combines human expertise with an LLM and have designed an LLM
prompt template, Think_Net_Prompt, with stronger expressive power to represent
structured professional knowledge. We further propose a method to progressively
decompose tasks and generate a task tree to reduce the planning volume for each
task, and we have designed a strategy to decouple robot task planning. By
dividing different planning entities and separating the task from the actual
machine binding process, the task planning process becomes more flexible.
Research results show that our method performs well in handling specified code
formats, understanding the relationship between tasks and subtasks, and
extracting parameters from text descriptions. However, there are also problems
such as limited complexity of task logic handling, ambiguity in the quantity of
parts and the precise location of assembly. Improving the precision of task
description and cognitive structure can bring certain improvements.
https://github.com/NOMIzy/Think_Net_Prompt</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2306.03604v8' target='_blank'>Enabling Intelligent Interactions between an Agent and an LLM: A
  Reinforcement Learning Approach</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Bin Hu, Chenyang Zhao, Pu Zhang, Zihao Zhou, Yuanhang Yang, Zenglin Xu, Bin Liu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-06-06 11:49:09</h6>
<p class='card-text'>Large language models (LLMs) encode a vast amount of world knowledge acquired
from massive text datasets. Recent studies have demonstrated that LLMs can
assist an embodied agent in solving complex sequential decision making tasks by
providing high-level instructions. However, interactions with LLMs can be
time-consuming. In many practical scenarios, it requires a significant amount
of storage space that can only be deployed on remote cloud servers.
Additionally, using commercial LLMs can be costly since they may charge based
on usage frequency. In this paper, we explore how to enable intelligent
cost-effective interactions between a down stream task oriented agent and an
LLM. We find that this problem can be naturally formulated by a Markov decision
process (MDP), and propose When2Ask, a reinforcement learning based approach
that learns when it is necessary to query LLMs for high-level instructions to
accomplish a target task. On one side, When2Ask discourages unnecessary
redundant interactions, while on the other side, it enables the agent to
identify and follow useful instructions from the LLM. This enables the agent to
halt an ongoing plan and transition to a more suitable one based on new
environmental observations. Experiments on MiniGrid and Habitat environments
that entail planning sub-goals demonstrate that When2Ask learns to solve target
tasks with only a few necessary interactions with the LLM, significantly
reducing interaction costs in testing environments compared with baseline
methods. Our code is available at: https://github.com/ZJLAB-AMMI/LLM4RL.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2306.03197v1' target='_blank'>AutoScrum: Automating Project Planning Using Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Martin Schroder</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-06-05 19:16:37</h6>
<p class='card-text'>Recent advancements in the field of large language models have made it
possible to use language models for advanced reasoning. In this paper we
leverage this ability for designing complex project plans based only on knowing
the current state and the desired state. Two approaches are demonstrated - a
scrum based approach and a shortcut plan approach. The scrum based approach
executes an automated process of requirements gathering, user story mapping,
feature identification, task decomposition and finally generates questions and
search terms for seeking out domain specific information to assist with task
completion. The shortcut approach looks at most recent snapshot of the current
and desired state and generates the next most reasonable task to do in order to
get to the desired state as quickly as possible. In this paper we automate
everything using a novel concept of "Language Programs". These are programs
written in natural language designed to process input data through the language
model. Guidance language is used for all LLM programs. All demo source code for
this paper is available at https://github.com/autoscrum/autoscrum</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2306.02754v1' target='_blank'>PULSAR: Pre-training with Extracted Healthcare Terms for Summarising
  Patients' Problems and Data Augmentation with Black-box Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hao Li, Yuping Wu, Viktor Schlegel, Riza Batista-Navarro, Thanh-Tung Nguyen, Abhinav Ramesh Kashyap, Xiaojun Zeng, Daniel Beck, Stefan Winkler, Goran Nenadic</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-06-05 10:17:50</h6>
<p class='card-text'>Medical progress notes play a crucial role in documenting a patient's
hospital journey, including his or her condition, treatment plan, and any
updates for healthcare providers. Automatic summarisation of a patient's
problems in the form of a problem list can aid stakeholders in understanding a
patient's condition, reducing workload and cognitive bias. BioNLP 2023 Shared
Task 1A focuses on generating a list of diagnoses and problems from the
provider's progress notes during hospitalisation. In this paper, we introduce
our proposed approach to this task, which integrates two complementary
components. One component employs large language models (LLMs) for data
augmentation; the other is an abstractive summarisation LLM with a novel
pre-training objective for generating the patients' problems summarised as a
list. Our approach was ranked second among all submissions to the shared task.
The performance of our model on the development and test datasets shows that
our approach is more robust on unknown data, with an improvement of up to 3.1
points over the same size of the larger model.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2306.01295v1' target='_blank'>Egocentric Planning for Scalable Embodied Task Achievement</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xiaotian Liu, Hector Palacios, Christian Muise</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-06-02 06:41:24</h6>
<p class='card-text'>Embodied agents face significant challenges when tasked with performing
actions in diverse environments, particularly in generalizing across object
types and executing suitable actions to accomplish tasks. Furthermore, agents
should exhibit robustness, minimizing the execution of illegal actions. In this
work, we present Egocentric Planning, an innovative approach that combines
symbolic planning and Object-oriented POMDPs to solve tasks in complex
environments, harnessing existing models for visual perception and natural
language processing. We evaluated our approach in ALFRED, a simulated
environment designed for domestic tasks, and demonstrated its high scalability,
achieving an impressive 36.07% unseen success rate in the ALFRED benchmark and
winning the ALFRED challenge at CVPR Embodied AI workshop. Our method requires
reliable perception and the specification or learning of a symbolic description
of the preconditions and effects of the agent's actions, as well as what object
types reveal information about others. It is capable of naturally scaling to
solve new tasks beyond ALFRED, as long as they can be solved using the
available skills. This work offers a solid baseline for studying end-to-end and
hybrid methods that aim to generalize to new tasks, including recent approaches
relying on LLMs, but often struggle to scale to long sequences of actions or
produce robust plans for novel tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2305.19472v3' target='_blank'>PlaSma: Making Small Language Models Better Procedural Knowledge Models
  for (Counterfactual) Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Faeze Brahman, Chandra Bhagavatula, Valentina Pyatkin, Jena D. Hwang, Xiang Lorraine Li, Hirona J. Arai, Soumya Sanyal, Keisuke Sakaguchi, Xiang Ren, Yejin Choi</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-05-31 00:55:40</h6>
<p class='card-text'>Procedural planning, which entails decomposing a high-level goal into a
sequence of temporally ordered steps, is an important yet intricate task for
machines. It involves integrating common-sense knowledge to reason about
complex and often contextualized situations, e.g. ``scheduling a doctor's
appointment without a phone''. While current approaches show encouraging
results using large language models (LLMs), they are hindered by drawbacks such
as costly API calls and reproducibility issues. In this paper, we advocate
planning using smaller language models. We present PlaSma, a novel two-pronged
approach to endow small language models with procedural knowledge and
(constrained) language planning capabilities. More concretely, we develop
symbolic procedural knowledge distillation to enhance the commonsense knowledge
in small language models and an inference-time algorithm to facilitate more
structured and accurate reasoning. In addition, we introduce a new related
task, Replanning, that requires a revision of a plan to cope with a constrained
situation. In both the planning and replanning settings, we show that
orders-of-magnitude smaller models (770M-11B parameters) can compete and often
surpass their larger teacher models' capabilities. Finally, we showcase
successful application of PlaSma in an embodied environment, VirtualHome.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2305.19308v2' target='_blank'>SheetCopilot: Bringing Software Productivity to the Next Level through
  Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hongxin Li, Jingran Su, Yuntao Chen, Qing Li, Zhaoxiang Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-05-30 17:59:30</h6>
<p class='card-text'>Computer end users have spent billions of hours completing daily tasks like
tabular data processing and project timeline scheduling. Most of these tasks
are repetitive and error-prone, yet most end users lack the skill to automate
these burdensome works. With the advent of large language models (LLMs),
directing software with natural language user requests become a reachable goal.
In this work, we propose a SheetCopilot agent that takes natural language task
and control spreadsheet to fulfill the requirements. We propose a set of atomic
actions as an abstraction of spreadsheet software functionalities. We further
design a state machine-based task planning framework for LLMs to robustly
interact with spreadsheets. We curate a representative dataset containing 221
spreadsheet control tasks and establish a fully automated evaluation pipeline
for rigorously benchmarking the ability of LLMs in software control tasks. Our
SheetCopilot correctly completes 44.3\% of tasks for a single generation,
outperforming the strong code generation baseline by a wide margin. Our project
page:https://sheetcopilot.github.io/.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2305.19234v3' target='_blank'>Grammar Prompting for Domain-Specific Language Generation with Large
  Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Bailin Wang, Zi Wang, Xuezhi Wang, Yuan Cao, Rif A. Saurous, Yoon Kim</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-05-30 17:26:01</h6>
<p class='card-text'>Large language models (LLMs) can learn to perform a wide range of natural
language tasks from just a handful of in-context examples. However, for
generating strings from highly structured languages (e.g., semantic parsing to
complex domain-specific languages), it is challenging for the LLM to generalize
from just a few exemplars. We propose \emph{grammar prompting}, a simple
approach to enable LLMs to use external knowledge and domain-specific
constraints, expressed through a grammar in Backus--Naur Form (BNF), during
in-context learning. Grammar prompting augments each demonstration example with
a specialized grammar that is minimally sufficient for generating the
particular output example, where the specialized grammar is a subset of the
full DSL grammar. For inference, the LLM first predicts a BNF grammar given a
test input, and then generates the output according to the rules of the
grammar. Experiments demonstrate that grammar prompting can enable LLMs to
perform competitively on a diverse set of DSL generation tasks, including
semantic parsing (SMCalFlow, Overnight, GeoQuery), PDDL planning, and
SMILES-based molecule generation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2305.18898v1' target='_blank'>AlphaBlock: Embodied Finetuning for Vision-Language Reasoning in Robot
  Manipulation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chuhao Jin, Wenhui Tan, Jiange Yang, Bei Liu, Ruihua Song, Limin Wang, Jianlong Fu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-05-30 09:54:20</h6>
<p class='card-text'>We propose a novel framework for learning high-level cognitive capabilities
in robot manipulation tasks, such as making a smiley face using building
blocks. These tasks often involve complex multi-step reasoning, presenting
significant challenges due to the limited paired data connecting human
instructions (e.g., making a smiley face) and robot actions (e.g., end-effector
movement). Existing approaches relieve this challenge by adopting an open-loop
paradigm decomposing high-level instructions into simple sub-task plans, and
executing them step-by-step using low-level control models. However, these
approaches are short of instant observations in multi-step reasoning, leading
to sub-optimal results. To address this issue, we propose to automatically
collect a cognitive robot dataset by Large Language Models (LLMs). The
resulting dataset AlphaBlock consists of 35 comprehensive high-level tasks of
multi-step text plans and paired observation sequences. To enable efficient
data acquisition, we employ elaborated multi-round prompt designs that
effectively reduce the burden of extensive human involvement. We further
propose a closed-loop multi-modal embodied planning model that autoregressively
generates plans by taking image observations as input. To facilitate effective
learning, we leverage MiniGPT-4 with a frozen visual encoder and LLM, and
finetune additional vision adapter and Q-former to enable fine-grained spatial
perception for manipulation tasks. We conduct experiments to verify the
superiority over existing open and closed-loop methods, and achieve a
significant increase in success rate by 21.4% and 14.5% over ChatGPT and GPT-4
based robot tasks. Real-world demos are shown in
https://www.youtube.com/watch?v=ayAzID1_qQk .</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2305.17590v2' target='_blank'>Integrating Action Knowledge and LLMs for Task Planning and Situation
  Handling in Open Worlds</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yan Ding, Xiaohan Zhang, Saeid Amiri, Nieqing Cao, Hao Yang, Andy Kaminski, Chad Esselink, Shiqi Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-05-27 22:30:15</h6>
<p class='card-text'>Task planning systems have been developed to help robots use human knowledge
(about actions) to complete long-horizon tasks. Most of them have been
developed for "closed worlds" while assuming the robot is provided with
complete world knowledge. However, the real world is generally open, and the
robots frequently encounter unforeseen situations that can potentially break
the planner's completeness. Could we leverage the recent advances on
pre-trained Large Language Models (LLMs) to enable classical planning systems
to deal with novel situations?
  This paper introduces a novel framework, called COWP, for open-world task
planning and situation handling. COWP dynamically augments the robot's action
knowledge, including the preconditions and effects of actions, with
task-oriented commonsense knowledge. COWP embraces the openness from LLMs, and
is grounded to specific domains via action knowledge. For systematic
evaluations, we collected a dataset that includes 1,085 execution-time
situations. Each situation corresponds to a state instance wherein a robot is
potentially unable to complete a task using a solution that normally works.
Experimental results show that our approach outperforms competitive baselines
from the literature in the success rate of service tasks. Additionally, we have
demonstrated COWP using a mobile manipulator. Supplementary materials are
available at: https://cowplanning.github.io/</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2305.17390v2' target='_blank'>SwiftSage: A Generative Agent with Fast and Slow Thinking for Complex
  Interactive Tasks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Bill Yuchen Lin, Yicheng Fu, Karina Yang, Faeze Brahman, Shiyu Huang, Chandra Bhagavatula, Prithviraj Ammanabrolu, Yejin Choi, Xiang Ren</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-05-27 07:04:15</h6>
<p class='card-text'>We introduce SwiftSage, a novel agent framework inspired by the dual-process
theory of human cognition, designed to excel in action planning for complex
interactive reasoning tasks. SwiftSage integrates the strengths of behavior
cloning and prompting large language models (LLMs) to enhance task completion
performance. The framework comprises two primary modules: the Swift module,
representing fast and intuitive thinking, and the Sage module, emulating
deliberate thought processes. The Swift module is a small encoder-decoder LM
fine-tuned on the oracle agent's action trajectories, while the Sage module
employs LLMs such as GPT-4 for subgoal planning and grounding. We develop a
heuristic method to harmoniously integrate the two modules, resulting in a more
efficient and robust problem-solving process. In 30 tasks from the ScienceWorld
benchmark, SwiftSage significantly outperforms other methods such as SayCan,
ReAct, and Reflexion, demonstrating its effectiveness in solving complex
interactive tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2305.17077v1' target='_blank'>Learning and Leveraging Verifiers to Improve Planning Capabilities of
  Pre-trained Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Daman Arora, Subbarao Kambhampati</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-05-26 16:36:55</h6>
<p class='card-text'>There have been wide spread claims in the literature about the emergent
reasoning capabilities of Pretrained Large Language Models. However, recent
studies, have found that their ability to plan remains questionable. Through
our experiments using GPT-2, we empirically demonstrate that the performance of
a finetuned baseline remains poor because it violates pre-conditions of actions
in the plans that it generates. To improve the planning capabilities of a
finetuned LLM, we train a verifier, which can classify actions as being valid
or invalid in a particular state. By randomly sampling actions from the same
dataset, we generate examples of invalid actions which are then used to train a
verifier which can check for action applicability. In the presence of diverse
sampling from a generator and a verifier which can prune invalid trajectories,
we show significant gains in the success rate on the Blocksworld domain.
Additionally, we show that finetuning the GPT-2 generator itself to create the
verifier generalizes better than finetuning the base GPT-2. Lastly, we
investigate the role of the sampling temperature which can be used to control
the exploration-exploitation tradeoff.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2305.16986v3' target='_blank'>NavGPT: Explicit Reasoning in Vision-and-Language Navigation with Large
  Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Gengze Zhou, Yicong Hong, Qi Wu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-05-26 14:41:06</h6>
<p class='card-text'>Trained with an unprecedented scale of data, large language models (LLMs)
like ChatGPT and GPT-4 exhibit the emergence of significant reasoning abilities
from model scaling. Such a trend underscored the potential of training LLMs
with unlimited language data, advancing the development of a universal embodied
agent. In this work, we introduce the NavGPT, a purely LLM-based
instruction-following navigation agent, to reveal the reasoning capability of
GPT models in complex embodied scenes by performing zero-shot sequential action
prediction for vision-and-language navigation (VLN). At each step, NavGPT takes
the textual descriptions of visual observations, navigation history, and future
explorable directions as inputs to reason the agent's current status, and makes
the decision to approach the target. Through comprehensive experiments, we
demonstrate NavGPT can explicitly perform high-level planning for navigation,
including decomposing instruction into sub-goal, integrating commonsense
knowledge relevant to navigation task resolution, identifying landmarks from
observed scenes, tracking navigation progress, and adapting to exceptions with
plan adjustment. Furthermore, we show that LLMs is capable of generating
high-quality navigational instructions from observations and actions along a
path, as well as drawing accurate top-down metric trajectory given the agent's
navigation history. Despite the performance of using NavGPT to zero-shot R2R
tasks still falling short of trained models, we suggest adapting multi-modality
inputs for LLMs to use as visual navigation agents and applying the explicit
reasoning of LLMs to benefit learning-based models.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2305.16653v1' target='_blank'>AdaPlanner: Adaptive Planning from Feedback with Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Haotian Sun, Yuchen Zhuang, Lingkai Kong, Bo Dai, Chao Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-05-26 05:52:27</h6>
<p class='card-text'>Large language models (LLMs) have recently demonstrated the potential in
acting as autonomous agents for sequential decision-making tasks. However, most
existing methods either take actions greedily without planning or rely on
static plans that are not adaptable to environmental feedback. Consequently,
the sequential decision-making performance of LLM agents degenerates with
problem complexity and plan horizons increase. We propose a closed-loop
approach, AdaPlanner, which allows the LLM agent to refine its self-generated
plan adaptively in response to environmental feedback. In AdaPlanner, the LLM
agent adaptively refines its plan from feedback with both in-plan and
out-of-plan refinement strategies. To mitigate hallucination, we develop a
code-style LLM prompt structure that facilitates plan generation across a
variety of tasks, environments, and agent capabilities. Furthermore, we propose
a skill discovery mechanism that leverages successful plans as few-shot
exemplars, enabling the agent to plan and refine with fewer task
demonstrations. Our experiments in the ALFWorld and MiniWoB++ environments
demonstrate that AdaPlanner outperforms state-of-the-art baselines by 3.73% and
4.11% while utilizing 2x and 600x fewer samples, respectively.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2305.17144v2' target='_blank'>Ghost in the Minecraft: Generally Capable Agents for Open-World
  Environments via Large Language Models with Text-based Knowledge and Memory</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xizhou Zhu, Yuntao Chen, Hao Tian, Chenxin Tao, Weijie Su, Chenyu Yang, Gao Huang, Bin Li, Lewei Lu, Xiaogang Wang, Yu Qiao, Zhaoxiang Zhang, Jifeng Dai</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-05-25 17:59:49</h6>
<p class='card-text'>The captivating realm of Minecraft has attracted substantial research
interest in recent years, serving as a rich platform for developing intelligent
agents capable of functioning in open-world environments. However, the current
research landscape predominantly focuses on specific objectives, such as the
popular "ObtainDiamond" task, and has not yet shown effective generalization to
a broader spectrum of tasks. Furthermore, the current leading success rate for
the "ObtainDiamond" task stands at around 20%, highlighting the limitations of
Reinforcement Learning (RL) based controllers used in existing methods. To
tackle these challenges, we introduce Ghost in the Minecraft (GITM), a novel
framework integrates Large Language Models (LLMs) with text-based knowledge and
memory, aiming to create Generally Capable Agents (GCAs) in Minecraft. These
agents, equipped with the logic and common sense capabilities of LLMs, can
skillfully navigate complex, sparse-reward environments with text-based
interactions. We develop a set of structured actions and leverage LLMs to
generate action plans for the agents to execute. The resulting LLM-based agent
markedly surpasses previous methods, achieving a remarkable improvement of
+47.5% in success rate on the "ObtainDiamond" task, demonstrating superior
robustness compared to traditional RL-based controllers. Notably, our agent is
the first to procure all items in the Minecraft Overworld technology tree,
demonstrating its extensive capabilities. GITM does not need any GPU for
training, but a single CPU node with 32 CPU cores is enough. This research
shows the potential of LLMs in developing capable agents for handling
long-horizon, complex tasks and adapting to uncertainties in open-world
environments. See the project website at https://github.com/OpenGVLab/GITM.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2305.16151v1' target='_blank'>Understanding the Capabilities of Large Language Models for Automated
  Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Vishal Pallagani, Bharath Muppasani, Keerthiram Murugesan, Francesca Rossi, Biplav Srivastava, Lior Horesh, Francesco Fabiano, Andrea Loreggia</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-05-25 15:21:09</h6>
<p class='card-text'>Automated planning is concerned with developing efficient algorithms to
generate plans or sequences of actions to achieve a specific goal in a given
environment. Emerging Large Language Models (LLMs) can answer questions, write
high-quality programming code, and predict protein folding, showcasing their
versatility in solving various tasks beyond language-based problems. In this
paper, we aim to explore how LLMs can also be used for automated planning. To
do so, we seek to answer four key questions. Firstly, we want to understand the
extent to which LLMs can be used for plan generation. Secondly, we aim to
identify which pre-training data is most effective in facilitating plan
generation. Thirdly, we investigate whether fine-tuning or prompting is a more
effective approach for plan generation. Finally, we explore whether LLMs are
capable of plan generalization. By answering these questions, the study seeks
to shed light on the capabilities of LLMs in solving complex planning problems
and provide insights into the most effective approaches for using LLMs in this
context.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2305.15771v2' target='_blank'>On the Planning Abilities of Large Language Models : A Critical
  Investigation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Karthik Valmeekam, Matthew Marquez, Sarath Sreedharan, Subbarao Kambhampati</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-05-25 06:32:23</h6>
<p class='card-text'>Intrigued by the claims of emergent reasoning capabilities in LLMs trained on
general web corpora, in this paper, we set out to investigate their planning
capabilities. We aim to evaluate (1) the effectiveness of LLMs in generating
plans autonomously in commonsense planning tasks and (2) the potential of LLMs
in LLM-Modulo settings where they act as a source of heuristic guidance for
external planners and verifiers. We conduct a systematic study by generating a
suite of instances on domains similar to the ones employed in the International
Planning Competition and evaluate LLMs in two distinct modes: autonomous and
heuristic. Our findings reveal that LLMs' ability to generate executable plans
autonomously is rather limited, with the best model (GPT-4) having an average
success rate of ~12% across the domains. However, the results in the LLM-Modulo
setting show more promise. In the LLM-Modulo setting, we demonstrate that
LLM-generated plans can improve the search process for underlying sound
planners and additionally show that external verifiers can help provide
feedback on the generated plans and back-prompt the LLM for better plan
generation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2305.15393v2' target='_blank'>LayoutGPT: Compositional Visual Planning and Generation with Large
  Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Weixi Feng, Wanrong Zhu, Tsu-jui Fu, Varun Jampani, Arjun Akula, Xuehai He, Sugato Basu, Xin Eric Wang, William Yang Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-05-24 17:56:16</h6>
<p class='card-text'>Attaining a high degree of user controllability in visual generation often
requires intricate, fine-grained inputs like layouts. However, such inputs
impose a substantial burden on users when compared to simple text inputs. To
address the issue, we study how Large Language Models (LLMs) can serve as
visual planners by generating layouts from text conditions, and thus
collaborate with visual generative models. We propose LayoutGPT, a method to
compose in-context visual demonstrations in style sheet language to enhance the
visual planning skills of LLMs. LayoutGPT can generate plausible layouts in
multiple domains, ranging from 2D images to 3D indoor scenes. LayoutGPT also
shows superior performance in converting challenging language concepts like
numerical and spatial relations to layout arrangements for faithful
text-to-image generation. When combined with a downstream image generation
model, LayoutGPT outperforms text-to-image models/systems by 20-40% and
achieves comparable performance as human users in designing visual layouts for
numerical and spatial correctness. Lastly, LayoutGPT achieves comparable
performance to supervised methods in 3D indoor scene synthesis, demonstrating
its effectiveness and potential in multiple visual domains.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2305.15064v3' target='_blank'>AutoPlan: Automatic Planning of Interactive Decision-Making Tasks With
  Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Siqi Ouyang, Lei Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-05-24 11:52:23</h6>
<p class='card-text'>Recent large language models (LLMs) are promising for making decisions in
grounded environments. However, LLMs frequently fail in complex decision-making
tasks due to the misalignment between the pre-trained knowledge in LLMs and the
actual rules in the environment. Existing methods require either costly
gradient computation or lengthy in-context demonstrations. In this paper, we
propose AutoPlan, an approach to guide LLM-based agents to accomplish
interactive decision-making tasks. AutoPlan augments the LLM prompt with a
task-solving plan and optimizes it through iterative experience collection and
reflection. Our experiments show that AutoPlan, though using no in-context
demonstrations, achieves success rates on par with the baselines using
human-written demonstrations on ALFWorld and even outperforms them by 8% on
HotpotQA. The code is available at https://github.com/owaski/AutoPlan.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2305.15021v2' target='_blank'>EmbodiedGPT: Vision-Language Pre-Training via Embodied Chain of Thought</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yao Mu, Qinglong Zhang, Mengkang Hu, Wenhai Wang, Mingyu Ding, Jun Jin, Bin Wang, Jifeng Dai, Yu Qiao, Ping Luo</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-05-24 11:04:30</h6>
<p class='card-text'>Embodied AI is a crucial frontier in robotics, capable of planning and
executing action sequences for robots to accomplish long-horizon tasks in
physical environments. In this work, we introduce EmbodiedGPT, an end-to-end
multi-modal foundation model for embodied AI, empowering embodied agents with
multi-modal understanding and execution capabilities. To achieve this, we have
made the following efforts: (i) We craft a large-scale embodied planning
dataset, termed EgoCOT. The dataset consists of carefully selected videos from
the Ego4D dataset, along with corresponding high-quality language instructions.
Specifically, we generate a sequence of sub-goals with the "Chain of Thoughts"
mode for effective embodied planning. (ii) We introduce an efficient training
approach to EmbodiedGPT for high-quality plan generation, by adapting a 7B
large language model (LLM) to the EgoCOT dataset via prefix tuning. (iii) We
introduce a paradigm for extracting task-related features from LLM-generated
planning queries to form a closed loop between high-level planning and
low-level control. Extensive experiments show the effectiveness of EmbodiedGPT
on embodied tasks, including embodied planning, embodied control, visual
captioning, and visual question answering. Notably, EmbodiedGPT significantly
enhances the success rate of the embodied control task by extracting more
effective features. It has achieved a remarkable 1.6 times increase in success
rate on the Franka Kitchen benchmark and a 1.3 times increase on the Meta-World
benchmark, compared to the BLIP-2 baseline fine-tuned with the Ego4D dataset.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2305.14992v2' target='_blank'>Reasoning with Language Model is Planning with World Model</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, Daisy Zhe Wang, Zhiting Hu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-05-24 10:28:28</h6>
<p class='card-text'>Large language models (LLMs) have shown remarkable reasoning capabilities,
especially when prompted to generate intermediate reasoning steps (e.g.,
Chain-of-Thought, CoT). However, LLMs can still struggle with problems that are
easy for humans, such as generating action plans for executing tasks in a given
environment, or performing complex math, logical, and commonsense reasoning.
The deficiency stems from the key fact that LLMs lack an internal
$\textit{world model}$ to predict the world $\textit{state}$ (e.g., environment
status, intermediate variable values) and simulate long-term outcomes of
actions. This prevents LLMs from performing deliberate planning akin to human
brains, which involves exploring alternative reasoning paths, anticipating
future states and rewards, and iteratively refining existing reasoning steps.
To overcome the limitations, we propose a new LLM reasoning framework,
$\underline{R}$easoning vi$\underline{a}$ $\underline{P}$lanning
$\textbf{(RAP)}$. RAP repurposes the LLM as both a world model and a reasoning
agent, and incorporates a principled planning algorithm (based on Monto Carlo
Tree Search) for strategic exploration in the vast reasoning space. During
reasoning, the LLM (as agent) incrementally builds a reasoning tree under the
guidance of the LLM (as world model) and task-specific rewards, and obtains a
high-reward reasoning path efficiently with a proper balance between
exploration $\textit{vs.}$ exploitation. We apply RAP to a variety of
challenging reasoning problems including plan generation, math reasoning, and
logical inference. Empirical results on these tasks demonstrate the superiority
of RAP over various strong baselines, including CoT and least-to-most prompting
with self-consistency. RAP on LLAMA-33B surpasses CoT on GPT-4 with 33%
relative improvement in a plan generation setting.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2305.14909v2' target='_blank'>Leveraging Pre-trained Large Language Models to Construct and Utilize
  World Models for Model-based Task Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lin Guan, Karthik Valmeekam, Sarath Sreedharan, Subbarao Kambhampati</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-05-24 08:59:15</h6>
<p class='card-text'>There is a growing interest in applying pre-trained large language models
(LLMs) to planning problems. However, methods that use LLMs directly as
planners are currently impractical due to several factors, including limited
correctness of plans, strong reliance on feedback from interactions with
simulators or even the actual environment, and the inefficiency in utilizing
human feedback. In this work, we introduce a novel alternative paradigm that
constructs an explicit world (domain) model in planning domain definition
language (PDDL) and then uses it to plan with sound domain-independent
planners. To address the fact that LLMs may not generate a fully functional
PDDL model initially, we employ LLMs as an interface between PDDL and sources
of corrective feedback, such as PDDL validators and humans. For users who lack
a background in PDDL, we show that LLMs can translate PDDL into natural
language and effectively encode corrective feedback back to the underlying
domain model. Our framework not only enjoys the correctness guarantee offered
by the external planners but also reduces human involvement by allowing users
to correct domain models at the beginning, rather than inspecting and
correcting (through interactive prompting) every generated plan as in previous
work. On two IPC domains and a Household domain that is more complicated than
commonly used benchmarks such as ALFWorld, we demonstrate that GPT-4 can be
leveraged to produce high-quality PDDL models for over 40 actions, and the
corrected PDDL models are then used to successfully solve 48 challenging
planning tasks. Resources, including the source code, are released at:
https://guansuns.github.io/pages/llm-dm.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2305.14564v1' target='_blank'>PEARL: Prompting Large Language Models to Plan and Execute Actions Over
  Long Documents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Simeng Sun, Yang Liu, Shuohang Wang, Chenguang Zhu, Mohit Iyyer</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-05-23 23:06:04</h6>
<p class='card-text'>Strategies such as chain-of-thought prompting improve the performance of
large language models (LLMs) on complex reasoning tasks by decomposing input
examples into intermediate steps. However, it remains unclear how to apply such
methods to reason over long input documents, in which both the decomposition
and the output of each intermediate step are non-trivial to obtain. In this
work, we propose PEARL, a prompting framework to improve reasoning over long
documents, which consists of three stages: action mining, plan formulation, and
plan execution. More specifically, given a question about a long document,
PEARL decomposes the question into a sequence of actions (e.g., SUMMARIZE,
FIND_EVENT, FIND_RELATION) and then executes them over the document to obtain
the answer. Each stage of PEARL is implemented via zero-shot or few-shot
prompting of LLMs (in our work, GPT-4) with minimal human input. We evaluate
PEARL on a challenging subset of the QuALITY dataset, which contains questions
that require complex reasoning over long narrative texts. PEARL outperforms
zero-shot and chain-of-thought prompting on this dataset, and ablation
experiments show that each stage of PEARL is critical to its performance.
Overall, PEARL is a first step towards leveraging LLMs to reason over long
documents.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2305.14318v3' target='_blank'>CREATOR: Tool Creation for Disentangling Abstract and Concrete Reasoning
  of Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Cheng Qian, Chi Han, Yi R. Fung, Yujia Qin, Zhiyuan Liu, Heng Ji</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-05-23 17:51:52</h6>
<p class='card-text'>Large Language Models (LLMs) have made significant progress in utilizing
tools, but their ability is limited by API availability and the instability of
implicit reasoning, particularly when both planning and execution are involved.
To overcome these limitations, we propose CREATOR, a novel framework that
enables LLMs to create their own tools using documentation and code
realization. CREATOR disentangles abstract tool creation and concrete decision
execution, resulting in improved performance. We evaluate CREATOR on MATH and
TabMWP benchmarks, respectively consisting of challenging math competition
problems and diverse tabular contents. Remarkably, CREATOR outperforms existing
chain-of-thought, program-of-thought, and tool-using baselines. Additionally,
we introduce the Creation Challenge dataset, featuring 2K diverse questions, to
emphasize the necessity and benefits of LLMs' tool creation ability. Further
research demonstrates that leveraging LLMs as tool creators facilitates
knowledge transfer, and LLMs exhibit varying levels of tool creation abilities,
enabling them to adapt to diverse situations. The tool creation ability
revolutionizes the LLM's problem-solving paradigm, driving us closer to the
next frontier of artificial intelligence. All the codes and data are released.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2305.14078v2' target='_blank'>Large Language Models as Commonsense Knowledge for Large-Scale Task
  Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zirui Zhao, Wee Sun Lee, David Hsu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-05-23 13:56:31</h6>
<p class='card-text'>Large-scale task planning is a major challenge. Recent work exploits large
language models (LLMs) directly as a policy and shows surprisingly interesting
results. This paper shows that LLMs provide a commonsense model of the world in
addition to a policy that acts on it. The world model and the policy can be
combined in a search algorithm, such as Monte Carlo Tree Search (MCTS), to
scale up task planning. In our new LLM-MCTS algorithm, the LLM-induced world
model provides a commonsense prior belief for MCTS to achieve effective
reasoning; the LLM-induced policy acts as a heuristic to guide the search,
vastly improving search efficiency. Experiments show that LLM-MCTS outperforms
both MCTS alone and policies induced by LLMs (GPT2 and GPT3.5) by a wide
margin, for complex, novel tasks. Further experiments and analyses on multiple
tasks -- multiplication, multi-hop travel planning, object rearrangement --
suggest minimum description length (MDL) as a general guiding principle: if the
description length of the world model is substantially smaller than that of the
policy, using LLM as a world model for model-based planning is likely better
than using LLM solely as a policy.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2305.13626v2' target='_blank'>Prompting and Evaluating Large Language Models for Proactive Dialogues:
  Clarification, Target-guided, and Non-collaboration</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yang Deng, Lizi Liao, Liang Chen, Hongru Wang, Wenqiang Lei, Tat-Seng Chua</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-05-23 02:49:35</h6>
<p class='card-text'>Conversational systems based on Large Language Models (LLMs), such as
ChatGPT, show exceptional proficiency in context understanding and response
generation. However, despite their impressive capabilities, they still possess
limitations, such as providing randomly-guessed answers to ambiguous queries or
failing to refuse users' requests, both of which are considered aspects of a
conversational agent's proactivity. This raises the question of whether
LLM-based conversational systems are equipped to handle proactive dialogue
problems. In this work, we conduct a comprehensive analysis of LLM-based
conversational systems, specifically focusing on three aspects of proactive
dialogue systems: clarification, target-guided, and non-collaborative
dialogues. To trigger the proactivity of LLMs, we propose the Proactive
Chain-of-Thought prompting scheme, which augments LLMs with the goal planning
capability over descriptive reasoning chains. Empirical findings are discussed
to promote future studies on LLM-based proactive dialogue systems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2305.11554v4' target='_blank'>ToolkenGPT: Augmenting Frozen Language Models with Massive Tools via
  Tool Embeddings</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shibo Hao, Tianyang Liu, Zhen Wang, Zhiting Hu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-05-19 09:54:21</h6>
<p class='card-text'>Augmenting large language models (LLMs) with external tools has emerged as a
promising approach to solving complex problems. However, traditional methods,
which finetune LLMs with tool demonstration data, can be both costly and
restricted to a predefined set of tools. Recent in-context learning paradigm
alleviates these issues, but the limited context length only allows for a few
shots of demonstrations, leading to suboptimal understandings of the tools.
Moreover, when there are numerous tools to choose from, in-context learning
could completely fail to work. In this paper, we propose an alternative
approach, $\textbf{ToolkenGPT}$, which combines the benefits of both sides. Our
approach represents each $\underline{tool}$ as a to$\underline{ken}$
($\textit{toolken}$) and learns an embedding for it, enabling tool calls in the
same way as generating a regular word token. Once a toolken is triggered, the
LLM is prompted to complete arguments for the tool to execute. ToolkenGPT
offers the flexibility to plug in an arbitrary number of tools by expanding the
set of toolkens on the fly. In addition, it improves tool use by allowing
extensive demonstration data for learning the toolken embeddings. In diverse
domains, including numerical reasoning, knowledge-based question answering, and
embodied plan generation, our approach effectively augments LLMs with tools and
substantially outperforms various latest baselines. ToolkenGPT demonstrates the
promising ability to use relevant tools from a large tool set in complex
scenarios.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2305.11483v2' target='_blank'>Sensecape: Enabling Multilevel Exploration and Sensemaking with Large
  Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sangho Suh, Bryan Min, Srishti Palani, Haijun Xia</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-05-19 07:31:59</h6>
<p class='card-text'>People are increasingly turning to large language models (LLMs) for complex
information tasks like academic research or planning a move to another city.
However, while they often require working in a nonlinear manner -- e.g., to
arrange information spatially to organize and make sense of it, current
interfaces for interacting with LLMs are generally linear to support
conversational interaction. To address this limitation and explore how we can
support LLM-powered exploration and sensemaking, we developed Sensecape, an
interactive system designed to support complex information tasks with an LLM by
enabling users to (1) manage the complexity of information through multilevel
abstraction and (2) seamlessly switch between foraging and sensemaking. Our
within-subject user study reveals that Sensecape empowers users to explore more
topics and structure their knowledge hierarchically, thanks to the
externalization of levels of abstraction. We contribute implications for
LLM-based workflows and interfaces for information tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2305.11176v3' target='_blank'>Instruct2Act: Mapping Multi-modality Instructions to Robotic Actions
  with Large Language Model</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Siyuan Huang, Zhengkai Jiang, Hao Dong, Yu Qiao, Peng Gao, Hongsheng Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-05-18 17:59:49</h6>
<p class='card-text'>Foundation models have made significant strides in various applications,
including text-to-image generation, panoptic segmentation, and natural language
processing. This paper presents Instruct2Act, a framework that utilizes Large
Language Models to map multi-modal instructions to sequential actions for
robotic manipulation tasks. Specifically, Instruct2Act employs the LLM model to
generate Python programs that constitute a comprehensive perception, planning,
and action loop for robotic tasks. In the perception section, pre-defined APIs
are used to access multiple foundation models where the Segment Anything Model
(SAM) accurately locates candidate objects, and CLIP classifies them. In this
way, the framework leverages the expertise of foundation models and robotic
abilities to convert complex high-level instructions into precise policy codes.
Our approach is adjustable and flexible in accommodating various instruction
modalities and input types and catering to specific task demands. We validated
the practicality and efficiency of our approach by assessing it on robotic
tasks in different scenarios within tabletop manipulation domains. Furthermore,
our zero-shot method outperformed many state-of-the-art learning-based policies
in several tasks. The code for our proposed approach is available at
https://github.com/OpenGVLab/Instruct2Act, serving as a robust benchmark for
high-level robotic instruction tasks with assorted modality inputs.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2305.11014v2' target='_blank'>Generalized Planning in PDDL Domains with Pretrained Large Language
  Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tom Silver, Soham Dan, Kavitha Srinivas, Joshua B. Tenenbaum, Leslie Pack Kaelbling, Michael Katz</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-05-18 14:48:20</h6>
<p class='card-text'>Recent work has considered whether large language models (LLMs) can function
as planners: given a task, generate a plan. We investigate whether LLMs can
serve as generalized planners: given a domain and training tasks, generate a
program that efficiently produces plans for other tasks in the domain. In
particular, we consider PDDL domains and use GPT-4 to synthesize Python
programs. We also consider (1) Chain-of-Thought (CoT) summarization, where the
LLM is prompted to summarize the domain and propose a strategy in words before
synthesizing the program; and (2) automated debugging, where the program is
validated with respect to the training tasks, and in case of errors, the LLM is
re-prompted with four types of feedback. We evaluate this approach in seven
PDDL domains and compare it to four ablations and four baselines. Overall, we
find that GPT-4 is a surprisingly powerful generalized planner. We also
conclude that automated debugging is very important, that CoT summarization has
non-uniform impact, that GPT-4 is far superior to GPT-3.5, and that just two
training tasks are often sufficient for strong generalization.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2305.10601v2' target='_blank'>Tree of Thoughts: Deliberate Problem Solving with Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan Cao, Karthik Narasimhan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-05-17 23:16:17</h6>
<p class='card-text'>Language models are increasingly being deployed for general problem solving
across a wide range of tasks, but are still confined to token-level,
left-to-right decision-making processes during inference. This means they can
fall short in tasks that require exploration, strategic lookahead, or where
initial decisions play a pivotal role. To surmount these challenges, we
introduce a new framework for language model inference, Tree of Thoughts (ToT),
which generalizes over the popular Chain of Thought approach to prompting
language models, and enables exploration over coherent units of text (thoughts)
that serve as intermediate steps toward problem solving. ToT allows LMs to
perform deliberate decision making by considering multiple different reasoning
paths and self-evaluating choices to decide the next course of action, as well
as looking ahead or backtracking when necessary to make global choices. Our
experiments show that ToT significantly enhances language models'
problem-solving abilities on three novel tasks requiring non-trivial planning
or search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in
Game of 24, while GPT-4 with chain-of-thought prompting only solved 4% of
tasks, our method achieved a success rate of 74%. Code repo with all prompts:
https://github.com/princeton-nlp/tree-of-thought-llm.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2305.10276v7' target='_blank'>Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hanxu Hu, Hongyuan Lu, Huajian Zhang, Yun-Ze Song, Wai Lam, Yue Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-05-17 15:07:50</h6>
<p class='card-text'>In this paper, we take the initiative to investigate the performance of LLMs
on complex planning tasks that require LLMs to understand a virtual spatial
environment simulated via natural language and act correspondingly in text. We
propose a benchmark named Natural Language Planning and Action (Natala)
composed of a set of novel tasks: Brick World, NLVR-based Manipulations, and
Natural Language Navigation. We found that current popular LLMs such as ChatGPT
still lack abilities in complex planning. This arises a question -- do the LLMs
have a good understanding of the environments described in natural language, or
maybe other alternatives such as symbolic representations are neater and hence
better to be understood by LLMs? To this end, we propose a novel method called
CoS (Chain-of-Symbol Prompting) that represents the complex environments with
condensed symbolic spatial representations during the chained intermediate
thinking steps. CoS is easy to use and does not need additional training on
LLMs. Extensive experiments indicate that CoS clearly surpasses the performance
of the Chain-of-Thought (CoT) Prompting in all three planning tasks with even
fewer tokens used in the inputs compared with CoT on ChatGPT and InstructGPT.
The performance gain is strong, by up to 60.8% accuracy (from 31.8% to 92.6%)
on Brick World for ChatGPT. CoS also reduces the number of tokens in the prompt
obviously, by up to 65.8% of the tokens (from 407 to 139) for the intermediate
steps from demonstrations on Brick World. Code and data available at:
https://github.com/hanxuhu/chain-of-symbol-planning</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2305.10037v3' target='_blank'>Can Language Models Solve Graph Problems in Natural Language?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Heng Wang, Shangbin Feng, Tianxing He, Zhaoxuan Tan, Xiaochuang Han, Yulia Tsvetkov</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-05-17 08:29:21</h6>
<p class='card-text'>Large language models (LLMs) are increasingly adopted for a variety of tasks
with implicit graphical structures, such as planning in robotics, multi-hop
question answering or knowledge probing, structured commonsense reasoning, and
more. While LLMs have advanced the state-of-the-art on these tasks with
structure implications, whether LLMs could explicitly process textual
descriptions of graphs and structures, map them to grounded conceptual spaces,
and perform structured operations remains underexplored. To this end, we
propose NLGraph (Natural Language Graph), a comprehensive benchmark of
graph-based problem solving designed in natural language. NLGraph contains
29,370 problems, covering eight graph reasoning tasks with varying complexity
from simple tasks such as connectivity and shortest path up to complex problems
such as maximum flow and simulating graph neural networks. We evaluate LLMs
(GPT-3/4) with various prompting approaches on the NLGraph benchmark and find
that 1) language models do demonstrate preliminary graph reasoning abilities,
2) the benefit of advanced prompting and in-context learning diminishes on more
complex graph problems, while 3) LLMs are also (un)surprisingly brittle in the
face of spurious correlations in graph and problem settings. We then propose
Build-a-Graph Prompting and Algorithmic Prompting, two instruction-based
approaches to enhance LLMs in solving natural language graph problems.
Build-a-Graph and Algorithmic prompting improve the performance of LLMs on
NLGraph by 3.07% to 16.85% across multiple tasks and settings, while how to
solve the most complicated graph reasoning tasks in our setup with language
models remains an open research question. The NLGraph benchmark and evaluation
code are available at https://github.com/Arthur-Heng/NLGraph.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2305.09802v3' target='_blank'>Sasha: Creative Goal-Oriented Reasoning in Smart Homes with Large
  Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Evan King, Haoxiang Yu, Sangsu Lee, Christine Julien</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-05-16 20:52:04</h6>
<p class='card-text'>Smart home assistants function best when user commands are direct and
well-specified (e.g., "turn on the kitchen light"), or when a hard-coded
routine specifies the response. In more natural communication, however, human
speech is unconstrained, often describing goals (e.g., "make it cozy in here"
or "help me save energy") rather than indicating specific target devices and
actions to take on those devices. Current systems fail to understand these
under-specified commands since they cannot reason about devices and settings as
they relate to human situations. We introduce large language models (LLMs) to
this problem space, exploring their use for controlling devices and creating
automation routines in response to under-specified user commands in smart
homes. We empirically study the baseline quality and failure modes of
LLM-created action plans with a survey of age-diverse users. We find that LLMs
can reason creatively to achieve challenging goals, but they experience
patterns of failure that diminish their usefulness. We address these gaps with
Sasha, a smarter smart home assistant. Sasha responds to loosely-constrained
commands like "make it cozy" or "help me sleep better" by executing plans to
achieve user goals, e.g., setting a mood with available devices, or devising
automation routines. We implement and evaluate Sasha in a hands-on user study,
showing the capabilities and limitations of LLM-driven smart homes when faced
with unconstrained user-generated scenarios.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2305.09656v3' target='_blank'>SatLM: Satisfiability-Aided Language Models Using Declarative Prompting</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xi Ye, Qiaochu Chen, Isil Dillig, Greg Durrett</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-05-16 17:55:51</h6>
<p class='card-text'>Prior work has combined chain-of-thought prompting in large language models
(LLMs) with programmatic representations to perform effective and transparent
reasoning. While such an approach works well for tasks that only require
forward reasoning (e.g., straightforward arithmetic), it is less effective for
constraint solving problems that require more sophisticated planning and
search. In this paper, we propose a new satisfiability-aided language modeling
(SatLM) approach for improving the reasoning capabilities of LLMs. We use an
LLM to generate a declarative task specification rather than an imperative
program and leverage an off-the-shelf automated theorem prover to derive the
final answer. This approach has two key advantages. The declarative
specification is closer to the problem description than the reasoning steps
are, so the LLM can parse it out of the description more accurately.
Furthermore, by offloading the actual reasoning task to an automated theorem
prover, our approach can guarantee the correctness of the answer with respect
to the parsed specification and avoid planning errors in the solving process.
We evaluate SATLM on 8 different datasets and show that it consistently
outperforms program-aided LMs in the imperative paradigm. In particular, SATLM
outperforms program-aided LMs by 23% on a challenging subset of the GSM
arithmetic reasoning dataset; SATLM also achieves a new SoTA on LSAT and
BoardgameQA, surpassing previous models that are trained on the respective
training sets.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2305.08677v2' target='_blank'>Natural Language Decomposition and Interpretation of Complex Utterances</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Harsh Jhamtani, Hao Fang, Patrick Xia, Eran Levy, Jacob Andreas, Ben Van Durme</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-05-15 14:35:00</h6>
<p class='card-text'>Designing natural language interfaces has historically required collecting
supervised data to translate user requests into carefully designed intent
representations. This requires enumerating and labeling a long tail of user
requests, which is challenging. At the same time, large language models (LLMs)
encode knowledge about goals and plans that can help conversational assistants
interpret user requests requiring numerous steps to complete. We introduce an
approach to handle complex-intent-bearing utterances from a user via a process
of hierarchical natural language decomposition and interpretation. Our approach
uses a pre-trained language model to decompose a complex utterance into a
sequence of simpler natural language steps and interprets each step using the
language-to-program model designed for the interface. To test our approach, we
collect and release DeCU -- a new NL-to-program benchmark to evaluate
Decomposition of Complex Utterances. Experiments show that the proposed
approach enables the interpretation of complex utterances with almost no
complex training data, while outperforming standard few-shot prompting
approaches.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2305.07716v1' target='_blank'>Learning to Reason over Scene Graphs: A Case Study of Finetuning GPT-2
  into a Robot Language Model for Grounded Task Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Georgia Chalvatzaki, Ali Younes, Daljeet Nandha, An Le, Leonardo F. R. Ribeiro, Iryna Gurevych</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-05-12 18:14:32</h6>
<p class='card-text'>Long-horizon task planning is essential for the development of intelligent
assistive and service robots. In this work, we investigate the applicability of
a smaller class of large language models (LLMs), specifically GPT-2, in robotic
task planning by learning to decompose tasks into subgoal specifications for a
planner to execute sequentially. Our method grounds the input of the LLM on the
domain that is represented as a scene graph, enabling it to translate human
requests into executable robot plans, thereby learning to reason over
long-horizon tasks, as encountered in the ALFRED benchmark. We compare our
approach with classical planning and baseline methods to examine the
applicability and generalizability of LLM-based planners. Our findings suggest
that the knowledge stored in an LLM can be effectively grounded to perform
long-horizon task planning, demonstrating the promising potential for the
future application of neuro-symbolic planning methods in robotics.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2305.05662v4' target='_blank'>InternGPT: Solving Vision-Centric Tasks by Interacting with ChatGPT
  Beyond Language</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhaoyang Liu, Yinan He, Wenhai Wang, Weiyun Wang, Yi Wang, Shoufa Chen, Qinglong Zhang, Zeqiang Lai, Yang Yang, Qingyun Li, Jiashuo Yu, Kunchang Li, Zhe Chen, Xue Yang, Xizhou Zhu, Yali Wang, Limin Wang, Ping Luo, Jifeng Dai, Yu Qiao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-05-09 17:58:34</h6>
<p class='card-text'>We present an interactive visual framework named InternGPT, or iGPT for
short. The framework integrates chatbots that have planning and reasoning
capabilities, such as ChatGPT, with non-verbal instructions like pointing
movements that enable users to directly manipulate images or videos on the
screen. Pointing (including gestures, cursors, etc.) movements can provide more
flexibility and precision in performing vision-centric tasks that require
fine-grained control, editing, and generation of visual content. The name
InternGPT stands for \textbf{inter}action, \textbf{n}onverbal, and
\textbf{chat}bots. Different from existing interactive systems that rely on
pure language, by incorporating pointing instructions, the proposed iGPT
significantly improves the efficiency of communication between users and
chatbots, as well as the accuracy of chatbots in vision-centric tasks,
especially in complicated visual scenarios where the number of objects is
greater than 2. Additionally, in iGPT, an auxiliary control mechanism is used
to improve the control capability of LLM, and a large vision-language model
termed Husky is fine-tuned for high-quality multi-modal dialogue (impressing
ChatGPT-3.5-turbo with 93.89\% GPT-4 Quality). We hope this work can spark new
ideas and directions for future interactive visual systems. Welcome to watch
the code at https://github.com/OpenGVLab/InternGPT.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2305.05658v2' target='_blank'>TidyBot: Personalized Robot Assistance with Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jimmy Wu, Rika Antonova, Adam Kan, Marion Lepert, Andy Zeng, Shuran Song, Jeannette Bohg, Szymon Rusinkiewicz, Thomas Funkhouser</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-05-09 17:52:59</h6>
<p class='card-text'>For a robot to personalize physical assistance effectively, it must learn
user preferences that can be generally reapplied to future scenarios. In this
work, we investigate personalization of household cleanup with robots that can
tidy up rooms by picking up objects and putting them away. A key challenge is
determining the proper place to put each object, as people's preferences can
vary greatly depending on personal taste or cultural background. For instance,
one person may prefer storing shirts in the drawer, while another may prefer
them on the shelf. We aim to build systems that can learn such preferences from
just a handful of examples via prior interactions with a particular person. We
show that robots can combine language-based planning and perception with the
few-shot summarization capabilities of large language models (LLMs) to infer
generalized user preferences that are broadly applicable to future
interactions. This approach enables fast adaptation and achieves 91.2% accuracy
on unseen objects in our benchmark dataset. We also demonstrate our approach on
a real-world mobile manipulator called TidyBot, which successfully puts away
85.0% of objects in real-world test scenarios.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2305.05252v5' target='_blank'>Distilling Script Knowledge from Large Language Models for Constrained
  Language Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Siyu Yuan, Jiangjie Chen, Ziquan Fu, Xuyang Ge, Soham Shah, Charles Robert Jankowski, Yanghua Xiao, Deqing Yang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-05-09 08:19:32</h6>
<p class='card-text'>In everyday life, humans often plan their actions by following step-by-step
instructions in the form of goal-oriented scripts. Previous work has exploited
language models (LMs) to plan for abstract goals of stereotypical activities
(e.g., "make a cake"), but leaves more specific goals with multi-facet
constraints understudied (e.g., "make a cake for diabetics"). In this paper, we
define the task of constrained language planning for the first time. We propose
an overgenerate-then-filter approach to improve large language models (LLMs) on
this task, and use it to distill a novel constrained language planning dataset,
CoScript, which consists of 55,000 scripts. Empirical results demonstrate that
our method significantly improves the constrained language planning ability of
LLMs, especially on constraint faithfulness. Furthermore, CoScript is
demonstrated to be quite effective in endowing smaller LMs with constrained
language planning ability.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2305.04134v2' target='_blank'>Artificial Neuropsychology: Are Large Language Models Developing
  Executive Functions?</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hernan Ceferino Vazquez</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-05-06 20:53:22</h6>
<p class='card-text'>Artificial Intelligence (AI) has been rapidly advancing and has demonstrated
its ability to perform a wide range of cognitive tasks, including language
processing, visual recognition, and decision-making. Part of this progress is
due to LLMs (Large Language Models) like those of the GPT (Generative
Pre-Trained Transformers) family. These models are capable of exhibiting
behavior that can be perceived as intelligent. Most authors in Neuropsychology
consider intelligent behavior to depend on a number of overarching skills, or
Executive Functions (EFs), which rely on the correct functioning of neural
networks in the frontal lobes, and have developed a series of tests to evaluate
them. In this work, we raise the question of whether LLMs are developing
executive functions similar to those of humans as part of their learning, and
we evaluate the planning function and working memory of GPT using the popular
Towers of Hanoi method. Additionally, we introduce a new variant of the
classical method in order to avoid that the solutions are found in the LLM
training data (dataleakeage). Preliminary results show that LLMs generates
near-optimal solutions in Towers of Hanoi related tasks, adheres to task
constraints, and exhibits rapid planning capabilities and efficient working
memory usage, indicating a potential development of executive functions.
However, these abilities are quite limited and worse than well-trained humans
when the tasks are not known and are not part of the training data.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2305.04091v3' target='_blank'>Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning
  by Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan, Roy Ka-Wei Lee, Ee-Peng Lim</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-05-06 16:34:37</h6>
<p class='card-text'>Large language models (LLMs) have recently been shown to deliver impressive
performance in various NLP tasks. To tackle multi-step reasoning tasks,
few-shot chain-of-thought (CoT) prompting includes a few manually crafted
step-by-step reasoning demonstrations which enable LLMs to explicitly generate
reasoning steps and improve their reasoning task accuracy. To eliminate the
manual effort, Zero-shot-CoT concatenates the target problem statement with
"Let's think step by step" as an input prompt to LLMs. Despite the success of
Zero-shot-CoT, it still suffers from three pitfalls: calculation errors,
missing-step errors, and semantic misunderstanding errors. To address the
missing-step errors, we propose Plan-and-Solve (PS) Prompting. It consists of
two components: first, devising a plan to divide the entire task into smaller
subtasks, and then carrying out the subtasks according to the plan. To address
the calculation errors and improve the quality of generated reasoning steps, we
extend PS prompting with more detailed instructions and derive PS+ prompting.
We evaluate our proposed prompting strategy on ten datasets across three
reasoning problems. The experimental results over GPT-3 show that our proposed
zero-shot prompting consistently outperforms Zero-shot-CoT across all datasets
by a large margin, is comparable to or exceeds Zero-shot-Program-of-Thought
Prompting, and has comparable performance with 8-shot CoT prompting on the math
reasoning problem. The code can be found at
https://github.com/AGI-Edgerunners/Plan-and-Solve-Prompting.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2305.02412v2' target='_blank'>Plan, Eliminate, and Track -- Language Models are Good Teachers for
  Embodied Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yue Wu, So Yeon Min, Yonatan Bisk, Ruslan Salakhutdinov, Amos Azaria, Yuanzhi Li, Tom Mitchell, Shrimai Prabhumoye</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-05-03 20:11:22</h6>
<p class='card-text'>Pre-trained large language models (LLMs) capture procedural knowledge about
the world. Recent work has leveraged LLM's ability to generate abstract plans
to simplify challenging control tasks, either by action scoring, or action
modeling (fine-tuning). However, the transformer architecture inherits several
constraints that make it difficult for the LLM to directly serve as the agent:
e.g. limited input lengths, fine-tuning inefficiency, bias from pre-training,
and incompatibility with non-text environments. To maintain compatibility with
a low-level trainable actor, we propose to instead use the knowledge in LLMs to
simplify the control problem, rather than solving it. We propose the Plan,
Eliminate, and Track (PET) framework. The Plan module translates a task
description into a list of high-level sub-tasks. The Eliminate module masks out
irrelevant objects and receptacles from the observation for the current
sub-task. Finally, the Track module determines whether the agent has
accomplished each sub-task. On the AlfWorld instruction following benchmark,
the PET framework leads to a significant 15% improvement over SOTA for
generalization to human goal specifications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2305.01795v1' target='_blank'>Multimodal Procedural Planning via Dual Text-Image Prompting</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yujie Lu, Pan Lu, Zhiyu Chen, Wanrong Zhu, Xin Eric Wang, William Yang Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-05-02 21:46:44</h6>
<p class='card-text'>Embodied agents have achieved prominent performance in following human
instructions to complete tasks. However, the potential of providing
instructions informed by texts and images to assist humans in completing tasks
remains underexplored. To uncover this capability, we present the multimodal
procedural planning (MPP) task, in which models are given a high-level goal and
generate plans of paired text-image steps, providing more complementary and
informative guidance than unimodal plans. The key challenges of MPP are to
ensure the informativeness, temporal coherence,and accuracy of plans across
modalities. To tackle this, we propose Text-Image Prompting (TIP), a
dual-modality prompting method that jointly leverages zero-shot reasoning
ability in large language models (LLMs) and compelling text-to-image generation
ability from diffusion-based models. TIP improves the interaction in the dual
modalities using Text-to-Image Bridge and Image-to-Text Bridge, allowing LLMs
to guide the textual-grounded image plan generation and leveraging the
descriptions of image plans to ground the textual plan reversely. To address
the lack of relevant datasets, we collect WIKIPLAN and RECIPEPLAN as a testbed
for MPP. Our results show compelling human preferences and automatic scores
against unimodal and multimodal baselines on WIKIPLAN and RECIPEPLAN in terms
of informativeness, temporal coherence, and plan accuracy. Our code and data:
https://github.com/YujieLu10/MPP.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2304.14721v4' target='_blank'>Towards autonomous system: flexible modular production system enhanced
  with large language model agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuchen Xia, Manthan Shenoy, Nasser Jazdi, Michael Weyrich</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-04-28 09:42:18</h6>
<p class='card-text'>In this paper, we present a novel framework that combines large language
models (LLMs), digital twins and industrial automation system to enable
intelligent planning and control of production processes. We retrofit the
automation system for a modular production facility and create executable
control interfaces of fine-granular functionalities and coarse-granular skills.
Low-level functionalities are executed by automation components, and high-level
skills are performed by automation modules. Subsequently, a digital twin system
is developed, registering these interfaces and containing additional
descriptive information about the production system. Based on the retrofitted
automation system and the created digital twins, LLM-agents are designed to
interpret descriptive information in the digital twins and control the physical
system through service interfaces. These LLM-agents serve as intelligent agents
on different levels within an automation system, enabling autonomous planning
and control of flexible production. Given a task instruction as input, the
LLM-agents orchestrate a sequence of atomic functionalities and skills to
accomplish the task. We demonstrate how our implemented prototype can handle
un-predefined tasks, plan a production process, and execute the operations.
This research highlights the potential of integrating LLMs into industrial
automation systems in the context of smart factory for more agile, flexible,
and adaptive production processes, while it also underscores the critical
insights and limitations for future work. Demos at:
https://github.com/YuchenXia/GPT4IndustrialAutomation</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2304.11477v3' target='_blank'>LLM+P: Empowering Large Language Models with Optimal Planning
  Proficiency</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Bo Liu, Yuqian Jiang, Xiaohan Zhang, Qiang Liu, Shiqi Zhang, Joydeep Biswas, Peter Stone</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-04-22 20:34:03</h6>
<p class='card-text'>Large language models (LLMs) have demonstrated remarkable zero-shot
generalization abilities: state-of-the-art chatbots can provide plausible
answers to many common questions that arise in daily life. However, so far,
LLMs cannot reliably solve long-horizon planning problems. By contrast,
classical planners, once a problem is given in a formatted way, can use
efficient search algorithms to quickly identify correct, or even optimal,
plans. In an effort to get the best of both worlds, this paper introduces
LLM+P, the first framework that incorporates the strengths of classical
planners into LLMs. LLM+P takes in a natural language description of a planning
problem, then returns a correct (or optimal) plan for solving that problem in
natural language. LLM+P does so by first converting the language description
into a file written in the planning domain definition language (PDDL), then
leveraging classical planners to quickly find a solution, and then translating
the found solution back into natural language. Along with LLM+P, we define a
diverse set of different benchmark problems taken from common planning
scenarios. Via a comprehensive set of experiments on these benchmark problems,
we find that LLM+P is able to provide optimal solutions for most problems,
while LLMs fail to provide even feasible plans for most problems.\footnote{The
code and results are publicly available at
https://github.com/Cranial-XIX/llm-pddl.git.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2304.10464v4' target='_blank'>Learning to Plan with Natural Language</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yiduo Guo, Yaobo Liang, Chenfei Wu, Wenshan Wu, Dongyan Zhao, Nan Duan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-04-20 17:09:12</h6>
<p class='card-text'>Large Language Models (LLMs) have shown remarkable performance in various
basic natural language tasks. For completing the complex task, we still need a
plan for the task to guide LLMs to generate the specific solutions step by
step. LLMs can directly generate task plans, but these plans may still contain
factual errors or are incomplete. A high-quality task plan contains correct
step-by-step solutions for solving all situations and behavioral instructions
for avoiding mistakes. To obtain it, we propose the Learning to Plan method,
which involves two phases: (1) In the first learning task plan phase, it
iteratively updates the task plan with new step-by-step solutions and
behavioral instructions, which are obtained by prompting LLMs to derive from
training error feedback. (2) In the subsequent test phase, the LLM uses the
learned task plan to guide the inference of LLM on the test set. We demonstrate
the effectiveness of our method on the five different reasoning type tasks (8
datasets). Further, our analysis experiment shows that the task plan learned by
one LLM can directly guide another LLM to improve its performance, which
reveals a new transfer learning paradigm. We release the code at
\url{https://github.com/Eureka6174/LearnNLPlan}</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2304.09349v4' target='_blank'>LLM as A Robotic Brain: Unifying Egocentric Memory and Control</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jinjie Mai, Jun Chen, Bing Li, Guocheng Qian, Mohamed Elhoseiny, Bernard Ghanem</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-04-19 00:08:48</h6>
<p class='card-text'>Embodied AI focuses on the study and development of intelligent systems that
possess a physical or virtual embodiment (i.e. robots) and are able to
dynamically interact with their environment. Memory and control are the two
essential parts of an embodied system and usually require separate frameworks
to model each of them. In this paper, we propose a novel and generalizable
framework called LLM-Brain: using Large-scale Language Model as a robotic brain
to unify egocentric memory and control. The LLM-Brain framework integrates
multiple multimodal language models for robotic tasks, utilizing a zero-shot
learning approach. All components within LLM-Brain communicate using natural
language in closed-loop multi-round dialogues that encompass perception,
planning, control, and memory. The core of the system is an embodied LLM to
maintain egocentric memory and control the robot. We demonstrate LLM-Brain by
examining two downstream tasks: active exploration and embodied question
answering. The active exploration tasks require the robot to extensively
explore an unknown environment within a limited number of actions. Meanwhile,
the embodied question answering tasks necessitate that the robot answers
questions based on observations acquired during prior explorations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2304.09064v1' target='_blank'>LLM-based Interaction for Content Generation: A Case Study on the
  Perception of Employees in an IT department</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Alexandre Agossah, Frédérique Krupa, Matthieu Perreira Da Silva, Patrick Le Callet</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-04-18 15:35:43</h6>
<p class='card-text'>In the past years, AI has seen many advances in the field of NLP. This has
led to the emergence of LLMs, such as the now famous GPT-3.5, which
revolutionise the way humans can access or generate content. Current studies on
LLM-based generative tools are mainly interested in the performance of such
tools in generating relevant content (code, text or image). However, ethical
concerns related to the design and use of generative tools seem to be growing,
impacting the public acceptability for specific tasks. This paper presents a
questionnaire survey to identify the intention to use generative tools by
employees of an IT company in the context of their work. This survey is based
on empirical models measuring intention to use (TAM by Davis, 1989, and UTAUT2
by Venkatesh and al., 2008). Our results indicate a rather average
acceptability of generative tools, although the more useful the tool is
perceived to be, the higher the intention to use seems to be. Furthermore, our
analyses suggest that the frequency of use of generative tools is likely to be
a key factor in understanding how employees perceive these tools in the context
of their work. Following on from this work, we plan to investigate the nature
of the requests that may be made to these tools by specific audiences.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2304.08103v3' target='_blank'>Low-code LLM: Graphical User Interface over Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yuzhe Cai, Shaoguang Mao, Wenshan Wu, Zehua Wang, Yaobo Liang, Tao Ge, Chenfei Wu, Wang You, Ting Song, Yan Xia, Jonathan Tien, Nan Duan, Furu Wei</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-04-17 09:27:40</h6>
<p class='card-text'>Utilizing Large Language Models (LLMs) for complex tasks is challenging,
often involving a time-consuming and uncontrollable prompt engineering process.
This paper introduces a novel human-LLM interaction framework, Low-code LLM. It
incorporates six types of simple low-code visual programming interactions to
achieve more controllable and stable responses. Through visual interaction with
a graphical user interface, users can incorporate their ideas into the process
without writing trivial prompts. The proposed Low-code LLM framework consists
of a Planning LLM that designs a structured planning workflow for complex
tasks, which can be correspondingly edited and confirmed by users through
low-code visual programming operations, and an Executing LLM that generates
responses following the user-confirmed workflow. We highlight three advantages
of the low-code LLM: user-friendly interaction, controllable generation, and
wide applicability. We demonstrate its benefits using four typical
applications. By introducing this framework, we aim to bridge the gap between
humans and LLMs, enabling more effective and efficient utilization of LLMs for
complex tasks. The code, prompts, and experimental details are available at
https://github.com/moymix/TaskMatrix/tree/main/LowCodeLLM. A system
demonstration video can be found at
https://www.youtube.com/watch?v=jb2C1vaeO3E.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2304.07810v2' target='_blank'>VISAR: A Human-AI Argumentative Writing Assistant with Visual
  Programming and Rapid Draft Prototyping</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zheng Zhang, Jie Gao, Ranjodh Singh Dhaliwal, Toby Jia-Jun Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-04-16 15:29:03</h6>
<p class='card-text'>In argumentative writing, writers must brainstorm hierarchical writing goals,
ensure the persuasiveness of their arguments, and revise and organize their
plans through drafting. Recent advances in large language models (LLMs) have
made interactive text generation through a chat interface (e.g., ChatGPT)
possible. However, this approach often neglects implicit writing context and
user intent, lacks support for user control and autonomy, and provides limited
assistance for sensemaking and revising writing plans. To address these
challenges, we introduce VISAR, an AI-enabled writing assistant system designed
to help writers brainstorm and revise hierarchical goals within their writing
context, organize argument structures through synchronized text editing and
visual programming, and enhance persuasiveness with argumentation spark
recommendations. VISAR allows users to explore, experiment with, and validate
their writing plans using automatic draft prototyping. A controlled lab study
confirmed the usability and effectiveness of VISAR in facilitating the
argumentative writing planning process.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2304.08244v2' target='_blank'>API-Bank: A Comprehensive Benchmark for Tool-Augmented LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Minghao Li, Yingxiu Zhao, Bowen Yu, Feifan Song, Hangyu Li, Haiyang Yu, Zhoujun Li, Fei Huang, Yongbin Li</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-04-14 14:05:32</h6>
<p class='card-text'>Recent research has demonstrated that Large Language Models (LLMs) can
enhance their capabilities by utilizing external tools. However, three pivotal
questions remain unanswered: (1) How effective are current LLMs in utilizing
tools? (2) How can we enhance LLMs' ability to utilize tools? (3) What
obstacles need to be overcome to leverage tools? To address these questions, we
introduce API-Bank, a groundbreaking benchmark, specifically designed for
tool-augmented LLMs. For the first question, we develop a runnable evaluation
system consisting of 73 API tools. We annotate 314 tool-use dialogues with 753
API calls to assess the existing LLMs' capabilities in planning, retrieving,
and calling APIs. For the second question, we construct a comprehensive
training set containing 1,888 tool-use dialogues from 2,138 APIs spanning 1,000
distinct domains. Using this dataset, we train Lynx, a tool-augmented LLM
initialized from Alpaca. Experimental results demonstrate that GPT-3.5 exhibits
improved tool utilization compared to GPT-3, while GPT-4 excels in planning.
However, there is still significant potential for further improvement.
Moreover, Lynx surpasses Alpaca's tool utilization performance by more than 26
pts and approaches the effectiveness of GPT-3.5. Through error analysis, we
highlight the key challenges for future research in this field to answer the
third question.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2304.05376v5' target='_blank'>ChemCrow: Augmenting large-language models with chemistry tools</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Andres M Bran, Sam Cox, Oliver Schilter, Carlo Baldassari, Andrew D White, Philippe Schwaller</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-04-11 17:41:13</h6>
<p class='card-text'>Over the last decades, excellent computational chemistry tools have been
developed. Integrating them into a single platform with enhanced accessibility
could help reaching their full potential by overcoming steep learning curves.
Recently, large-language models (LLMs) have shown strong performance in tasks
across domains, but struggle with chemistry-related problems. Moreover, these
models lack access to external knowledge sources, limiting their usefulness in
scientific applications. In this study, we introduce ChemCrow, an LLM chemistry
agent designed to accomplish tasks across organic synthesis, drug discovery,
and materials design. By integrating 18 expert-designed tools, ChemCrow
augments the LLM performance in chemistry, and new capabilities emerge. Our
agent autonomously planned and executed the syntheses of an insect repellent,
three organocatalysts, and guided the discovery of a novel chromophore. Our
evaluation, including both LLM and expert assessments, demonstrates ChemCrow's
effectiveness in automating a diverse set of chemical tasks. Surprisingly, we
find that GPT-4 as an evaluator cannot distinguish between clearly wrong GPT-4
completions and Chemcrow's performance. Our work not only aids expert chemists
and lowers barriers for non-experts, but also fosters scientific advancement by
bridging the gap between experimental and computational chemistry.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2304.00472v3' target='_blank'>Querying Large Language Models with SQL</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Mohammed Saeed, Nicola De Cao, Paolo Papotti</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-04-02 06:58:14</h6>
<p class='card-text'>In many use-cases, information is stored in text but not available in
structured data. However, extracting data from natural language text to
precisely fit a schema, and thus enable querying, is a challenging task. With
the rise of pre-trained Large Language Models (LLMs), there is now an effective
solution to store and use information extracted from massive corpora of text
documents. Thus, we envision the use of SQL queries to cover a broad range of
data that is not captured by traditional databases by tapping the information
in LLMs. To ground this vision, we present Galois, a prototype based on a
traditional database architecture, but with new physical operators for querying
the underlying LLM. The main idea is to execute some operators of the the query
plan with prompts that retrieve data from the LLM. For a large class of SQL
queries, querying LLMs returns well structured relations, with encouraging
qualitative results. Preliminary experimental results make pre-trained LLMs a
promising addition to the field of database systems, introducing a new
direction for hybrid query processing. However, we pinpoint several research
challenges that must be addressed to build a DBMS that exploits LLMs. While
some of these challenges necessitate integrating concepts from the NLP
literature, others offer novel research avenues for the DB community.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2304.00121v1' target='_blank'>Decoding the End-to-end Writing Trajectory in Scholarly Manuscripts</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ryan Koo, Anna Martin, Linghe Wang, Dongyeop Kang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-03-31 20:33:03</h6>
<p class='card-text'>Scholarly writing presents a complex space that generally follows a
methodical procedure to plan and produce both rationally sound and creative
compositions. Recent works involving large language models (LLM) demonstrate
considerable success in text generation and revision tasks; however, LLMs still
struggle to provide structural and creative feedback on the document level that
is crucial to academic writing. In this paper, we introduce a novel taxonomy
that categorizes scholarly writing behaviors according to intention, writer
actions, and the information types of the written data. We also provide
ManuScript, an original dataset annotated with a simplified version of our
taxonomy to show writer actions and the intentions behind them. Motivated by
cognitive writing theory, our taxonomy for scientific papers includes three
levels of categorization in order to trace the general writing flow and
identify the distinct writer activities embedded within each higher-level
process. ManuScript intends to provide a complete picture of the scholarly
writing process by capturing the linearity and non-linearity of writing
trajectory, such that writing assistants can provide stronger feedback and
suggestions on an end-to-end level. The collected writing trajectories are
viewed at https://minnesotanlp.github.io/REWARD_demo/</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2303.17580v4' target='_blank'>HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging
  Face</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, Yueting Zhuang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-03-30 17:48:28</h6>
<p class='card-text'>Solving complicated AI tasks with different domains and modalities is a key
step toward artificial general intelligence. While there are numerous AI models
available for various domains and modalities, they cannot handle complicated AI
tasks autonomously. Considering large language models (LLMs) have exhibited
exceptional abilities in language understanding, generation, interaction, and
reasoning, we advocate that LLMs could act as a controller to manage existing
AI models to solve complicated AI tasks, with language serving as a generic
interface to empower this. Based on this philosophy, we present HuggingGPT, an
LLM-powered agent that leverages LLMs (e.g., ChatGPT) to connect various AI
models in machine learning communities (e.g., Hugging Face) to solve AI tasks.
Specifically, we use ChatGPT to conduct task planning when receiving a user
request, select models according to their function descriptions available in
Hugging Face, execute each subtask with the selected AI model, and summarize
the response according to the execution results. By leveraging the strong
language capability of ChatGPT and abundant AI models in Hugging Face,
HuggingGPT can tackle a wide range of sophisticated AI tasks spanning different
modalities and domains and achieve impressive results in language, vision,
speech, and other challenging tasks, which paves a new way towards the
realization of artificial general intelligence.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2303.17071v1' target='_blank'>DERA: Enhancing Large Language Model Completions with Dialog-Enabled
  Resolving Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Varun Nair, Elliot Schumacher, Geoffrey Tso, Anitha Kannan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-03-30 00:30:19</h6>
<p class='card-text'>Large language models (LLMs) have emerged as valuable tools for many natural
language understanding tasks. In safety-critical applications such as
healthcare, the utility of these models is governed by their ability to
generate outputs that are factually accurate and complete. In this work, we
present dialog-enabled resolving agents (DERA). DERA is a paradigm made
possible by the increased conversational abilities of LLMs, namely GPT-4. It
provides a simple, interpretable forum for models to communicate feedback and
iteratively improve output. We frame our dialog as a discussion between two
agent types - a Researcher, who processes information and identifies crucial
problem components, and a Decider, who has the autonomy to integrate the
Researcher's information and makes judgments on the final output.
  We test DERA against three clinically-focused tasks. For medical conversation
summarization and care plan generation, DERA shows significant improvement over
the base GPT-4 performance in both human expert preference evaluations and
quantitative metrics. In a new finding, we also show that GPT-4's performance
(70%) on an open-ended version of the MedQA question-answering (QA) dataset
(Jin et al. 2021, USMLE) is well above the passing level (60%), with DERA
showing similar performance. We release the open-ended MEDQA dataset at
https://github.com/curai/curai-research/tree/main/DERA.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2303.15125v1' target='_blank'>LMCanvas: Object-Oriented Interaction to Personalize Large Language
  Model-Powered Writing Environments</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Tae Soo Kim, Arghya Sarkar, Yoonjoo Lee, Minsuk Chang, Juho Kim</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-03-27 11:56:26</h6>
<p class='card-text'>Large language models (LLMs) can enhance writing by automating or supporting
specific tasks in writers' workflows (e.g., paraphrasing, creating analogies).
Leveraging this capability, a collection of interfaces have been developed that
provide LLM-powered tools for specific writing tasks. However, these interfaces
provide limited support for writers to create personal tools for their own
unique tasks, and may not comprehensively fulfill a writer's needs -- requiring
them to continuously switch between interfaces during writing. In this work, we
envision LMCanvas, an interface that enables writers to create their own
LLM-powered writing tools and arrange their personal writing environment by
interacting with "blocks" in a canvas. In this interface, users can create text
blocks to encapsulate writing and LLM prompts, model blocks for model parameter
configurations, and connect these to create pipeline blocks that output
generations. In this workshop paper, we discuss the design for LMCanvas and our
plans to develop this concept.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2303.14143v1' target='_blank'>"Get ready for a party": Exploring smarter smart spaces with help from
  large language models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Evan King, Haoxiang Yu, Sangsu Lee, Christine Julien</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-03-24 16:51:08</h6>
<p class='card-text'>The right response to someone who says "get ready for a party" is deeply
influenced by meaning and context. For a smart home assistant (e.g., Google
Home), the ideal response might be to survey the available devices in the home
and change their state to create a festive atmosphere. Current practical
systems cannot service such requests since they require the ability to (1)
infer meaning behind an abstract statement and (2) map that inference to a
concrete course of action appropriate for the context (e.g., changing the
settings of specific devices). In this paper, we leverage the observation that
recent task-agnostic large language models (LLMs) like GPT-3 embody a vast
amount of cross-domain, sometimes unpredictable contextual knowledge that
existing rule-based home assistant systems lack, which can make them powerful
tools for inferring user intent and generating appropriate context-dependent
responses during smart home interactions. We first explore the feasibility of a
system that places an LLM at the center of command inference and action
planning, showing that LLMs have the capacity to infer intent behind vague,
context-dependent commands like "get ready for a party" and respond with
concrete, machine-parseable instructions that can be used to control smart
devices. We furthermore demonstrate a proof-of-concept implementation that puts
an LLM in control of real devices, showing its ability to infer intent and
change device state appropriately with no fine-tuning or task-specific
training. Our work hints at the promise of LLM-driven systems for
context-awareness in smart environments, motivating future research in this
area.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2303.13466v2' target='_blank'>Mining Clinical Notes for Physical Rehabilitation Exercise Information:
  Natural Language Processing Algorithm Development and Validation Study</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sonish Sivarajkumar, Fengyi Gao, Parker E. Denny, Bayan M. Aldhahwani, Shyam Visweswaran, Allyn Bove, Yanshan Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-03-22 13:46:16</h6>
<p class='card-text'>Post-stroke patient rehabilitation requires precise, personalized treatment
plans. Natural Language Processing (NLP) offers potential to extract valuable
exercise information from clinical notes, aiding in the development of more
effective rehabilitation strategies. Objective: This study aims to develop and
evaluate a variety of NLP algorithms to extract and categorize physical
rehabilitation exercise information from the clinical notes of post-stroke
patients treated at the University of Pittsburgh Medical Center. A cohort of
13,605 patients diagnosed with stroke was identified, and their clinical notes
containing rehabilitation therapy notes were retrieved. A comprehensive
clinical ontology was created to represent various aspects of physical
rehabilitation exercises. State-of-the-art NLP algorithms were then developed
and compared, including rule-based, machine learning-based algorithms, and
large language model (LLM)-based algorithms (ChatGPT). Analysis was conducted
on a dataset comprising 23,724 notes with detailed demographic and clinical
characteristics. The rule-based NLP algorithm demonstrated superior performance
in most areas, particularly in detecting the 'Right Side' location with an F1
score of 0.975, outperforming Gradient Boosting by 0.063. Gradient Boosting
excelled in 'Lower Extremity' location detection (F1 score: 0.978), surpassing
rule-based NLP by 0.023. It also showed notable performance in 'Passive Range
of Motion' with an F1 score of 0.970, a 0.032 improvement over rule-based NLP.
The rule-based algorithm efficiently handled 'Duration', 'Sets', and 'Reps'
with F1 scores up to 0.65. LLM-based NLP, particularly ChatGPT with few-shot
prompts, achieved high recall but generally lower precision and F1 scores.
However, it notably excelled in 'Backward Plane' motion detection, achieving an
F1 score of 0.846, surpassing the rule-based algorithm's 0.720.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2304.02016v1' target='_blank'>The Multimodal And Modular Ai Chef: Complex Recipe Generation From
  Imagery</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:David Noever, Samantha Elizabeth Miller Noever</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-03-20 01:57:52</h6>
<p class='card-text'>The AI community has embraced multi-sensory or multi-modal approaches to
advance this generation of AI models to resemble expected intelligent
understanding. Combining language and imagery represents a familiar method for
specific tasks like image captioning or generation from descriptions. This
paper compares these monolithic approaches to a lightweight and specialized
method based on employing image models to label objects, then serially
submitting this resulting object list to a large language model (LLM). This use
of multiple Application Programming Interfaces (APIs) enables better than 95%
mean average precision for correct object lists, which serve as input to the
latest Open AI text generator (GPT-4). To demonstrate the API as a modular
alternative, we solve the problem of a user taking a picture of ingredients
available in a refrigerator, then generating novel recipe cards tailored to
complex constraints on cost, preparation time, dietary restrictions, portion
sizes, and multiple meal plans. The research concludes that monolithic
multimodal models currently lack the coherent memory to maintain context and
format for this task and that until recently, the language models like GPT-2/3
struggled to format similar problems without degenerating into repetitive or
non-sensical combinations of ingredients. For the first time, an AI chef or
cook seems not only possible but offers some enhanced capabilities to augment
human recipe libraries in pragmatic ways. The work generates a 100-page recipe
book featuring the thirty top ingredients using over 2000 refrigerator images
as initializing lists.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2303.08268v3' target='_blank'>Chat with the Environment: Interactive Multimodal Perception Using Large
  Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xufeng Zhao, Mengdi Li, Cornelius Weber, Muhammad Burhan Hafez, Stefan Wermter</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-03-14 23:01:27</h6>
<p class='card-text'>Programming robot behavior in a complex world faces challenges on multiple
levels, from dextrous low-level skills to high-level planning and reasoning.
Recent pre-trained Large Language Models (LLMs) have shown remarkable reasoning
ability in few-shot robotic planning. However, it remains challenging to ground
LLMs in multimodal sensory input and continuous action output, while enabling a
robot to interact with its environment and acquire novel information as its
policies unfold. We develop a robot interaction scenario with a partially
observable state, which necessitates a robot to decide on a range of epistemic
actions in order to sample sensory information among multiple modalities,
before being able to execute the task correctly. Matcha (Multimodal environment
chatting) agent, an interactive perception framework, is therefore proposed
with an LLM as its backbone, whose ability is exploited to instruct epistemic
actions and to reason over the resulting multimodal sensations (vision, sound,
haptics, proprioception), as well as to plan an entire task execution based on
the interactively acquired information. Our study demonstrates that LLMs can
provide high-level planning and reasoning skills and control interactive robot
behavior in a multimodal environment, while multimodal modules with the context
of the environmental state help ground the LLMs and extend their processing
ability. The project website can be found at https://matcha-agent.github.io.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2303.06689v4' target='_blank'>Self-planning Code Generation with Large Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xue Jiang, Yihong Dong, Lecheng Wang, Zheng Fang, Qiwei Shang, Ge Li, Zhi Jin, Wenpin Jiao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-03-12 15:36:03</h6>
<p class='card-text'>Although large language models (LLMs) have demonstrated impressive ability in
code generation, they are still struggling to address the complicated intent
provided by humans. It is widely acknowledged that humans typically employ
planning to decompose complex problems and schedule solution steps prior to
implementation. To this end, we introduce planning into code generation to help
the model understand complex intent and reduce the difficulty of
problem-solving. This paper proposes a self-planning code generation approach
with large language models, which consists of two phases, namely planning phase
and implementation phase. Specifically, in the planning phase, LLM plans out
concise solution steps from the intent combined with few-shot prompting.
Subsequently, in the implementation phase, the model generates code step by
step, guided by the preceding solution steps. We conduct extensive experiments
on various code-generation benchmarks across multiple programming languages.
Experimental results show that self-planning code generation achieves a
relative improvement of up to 25.4% in Pass@1 compared to direct code
generation, and up to 11.9% compared to Chain-of-Thought of code generation.
Moreover, our self-planning approach also enhances the quality of the generated
code with respect to correctness, readability, and robustness, as assessed by
humans.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2303.06247v4' target='_blank'>Task and Motion Planning with Large Language Models for Object
  Rearrangement</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yan Ding, Xiaohan Zhang, Chris Paxton, Shiqi Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-03-10 23:45:30</h6>
<p class='card-text'>Multi-object rearrangement is a crucial skill for service robots, and
commonsense reasoning is frequently needed in this process. However, achieving
commonsense arrangements requires knowledge about objects, which is hard to
transfer to robots. Large language models (LLMs) are one potential source of
this knowledge, but they do not naively capture information about plausible
physical arrangements of the world. We propose LLM-GROP, which uses prompting
to extract commonsense knowledge about semantically valid object configurations
from an LLM and instantiates them with a task and motion planner in order to
generalize to varying scene geometry. LLM-GROP allows us to go from
natural-language commands to human-aligned object rearrangement in varied
environments. Based on human evaluations, our approach achieves the highest
rating while outperforming competitive baselines in terms of success rate while
maintaining comparable cumulative action costs. Finally, we demonstrate a
practical implementation of LLM-GROP on a mobile manipulator in real-world
scenarios. Supplementary materials are available at:
https://sites.google.com/view/llm-grop</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2303.08006v2' target='_blank'>Data-Efficient Learning of Natural Language to Linear Temporal Logic
  Translators for Robot Task Specification</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiayi Pan, Glen Chou, Dmitry Berenson</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-03-09 00:09:58</h6>
<p class='card-text'>To make robots accessible to a broad audience, it is critical to endow them
with the ability to take universal modes of communication, like commands given
in natural language, and extract a concrete desired task specification, defined
using a formal language like linear temporal logic (LTL). In this paper, we
present a learning-based approach for translating from natural language
commands to LTL specifications with very limited human-labeled training data.
This is in stark contrast to existing natural-language to LTL translators,
which require large human-labeled datasets, often in the form of labeled pairs
of LTL formulas and natural language commands, to train the translator. To
reduce reliance on human data, our approach generates a large synthetic
training dataset through algorithmic generation of LTL formulas, conversion to
structured English, and then exploiting the paraphrasing capabilities of modern
large language models (LLMs) to synthesize a diverse corpus of natural language
commands corresponding to the LTL formulas. We use this generated data to
finetune an LLM and apply a constrained decoding procedure at inference time to
ensure the returned LTL formula is syntactically correct. We evaluate our
approach on three existing LTL/natural language datasets and show that we can
translate natural language commands at 75\% accuracy with far less human data
($\le$12 annotations). Moreover, when training on large human-annotated
datasets, our method achieves higher test accuracy (95\% on average) than prior
work. Finally, we show the translated formulas can be used to plan
long-horizon, multi-stage tasks on a 12D quadrotor.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2303.03548v2' target='_blank'>Large Language Models as Zero-Shot Human Models for Human-Robot
  Interaction</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Bowen Zhang, Harold Soh</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-03-06 23:16:24</h6>
<p class='card-text'>Human models play a crucial role in human-robot interaction (HRI), enabling
robots to consider the impact of their actions on people and plan their
behavior accordingly. However, crafting good human models is challenging;
capturing context-dependent human behavior requires significant prior knowledge
and/or large amounts of interaction data, both of which are difficult to
obtain. In this work, we explore the potential of large-language models (LLMs)
-- which have consumed vast amounts of human-generated text data -- to act as
zero-shot human models for HRI. Our experiments on three social datasets yield
promising results; the LLMs are able to achieve performance comparable to
purpose-built models. That said, we also discuss current limitations, such as
sensitivity to prompts and spatial/numerical reasoning mishaps. Based on our
findings, we demonstrate how LLM-based human models can be integrated into a
social robot's planning process and applied in HRI scenarios. Specifically, we
present one case study on a simulated trust-based table-clearing task and
replicate past results that relied on custom models. Next, we conduct a new
robot utensil-passing experiment (n = 65) where preliminary results show that
planning with a LLM-based human model can achieve gains over a basic myopic
plan. In summary, our results show that LLMs offer a promising (but incomplete)
approach to human modeling for HRI.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2303.00438v3' target='_blank'>A Framework for Neurosymbolic Robot Action Planning using Large Language
  Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Alessio Capitanelli, Fulvio Mastrogiovanni</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-03-01 11:54:22</h6>
<p class='card-text'>Symbolic task planning is a widely used approach to enforce robot autonomy
due to its ease of understanding and deployment in robot architectures.
However, techniques for symbolic task planning are difficult to scale in
real-world, human-robot collaboration scenarios because of the poor performance
in complex planning domains or when frequent re-planning is needed. We present
a framework, Teriyaki, specifically aimed at bridging the gap between symbolic
task planning and machine learning approaches. The rationale is training Large
Language Models (LLMs), namely GPT-3, into a neurosymbolic task planner
compatible with the Planning Domain Definition Language (PDDL), and then
leveraging its generative capabilities to overcome a number of limitations
inherent to symbolic task planners. Potential benefits include (i) a better
scalability in so far as the planning domain complexity increases, since LLMs'
response time linearly scales with the combined length of the input and the
output, and (ii) the ability to synthesize a plan action-by-action instead of
end-to-end, making each action available for execution as soon as it is
generated instead of waiting for the whole plan to be available, which in turn
enables concurrent planning and execution. Recently, significant efforts have
been devoted by the research community to evaluate the cognitive capabilities
of LLMs, with alternate successes. Instead, with Teriyaki we aim to provide an
overall planning performance comparable to traditional planners in specific
planning domains, while leveraging LLMs capabilities to build a look-ahead
predictive planning model. Preliminary results in selected domains show that
our method can: (i) solve 95.5% of problems in a test data set of 1,000
samples; (ii) produce plans up to 13.5% shorter than a traditional symbolic
planner; (iii) reduce average overall waiting times for a plan availability by
up to 61.4%</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2302.08081v1' target='_blank'>Exploring the Limits of ChatGPT for Query or Aspect-based Text
  Summarization</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xianjun Yang, Yan Li, Xinlu Zhang, Haifeng Chen, Wei Cheng</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-02-16 04:41:30</h6>
<p class='card-text'>Text summarization has been a crucial problem in natural language processing
(NLP) for several decades. It aims to condense lengthy documents into shorter
versions while retaining the most critical information. Various methods have
been proposed for text summarization, including extractive and abstractive
summarization. The emergence of large language models (LLMs) like GPT3 and
ChatGPT has recently created significant interest in using these models for
text summarization tasks. Recent studies \cite{goyal2022news,
zhang2023benchmarking} have shown that LLMs-generated news summaries are
already on par with humans. However, the performance of LLMs for more practical
applications like aspect or query-based summaries is underexplored. To fill
this gap, we conducted an evaluation of ChatGPT's performance on four widely
used benchmark datasets, encompassing diverse summaries from Reddit posts, news
articles, dialogue meetings, and stories. Our experiments reveal that ChatGPT's
performance is comparable to traditional fine-tuning methods in terms of Rouge
scores. Moreover, we highlight some unique differences between
ChatGPT-generated summaries and human references, providing valuable insights
into the superpower of ChatGPT for diverse text summarization tasks. Our
findings call for new directions in this area, and we plan to conduct further
research to systematically examine the characteristics of ChatGPT-generated
summaries through extensive human evaluation.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2302.06706v1' target='_blank'>On the Planning Abilities of Large Language Models (A Critical
  Investigation with a Proposed Benchmark)</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Karthik Valmeekam, Sarath Sreedharan, Matthew Marquez, Alberto Olmo, Subbarao Kambhampati</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-02-13 21:37:41</h6>
<p class='card-text'>Intrigued by the claims of emergent reasoning capabilities in LLMs trained on
general web corpora, in this paper, we set out to investigate their planning
capabilities. We aim to evaluate (1) how good LLMs are by themselves in
generating and validating simple plans in commonsense planning tasks (of the
type that humans are generally quite good at) and (2) how good LLMs are in
being a source of heuristic guidance for other agents--either AI planners or
human planners--in their planning tasks. To investigate these questions in a
systematic rather than anecdotal manner, we start by developing a benchmark
suite based on the kinds of domains employed in the International Planning
Competition. On this benchmark, we evaluate LLMs in three modes: autonomous,
heuristic and human-in-the-loop. Our results show that LLM's ability to
autonomously generate executable plans is quite meager, averaging only about 3%
success rate. The heuristic and human-in-the-loop modes show slightly more
promise. In addition to these results, we also make our benchmark and
evaluation tools available to support investigations by research community.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2302.05128v1' target='_blank'>Translating Natural Language to Planning Goals with Large-Language
  Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yaqi Xie, Chen Yu, Tongyao Zhu, Jinbin Bai, Ze Gong, Harold Soh</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-02-10 09:17:52</h6>
<p class='card-text'>Recent large language models (LLMs) have demonstrated remarkable performance
on a variety of natural language processing (NLP) tasks, leading to intense
excitement about their applicability across various domains. Unfortunately,
recent work has also shown that LLMs are unable to perform accurate reasoning
nor solve planning problems, which may limit their usefulness for
robotics-related tasks. In this work, our central question is whether LLMs are
able to translate goals specified in natural language to a structured planning
language. If so, LLM can act as a natural interface between the planner and
human users; the translated goal can be handed to domain-independent AI
planners that are very effective at planning. Our empirical results on GPT 3.5
variants show that LLMs are much better suited towards translation rather than
planning. We find that LLMs are able to leverage commonsense knowledge and
reasoning to furnish missing details from under-specified goals (as is often
the case in natural language). However, our experiments also reveal that LLMs
can fail to generate goals in tasks that involve numerical or physical (e.g.,
spatial) reasoning, and that LLMs are sensitive to the prompts used. As such,
these models are promising for translation to structured planning languages,
but care should be taken in their use.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2302.01560v3' target='_blank'>Describe, Explain, Plan and Select: Interactive Planning with Large
  Language Models Enables Open-World Multi-Task Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zihao Wang, Shaofei Cai, Guanzhou Chen, Anji Liu, Xiaojian Ma, Yitao Liang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-02-03 06:06:27</h6>
<p class='card-text'>We investigate the challenge of task planning for multi-task embodied agents
in open-world environments. Two main difficulties are identified: 1) executing
plans in an open-world environment (e.g., Minecraft) necessitates accurate and
multi-step reasoning due to the long-term nature of tasks, and 2) as vanilla
planners do not consider how easy the current agent can achieve a given
sub-task when ordering parallel sub-goals within a complicated plan, the
resulting plan could be inefficient or even infeasible. To this end, we propose
"$\underline{D}$escribe, $\underline{E}$xplain, $\underline{P}$lan and
$\underline{S}$elect" ($\textbf{DEPS}$), an interactive planning approach based
on Large Language Models (LLMs). DEPS facilitates better error correction on
initial LLM-generated $\textit{plan}$ by integrating $\textit{description}$ of
the plan execution process and providing self-$\textit{explanation}$ of
feedback when encountering failures during the extended planning phases.
Furthermore, it includes a goal $\textit{selector}$, which is a trainable
module that ranks parallel candidate sub-goals based on the estimated steps of
completion, consequently refining the initial plan. Our experiments mark the
milestone of the first zero-shot multi-task agent that can robustly accomplish
70+ Minecraft tasks and nearly double the overall performances. Further testing
reveals our method's general effectiveness in popularly adopted non-open-ended
domains as well (i.e., ALFWorld and tabletop manipulation). The ablation and
exploratory studies detail how our design beats the counterparts and provide a
promising update on the $\texttt{ObtainDiamond}$ grand challenge with our
approach. The code is released at https://github.com/CraftJarvis/MC-Planner.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2301.12050v2' target='_blank'>Do Embodied Agents Dream of Pixelated Sheep: Embodied Decision Making
  using Language Guided World Modelling</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kolby Nottingham, Prithviraj Ammanabrolu, Alane Suhr, Yejin Choi, Hannaneh Hajishirzi, Sameer Singh, Roy Fox</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-01-28 02:04:07</h6>
<p class='card-text'>Reinforcement learning (RL) agents typically learn tabula rasa, without prior
knowledge of the world. However, if initialized with knowledge of high-level
subgoals and transitions between subgoals, RL agents could utilize this
Abstract World Model (AWM) for planning and exploration. We propose using
few-shot large language models (LLMs) to hypothesize an AWM, that will be
verified through world experience, to improve sample efficiency of RL agents.
Our DECKARD agent applies LLM-guided exploration to item crafting in Minecraft
in two phases: (1) the Dream phase where the agent uses an LLM to decompose a
task into a sequence of subgoals, the hypothesized AWM; and (2) the Wake phase
where the agent learns a modular policy for each subgoal and verifies or
corrects the hypothesized AWM. Our method of hypothesizing an AWM with LLMs and
then verifying the AWM based on agent experience not only increases sample
efficiency over contemporary methods by an order of magnitude but is also
robust to and corrects errors in the LLM, successfully blending noisy
internet-scale information from LLMs with knowledge grounded in environment
dynamics.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2301.11845v2' target='_blank'>Learning the Effects of Physical Actions in a Multi-modal Environment</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Gautier Dagan, Frank Keller, Alex Lascarides</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-01-27 16:49:52</h6>
<p class='card-text'>Large Language Models (LLMs) handle physical commonsense information
inadequately. As a result of being trained in a disembodied setting, LLMs often
fail to predict an action's outcome in a given environment. However, predicting
the effects of an action before it is executed is crucial in planning, where
coherent sequences of actions are often needed to achieve a goal. Therefore, we
introduce the multi-modal task of predicting the outcomes of actions solely
from realistic sensory inputs (images and text). Next, we extend an LLM to
model latent representations of objects to better predict action outcomes in an
environment. We show that multi-modal models can capture physical commonsense
when augmented with visual information. Finally, we evaluate our model's
performance on novel actions and objects and find that combining modalities
help models to generalize and learn physical commonsense reasoning better.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2301.11564v2' target='_blank'>Learning 6-DoF Fine-grained Grasp Detection Based on Part Affordance
  Grounding</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yaoxian Song, Penglei Sun, Piaopiao Jin, Yi Ren, Yu Zheng, Zhixu Li, Xiaowen Chu, Yue Zhang, Tiefeng Li, Jason Gu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2023-01-27 07:00:54</h6>
<p class='card-text'>Robotic grasping is a fundamental ability for a robot to interact with the
environment. Current methods focus on how to obtain a stable and reliable
grasping pose in object level, while little work has been studied on part
(shape)-wise grasping which is related to fine-grained grasping and robotic
affordance. Parts can be seen as atomic elements to compose an object, which
contains rich semantic knowledge and a strong correlation with affordance.
However, lacking a large part-wise 3D robotic dataset limits the development of
part representation learning and downstream applications. In this paper, we
propose a new large Language-guided SHape grAsPing datasEt (named LangSHAPE) to
promote 3D part-level affordance and grasping ability learning. From the
perspective of robotic cognition, we design a two-stage fine-grained robotic
grasping framework (named LangPartGPD), including a novel 3D part language
grounding model and a part-aware grasp pose detection model, in which explicit
language input from human or large language models (LLMs) could guide a robot
to generate part-level 6-DoF grasping pose with textual explanation. Our method
combines the advantages of human-robot collaboration and LLMs' planning ability
using explicit language as a symbolic intermediate. To evaluate the
effectiveness of our proposed method, we perform 3D part grounding and
fine-grained grasp detection experiments on both simulation and physical robot
settings, following language instructions across different degrees of textual
complexity. Results show our method achieves competitive performance in 3D
geometry fine-grained grounding, object affordance inference, and 3D part-aware
grasping tasks. Our dataset and code are available on our project website
https://sites.google.com/view/lang-shape</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2212.10561v3' target='_blank'>Parsel: Algorithmic Reasoning with Language Models by Composing
  Decompositions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Eric Zelikman, Qian Huang, Gabriel Poesia, Noah D. Goodman, Nick Haber</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2022-12-20 18:59:23</h6>
<p class='card-text'>Despite recent success in large language model (LLM) reasoning, LLMs struggle
with hierarchical multi-step reasoning tasks like generating complex programs.
For these tasks, humans often start with a high-level algorithmic design and
implement each part gradually. We introduce Parsel, a framework enabling
automatic implementation and validation of complex algorithms with code LLMs.
With Parsel, we automatically decompose algorithmic tasks into hierarchical
natural language function descriptions and then search over combinations of
possible function implementations using tests. We show that Parsel can be used
across domains requiring hierarchical reasoning, including program synthesis
and robotic planning. We find that, using Parsel, LLMs solve more
competition-level problems in the APPS dataset, resulting in pass rates over
75\% higher than prior results from directly sampling AlphaCode and Codex,
while often using a smaller sample budget. Moreover, with automatically
generated tests, we find that Parsel can improve the state-of-the-art pass@1
performance on HumanEval from 67\% to 85\%. We also find that LLM-generated
robotic plans using Parsel are more than twice as likely to be considered
accurate than directly generated plans. Lastly, we explore how Parsel addresses
LLM limitations and discuss how Parsel may be useful for human programmers. We
release our code at https://github.com/ezelikman/parsel</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2212.08681v1' target='_blank'>Plansformer: Generating Symbolic Plans using Transformers</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Vishal Pallagani, Bharath Muppasani, Keerthiram Murugesan, Francesca Rossi, Lior Horesh, Biplav Srivastava, Francesco Fabiano, Andrea Loreggia</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2022-12-16 19:06:49</h6>
<p class='card-text'>Large Language Models (LLMs) have been the subject of active research,
significantly advancing the field of Natural Language Processing (NLP). From
BERT to BLOOM, LLMs have surpassed state-of-the-art results in various natural
language tasks such as question answering, summarization, and text generation.
Many ongoing efforts focus on understanding LLMs' capabilities, including their
knowledge of the world, syntax, and semantics. However, extending the textual
prowess of LLMs to symbolic reasoning has been slow and predominantly focused
on tackling problems related to the mathematical field. In this paper, we
explore the use of LLMs for automated planning - a branch of AI concerned with
the realization of action sequences (plans) to achieve a goal, typically
executed by intelligent agents, autonomous robots, and unmanned vehicles. We
introduce Plansformer; an LLM fine-tuned on planning problems and capable of
generating plans with favorable behavior in terms of correctness and length
with reduced knowledge-engineering efforts. We also demonstrate the
adaptability of Plansformer in solving different planning domains with varying
complexities, owing to the transfer learning abilities of LLMs. For one
configuration of Plansformer, we achieve ~97% valid plans, out of which ~95%
are optimal for Towers of Hanoi - a puzzle-solving domain.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2212.04088v3' target='_blank'>LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large
  Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chan Hee Song, Jiaman Wu, Clayton Washington, Brian M. Sadler, Wei-Lun Chao, Yu Su</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2022-12-08 05:46:32</h6>
<p class='card-text'>This study focuses on using large language models (LLMs) as a planner for
embodied agents that can follow natural language instructions to complete
complex tasks in a visually-perceived environment. The high data cost and poor
sample efficiency of existing methods hinders the development of versatile
agents that are capable of many tasks and can learn new tasks quickly. In this
work, we propose a novel method, LLM-Planner, that harnesses the power of large
language models to do few-shot planning for embodied agents. We further propose
a simple but effective way to enhance LLMs with physical grounding to generate
and update plans that are grounded in the current environment. Experiments on
the ALFRED dataset show that our method can achieve very competitive few-shot
performance: Despite using less than 0.5% of paired training data, LLM-Planner
achieves competitive performance with recent baselines that are trained using
the full training data. Existing methods can barely complete any task
successfully under the same few-shot setting. Our work opens the door for
developing versatile and sample-efficient embodied agents that can quickly
learn many tasks. Website: https://dki-lab.github.io/LLM-Planner</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2211.15533v1' target='_blank'>The Stack: 3 TB of permissively licensed source code</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Denis Kocetkov, Raymond Li, Loubna Ben Allal, Jia Li, Chenghao Mou, Carlos Muñoz Ferrandis, Yacine Jernite, Margaret Mitchell, Sean Hughes, Thomas Wolf, Dzmitry Bahdanau, Leandro von Werra, Harm de Vries</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2022-11-20 18:15:30</h6>
<p class='card-text'>Large Language Models (LLMs) play an ever-increasing role in the field of
Artificial Intelligence (AI)--not only for natural language processing but also
for code understanding and generation. To stimulate open and responsible
research on LLMs for code, we introduce The Stack, a 3.1 TB dataset consisting
of permissively licensed source code in 30 programming languages. We describe
how we collect the full dataset, construct a permissively licensed subset,
present a data governance plan, discuss limitations, and show promising results
on text2code benchmarks by training 350M-parameter decoders on different Python
subsets. We find that (1) near-deduplicating the data significantly boosts
performance across all experiments, and (2) it is possible to match previously
reported HumanEval and MBPP performance using only permissively licensed data.
We make the dataset available at https://hf.co/BigCode, provide a tool called
"Am I in The Stack" (https://hf.co/spaces/bigcode/in-the-stack) for developers
to search The Stack for copies of their code, and provide a process for code to
be removed from the dataset by following the instructions at
https://www.bigcode-project.org/docs/about/the-stack/.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2211.09935v3' target='_blank'>CAPE: Corrective Actions from Precondition Errors using Large Language
  Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shreyas Sundara Raman, Vanya Cohen, Ifrah Idrees, Eric Rosen, Ray Mooney, Stefanie Tellex, David Paulius</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2022-11-17 23:14:51</h6>
<p class='card-text'>Extracting commonsense knowledge from a large language model (LLM) offers a
path to designing intelligent robots. Existing approaches that leverage LLMs
for planning are unable to recover when an action fails and often resort to
retrying failed actions, without resolving the error's underlying cause. We
propose a novel approach (CAPE) that attempts to propose corrective actions to
resolve precondition errors during planning. CAPE improves the quality of
generated plans by leveraging few-shot reasoning from action preconditions. Our
approach enables embodied agents to execute more tasks than baseline methods
while ensuring semantic correctness and minimizing re-prompting. In
VirtualHome, CAPE generates executable plans while improving a human-annotated
plan correctness metric from 28.89% to 49.63% over SayCan. Our improvements
transfer to a Boston Dynamics Spot robot initialized with a set of skills
(specified in language) and associated preconditions, where CAPE improves the
correctness metric of the executed task plans by 76.49% compared to SayCan. Our
approach enables the robot to follow natural language commands and robustly
recover from failures, which baseline approaches largely cannot resolve or
address inefficiently.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2210.04964v2' target='_blank'>Generating Executable Action Plans with Environmentally-Aware Language
  Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Maitrey Gramopadhye, Daniel Szafir</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2022-10-10 18:56:57</h6>
<p class='card-text'>Large Language Models (LLMs) trained using massive text datasets have
recently shown promise in generating action plans for robotic agents from high
level text queries. However, these models typically do not consider the robot's
environment, resulting in generated plans that may not actually be executable,
due to ambiguities in the planned actions or environmental constraints. In this
paper, we propose an approach to generate environmentally-aware action plans
that agents are better able to execute. Our approach involves integrating
environmental objects and object relations as additional inputs into LLM action
plan generation to provide the system with an awareness of its surroundings,
resulting in plans where each generated action is mapped to objects present in
the scene. We also design a novel scoring function that, along with generating
the action steps and associating them with objects, helps the system
disambiguate among object instances and take into account their states. We
evaluated our approach using the VirtualHome simulator and the ActivityPrograms
knowledge base and found that action plans generated from our system had a 310%
improvement in executability and a 147% improvement in correctness over prior
work. The complete code and a demo of our method is publicly available at
https://github.com/hri-ironlab/scene_aware_language_planner.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2210.03629v3' target='_blank'>ReAct: Synergizing Reasoning and Acting in Language Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, Yuan Cao</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2022-10-06 01:00:32</h6>
<p class='card-text'>While large language models (LLMs) have demonstrated impressive capabilities
across tasks in language understanding and interactive decision making, their
abilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g.
action plan generation) have primarily been studied as separate topics. In this
paper, we explore the use of LLMs to generate both reasoning traces and
task-specific actions in an interleaved manner, allowing for greater synergy
between the two: reasoning traces help the model induce, track, and update
action plans as well as handle exceptions, while actions allow it to interface
with external sources, such as knowledge bases or environments, to gather
additional information. We apply our approach, named ReAct, to a diverse set of
language and decision making tasks and demonstrate its effectiveness over
state-of-the-art baselines, as well as improved human interpretability and
trustworthiness over methods without reasoning or acting components.
Concretely, on question answering (HotpotQA) and fact verification (Fever),
ReAct overcomes issues of hallucination and error propagation prevalent in
chain-of-thought reasoning by interacting with a simple Wikipedia API, and
generates human-like task-solving trajectories that are more interpretable than
baselines without reasoning traces. On two interactive decision making
benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and
reinforcement learning methods by an absolute success rate of 34% and 10%
respectively, while being prompted with only one or two in-context examples.
Project site with code: https://react-lm.github.io</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2210.01240v4' target='_blank'>Language Models Are Greedy Reasoners: A Systematic Formal Analysis of
  Chain-of-Thought</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Abulhair Saparov, He He</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2022-10-03 21:34:32</h6>
<p class='card-text'>Large language models (LLMs) have shown remarkable reasoning capabilities
given chain-of-thought prompts (examples with intermediate reasoning steps).
Existing benchmarks measure reasoning ability indirectly, by evaluating
accuracy on downstream tasks such as mathematical reasoning. However, it is
unclear how these models obtain the answers and whether they rely on simple
heuristics rather than the generated chain-of-thought. To enable systematic
exploration of the reasoning ability of LLMs, we present a new synthetic
question-answering dataset called PrOntoQA, where each example is generated
from a synthetic world model represented in first-order logic. This allows us
to parse the generated chain-of-thought into symbolic proofs for formal
analysis. Our analysis on InstructGPT and GPT-3 shows that LLMs are quite
capable of making correct individual deduction steps, and so are generally
capable of reasoning, even in fictional contexts. However, they have difficulty
with proof planning: When multiple valid deduction steps are available, they
are not able to systematically explore the different options.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2209.11302v1' target='_blank'>ProgPrompt: Generating Situated Robot Task Plans using Large Language
  Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Ishika Singh, Valts Blukis, Arsalan Mousavian, Ankit Goyal, Danfei Xu, Jonathan Tremblay, Dieter Fox, Jesse Thomason, Animesh Garg</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2022-09-22 20:29:49</h6>
<p class='card-text'>Task planning can require defining myriad domain knowledge about the world in
which a robot needs to act. To ameliorate that effort, large language models
(LLMs) can be used to score potential next actions during task planning, and
even generate action sequences directly, given an instruction in natural
language with no additional domain information. However, such methods either
require enumerating all possible next steps for scoring, or generate free-form
text that may contain actions not possible on a given robot in its current
context. We present a programmatic LLM prompt structure that enables plan
generation functional across situated environments, robot capabilities, and
tasks. Our key insight is to prompt the LLM with program-like specifications of
the available actions and objects in an environment, as well as with example
programs that can be executed. We make concrete recommendations about prompt
structure and generation constraints through ablation experiments, demonstrate
state of the art success rates in VirtualHome household tasks, and deploy our
method on a physical robot arm for tabletop tasks. Website at
progprompt.github.io</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2209.09874v2' target='_blank'>Open-vocabulary Queryable Scene Representations for Real World Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Boyuan Chen, Fei Xia, Brian Ichter, Kanishka Rao, Keerthana Gopalakrishnan, Michael S. Ryoo, Austin Stone, Daniel Kappler</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2022-09-20 17:29:56</h6>
<p class='card-text'>Large language models (LLMs) have unlocked new capabilities of task planning
from human instructions. However, prior attempts to apply LLMs to real-world
robotic tasks are limited by the lack of grounding in the surrounding scene. In
this paper, we develop NLMap, an open-vocabulary and queryable scene
representation to address this problem. NLMap serves as a framework to gather
and integrate contextual information into LLM planners, allowing them to see
and query available objects in the scene before generating a
context-conditioned plan. NLMap first establishes a natural language queryable
scene representation with Visual Language models (VLMs). An LLM based object
proposal module parses instructions and proposes involved objects to query the
scene representation for object availability and location. An LLM planner then
plans with such information about the scene. NLMap allows robots to operate
without a fixed list of objects nor executable options, enabling real robot
operation unachievable by previous methods. Project website:
https://nlmap-saycan.github.io</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2208.13266v3' target='_blank'>JARVIS: A Neuro-Symbolic Commonsense Reasoning Framework for
  Conversational Embodied Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kaizhi Zheng, Kaiwen Zhou, Jing Gu, Yue Fan, Jialu Wang, Zonglin Di, Xuehai He, Xin Eric Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2022-08-28 18:30:46</h6>
<p class='card-text'>Building a conversational embodied agent to execute real-life tasks has been
a long-standing yet quite challenging research goal, as it requires effective
human-agent communication, multi-modal understanding, long-range sequential
decision making, etc. Traditional symbolic methods have scaling and
generalization issues, while end-to-end deep learning models suffer from data
scarcity and high task complexity, and are often hard to explain. To benefit
from both worlds, we propose JARVIS, a neuro-symbolic commonsense reasoning
framework for modular, generalizable, and interpretable conversational embodied
agents. First, it acquires symbolic representations by prompting large language
models (LLMs) for language understanding and sub-goal planning, and by
constructing semantic maps from visual observations. Then the symbolic module
reasons for sub-goal planning and action generation based on task- and
action-level common sense. Extensive experiments on the TEACh dataset validate
the efficacy and efficiency of our JARVIS framework, which achieves
state-of-the-art (SOTA) results on all three dialog-based embodied tasks,
including Execution from Dialog History (EDH), Trajectory from Dialog (TfD),
and Two-Agent Task Completion (TATC) (e.g., our method boosts the unseen
Success Rate on EDH from 6.1\% to 15.8\%). Moreover, we systematically analyze
the essential factors that affect the task performance and also demonstrate the
superiority of our method in few-shot settings. Our JARVIS model ranks first in
the Alexa Prize SimBot Public Benchmark Challenge.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2207.05608v1' target='_blank'>Inner Monologue: Embodied Reasoning through Planning with Language
  Models</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wenlong Huang, Fei Xia, Ted Xiao, Harris Chan, Jacky Liang, Pete Florence, Andy Zeng, Jonathan Tompson, Igor Mordatch, Yevgen Chebotar, Pierre Sermanet, Noah Brown, Tomas Jackson, Linda Luu, Sergey Levine, Karol Hausman, Brian Ichter</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2022-07-12 15:20:48</h6>
<p class='card-text'>Recent works have shown how the reasoning capabilities of Large Language
Models (LLMs) can be applied to domains beyond natural language processing,
such as planning and interaction for robots. These embodied problems require an
agent to understand many semantic aspects of the world: the repertoire of
skills available, how these skills influence the world, and how changes to the
world map back to the language. LLMs planning in embodied environments need to
consider not just what skills to do, but also how and when to do them - answers
that change over time in response to the agent's own choices. In this work, we
investigate to what extent LLMs used in such embodied contexts can reason over
sources of feedback provided through natural language, without any additional
training. We propose that by leveraging environment feedback, LLMs are able to
form an inner monologue that allows them to more richly process and plan in
robotic control scenarios. We investigate a variety of sources of feedback,
such as success detection, scene description, and human interaction. We find
that closed-loop language feedback significantly improves high-level
instruction completion on three domains, including simulated and real table top
rearrangement tasks and long-horizon mobile manipulation tasks in a kitchen
environment in the real world.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2206.10498v4' target='_blank'>PlanBench: An Extensible Benchmark for Evaluating Large Language Models
  on Planning and Reasoning about Change</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Karthik Valmeekam, Matthew Marquez, Alberto Olmo, Sarath Sreedharan, Subbarao Kambhampati</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2022-06-21 16:15:27</h6>
<p class='card-text'>Generating plans of action, and reasoning about change have long been
considered a core competence of intelligent agents. It is thus no surprise that
evaluating the planning and reasoning capabilities of large language models
(LLMs) has become a hot topic of research. Most claims about LLM planning
capabilities are however based on common sense tasks-where it becomes hard to
tell whether LLMs are planning or merely retrieving from their vast world
knowledge. There is a strong need for systematic and extensible planning
benchmarks with sufficient diversity to evaluate whether LLMs have innate
planning capabilities. Motivated by this, we propose PlanBench, an extensible
benchmark suite based on the kinds of domains used in the automated planning
community, especially in the International Planning Competition, to test the
capabilities of LLMs in planning or reasoning about actions and change.
PlanBench provides sufficient diversity in both the task domains and the
specific planning capabilities. Our studies also show that on many critical
capabilities-including plan generation-LLM performance falls quite short, even
with the SOTA models. PlanBench can thus function as a useful marker of
progress of LLMs in planning and reasoning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2206.02928v6' target='_blank'>Neuro-Symbolic Procedural Planning with Commonsense Prompting</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yujie Lu, Weixi Feng, Wanrong Zhu, Wenda Xu, Xin Eric Wang, Miguel Eckstein, William Yang Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2022-06-06 22:09:52</h6>
<p class='card-text'>Procedural planning aims to implement complex high-level goals by
decomposition into sequential simpler low-level steps. Although procedural
planning is a basic skill set for humans in daily life, it remains a challenge
for large language models (LLMs) that lack a deep understanding of the
cause-effect relations in procedures. Previous methods require manual exemplars
to acquire procedural planning knowledge from LLMs in the zero-shot setting.
However, such elicited pre-trained knowledge in LLMs induces spurious
correlations between goals and steps, which impair the model generalization to
unseen tasks. In contrast, this paper proposes a neuro-symbolic procedural
PLANner (PLAN) that elicits procedural planning knowledge from the LLMs with
commonsense-infused prompting. To mitigate spurious goal-step correlations, we
use symbolic program executors on the latent procedural representations to
formalize prompts from commonsense knowledge bases as a causal intervention
toward the Structural Causal Model. Both automatic and human evaluations on
WikiHow and RobotHow show the superiority of PLAN on procedural planning
without further training or manual exemplars.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2205.10712v1' target='_blank'>Housekeep: Tidying Virtual Households using Commonsense Reasoning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yash Kant, Arun Ramachandran, Sriram Yenamandra, Igor Gilitschenski, Dhruv Batra, Andrew Szot, Harsh Agrawal</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2022-05-22 02:37:09</h6>
<p class='card-text'>We introduce Housekeep, a benchmark to evaluate commonsense reasoning in the
home for embodied AI. In Housekeep, an embodied agent must tidy a house by
rearranging misplaced objects without explicit instructions specifying which
objects need to be rearranged. Instead, the agent must learn from and is
evaluated against human preferences of which objects belong where in a tidy
house. Specifically, we collect a dataset of where humans typically place
objects in tidy and untidy houses constituting 1799 objects, 268 object
categories, 585 placements, and 105 rooms. Next, we propose a modular baseline
approach for Housekeep that integrates planning, exploration, and navigation.
It leverages a fine-tuned large language model (LLM) trained on an internet
text corpus for effective planning. We show that our baseline agent generalizes
to rearranging unseen objects in unknown environments. See our webpage for more
details: https://yashkant.github.io/housekeep/</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2205.05718v1' target='_blank'>Structured, flexible, and robust: benchmarking and improving large
  language models towards more human-like behavior in out-of-distribution
  reasoning tasks</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Katherine M. Collins, Catherine Wong, Jiahai Feng, Megan Wei, Joshua B. Tenenbaum</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2022-05-11 18:14:33</h6>
<p class='card-text'>Human language offers a powerful window into our thoughts -- we tell stories,
give explanations, and express our beliefs and goals through words. Abundant
evidence also suggests that language plays a developmental role in structuring
our learning. Here, we ask: how much of human-like thinking can be captured by
learning statistical patterns in language alone? We first contribute a new
challenge benchmark for comparing humans and distributional large language
models (LLMs). Our benchmark contains two problem-solving domains (planning and
explanation generation) and is designed to require generalization to new,
out-of-distribution problems expressed in language. We find that humans are far
more robust than LLMs on this benchmark. Next, we propose a hybrid
Parse-and-Solve model, which augments distributional LLMs with a structured
symbolic reasoning module. We find that this model shows more robust adaptation
to out-of-distribution planning problems, demonstrating the promise of hybrid
AI models for more human-like reasoning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2201.07207v2' target='_blank'>Language Models as Zero-Shot Planners: Extracting Actionable Knowledge
  for Embodied Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Wenlong Huang, Pieter Abbeel, Deepak Pathak, Igor Mordatch</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2022-01-18 18:59:45</h6>
<p class='card-text'>Can world knowledge learned by large language models (LLMs) be used to act in
interactive environments? In this paper, we investigate the possibility of
grounding high-level tasks, expressed in natural language (e.g. "make
breakfast"), to a chosen set of actionable steps (e.g. "open fridge"). While
prior work focused on learning from explicit step-by-step examples of how to
act, we surprisingly find that if pre-trained LMs are large enough and prompted
appropriately, they can effectively decompose high-level tasks into mid-level
plans without any further training. However, the plans produced naively by LLMs
often cannot map precisely to admissible actions. We propose a procedure that
conditions on existing demonstrations and semantically translates the plans to
admissible actions. Our evaluation in the recent VirtualHome environment shows
that the resulting method substantially improves executability over the LLM
baseline. The conducted human evaluation reveals a trade-off between
executability and correctness but shows a promising sign towards extracting
actionable knowledge from language models. Website at
https://huangwl18.github.io/language-planner</p>
</div>
</div>
</div>
</div>
</div>
<script src='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js'></script>
</body>
</html>