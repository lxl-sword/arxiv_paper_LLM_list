<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='UTF-8'>
<title>LLM-planning - 2025-03-02</title>
<link href='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css' rel='stylesheet'>
<link href='https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap' rel='stylesheet'>
<link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css'>
<style>
body {
font-family: 'Roboto', sans-serif;
background-color: #f5f7fa;
padding: 20px;
}
.card {
    border-radius: 10px;
    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
}
.card-title {
    font-weight: 700;
}
.card:hover {
    transform: scale(1.02);
    transition: 0.3s ease-in-out;
}
</style>
</head>
<body>
<div class='container'>
<h1 class='text-center my-4'><i class='fas fa-book'></i>LLM-planning - 2025-03-02</h1>
<div class='row'>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.20284v1' target='_blank'>Evaluating Human Trust in LLM-Based Planners: A Preliminary Study</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Shenghui Chen, Yunhao Yang, Kayla Boggess, Seongkook Heo, Lu Feng, Ufuk Topcu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-27 17:10:52</h6>
<p class='card-text'>Large Language Models (LLMs) are increasingly used for planning tasks,
offering unique capabilities not found in classical planners such as generating
explanations and iterative refinement. However, trust--a critical factor in the
adoption of planning systems--remains underexplored in the context of LLM-based
planning tasks. This study bridges this gap by comparing human trust in
LLM-based planners with classical planners through a user study in a Planning
Domain Definition Language (PDDL) domain. Combining subjective measures, such
as trust questionnaires, with objective metrics like evaluation accuracy, our
findings reveal that correctness is the primary driver of trust and
performance. Explanations provided by the LLM improved evaluation accuracy but
had limited impact on trust, while plan refinement showed potential for
increasing trust without significantly enhancing evaluation accuracy.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.20238v1' target='_blank'>FINEREASON: Evaluating and Improving LLMs' Deliberate Reasoning through
  Reflective Puzzle Solving</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Guizhen Chen, Weiwen Xu, Hao Zhang, Hou Pong Chan, Chaoqun Liu, Lidong Bing, Deli Zhao, Anh Tuan Luu, Yu Rong</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-27 16:23:25</h6>
<p class='card-text'>Many challenging reasoning tasks require not just rapid, intuitive responses,
but a more deliberate, multi-step approach. Recent progress in large language
models (LLMs) highlights an important shift from the "System 1" way of quick
reactions to the "System 2" style of reflection-and-correction problem solving.
However, current benchmarks heavily rely on the final-answer accuracy, leaving
much of a model's intermediate reasoning steps unexamined. This fails to assess
the model's ability to reflect and rectify mistakes within the reasoning
process. To bridge this gap, we introduce FINEREASON, a logic-puzzle benchmark
for fine-grained evaluation of LLMs' reasoning capabilities. Each puzzle can be
decomposed into atomic steps, making it ideal for rigorous validation of
intermediate correctness. Building on this, we introduce two tasks: state
checking, and state transition, for a comprehensive evaluation of how models
assess the current situation and plan the next move. To support broader
research, we also provide a puzzle training set aimed at enhancing performance
on general mathematical tasks. We show that models trained on our state
checking and transition data demonstrate gains in math reasoning by up to 5.1%
on GSM8K.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.20175v1' target='_blank'>An Extensive Evaluation of PDDL Capabilities in off-the-shelf LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Kaustubh Vyas, Damien Graux, Sébastien Montella, Pavlos Vougiouklis, Ruofei Lai, Keshuang Li, Yang Ren, Jeff Z. Pan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-27 15:13:07</h6>
<p class='card-text'>In recent advancements, large language models (LLMs) have exhibited
proficiency in code generation and chain-of-thought reasoning, laying the
groundwork for tackling automatic formal planning tasks. This study evaluates
the potential of LLMs to understand and generate Planning Domain Definition
Language (PDDL), an essential representation in artificial intelligence
planning. We conduct an extensive analysis across 20 distinct models spanning 7
major LLM families, both commercial and open-source. Our comprehensive
evaluation sheds light on the zero-shot LLM capabilities of parsing,
generating, and reasoning with PDDL. Our findings indicate that while some
models demonstrate notable effectiveness in handling PDDL, others pose
limitations in more complex scenarios requiring nuanced planning knowledge.
These results highlight the promise and current limitations of LLMs in formal
planning tasks, offering insights into their application and guiding future
efforts in AI-driven planning paradigms.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.19805v1' target='_blank'>Implicit Search via Discrete Diffusion: A Study on Chess</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiacheng Ye, Zhenyu Wu, Jiahui Gao, Zhiyong Wu, Xin Jiang, Zhenguo Li, Lingpeng Kong</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-27 06:25:15</h6>
<p class='card-text'>In the post-AlphaGo era, there has been a renewed interest in search
techniques such as Monte Carlo Tree Search (MCTS), particularly in their
application to Large Language Models (LLMs). This renewed attention is driven
by the recognition that current next-token prediction models often lack the
ability for long-term planning. Is it possible to instill search-like abilities
within the models to enhance their planning abilities without relying on
explicit search? We propose DiffuSearch , a model that does \textit{implicit
search} by looking into the future world via discrete diffusion modeling. We
instantiate DiffuSearch on a classical board game, Chess, where explicit search
is known to be essential. Through extensive controlled experiments, we show
DiffuSearch outperforms both the searchless and explicit search-enhanced
policies. Specifically, DiffuSearch outperforms the one-step policy by 19.2%
and the MCTS-enhanced policy by 14% on action accuracy. Furthermore,
DiffuSearch demonstrates a notable 30% enhancement in puzzle-solving abilities
compared to explicit search-based policies, along with a significant 540 Elo
increase in game-playing strength assessment. These results indicate that
implicit search via discrete diffusion is a viable alternative to explicit
search over a one-step policy. All codes are publicly available at
\href{https://github.com/HKUNLP/DiffuSearch}{https://github.com/HKUNLP/DiffuSearch}.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.19500v1' target='_blank'>Conversational Planning for Personal Plans</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Konstantina Christakopoulou, Iris Qu, John Canny, Andrew Goodridge, Cj Adams, Minmin Chen, Maja Matarić</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-26 19:04:26</h6>
<p class='card-text'>The language generation and reasoning capabilities of large language models
(LLMs) have enabled conversational systems with impressive performance in a
variety of tasks, from code generation, to composing essays, to passing STEM
and legal exams, to a new paradigm for knowledge search. Besides those
short-term use applications, LLMs are increasingly used to help with real-life
goals or tasks that take a long time to complete, involving multiple sessions
across days, weeks, months, or even years. Thus to enable conversational
systems for long term interactions and tasks, we need language-based agents
that can plan for long horizons. Traditionally, such capabilities were
addressed by reinforcement learning agents with hierarchical planning
capabilities. In this work, we explore a novel architecture where the LLM acts
as the meta-controller deciding the agent's next macro-action, and tool use
augmented LLM-based option policies execute the selected macro-action. We
instantiate this framework for a specific set of macro-actions enabling
adaptive planning for users' personal plans through conversation and follow-up
questions collecting user feedback. We show how this paradigm can be applicable
in scenarios ranging from tutoring for academic and non-academic tasks to
conversational coaching for personal health plans.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.19411v1' target='_blank'>Code to Think, Think to Code: A Survey on Code-Enhanced Reasoning and
  Reasoning-Driven Code Intelligence in LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Dayu Yang, Tianyang Liu, Daoan Zhang, Antoine Simoulin, Xiaoyi Liu, Yuwei Cao, Zhaopu Teng, Xin Qian, Grey Yang, Jiebo Luo, Julian McAuley</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-26 18:55:42</h6>
<p class='card-text'>In large language models (LLMs), code and reasoning reinforce each other:
code offers an abstract, modular, and logic-driven structure that supports
reasoning, while reasoning translates high-level goals into smaller, executable
steps that drive more advanced code intelligence. In this study, we examine how
code serves as a structured medium for enhancing reasoning: it provides
verifiable execution paths, enforces logical decomposition, and enables runtime
validation. We also explore how improvements in reasoning have transformed code
intelligence from basic completion to advanced capabilities, enabling models to
address complex software engineering tasks through planning and debugging.
Finally, we identify key challenges and propose future research directions to
strengthen this synergy, ultimately improving LLM's performance in both areas.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.19400v1' target='_blank'>TheoremExplainAgent: Towards Multimodal Explanations for LLM Theorem
  Understanding</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Max Ku, Thomas Chong, Jonathan Leung, Krish Shah, Alvin Yu, Wenhu Chen</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-26 18:50:09</h6>
<p class='card-text'>Understanding domain-specific theorems often requires more than just
text-based reasoning; effective communication through structured visual
explanations is crucial for deeper comprehension. While large language models
(LLMs) demonstrate strong performance in text-based theorem reasoning, their
ability to generate coherent and pedagogically meaningful visual explanations
remains an open challenge. In this work, we introduce TheoremExplainAgent, an
agentic approach for generating long-form theorem explanation videos (over 5
minutes) using Manim animations. To systematically evaluate multimodal theorem
explanations, we propose TheoremExplainBench, a benchmark covering 240 theorems
across multiple STEM disciplines, along with 5 automated evaluation metrics.
Our results reveal that agentic planning is essential for generating detailed
long-form videos, and the o3-mini agent achieves a success rate of 93.8% and an
overall score of 0.77. However, our quantitative and qualitative studies show
that most of the videos produced exhibit minor issues with visual element
layout. Furthermore, multimodal explanations expose deeper reasoning flaws that
text-based explanations fail to reveal, highlighting the importance of
multimodal explanations.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.19295v1' target='_blank'>Complex LLM Planning via Automated Heuristics Discovery</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Hongyi Ling, Shubham Parashar, Sambhav Khurana, Blake Olson, Anwesha Basu, Gaurangi Sinha, Zhengzhong Tu, James Caverlee, Shuiwang Ji</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-26 16:52:31</h6>
<p class='card-text'>We consider enhancing large language models (LLMs) for complex planning
tasks. While existing methods allow LLMs to explore intermediate steps to make
plans, they either depend on unreliable self-verification or external verifiers
to evaluate these steps, which demand significant data and computations. Here,
we propose automated heuristics discovery (AutoHD), a novel approach that
enables LLMs to explicitly generate heuristic functions to guide inference-time
search, allowing accurate evaluation of intermediate states. These heuristic
functions are further refined through a heuristic evolution process, improving
their robustness and effectiveness. Our proposed method requires no additional
model training or fine-tuning, and the explicit definition of heuristic
functions generated by the LLMs provides interpretability and insights into the
reasoning process. Extensive experiments across diverse benchmarks demonstrate
significant gains over multiple baselines, including nearly twice the accuracy
on some datasets, establishing our approach as a reliable and interpretable
solution for complex planning tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.19135v1' target='_blank'>A Temporal Planning Framework for Multi-Agent Systems via LLM-Aided
  Knowledge Base Management</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Enrico Saccon, Ahmet Tikna, Davide De Martini, Edoardo Lamon, Luigi Palopoli, Marco Roveri</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-26 13:51:28</h6>
<p class='card-text'>This paper presents a novel framework, called PLANTOR (PLanning with Natural
language for Task-Oriented Robots), that integrates Large Language Models
(LLMs) with Prolog-based knowledge management and planning for multi-robot
tasks. The system employs a two-phase generation of a robot-oriented knowledge
base, ensuring reusability and compositional reasoning, as well as a three-step
planning procedure that handles temporal dependencies, resource constraints,
and parallel task execution via mixed-integer linear programming. The final
plan is converted into a Behaviour Tree for direct use in ROS2. We tested the
framework in multi-robot assembly tasks within a block world and an
arch-building scenario. Results demonstrate that LLMs can produce accurate
knowledge bases with modest human feedback, while Prolog guarantees formal
correctness and explainability. This approach underscores the potential of LLM
integration for advanced robotics tasks requiring flexible, scalable, and
human-understandable planning.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.19103v1' target='_blank'>LongEval: A Comprehensive Analysis of Long-Text Generation Through a
  Plan-based Paradigm</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Siwei Wu, Yizhi Li, Xingwei Qu, Rishi Ravikumar, Yucheng Li, Tyler Loakman Shanghaoran Quan Xiaoyong Wei, Riza Batista-Navarro, Chenghua Lin</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-26 12:46:36</h6>
<p class='card-text'>Large Language Models (LLMs) have achieved remarkable success in various
natural language processing tasks, yet their ability to generate long-form
content remains poorly understood and evaluated. Our analysis reveals that
current LLMs struggle with length requirements and information density in
long-text generation, with performance deteriorating as text length increases.
To quantitively locate such a performance degradation and provide further
insights on model development, we present LongEval, a benchmark that evaluates
long-text generation through both direct and plan-based generation paradigms,
inspired by cognitive and linguistic writing models. The comprehensive
experiments in this work reveal interesting findings such as that while model
size correlates with generation ability, the small-scale model (e.g.,
LongWriter), well-trained on long texts, has comparable performance. All code
and datasets are released in https://github.com/Wusiwei0410/LongEval.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.18836v1' target='_blank'>REALM-Bench: A Real-World Planning Benchmark for LLMs and Multi-Agent
  Systems</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Longling Geng, Edward Y. Chang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-26 05:24:22</h6>
<p class='card-text'>This benchmark suite provides a comprehensive evaluation framework for
assessing both individual LLMs and multi-agent systems in real-world planning
scenarios. The suite encompasses eleven designed problems that progress from
basic to highly complex, incorporating key aspects such as multi-agent
coordination, inter-agent dependencies, and dynamic environmental disruptions.
Each problem can be scaled along three dimensions: the number of parallel
planning threads, the complexity of inter-dependencies, and the frequency of
unexpected disruptions requiring real-time adaptation. The benchmark includes
detailed specifications, evaluation metrics, and baseline implementations using
contemporary frameworks like LangGraph, enabling rigorous testing of both
single-agent and multi-agent planning capabilities. Through standardized
evaluation criteria and scalable complexity, this benchmark aims to drive
progress in developing more robust and adaptable AI planning systems for
real-world applications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.18822v1' target='_blank'>Data-Efficient Multi-Agent Spatial Planning with LLMs</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Huangyuan Su, Aaron Walsman, Daniel Garces, Sham Kakade, Stephanie Gil</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-26 04:53:07</h6>
<p class='card-text'>In this project, our goal is to determine how to leverage the world-knowledge
of pretrained large language models for efficient and robust learning in
multiagent decision making. We examine this in a taxi routing and assignment
problem where agents must decide how to best pick up passengers in order to
minimize overall waiting time. While this problem is situated on a graphical
road network, we show that with the proper prompting zero-shot performance is
quite strong on this task. Furthermore, with limited fine-tuning along with the
one-at-a-time rollout algorithm for look ahead, LLMs can out-compete existing
approaches with 50 times fewer environmental interactions. We also explore the
benefits of various linguistic prompting approaches and show that including
certain easy-to-compute information in the prompt significantly improves
performance. Finally, we highlight the LLM's built-in semantic understanding,
showing its ability to adapt to environmental factors through simple prompts.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.18712v1' target='_blank'>TrajLLM: A Modular LLM-Enhanced Agent-Based Framework for Realistic
  Human Trajectory Simulation</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Chenlu Ju, Jiaxin Liu, Shobhit Sinha, Hao Xue, Flora Salim</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-26 00:13:26</h6>
<p class='card-text'>This work leverages Large Language Models (LLMs) to simulate human mobility,
addressing challenges like high costs and privacy concerns in traditional
models. Our hierarchical framework integrates persona generation, activity
selection, and destination prediction, using real-world demographic and
psychological data to create realistic movement patterns. Both physical models
and language models are employed to explore and demonstrate different
methodologies for human mobility simulation. By structuring data with
summarization and weighted density metrics, the system ensures scalable memory
management while retaining actionable insights. Preliminary results indicate
that LLM-driven simulations align with observed real-world patterns, offering
scalable, interpretable insights for social problems such as urban planning,
traffic management, and public health. The framework's ability to dynamically
generate personas and activities enables it to provide adaptable and realistic
daily routines. This study demonstrates the transformative potential of LLMs in
advancing mobility modeling for societal and urban applications. The source
code and interactive demo for our framework are available at
https://github.com/cju0/TrajLLM.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.18690v1' target='_blank'>Hybrid Voting-Based Task Assignment in Role-Playing Games</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Daniel Weiner, Raj Korpan</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-25 22:58:21</h6>
<p class='card-text'>In role-playing games (RPGs), the level of immersion is critical-especially
when an in-game agent conveys tasks, hints, or ideas to the player. For an
agent to accurately interpret the player's emotional state and contextual
nuances, a foundational level of understanding is required, which can be
achieved using a Large Language Model (LLM). Maintaining the LLM's focus across
multiple context changes, however, necessitates a more robust approach, such as
integrating the LLM with a dedicated task allocation model to guide its
performance throughout gameplay. In response to this need, we introduce
Voting-Based Task Assignment (VBTA), a framework inspired by human reasoning in
task allocation and completion. VBTA assigns capability profiles to agents and
task descriptions to tasks, then generates a suitability matrix that quantifies
the alignment between an agent's abilities and a task's requirements.
Leveraging six distinct voting methods, a pre-trained LLM, and integrating
conflict-based search (CBS) for path planning, VBTA efficiently identifies and
assigns the most suitable agent to each task. While existing approaches focus
on generating individual aspects of gameplay, such as single quests, or combat
encounters, our method shows promise when generating both unique combat
encounters and narratives because of its generalizable nature.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.18641v1' target='_blank'>WhatELSE: Shaping Narrative Spaces at Configurable Level of Abstraction
  for AI-bridged Interactive Storytelling</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhuoran Lu, Qian Zhou, Yi Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-25 21:02:15</h6>
<p class='card-text'>Generative AI significantly enhances player agency in interactive narratives
(IN) by enabling just-in-time content generation that adapts to player actions.
While delegating generation to AI makes IN more interactive, it becomes
challenging for authors to control the space of possible narratives - within
which the final story experienced by the player emerges from their interaction
with AI. In this paper, we present WhatELSE, an AI-bridged IN authoring system
that creates narrative possibility spaces from example stories. WhatELSE
provides three views (narrative pivot, outline, and variants) to help authors
understand the narrative space and corresponding tools leveraging linguistic
abstraction to control the boundaries of the narrative space. Taking innovative
LLM-based narrative planning approaches, WhatELSE further unfolds the narrative
space into executable game events. Through a user study (N=12) and technical
evaluations, we found that WhatELSE enables authors to perceive and edit the
narrative space and generates engaging interactive narratives at play-time.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.18387v2' target='_blank'>How Far are LLMs from Real Search? A Comprehensive Study on Efficiency,
  Completeness, and Inherent Capabilities</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Minhua Lin, Hui Liu, Xianfeng Tang, Jingying Zeng, Zhenwei Dai, Chen Luo, Zheng Li, Xiang Zhang, Qi He, Suhang Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-25 17:30:40</h6>
<p class='card-text'>Search plays a fundamental role in problem-solving across various domains,
with most real-world decision-making problems being solvable through systematic
search. Drawing inspiration from recent discussions on search and learning, we
systematically explore the complementary relationship between search and Large
Language Models (LLMs) from three perspectives. First, we analyze how learning
can enhance search efficiency and propose Search via Learning (SeaL), a
framework that leverages LLMs for effective and efficient search. Second, we
further extend SeaL to SeaL-C to ensure rigorous completeness during search.
Our evaluation across three real-world planning tasks demonstrates that SeaL
achieves near-perfect accuracy while reducing search spaces by up to 99.1%
compared to traditional approaches. Finally, we explore how far LLMs are from
real search by investigating whether they can develop search capabilities
independently. Our analysis reveals that while current LLMs struggle with
efficient search in complex problems, incorporating systematic search
strategies significantly enhances their problem-solving capabilities. These
findings not only validate the effectiveness of our approach but also highlight
the need for improving LLMs' search abilities for real-world applications.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.18228v1' target='_blank'>Debt Collection Negotiations with Large Language Models: An Evaluation
  System and Optimizing Decision Making with Multi-Agent</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Xiaofeng Wang, Zhixin Zhang, Jinguang Zheng, Yiming Ai, Rui Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-25 14:13:03</h6>
<p class='card-text'>Debt collection negotiations (DCN) are vital for managing non-performing
loans (NPLs) and reducing creditor losses. Traditional methods are
labor-intensive, while large language models (LLMs) offer promising automation
potential. However, prior systems lacked dynamic negotiation and real-time
decision-making capabilities. This paper explores LLMs in automating DCN and
proposes a novel evaluation framework with 13 metrics across 4 aspects. Our
experiments reveal that LLMs tend to over-concede compared to human
negotiators. To address this, we propose the Multi-Agent Debt Negotiation
(MADeN) framework, incorporating planning and judging modules to improve
decision rationality. We also apply post-training techniques, including DPO
with rejection sampling, to optimize performance. Our studies provide valuable
insights for practitioners and researchers seeking to enhance efficiency and
outcomes in this domain.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.18139v1' target='_blank'>LevelRAG: Enhancing Retrieval-Augmented Generation with Multi-hop Logic
  Planning over Rewriting Augmented Searchers</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhuocheng Zhang, Yang Feng, Min Zhang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-25 12:09:16</h6>
<p class='card-text'>Retrieval-Augmented Generation (RAG) is a crucial method for mitigating
hallucinations in Large Language Models (LLMs) and integrating external
knowledge into their responses. Existing RAG methods typically employ query
rewriting to clarify the user intent and manage multi-hop logic, while using
hybrid retrieval to expand search scope. However, the tight coupling of query
rewriting to the dense retriever limits its compatibility with hybrid
retrieval, impeding further RAG performance improvements. To address this
challenge, we introduce a high-level searcher that decomposes complex queries
into atomic queries, independent of any retriever-specific optimizations.
Additionally, to harness the strengths of sparse retrievers for precise keyword
retrieval, we have developed a new sparse searcher that employs Lucene syntax
to enhance retrieval accuracy.Alongside web and dense searchers, these
components seamlessly collaborate within our proposed method,
\textbf{LevelRAG}. In LevelRAG, the high-level searcher orchestrates the
retrieval logic, while the low-level searchers (sparse, web, and dense) refine
the queries for optimal retrieval. This approach enhances both the completeness
and accuracy of the retrieval process, overcoming challenges associated with
current query rewriting techniques in hybrid retrieval scenarios. Empirical
experiments conducted on five datasets, encompassing both single-hop and
multi-hop question answering tasks, demonstrate the superior performance of
LevelRAG compared to existing RAG methods. Notably, LevelRAG outperforms the
state-of-the-art proprietary model, GPT4o, underscoring its effectiveness and
potential impact on the RAG field.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.18072v1' target='_blank'>MRBTP: Efficient Multi-Robot Behavior Tree Planning and Collaboration</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yishuai Cai, Xinglin Chen, Zhongxuan Cai, Yunxin Mao, Minglong Li, Wenjing Yang, Ji Wang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-25 10:39:28</h6>
<p class='card-text'>Multi-robot task planning and collaboration are critical challenges in
robotics. While Behavior Trees (BTs) have been established as a popular control
architecture and are plannable for a single robot, the development of effective
multi-robot BT planning algorithms remains challenging due to the complexity of
coordinating diverse action spaces. We propose the Multi-Robot Behavior Tree
Planning (MRBTP) algorithm, with theoretical guarantees of both soundness and
completeness. MRBTP features cross-tree expansion to coordinate heterogeneous
actions across different BTs to achieve the team's goal. For homogeneous
actions, we retain backup structures among BTs to ensure robustness and prevent
redundant execution through intention sharing. While MRBTP is capable of
generating BTs for both homogeneous and heterogeneous robot teams, its
efficiency can be further improved. We then propose an optional plugin for
MRBTP when Large Language Models (LLMs) are available to reason goal-related
actions for each robot. These relevant actions can be pre-planned to form
long-horizon subtrees, significantly enhancing the planning speed and
collaboration efficiency of MRBTP. We evaluate our algorithm in warehouse
management and everyday service scenarios. Results demonstrate MRBTP's
robustness and execution efficiency under varying settings, as well as the
ability of the pre-trained LLM to generate effective task-specific subtrees for
MRBTP.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.17910v1' target='_blank'>Scaling LLM Pre-training with Vocabulary Curriculum</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Fangyuan Yu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-25 07:18:29</h6>
<p class='card-text'>Modern language models rely on static vocabularies, fixed before pretraining,
in contrast to the adaptive vocabulary acquisition observed in human language
learning. To bridge this gap, we introduce vocabulary curriculum learning, an
approach that improves pretraining efficiency with log-linear scaling gains
relative to vocabulary size. Our method alternates between entropy-guided
vocabulary expansion and model optimization, enabling models to learn
transferable representations across diverse tokenization granularities. This
approach naturally gives rise to an optimal computation allocation pattern:
longer tokens capture predictable content, while shorter tokens focus on more
complex, harder-to-predict contexts. Experiments on small-scale GPT models
demonstrate improved scaling efficiency, reinforcing the effectiveness of
dynamic tokenization. We release our code to support further research and plan
to extend our experiments to larger models and diverse domains.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.17898v1' target='_blank'>VeriPlan: Integrating Formal Verification and LLMs into End-User
  Planning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Christine Lee, David Porfirio, Xinyu Jessica Wang, Kevin Zhao, Bilge Mutlu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-25 06:53:00</h6>
<p class='card-text'>Automated planning is traditionally the domain of experts, utilized in fields
like manufacturing and healthcare with the aid of expert planning tools. Recent
advancements in LLMs have made planning more accessible to everyday users due
to their potential to assist users with complex planning tasks. However, LLMs
face several application challenges within end-user planning, including
consistency, accuracy, and user trust issues. This paper introduces VeriPlan, a
system that applies formal verification techniques, specifically model
checking, to enhance the reliability and flexibility of LLMs for end-user
planning. In addition to the LLM planner, VeriPlan includes three additional
core features -- a rule translator, flexibility sliders, and a model checker --
that engage users in the verification process. Through a user study (n=12), we
evaluate VeriPlan, demonstrating improvements in the perceived quality,
usability, and user satisfaction of LLMs. Our work shows the effective
integration of formal verification and user-control features with LLMs for
end-user planning tasks.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.17132v1' target='_blank'>Applications of Large Models in Medicine</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:YunHe Su, Zhengyang Lu, Junhui Liu, Ke Pang, Haoran Dai, Sa Liu Yuxin Jia, Lujia Ge, Jing-min Yang</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-24 13:21:30</h6>
<p class='card-text'>This paper explores the advancements and applications of large-scale models
in the medical field, with a particular focus on Medical Large Models (MedLMs).
These models, encompassing Large Language Models (LLMs), Vision Models, 3D
Large Models, and Multimodal Models, are revolutionizing healthcare by
enhancing disease prediction, diagnostic assistance, personalized treatment
planning, and drug discovery. The integration of graph neural networks in
medical knowledge graphs and drug discovery highlights the potential of Large
Graph Models (LGMs) in understanding complex biomedical relationships. The
study also emphasizes the transformative role of Vision-Language Models (VLMs)
and 3D Large Models in medical image analysis, anatomical modeling, and
prosthetic design. Despite the challenges, these technologies are setting new
benchmarks in medical innovation, improving diagnostic accuracy, and paving the
way for personalized healthcare solutions. This paper aims to provide a
comprehensive overview of the current state and future directions of large
models in medicine, underscoring their significance in advancing global health.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.16804v1' target='_blank'>Multi-Agent Autonomous Driving Systems with Large Language Models: A
  Survey of Recent Advances</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Yaozu Wu, Dongyuan Li, Yankai Chen, Renhe Jiang, Henry Peng Zou, Liancheng Fang, Zhen Wang, Philip S. Yu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-24 03:26:13</h6>
<p class='card-text'>Autonomous Driving Systems (ADSs) are revolutionizing transportation by
reducing human intervention, improving operational efficiency, and enhancing
safety. Large Language Models (LLMs), known for their exceptional planning and
reasoning capabilities, have been integrated into ADSs to assist with driving
decision-making. However, LLM-based single-agent ADSs face three major
challenges: limited perception, insufficient collaboration, and high
computational demands. To address these issues, recent advancements in
LLM-based multi-agent ADSs have focused on improving inter-agent communication
and cooperation. This paper provides a frontier survey of LLM-based multi-agent
ADSs. We begin with a background introduction to related concepts, followed by
a categorization of existing LLM-based approaches based on different agent
interaction modes. We then discuss agent-human interactions in scenarios where
LLM-based agents engage with humans. Finally, we summarize key applications,
datasets, and challenges in this field to support future research
(https://anonymous.4open.science/r/LLM-based_Multi-agent_ADS-3A5C/README.md).</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.16730v1' target='_blank'>RapidPen: Fully Automated IP-to-Shell Penetration Testing with LLM-based
  Agents</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Sho Nakatani</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-23 21:57:46</h6>
<p class='card-text'>We present RapidPen, a fully automated penetration testing (pentesting)
framework that addresses
  the challenge of achieving an initial foothold (IP-to-Shell) without human
intervention. Unlike prior
  approaches that focus primarily on post-exploitation or require a
human-in-the-loop, RapidPen
  leverages large language models (LLMs) to autonomously discover and exploit
vulnerabilities, starting from
  a single IP address. By integrating advanced ReAct-style task planning (Re)
with retrieval-augmented
  knowledge bases of successful exploits, along with a command-generation and
direct execution feedback loop
  (Act), RapidPen systematically scans services, identifies viable attack
vectors, and executes targeted
  exploits in a fully automated manner.
  In our evaluation against a vulnerable target from the Hack The Box platform,
RapidPen achieved shell
  access within 200-400 seconds at a per-run cost of approximately \$0.3-\$0.6,
demonstrating a
  60\% success rate when reusing prior "success-case" data. These results
underscore the potential
  of truly autonomous pentesting for both security novices and seasoned
professionals. Organizations
  without dedicated security teams can leverage RapidPen to quickly identify
critical vulnerabilities,
  while expert pentesters can offload repetitive tasks and focus on complex
challenges.
  Ultimately, our work aims to make penetration testing more accessible and
cost-efficient,
  thereby enhancing the overall security posture of modern software ecosystems.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.16515v1' target='_blank'>Path Planning using Instruction-Guided Probabilistic Roadmaps</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Jiaqi Bao, Ryo Yonetani</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-23 09:26:20</h6>
<p class='card-text'>This work presents a novel data-driven path planning algorithm named
Instruction-Guided Probabilistic Roadmap (IG-PRM). Despite the recent
development and widespread use of mobile robot navigation, the safe and
effective travels of mobile robots still require significant engineering effort
to take into account the constraints of robots and their tasks. With IG-PRM, we
aim to address this problem by allowing robot operators to specify such
constraints through natural language instructions, such as ``aim for wider
paths'' or ``mind small gaps''. The key idea is to convert such instructions
into embedding vectors using large-language models (LLMs) and use the vectors
as a condition to predict instruction-guided cost maps from occupancy maps. By
constructing a roadmap based on the predicted costs, we can find
instruction-guided paths via the standard shortest path search. Experimental
results demonstrate the effectiveness of our approach on both synthetic and
real-world indoor navigation environments.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.16198v1' target='_blank'>An Autonomous Network Orchestration Framework Integrating Large Language
  Models with Continual Reinforcement Learning</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Masoud Shokrnezhad, Tarik Taleb</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-22 11:53:34</h6>
<p class='card-text'>6G networks aim to achieve global coverage, massive connectivity, and
ultra-stringent requirements. Space-Air-Ground Integrated Networks (SAGINs) and
Semantic Communication (SemCom) are essential for realizing these goals, yet
they introduce considerable complexity in resource orchestration. Drawing
inspiration from research in robotics, a viable solution to manage this
complexity is the application of Large Language Models (LLMs). Although the use
of LLMs in network orchestration has recently gained attention, existing
solutions have not sufficiently addressed LLM hallucinations or their
adaptation to network dynamics. To address this gap, this paper proposes a
framework called Autonomous Reinforcement Coordination (ARC) for a
SemCom-enabled SAGIN. This framework employs an LLM-based Retrieval-Augmented
Generator (RAG) monitors services, users, and resources and processes the
collected data, while a Hierarchical Action Planner (HAP) orchestrates
resources. ARC decomposes orchestration into two tiers, utilizing LLMs for
high-level planning and Reinforcement Learning (RL) agents for low-level
decision-making, in alignment with the Mixture of Experts (MoE) concept. The
LLMs utilize Chain-of-Thought (CoT) reasoning for few-shot learning, empowered
by contrastive learning, while the RL agents employ replay buffer management
for continual learning, thereby achieving efficiency, accuracy, and
adaptability. Simulations are provided to demonstrate the effectiveness of ARC,
along with a comprehensive discussion on potential future research directions
to enhance and upgrade ARC.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.15939v1' target='_blank'>"Kya family planning after marriage hoti hai?": Integrating Cultural
  Sensitivity in an LLM Chatbot for Reproductive Health</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Roshini Deva, Dhruv Ramani, Tanvi Divate, Suhani Jalota, Azra Ismail</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-21 21:08:50</h6>
<p class='card-text'>Access to sexual and reproductive health information remains a challenge in
many communities globally, due to cultural taboos and limited availability of
healthcare providers. Public health organizations are increasingly turning to
Large Language Models (LLMs) to improve access to timely and personalized
information. However, recent HCI scholarship indicates that significant
challenges remain in incorporating context awareness and mitigating bias in
LLMs. In this paper, we study the development of a culturally-appropriate
LLM-based chatbot for reproductive health with underserved women in urban
India. Through user interactions, focus groups, and interviews with multiple
stakeholders, we examine the chatbot's response to sensitive and highly
contextual queries on reproductive health. Our findings reveal strengths and
limitations of the system in capturing local context, and complexities around
what constitutes "culture". Finally, we discuss how local context might be
better integrated, and present a framework to inform the design of
culturally-sensitive chatbots for community health.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.15872v1' target='_blank'>MutaGReP: Execution-Free Repository-Grounded Plan Search for Code-Use</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zaid Khan, Ali Farhadi, Ranjay Krishna, Luca Weihs, Mohit Bansal, Tanmay Gupta</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-21 18:58:17</h6>
<p class='card-text'>When a human requests an LLM to complete a coding task using functionality
from a large code repository, how do we provide context from the repo to the
LLM? One approach is to add the entire repo to the LLM's context window.
However, most tasks involve only fraction of symbols from a repo, longer
contexts are detrimental to the LLM's reasoning abilities, and context windows
are not unlimited. Alternatively, we could emulate the human ability to
navigate a large repo, pick out the right functionality, and form a plan to
solve the task. We propose MutaGReP (Mutation-guided Grounded Repository Plan
Search), an approach to search for plans that decompose a user request into
natural language steps grounded in the codebase. MutaGReP performs neural tree
search in plan space, exploring by mutating plans and using a symbol retriever
for grounding. On the challenging LongCodeArena benchmark, our plans use less
than 5% of the 128K context window for GPT-4o but rival the coding performance
of GPT-4o with a context window filled with the repo. Plans produced by
MutaGReP allow Qwen 2.5 Coder 32B and 72B to match the performance of GPT-4o
with full repo context and enable progress on the hardest LongCodeArena tasks.
Project page: zaidkhan.me/MutaGReP</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.15676v1' target='_blank'>AutoToM: Automated Bayesian Inverse Planning and Model Discovery for
  Open-ended Theory of Mind</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Zhining Zhang, Chuanyang Jin, Mung Yao Jia, Tianmin Shu</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-21 18:57:52</h6>
<p class='card-text'>Theory of Mind (ToM), the ability to understand people's mental variables
based on their behavior, is key to developing socially intelligent agents.
Current approaches to Theory of Mind reasoning either rely on prompting Large
Language Models (LLMs), which are prone to systematic errors, or use rigid,
handcrafted Bayesian Theory of Mind (BToM) models, which are more robust but
cannot generalize across different domains. In this work, we introduce AutoToM,
an automated Bayesian Theory of Mind method for achieving open-ended machine
Theory of Mind. AutoToM can operate in any domain, infer any mental variable,
and conduct robust Theory of Mind reasoning of any order. Given a Theory of
Mind inference problem, AutoToM first proposes an initial BToM model. It then
conducts automated Bayesian inverse planning based on the proposed model,
leveraging an LLM as the backend. Based on the uncertainty of the inference, it
iteratively refines the model, by introducing additional mental variables
and/or incorporating more timesteps in the context. Empirical evaluations
across multiple Theory of Mind benchmarks demonstrate that AutoToM consistently
achieves state-of-the-art performance, offering a scalable, robust, and
interpretable approach to machine Theory of Mind.</p>
</div>
</div>
</div>
<div class='col-md-6 mb-4'>
<div class='card'>
<div class='card-body'>
<h4 class='card-title'><a href='http://arxiv.org/abs/2502.15332v1' target='_blank'>Detecting Future-related Contexts of Entity Mentions</a></h5>
<h5 class='card-subtitle mb-2 text-muted'>Authors:Puneet Prashar, Krishna Mohan Shukla, Adam Jatowt</h6>
<h6 class='card-subtitle mb-2 text-muted'>Date:2025-02-21 09:34:34</h6>
<p class='card-text'>The ability to automatically identify whether an entity is referenced in a
future context can have multiple applications including decision making,
planning and trend forecasting. This paper focuses on detecting implicit future
references in entity-centric texts, addressing the growing need for automated
temporal analysis in information processing. We first present a novel dataset
of 19,540 sentences built around popular entities sourced from Wikipedia, which
consists of future-related and non-future-related contexts in which those
entities appear. As a second contribution, we evaluate the performance of
several Language Models including also Large Language Models (LLMs) on the task
of distinguishing future-oriented content in the absence of explicit temporal
references.</p>
</div>
</div>
</div>
</div>
</div>
<script src='https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js'></script>
</body>
</html>